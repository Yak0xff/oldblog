{"title":"深入了解Core ML 3","uid":"04c112f33ade68949ca049cf167e7b66","slug":"2019-09-05-coreml-indepth-look","date":"2023-05-13T14:28:22.148Z","updated":"2023-05-13T14:28:22.148Z","comments":true,"path":"api/articles/2019-09-05-coreml-indepth-look.json","keywords":null,"cover":"/images/coreml-indepth/coreml-og.png","content":"<hr>\n<p>在之前的文章中，介绍过<a href=\"https://robinchao.github.io/2017/06/23/ios11-machine-learning.html\">iOS 11中的机器学习</a>，简单了解了伴随iOS 11发布的Core ML框架，以及简单的使用方式等，随后，<a href=\"https://robinchao.github.io/2017/10/07/coreml-inside.html\">Core ML 技术底层探秘</a>也揭开了点Core ML背后的技术和数据结构，对Core ML相对有了一个认识。随着<a href=\"https://robinchao.github.io/2018/08/28/coreml-vs-mlkit.html\">Core ML vs ML Kit：哪一个移动端机器学习框架更适合你？</a>，简单比较了两者的差异之后，尝试了<a href=\"https://robinchao.github.io/2019/01/22/keras-mnist-for-iOS.html\">从Keras开始构建iOS平台手写数字实时识别</a>的实现，以及学习了<a href=\"https://robinchao.github.io/2018/01/13/turi-create-intro.html\">Apple开源机器学习框架 Turi Create 简介与实践</a>，并使用Turi Create进行了人类行为识别任务的尝试，<a href=\"https://robinchao.github.io/2018/01/23/turi-create-activity-classifier.html\">如何使用Turi Create进行人类行为识别</a>，对Apple的机器学习架构有了基本的认识。经过两次大版本的迭代，目前Core ML 3 也随即推出，对比之前的版本，Core ML 3 可以说已经是一个<strong>完整的端测智能计算架构</strong>，其中也改变了很多实现方式和支持的协议类型等，这里将再次学习，以加深对Core ML的架构认识，并<code>探索其端测智能计算体的使用和可能的业务</code>等。</p>\n<hr>\n<p>通过<a href=\"https://developer.apple.com/videos/frameworks/machine-learning-and-vision\">WWDC 2019 Machine Learning and Vision</a>的介绍可以了解到，全新的Core ML 3 为iOS侧的机器学习增加了很多特性，其中称得上杀手锏的是<strong>端测训练</strong>模型的特性，以及支持更多先进的模型结构，由于增加了非常多的新的层类型，是的曾经无法执行的模型结构在端测使用也称为了可能。</p>\n<p><img src=\"/images/coreml-indepth/on-device-training.png\"></p>\n<p>这次的更新，是2017年Core ML推出以来最大的一次更新。新特性的Core ML配合Apple 的 A12 神经引擎芯片，Apple可谓在端测计算能力上提升了一大步，可想而知，未来苹果会在此方向在此提高和优化，构建完善的CoreML端测计算生态系统。</p>\n<p>这篇文章将在<a href=\"https://robinchao.github.io/2017/10/07/coreml-inside.html\">Core ML 技术底层探秘</a>的基础上，学习<code>mlmodel</code>格式的改变和新增的层类型等，而不会直接涉及<code>CoreML.framework</code>的API（事实上，除了增加了训练模型的API外，其他并没有变化）。</p>\n<p>由于Core ML所使用的模型目前都是由其他机器学习框架训练后，进行转换后来使用的，因此如果能够详细的了解Core ML所支持的类型，那么对于设计自己的机器学习模型，并能够顺利投入到Core ML中使用，是有一定的帮助的。</p>\n<h2 id=\"万变不离其宗-—-proto文件\"><a href=\"#万变不离其宗-—-proto文件\" class=\"headerlink\" title=\"万变不离其宗 — proto文件\"></a>万变不离其宗 — proto文件</h2><p>如果仅仅是查阅<a href=\"https://developer.apple.com/documentation/coreml\">CoreML.framework 的 API文档</a>，并不能找到相关的模型格式细节说明等，事实真相是，细节内容并不在API的文档中，而是在<a href=\"https://apple.github.io/coremltools/coremlspecification/\">Core ML的模型规格文档</a>里。</p>\n<p>该规范是由许多包含protobuf消息定义的**.proto**文件组成。Protobuf是Core ML的mlmodel文件使用的序列化格式，该序列化技术是目前较为常用的，TensorFlow和ONNX也同样使用该格式。关于proto文件的具体内容，可以在<a href=\"https://apple.github.io/coremltools/coremlspecification/\">Core ML的模型规格文档</a>中找到，如果你习惯阅读源码，也可以直接查看<a href=\"https://github.com/apple/coremltools/tree/master/mlmodel/format\">coremltools repo</a>，其中有目前支持的所有内容。</p>\n<p>在所有的proto文件中，主要的格式规格文件是<strong>Model.proto</strong>，该文件中定义了模型的种类，以及输入和输出的类型，另外还定义了已支持模型的不同类型等等。</p>\n<p>在该文件中，比较重要的属性还有<code>Model</code>类中的 <strong>specification version</strong>，该属性决定了模型的版本以及哪些函数在mlmodel文件中支持，那个操作系统能够运行模型等。</p>\n<p><img src=\"/images/coreml-indepth/spec-version.png\"></p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>目前官网还没有将<strong>specification version</strong>修改为最新的 <strong>4</strong>，上图是官网文件中的定义，可以预知到正式版推出后，<strong>specification version</strong>将是 <strong>4</strong>。</p></blockquote>\n<p>Core ML的模型规格版本号为 <strong>4</strong> 的情况下，只能运行在iOS 13 和macOS 10.15（Catalina）或更新的版本上。如果你需要运行在iOS 12或者iOS 11，需要剔除掉最新的特性。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>当使用coremltools进行模型转换的时候，coremltools将选择最低的可能规格版本对模型格式进行兼容。v3版本的模型能够运行在iOS 12上，v2版本的模型能够运行在iOS 11.2上，v1版本能够在iOS 11上运行，当然，如果你的模型使用了任何最新的特性，就只能运行在iOS 13及以后的系统中。</p></blockquote>\n<h2 id=\"新的模型类型\"><a href=\"#新的模型类型\" class=\"headerlink\" title=\"新的模型类型\"></a>新的模型类型</h2><p>Core ML始终支持以下模型类型（spec v1）：</p>\n<ul>\n<li><strong>Identity（映射）：</strong> 仅用于测试，将输入数据传递到输出；</li>\n<li><strong>GLM（广义线性）：</strong> 支持广义线性回归器和分类器；</li>\n<li><strong>SVM（支持向量机）：</strong> 支持支持向量机回归和分类，底层使用的是<a href=\"https://www.csie.ntu.edu.tw/~cjlin/libsvm/\">libsvm</a>；</li>\n<li><strong>Tree ensemble（决策树模型）：</strong> 支持回归和分类；</li>\n<li><strong>Neural networks（神经网络）：</strong> 支持回归、分类，以及一般目标的神经网络；</li>\n<li><strong>Pipeline models（管道模型）：</strong> 连接多个模型，形成一个机器学习工作流；</li>\n<li><strong>Feature engineering（特征工程）：</strong> 这里指的是支持特征工程的数学模型类型，例如<strong>One-Hot编码、缺失值处理、输入矢量化</strong>等，这些主要用于将scikit-learn模型转换为Core ML。该模型将变为一个管道，该管道连续具有多个这些特征工程模型。</li>\n</ul>\n<p>spec v2 仅仅是一个小小的更新，支持了<strong>16-bit</strong>浮点权重。开启之后，mlmodel文件将减小2倍，但是经过一些使用者反映，此优化并没有提高模型的运行耗时。</p>\n<p>在Core ML 2（spec v3）中，增加了如下的模型类型：</p>\n<ul>\n<li><strong>Bayesian probit regressor（贝叶斯概率回归）：</strong> 一种奇特的逻辑回归版本；</li>\n<li><strong>Non-maximum suppression（非极大值抑制）：</strong> 对目标检测任务的后期处理有用，通常位于Pipeline的最后一层；</li>\n<li><strong>VisionFeaturePrint（可视化特征描述）：</strong> 用于卷积神经网络，从图像中提取特征，输出规格是2048个元素的向量。也可用于图像的相似性检测等任务；</li>\n<li><strong>Create ML Support Models：</strong> 其他来自Create ML工具的模型类型，例如文本分类、词标注等；</li>\n<li><strong>Custom models（自定义模型）：</strong> 有时候，你可能有一个CoreML还不支持的模型类型，但是仍然希望将该模型与其他模型放在一起使用。自定义模型的功能允许开发者将模型参数和数据放置在mlmodel文件中，同时将自定义的逻辑放在应用程序中。</li>\n</ul>\n<p>spec v3 还增加了以减小mlmodel文件大小的<strong>权重量化</strong>功能以及灵活的输入大小，API层面增加了批处理预测，并为顺序数据提供了更好的支持。</p>\n<p>在Core ML 3（spec v4）中，增加了如下的模型类型：</p>\n<ul>\n<li><strong>k-Nearest Neighbors（k-NN，k近邻）：</strong> k-NN分类器；</li>\n<li><strong>ItemSimilarityRecommender（基于相似度的推荐器）：</strong> 可以使用该类型构建个性化推荐模型</li>\n<li><strong>SoundAnalysisPreprocessing（声音分析预处理）：</strong> 支持Create ML的声音分类模型。输入音频信号样本，并会转换为mel频谱图，可以在Pipeline中用做音频特征模型的输入；</li>\n<li><strong>Gazetteer：</strong> 支持Create ML的<code>MLGazetteer</code>模型，使用自然语言处理框架中的<code>NLTagger</code>。一个gazetteer是一个用于单词和短语的花式查找表；</li>\n<li><strong>WordEmbedding：</strong> 支持Create ML的新<code>MLWordEmbedding</code>模型，该模型是单词及其嵌入向量的字典。也用于自然语言框架；</li>\n<li><strong>Linked models：</strong> 对应用程序包中另一个mlmodel文件（编译版本，mlmodelc）的引用。这使得可以跨多个分类器重用昂贵的特征提取器 - 如果两个不同的管道使用相同的链接模型，则只会加载一次。</li>\n</ul>\n<p>目前，<code>Model</code>对象的属性中增加了<strong>isUpdatable</strong>属性，当该属性是<code>true</code>时，代表模型可以在端测进行训练，目前仅支持神经网络和k-NN模型。</p>\n<p><strong>k-NN模型</strong>是一个相对简单的机器学习模型，非常适合在端测进行训练，常见的方法是使用固定的神经网络，例如VisionFeaturePrint，从输入数据中提取特征，然后使用k-NN对这些特征向量进行分类。这样的模型在训练时很快，因为它只是记住了你输入的样本，并没有做任何实际的学习。</p>\n<p><strong>k-NN模型</strong>的一个缺点是，当记忆了非常多的样本时，预测就会变得很慢，但是在Core ML中，使用了一个k-NN的变种**<a href=\"https://zh.wikipedia.org/wiki/K-d%E6%A0%91\">K-D树</a>**。(下图是一个三维k-d树)</p>\n<p><img src=\"/images/coreml-indepth/3dtree.png\"></p>\n<h2 id=\"神经网络的更新\"><a href=\"#神经网络的更新\" class=\"headerlink\" title=\"神经网络的更新\"></a>神经网络的更新</h2><p>在Core ML 2的版本中，仅支持40中不同的神经网络层类型，Core ML 3中增加了超过100中层类型。但是并不是所有的都是新增，部分是对旧的层类型的改进，以支持或者更加适合处理柔性张量的处理等。</p>\n<p>在Core ML 2及之前的版本，流入神经网络的数据总是一个5等级的张量，也就是说每个张量都是由如下5个维度组成的：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">(sequence length, batch size, channels, height, width)</code></pre>\n\n<p>当神经网络的输入是图像的话，这个数据结构非常适合，但是对于其他数据结构就不那么适合了。</p>\n<p>例如，在处理一维向量的神经网络中，应该使用<code>channels</code>来描述向量的大小，并将其他维度设置为1，在这种情况下，输入的张量形状是<code>(1, batch size, number of elements, 1, 1)</code>。虽然这样的方式也可以解决问题，但是对于开发者来说，无意义的参数设置就是浪费时间，因此在Core ML 3中新增了很多新层来支持任意等级和形状的张量，使Core ML对于处理图像之外的数据也更适合。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>上面部分的描述均来自proto文件中的描述和解释的理解，在其他的文档中并不会去解释和说明这些内容，因此有兴趣的话，可以详细阅读下proto文件的内容，以加深理解。</p></blockquote>\n<p>在<a href=\"https://github.com/apple/coremltools/blob/master/mlmodel/format/NeuralNetwork.proto\">NeuralNetwork.proto</a>文件中，接近6000行的内容，对Core ML中神经网络的内容进行了描述和定义。</p>\n<p>其中，主对象是<strong>NeuralNetwork</strong>，还有另外两个变种<strong>NeuralNetworkClassifier</strong>和<strong>NeuralNetworkRegressor</strong>，不同的是，普通的神经网络输出的是MultiArray对象或者image，分类器输出的是包含类别和对应预测概率的字典，回归器输出的是一个数值。除了输出和响应的解释不同，但是这三种模型的工作方式是相同的。</p>\n<p><strong>NeuralNetwork</strong>对象含有一个层的列表，以及任何图像输入的预处理选项列表。Core ML 3 增加了一些描述的新特性：</p>\n<ul>\n<li>输入的MultiArray类型是如何转换为张量的。此时，开发者可以选择老的方式，创建一个秩为5的张量，或者使用新的方式。大多数情况下的输入类型都不是图像，因此这里将是常用的方法。</li>\n<li>输入的Image类型是如何转换为张量的。更换了老的秩为5的张量，开发者可以使用秩为4的张量，<code>(batch size, channels, height, width)</code>。这里去除了在图像处理中不需要的<code>sequence length</code>维度。</li>\n<li>训练模型的超参数。在<strong>NetworkUpdateParameters</strong>中描述。</li>\n</ul>\n<p>关于<strong>端测训练</strong>的能力，Core ML 3中也相应增加了一些支持的描述，具体如下：</p>\n<ul>\n<li><strong>isUpdatable</strong>位于<strong>Model</strong>对象中，表示模型是否可以被训练或再训练；</li>\n<li>在任何希望进行训练的层中，<strong>isUpdatable</strong>必须设置为<strong>true</strong>。使用该参数，开发者可以控制某些层的训练与否。目前，端测训练仅支持卷积层和全链接层；</li>\n<li><strong>WeightParams</strong>是训练时可学习的参数，只有在<strong>isUpdatable</strong>为<strong>true</strong>的时候会起效；</li>\n<li>在训练前，需要为模型定义一个训练输入，该输入将用于训练中损失函数的实际标签。</li>\n</ul>\n<p>另外，在<strong>NetworkUpdateParameters</strong>对象中，定义了模型训练的一些方法和参数等，具体描述如下：</p>\n<ul>\n<li><strong>lossLayers</strong>：指定使用那种损失函数，目前支持分类交叉熵和MSE（均方误差）。在mlmodel文件中，损失函数是另外的一层，含有两个属性，模型输出层名称和对应目标类别的训练输入名称。对于交叉熵损失函数，输入必须连接softmax输出层；</li>\n<li><strong>optimizer</strong>：目前支持SGD（随机梯度下降）和Adam（可替代SGD的一种一阶优化算法）；</li>\n<li><strong>epochs</strong>：模型训练的迭代次数。</li>\n<li><strong>shuffle</strong>：每次迭代时，数据是否需要随机重新排序；</li>\n<li><strong>seed</strong>：随机种子参数。</li>\n</ul>\n<h2 id=\"Core-ML-2-中的神经网络层\"><a href=\"#Core-ML-2-中的神经网络层\" class=\"headerlink\" title=\"Core ML 2 中的神经网络层\"></a>Core ML 2 中的神经网络层</h2><p> 对于神经网络来说，最有意思的还算各种神经网络层了，在Core ML第一个版本中，支持一下的神经网络层类型：</p>\n<ul>\n<li><strong>Convolution（卷积层）：</strong>仅支持2维度，但是可以设置内核宽度和高度为1来使用1维。同时支持空洞卷积或扩张卷积、分组卷积和反卷积；</li>\n<li><strong>Pooling（池化层）：</strong>支持max、average、L2，以及全局Pooling；</li>\n<li><strong>Fully-connected（全链接层）：</strong>也被称为内积层或密集层；</li>\n<li><strong>Activation functions（激活函数）：</strong>支持linear、ReLU、leaky ReLU、thresholded ReLU、PReLU、tanh、scaled tanh、sigmoid、hard sigmoid、ELU、softsign、softplus、parametric soft plus；</li>\n<li><strong>Batch normalization（批量标准化层）：</strong></li>\n<li><strong>Normalization（标准化层）：</strong>mean &amp; variance, L2 norm, and local response normalization (LRN)；</li>\n<li><strong>Softmax：</strong>在<strong>NeuralNetworkClassifier</strong>中的最后一层使用；</li>\n<li><strong>Padding（填充）：</strong>用于在图像张量的边缘周围添加额外的零填充。卷积和池化层已经可以自己处理填充，但是使用此层可以执行诸如反射或复制填充之类的操作；</li>\n<li><strong>Cropping（剪裁）：</strong>用于去除张量边缘周围的像素；</li>\n<li><strong>Upsampling（上采样）：</strong>最近邻或双线性上采样整数比例因子；</li>\n<li><strong>Unary operations（一元处理）：</strong>sqrt, 1&#x2F;sqrt, 1&#x2F;x, x^power, exp, log, abs, thresholding；</li>\n<li><strong>Tensors Element-wise operations（两个及以上张量元素操作）：</strong>add, multiply, average, maximum, minimum；</li>\n<li><strong>Tensor Element-wise operations（两单个张量元素操作）：</strong>乘以比例因子，增加偏差；</li>\n<li><strong>Reduction operations（降维）：</strong> sum, sum of natural logarithm, sum of squares, average, product, L1 norm, L2 norm, maximum, minimum, argmax；</li>\n<li><strong>Dot product（张量点积）：</strong>计算余弦相似度；</li>\n<li><strong>Reorganize（张量重组）：</strong> reshape, flatten, permute, space-to-depth, depth-to-space；</li>\n<li><strong>Concat, split, and slice（张量联合、分割、切片）：</strong>张量合并或扩张；</li>\n<li><strong>Recurrent neural network layers（递归神经网络层）：</strong>basic RNN, uni- and bi-directional LSTM, GRU (unidirectional only)；</li>\n<li><strong>Sequence repeat（序列复制）：</strong>多次复制给定的输入序列；</li>\n<li><strong>Embeddings</strong></li>\n<li><strong>Load constant（负载常数）：</strong>可以用于向一些其他层提供数据，例如对象检测模型中的锚定区。</li>\n</ul>\n<p>Apple在 Spec v2 中增加了对神经网络中自定义层的支持。这个补充，对更多模型的转换有了很大的帮助。</p>\n<p>在mlmodel文件中，自定义图层只是一个占位符，可能具有经过训练的权重和配置参数。在应用程序中，应该提供该层功能的Swift或Objective-C实现，并且可能还有一个Metal版本以及在GPU上运行它。 不幸的是，神经引擎目前不是自定义图层的选项，该功能也仅支持传统机器学习模型。</p>\n<p>例如，如果模型需要不在上面列表中的激活函数，则可以将其实现为自定义层。也可以通过巧妙地组合其他一些图层类型来完成此操作。例如，可以通过进行常规ReLU，然后将数据乘以-1，将阈值乘以-6，最后再乘以-1来制作ReLU6。这需要4个不同的层，但理论上，Core ML框架可以在运行时优化它。</p>\n<p>在Core ML 2（Spec v3）中，添加了以下图层类型：</p>\n<ul>\n<li><strong>Resize bilinear：</strong>与上采样层（仅接受整数比例因子）不同，这使您可以将双线性调整为任意图像大小；</li>\n<li><strong>Crop-resize：</strong>用于从张量中提取感兴趣的区域。这可以用于实现掩模R-CNN中使用的RoI Align层。</li>\n</ul>\n<p>在Core ML 3（Spec v4）放宽了对这些现有层类型的要求，除了添加了一大堆新层之外，Core ML 3还使现有的图层类型更加灵活。</p>\n<h2 id=\"新的神经网络层\"><a href=\"#新的神经网络层\" class=\"headerlink\" title=\"新的神经网络层\"></a>新的神经网络层</h2><p>上文提到，此次更新，新增了100多个层，下面会一一查看都有哪些层，更加详细的内容可参考<a href=\"https://github.com/apple/coremltools/blob/master/mlmodel/format/NeuralNetwork.proto\">NeuralNetwork.proto</a>描述文件。</p>\n<p>Core ML 3 为元素明确的一元操作添加以下层：</p>\n<ul>\n<li><strong>ClipLayer</strong>：夹在最大值和最小值；</li>\n<li><strong>CeilLayer、FloorLayer</strong>：对张量进行ceil和floor运算；</li>\n<li><strong>SignLayer</strong>：告知数字是正数，零数还是负数；</li>\n<li><strong>RoundLayer</strong>：将张量的值四舍五入为整数；</li>\n<li><strong>Exp2Layer</strong>：对张量元素进行2^x运算；</li>\n<li><strong>SinLayer, CosLayer, TanLayer, AsinLayer, AcosLayer, AtanLayer, SinhLayer, CoshLayer, TanhLayer, AsinhLayer, AcoshLayer, AtanhLayer</strong>：（双曲线）三角函数；</li>\n<li><strong>ErfLayer</strong>：计算高斯误差函数。</li>\n</ul>\n<p>这次和运算相关的增加，扩展了Core ML支持的数学原语的数量，与已有的数学函数不同，它们可以处理任何等级的张量。</p>\n<p>这里只有一个新的激活函数：</p>\n<ul>\n<li><strong>GeluLayer</strong>：高斯误差线性单元激活函数，精确的或使用tanh或S形近似。</li>\n</ul>\n<p>当然，也可以使用任何一元函数作为激活函数，或通过组合不同的数学层来创建一个。</p>\n<p>另外还增加了用于比较张量的新的层类型：</p>\n<ul>\n<li><strong>EqualLayer, NotEqualLayer, LessThanLayer, LessEqualLayer, GreaterThanLayer, GreaterEqualLayer</strong></li>\n<li><strong>LogicalOrLayer, LogicalXorLayer, LogicalNotLayer, LogicalAndLayer</strong></li>\n</ul>\n<p>当条件为真时，这些函数输出一个新的张量，其值为1，反之为0。这些图层类型支持广播，因此您可以比较不同等级的张量。您还可以将张量与（硬编码）标量值进行比较。</p>\n<p>这些图层类型有用的一个地方是使用新的控制流操作（见下文），以便您可以根据比较的结果进行分支，或者创建一个循环，该循环一直重复直到某个条件变为false。</p>\n<p>以前，在两个或更多张量之间有一些用于元素操作的图层。Core ML 3添加了一些新类型，从名称可以看出这些新增的更加灵活，因为它们完全支持NumPy风格：</p>\n<ul>\n<li><strong>AddBroadcastableLayer</strong>： 加法</li>\n<li><strong>SubtractBroadcastableLayer</strong>：减法</li>\n<li><strong>MultiplyBroadcastableLayer</strong>：乘法</li>\n<li><strong>DivideBroadcastableLayer</strong>：除法</li>\n<li><strong>FloorDivBroadcastableLayer</strong>：除法返回四舍五入的整数结果</li>\n<li><strong>ModBroadcastableLayer</strong>：除法余数</li>\n<li><strong>PowBroadcastableLayer</strong>：幂运算</li>\n<li><strong>MinBroadcastableLayer, MaxBroadcastableLayer</strong>：最大、最小</li>\n</ul>\n<p>在新的Core ML中，内置了大量的张量操作方法，而且不仅是图像，也可以通过一个或者多个维度的变换来进行张量缩小等。</p>\n<ul>\n<li><strong>ReduceSumLayer</strong>：计算指定维度的总和</li>\n<li><strong>ReduceSumSquareLayer</strong>：计算张量元素的平方和 </li>\n<li><strong>ReduceLogSumLayer</strong>：计算元素的自然对数之和</li>\n<li><strong>ReduceLogSumExpLayer</strong>：指定元素进行加和，再取自然对数</li>\n<li><strong>ReduceMeanLayer</strong>：计算元素的平均值</li>\n<li><strong>ReduceProdLayer</strong>：所有元素的乘积</li>\n<li><strong>ReduceL1Layer, ReduceL2Layer</strong>： L1、L2标准化</li>\n<li><strong>ReduceMaxLayer, ReduceMinLayer</strong>：寻找最大值、最小值</li>\n<li><strong>ArgMaxLayer, ArgMinLayer</strong>：最大值、最小值的索引</li>\n<li><strong>TopKLayer</strong>：找到k个顶部（或底部）值及其索引。</li>\n</ul>\n<p>关于数学的计算，Core ML 3还增加了如下的类型：</p>\n<ul>\n<li><strong>BatchedMatMulLayer</strong>：两个输入张量上的通用矩阵乘法，或单个输入张量和一组固定的权重（加上可选的偏差）。支持广播并可在进行乘法之前转置输入；</li>\n<li><strong>LayerNormalizationLayerParams</strong>：一个简单的归一化层，它减去β（例如均值）并除以γ（例如标准偏差），两者都作为固定权重提供。这与现有的MeanVarianceNormalizeLayer不同，后者执行相同的公式但实际上在推理时计算张量的均值和方差。</li>\n</ul>\n<p>许多其他现有操作已经扩展到使用任意大小的张量，也称为秩-N张量或N维张量。您可以通过名称中的“ND”识别此类图层类型：</p>\n<ul>\n<li><strong>SoftmaxNDLayer</strong></li>\n<li><strong>ConcatNDLayer</strong></li>\n<li><strong>SplitNDLayer</strong></li>\n<li><strong>TransposeLayerParams</strong></li>\n<li><strong>EmbeddingNDLayer</strong></li>\n<li><strong>LoadConstantNDLayerParams</strong></li>\n</ul>\n<p>Core ML 3为我们提供了两个新的切片层，支持在任何轴上切片：</p>\n<ul>\n<li><strong>SliceStaticLayer</strong></li>\n<li><strong>SliceDynamicLayer</strong></li>\n</ul>\n<p>静态基本上意味着“预先知道此操作的一切”，而动态意味着“此操作的参数可以在运行之间改变”。例如，图层的静态版本可能具有硬编码的outputShape属性，而动态版本每次都可以使用不同的输出形状。</p>\n<p>因为Core ML不再局限于基于静态图像的模型，而是现在还包含控制流和其他动态操作的方法，因此它必须能够以各种奇特的方式操纵张量。</p>\n<ul>\n<li><strong>GetShapeLayer</strong></li>\n<li><strong>BroadcastToStaticLayer, BroadcastToLikeLayer，BroadcastToDynamicLayer</strong></li>\n<li><strong>RangeStaticLayer, RangeDynamicLayer</strong></li>\n<li><strong>FillStaticLayer, FillLikeLayer, FillDynamicLayer</strong></li>\n</ul>\n<p>其中一些图层类型有三种不同的变体：Like，Static和Dynamic。</p>\n<ul>\n<li><strong>Static</strong>：该图层的所有属性都在mlmodel文件中进行了硬编码。</li>\n<li><strong>Like</strong>：需要一个额外的输入张量并输出一个与输入具有相同形状的新张量。</li>\n<li><strong>Dynamic</strong>：它还需要一个额外的输入张量，但这次它不是那个重要的形状，而是它的内容。</li>\n</ul>\n<p>Core ML 3还允许您通过随机分布采样创建新的张量：</p>\n<ul>\n<li><strong>RandomNormalStaticLayer, …LikeLayer, …DynamicLayer</strong></li>\n<li><strong>RandomUniformStaticLayer, …LikeLayer, …DynamicLayer</strong></li>\n<li><strong>RandomBernoulliStaticLayer, …LikeLayer, …DynamicLayer</strong></li>\n<li><strong>CategoricalDistributionLayer</strong></li>\n</ul>\n<p>另外的一些变体层：</p>\n<ul>\n<li><strong>SqueezeLayer</strong>：删除任何大小为1的维度</li>\n<li><strong>ExpandDimsLayer</strong>：和<strong>SqueezeLayer</strong>相反</li>\n<li><strong>FlattenTo2DLayer</strong>：将输入张量展平为二维矩阵</li>\n<li><strong>ReshapeStaticLayer, ReshapeLikeLayer, ReshapeDynamicLayer</strong></li>\n<li><strong>RankPreservingReshapeLayer</strong>：类似NumPy中的<strong>reshape(…, -1)</strong></li>\n</ul>\n<p>除了任意张量的连续和分割操作外，Core ML 3还增加了以下张量操作操作：</p>\n<ul>\n<li><strong>TileLayer</strong>：重复张量一定次数</li>\n<li><strong>StackLayer</strong>：沿着新轴连接张量</li>\n<li><strong>ReverseLayer</strong>：反转输入张量的一个或多个维度</li>\n<li><strong>ReverseSeqLayer</strong>：对于存储数据序列的张量，反转序列</li>\n<li><strong>SlidingWindowsLayer</strong>：在输入数据上滑动一个窗口，并在每一步返回一个带有窗口内容的新张量</li>\n</ul>\n<p>同样支持聚集和缩放：</p>\n<ul>\n<li><strong>GatherLayer, GatherNDLayer, GatherAlongAxisLayer</strong>：给定一组索引，只保留输入张量的那些索引</li>\n<li><strong>ScatterLayer, ScatterNDLayer, ScatterAlongAxisLayer</strong>：将一个张量的值复制到另一个张量中，但仅限于给定的索引。除了复制之外，还有其他累积模式：加，减，乘，除，最大和最小。</li>\n</ul>\n<p>除了能够选择层之外，还可以选择某些指定的层：</p>\n<ul>\n<li><strong>WhereNonZeroLayer</strong>：创建一个只有非零元素的新张量。您可以将此与张量比较中的掩码张量一起使用，例如LessThanLayer。</li>\n<li><strong>WhereBroadcastableLayer</strong>：采用三个输入张量，两个数据张量和一个包含（真）或零（假）的掩码。返回包含第一个数据张量或第二个数据张量元素的新张量，具体取决于掩码中的值是true还是false。</li>\n<li><strong>UpperTriangularLayer, LowerTriangularLayer</strong>：将对角线下方或上方的元素归零</li>\n<li><strong>MatrixBandPartLayer</strong>：将中心带外的元素归零</li>\n</ul>\n<p>目前，coremltools 3.0的Beta中还隐藏了一些新的图层类型：</p>\n<ul>\n<li><strong>ConstantPaddingLayer</strong>：在张量周围添加一定量的填充。与现有的填充图层不同，此图层适用于任何轴，而不仅仅是宽度和高度尺寸。</li>\n<li><strong>NonMaximumSuppressionLayer</strong>：已经有一个单独的模型类型用于在边界框上进行NMS，您可以在对象检测检测模型之后将其放入管道中，但现在也可以直接在神经网络内部进行NMS。</li>\n</ul>\n<p>在Core ML 3中还增加了控制流层，这些层是激动人心的，极大的提高了神经网络的结构适配广度：</p>\n<ul>\n<li><strong>BranchLayer</strong></li>\n<li><strong>LoopLayer</strong></li>\n<li><strong>LoopBreakLayer</strong></li>\n<li><strong>LoopContinueLayer</strong></li>\n<li><strong>CopyLayer</strong></li>\n</ul>\n<p>这些控制流相关的层，coremltools给出了使用样例，详细使用方式可以参考<a href=\"https://github.com/apple/coremltools/blob/master/examples/Neural_network_control_flow_power_iteration.ipynb\">Neural_network_control_flow_power_iteration.ipynb</a>。</p>\n<p>至此，Core ML 3中的新的内容基本罗列出来了，可以看到，在新的升级更新中，大多数都是针对层张量的创建、整形和操作，还有很多的数学运算能力的提升，但是通过这些操作，开发者已经可以通过定制、组合等来支持新的层类型，然后实现不同的AI任务等。Apple在一步一步地强化着Core ML的体系，以增强端测AI的能力，</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"https://github.com/apple/coremltools\">coremltools</a></li>\n<li><a href=\"https://developer.apple.com/documentation/coreml\">Core ML Documentation</a></li>\n<li><a href=\"https://machinethink.net/blog/new-in-coreml3/\">An in-depth look at Core ML 3</a></li>\n</ul>\n","text":" 在之前的文章中，介绍过iOS 11中的机器学习，简单了解了伴随iOS 11发布的Core ML框架，以及简单的使用方式等，随后，Core ML 技术底层探秘也揭开了点Core ML背后的技术和数据结构，对Core ML相对有了一个认识。随着Core ML vs ML Kit：哪...","link":"","photos":[],"count_time":{"symbolsCount":"11k","symbolsTime":"10 mins."},"categories":[{"name":"端测计算","slug":"端测计算","count":1,"path":"api/categories/端测计算.json"}],"tags":[{"name":"端测计算 CoreML","slug":"端测计算-CoreML","count":1,"path":"api/tags/端测计算-CoreML.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%87%E5%8F%98%E4%B8%8D%E7%A6%BB%E5%85%B6%E5%AE%97-%E2%80%94-proto%E6%96%87%E4%BB%B6\"><span class=\"toc-text\">万变不离其宗 — proto文件</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%96%B0%E7%9A%84%E6%A8%A1%E5%9E%8B%E7%B1%BB%E5%9E%8B\"><span class=\"toc-text\">新的模型类型</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%9B%B4%E6%96%B0\"><span class=\"toc-text\">神经网络的更新</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Core-ML-2-%E4%B8%AD%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%B1%82\"><span class=\"toc-text\">Core ML 2 中的神经网络层</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%96%B0%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%B1%82\"><span class=\"toc-text\">新的神经网络层</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99\"><span class=\"toc-text\">参考资料</span></a></li></ol>","author":{"slug":"undefined","avatar":"/img/avatar.jpg","link":"https://github.com/zycslog","description":"","socials":{}},"mapped":true,"prev_post":{"title":"或许是频繁切换git分支的救星--git worktree","uid":"af1206b3336cbf2448dc968e084c5e69","slug":"2022-06-24-git-worktree","date":"2023-05-13T14:28:22.152Z","updated":"2023-05-13T14:28:22.152Z","comments":true,"path":"api/articles/2022-06-24-git-worktree.json","keywords":null,"cover":"/images/cover/2022-06-24-git-worktree.jpg","text":"在实际的开发过程中，你是否也需要经常来回切换分支，如果是，那么这篇文章介绍的方法或者正合适你。 频繁切换分支的情况 场景1：协助同事 第一种场景是你正在自己的分支feature-my上做着功能的开发，这时候你的同事给你发信息说，帮忙看一个问题，分支是：feature-abc,通常...","link":"","photos":[],"count_time":{"symbolsCount":"3k","symbolsTime":"3 mins."},"categories":[{"name":"开发知识","slug":"开发知识","count":9,"path":"api/categories/开发知识.json"}],"tags":[{"name":"开发知识","slug":"开发知识","count":3,"path":"api/tags/开发知识.json"}],"author":{"slug":"undefined","avatar":"/img/avatar.jpg","link":"https://github.com/zycslog","description":"","socials":{}}},"next_post":{"title":"机器学习与移动应用开发的未来","uid":"cbe0c261ec14d11a436421cf64def38c","slug":"2019-09-07-machine-learning-feature","date":"2023-05-13T14:28:22.148Z","updated":"2023-05-13T14:28:22.148Z","comments":true,"path":"api/articles/2019-09-07-machine-learning-feature.json","keywords":null,"cover":"/images/MLFeature/cover.jpeg","text":"移动开发者可以从设备上的机器学习（on-device machine learning）所能提供的革命性变化中获益匪浅。这是因为该技术能够支持移动应用程序，即允许通过利用强大的功能来实现更流畅的用户体验，例如提供准确的基于地理位置的建议或即时检测植物疾病等。 移动机器学习（mob...","link":"","photos":[],"count_time":{"symbolsCount":"3.3k","symbolsTime":"3 mins."},"categories":[{"name":"机器学习","slug":"机器学习","count":10,"path":"api/categories/机器学习.json"}],"tags":[{"name":"机器学习","slug":"机器学习","count":7,"path":"api/tags/机器学习.json"}],"author":{"slug":"undefined","avatar":"/img/avatar.jpg","link":"https://github.com/zycslog","description":"","socials":{}}}}