[{"id":"e7521306a70b406b8e5f7047760055b6","title":"\\#5\\ Linked List && Swift Collection Protocol","content":"在Swift标准库（Swift standard library）中定义了很多协议或协议的集合，这些协议分别对应了特定的数据类型，每个协议都对所定义的数据类型有一些特性和性能方面的保证，而对于开发者而言，这些协议也是自定义数据结构和对现有数据类型进行扩展的基础准则。在这些协议的集合中，有四种关于集合的协议（collection protocols），分别是：\n\nTier 1, Sequence：序列类型是Swift中最为朴素的协议,仅仅定义了一系列类型相同的元素，而不对这一系列元素的性质有任何额外的约定。它唯一约定了的动作，就是从序列当前位置读取下一个元素。\nTier 2, Collection：集合类型是一种提供额外保证的序列类型。集合类型是有限的，允许重复的非破坏性顺序访问。\nTier 3, BidirectionalColllection：集合类型可以是双向集合类型，可以允许在序列中上下双向移动。 这对于链表是不可能的，因为你只能从头到尾，而不是相反。\nTier 4, RandomAccessCollection：如果它可以保证访问特定索引处的元素将花费与访问任何其他索引处的元素一样长的时间。该双向集合类型就是随机访问集合类型， 这对于链表来说是不可能的，因为访问列表前面附近的节点比列表下方的节点快得多。\n\n因此对于链表数据结构来说，Sequence和Collection两种协议是适用的。首先链表是一个序列型数据结构，适用Sequence协议，另外链表是有限序列，适用Collection协议。\n\n\n\n进化为Swift集合集合类型是有限序列，并提供非破坏性顺序访问。 Swift Collection还允许通过下标（subscript）进行访问, 使用索引可以映射到集合中的值。\n例如Swift中Array通过下标的方式访问元素：\narray[5]\n\n数组的下标一律是整数类型，例如上例中5。下标被包裹在方括号内。通过下标可以获取到集合对应未知的元素。\n自定义集合索引衡量Collection协议性能的指标是下标对应到值的速度。和其他数据类型（例如Swift的Array）不同，链表结构不能使用整数实现O(1)的下标操作。因此，自定义下标索引是对各自节点引用的索引。\n在上文#4\\ Linked List 的Swift实现的LinkedList.swift中，继续添加如下扩展程序，实现自定义索引的操作：\nextension LinkedList: Collection &#123;\n    &#x2F;&#x2F; 自定义链表索引\n    &#x2F;&#x2F; 由于索引是一个可比较的对象，需要继承Comparable协议\n    public struct Index: Comparable &#123;\n        public var node: Node&lt;Value&gt;?\n        \n        &#x2F;&#x2F; 自定义结构体不能进行&#x3D;&#x3D;操作, 需要自行实现\n        static public func &#x3D;&#x3D;(lhs: Index, rhs: Index) -&gt; Bool &#123;\n            &#x2F;&#x2F; 属于switch语句中使用元组\n            switch (lhs.node, rhs.node) &#123;\n            case let (left?, right?):\n                return left.next &#x3D;&#x3D;&#x3D; right.next\n            case (nil, nil):\n                return true\n            default:\n                return false\n            &#125;\n        &#125;\n        &#x2F;&#x2F; 第一个参数是否小于第二个参数\n        static public func &lt;(lhs: Index, rhs: Index) -&gt; Bool &#123;\n            guard lhs !&#x3D; rhs else &#123;\n                return false\n            &#125;\n            &#x2F;&#x2F; 从链表的一个节点移动到根节点\n            &#x2F;&#x2F; 这里使用Swift的内联序列函数sequence(first: next:)，类似repeat...while操作\n            let nodes &#x3D; sequence(first: lhs.node) &#123; \n                $0?.next \n            &#125;\n\n            return nodes.contains &#123; \n                $0 &#x3D;&#x3D;&#x3D; rhs.node \n            &#125;\n        &#125;\n    &#125;\n    \n    &#x2F;&#x2F; 链表的头节点索引\n    public var startIndex: Index &#123;\n        return Index(node: head)\n    &#125;\n    &#x2F;&#x2F; 链表的尾节点索引\n    &#x2F;&#x2F; 由于Collection协议的endIndex默认是序列最后可访问的值的索引，对于链表来说，需要制定tail节点的next\n    public var endIndex: Index &#123;\n        return Index(node: tail?.next)\n    &#125;\n    &#x2F;&#x2F; 索引是可以递增的，给定索引的下一个索引就是当前节点的next\n    public func index(after i: Index) -&gt; Index &#123;\n        return Index(node: i.node?.next)\n    &#125;\n    &#x2F;&#x2F; 用于将索引映射到集合中的值。由于已经创建了自定义索引，因此可以通过引用节点的值在恒定时间内轻松实现此目的。\n    public subscript(position: Index) -&gt; Value &#123;\n        return position.node!.value\n    &#125;\n&#125;\n\n回到主Playground，编写自定义索引功能的使用操作，如下：\nexample(of: &quot;using collection&quot;) &#123;\n    var list &#x3D; LinkedList&lt;Int&gt;()\n    \n    for i in 0 ... 9 &#123;\n        list.append(i)\n    &#125;\n    \n    print(&quot;List: \\(list)&quot;)\n    print(&quot;First element: \\(list[list.startIndex])&quot;)\n    print(&quot;Array containing first 3 elements: \\(Array(list.prefix(3)))&quot;)\n    print(&quot;Array containing last 3 elements: \\(Array(list.suffix(3)))&quot;)\n    \n    let sum &#x3D; list.reduce(0, +)\n    print(&quot;Sum of all values: \\(sum)&quot;)\n&#125;\n\n&#x2F;&#x2F; ---Example of using collection---\n&#x2F;&#x2F; List: 0 -&gt;1 -&gt;2 -&gt;3 -&gt;4 -&gt;5 -&gt;6 -&gt;7 -&gt;8 -&gt;9         \n&#x2F;&#x2F; First element: 0\n&#x2F;&#x2F; Array containing first 3 elements: [0, 1, 2]\n&#x2F;&#x2F; Array containing last 3 elements: [7, 8, 9]\n&#x2F;&#x2F; Sum of all values: 45\n\n值语义和写入时复制（copy-on-write）Swift Collection的另一个重要特性是它们具有值语义，通过写入时复制实现的，特此称为 COW。为了说明此概念，您将使用数组验证此行为。在Playground页面的底部编写以下内容：\nexample(of: &quot;array cow&quot;) &#123;\n    let array1 &#x3D; [1, 2]\n    var array2 &#x3D; array1\n    \n    print(&quot;array1: \\(array1)&quot;)\n    print(&quot;array2: \\(array2)&quot;)\n    \n    print(&quot;--- After adding 3 to array 2 ---&quot;)\n    array2.append(3)\n    print(&quot;array1: \\(array1)&quot;)\n    print(&quot;array2: \\(array2)&quot;)\n&#125;\n\n&#x2F;&#x2F; ---Example of array cow---\n&#x2F;&#x2F; array1: [1, 2]\n&#x2F;&#x2F; array2: [1, 2]\n&#x2F;&#x2F; --- After adding 3 to array 2 ---\n&#x2F;&#x2F; array1: [1, 2]\n&#x2F;&#x2F; array2: [1, 2, 3]\narray1是不可变的常量，就算将array1赋值给了变量array2，当array2的内容改变的时候，array1也不会改变，而此时有一个关键的地方是，array2在被赋值为array1的时候，并没有开辟新的存储空间，而是指向了array1的存储空间。当对array2进行append操作时，array2才对array1的内存空间进行了一个拷贝，然后添加了元素3。\n\n了解了值语义之后，来检查我们首先的Linked List是否也具有值语义的特性，在Playground中变下如下测试代码：\nexample(of: &quot;linked list cow test&quot;) &#123;\n    var list1 &#x3D; LinkedList&lt;Int&gt;()\n    list1.append(1)\n    list1.append(2)\n    \n    var list2 &#x3D; list1\n    \n    print(&quot;list1: \\(list1)&quot;)\n    print(&quot;list2: \\(list2)&quot;)\n    \n    print(&quot;--- After adding 3 to list 2 ---&quot;)\n    list2.append(3)\n    print(&quot;list1: \\(list1)&quot;)\n    print(&quot;list2: \\(list2)&quot;)\n&#125;\n\n&#x2F;&#x2F; ---Example of linked list cow test---\n&#x2F;&#x2F; list1: 1 -&gt;2 \n&#x2F;&#x2F; list2: 1 -&gt;2 \n&#x2F;&#x2F; --- After adding 3 to list 2 ---\n&#x2F;&#x2F; list1: 1 -&gt;2 -&gt;3  \n&#x2F;&#x2F; list2: 1 -&gt;2 -&gt;3\n\n可以看到，我们实现的LinkedList并不具有值语义的特性。因为我们在基础存储的时候使用了引用类型（Node），在Swift中，结构体应该是支持值语义的，因此关于LinkedList的实现，还需要进行优化，以支持值语义特性。\n使用COW实现值语义的特性相对较为简单。在更改链表的内容之前，需要对基础存储部分进行copy操作，同时将链表的所有引用（head、tail）更新到新的copy副本中。实现代码如下：\nprivate mutating func copyNodes() &#123;\n    guard var oldNode &#x3D; head else &#123;\n        return\n    &#125;\n        \n    head &#x3D; Node(value: oldNode.value)\n    var newNode &#x3D; head\n        \n    while let nextOfNode &#x3D; oldNode.next &#123;\n        newNode!.next &#x3D; Node(value: nextOfNode.value)\n        newNode &#x3D; newNode!.next\n            \n        oldNode &#x3D; nextOfNode\n    &#125;\n    tail &#x3D; newNode\n&#125;\n\n该操作是原有链表节点的值赋值给新建的节点，为链表的所有节点建立了一个新的副本。接下来需要修改LinkedList中的一些方法，增加copyNodes()方法的调用，以支持值语义特性。\n\npush\nappend\ninsert(after:)\npop\nremoveLast\nremove(after:)\n\n完整了上述方法的修改后，回到主Playground，进行值语义特性的再次测试，得到如下结果：\n&#x2F;&#x2F; ---Example of linked list cow test---\n&#x2F;&#x2F; list1: 1 -&gt;2 \n&#x2F;&#x2F; list2: 1 -&gt;2 \n&#x2F;&#x2F; --- After adding 3 to list 2 ---\n&#x2F;&#x2F; list1: 1 -&gt;2 \n&#x2F;&#x2F; list2: 1 -&gt;2 -&gt;3 \n\n得到的结果也符合值语义的特性，但是这里有一个问题，在加入了值语义特性后，在每一个支持mutating的方法中，都多了一个**O(n)**的copy操作，显得得不偿失。\nCOW的优化每一个支持mutating的方法中，都多了一个**O(n)**的copy操作，显然是不可接受的。接下来着手对其进行进一步的优化，有两种方式可以帮助解决这个问题。第一种便是当节点仅有一个拥有者的时候，避免进行复制。\nisKnownUniquelyReferenced在Swift的标准库中,有一个函数isKnownUniquelyReferenced,该函数可用于检查对象是否只有一个引用。使用该函数对上述实现进行测试，在上述值语义的测试代码中的var list2 = list1语句前后，添加检查：\nprint(&quot;List1 uniquely referenced: \\(isKnownUniquelyReferenced(&amp;list1.head))&quot;)\nvar list2 &#x3D; list1\nprint(&quot;List1 uniquely referenced: \\(isKnownUniquelyReferenced(&amp;list1.head))&quot;)\n\n执行后，打印结果如下：\nList1 uniquely referenced: true\nList1 uniquely referenced: false\n\n使用isKnownUniquelyReferenced能够检查node对象是否被共享。验证了此函数的功能后，删除上述打印语句，在**copyNodes()**函数中添加检查性代码：\nguard !isKnownUniquelyReferenced(&amp;head) else &#123;\n    return\n&#125;\n\n添加后，测试COW，打印结果：\n&#x2F;&#x2F; ---Example of linked list cow test---\n&#x2F;&#x2F; list1: 1 -&gt;2 \n&#x2F;&#x2F; list2: 1 -&gt;2 \n&#x2F;&#x2F; --- After adding 3 to list 2 ---\n&#x2F;&#x2F; list1: 1 -&gt;2 \n&#x2F;&#x2F; list2: 1 -&gt;2 -&gt;3 \n\n可以看到值语义特性依然运行良好。通过这个优化，LinkedList的性能将借助COW的特性恢复到之前的水平。\n节点共享\n\n\n\n\n\n\n\n\n节点共享是在禁用COW的情况下的另一种方式，因此在下面的工作原理中，均属于禁用COW的范畴。\n另一种优化COW的方式是通过节点部分共享的方式。在一些情况下，并不需要完全复制整个链表，其中部分节点可以采用共享的方式实现。其工作原理如下：\nexample(of: &quot;share nodes &quot;) &#123;\n    var list1 &#x3D; LinkedList&lt;Int&gt;()\n    (1 ... 3).forEach &#123; list1.append($0) &#125;\n    var list2 &#x3D; list1\n&#125;\n\n上述代码中list2并未新建内存空间，而是将指针指向了list1对应的位置。\n\n接下来向list2中添加元素：\nlist2.push(0)\n\n\n通过上述图例可知，list1和list2两个链表共享了节点1、2、3，并且list1的头节点属于共享节点1。\nlist1: 1 -&gt;2 -&gt;3  \nlist2: 0 -&gt;1 -&gt;2 -&gt;3 \n\n如果此时向list1添加元素：\nlist1.push(100)\n\n\n打印结果如下：\nlist1: 100 -&gt;1 -&gt;2 -&gt;3   \nlist2: 0 -&gt;1 -&gt;2 -&gt;3  \n\n可以看到两个链表依然共享节点1、2、3，list1的头节点已经改变。\n节点共享的方式是另一种可以实现类似COW特性的方式，在值语义的功能中可能会比Copy操作更加有效。这里不再进行具体的实现。\n关键点总结\n单向链表是一个线性的、单向的数据结构，一旦将引用从一个节点移动到另一个节点，将无法返回；\n链接列表具有头插入的 O（1） 时间复杂性。数组具有 O（n） 时间复杂性；\n符合 Swift 集合协议（如Sequence和Collection）为相当少量的需求提供了大量有用的方法；\n通过写入时复制（COW）行为，您可以实现值语义。\n\n","slug":"2019-12-04-Data-Structures-&-Algorithms-in-Swift-05","date":"2023-05-13T11:29:06.795Z","categories_index":"Data Structures & Algorithms in Swift","tags_index":"Swift中的数据结构与算法"},{"id":"433ae949273168d0f60f97343029174d","title":"\\#4\\ 单向链表的Swift实现","content":"链表是一种线性的、单向的数据结构，不同于数组连续的内存存储，链表中的元素在内存是独立的对象。链表具有以下理论优势：\n\n元素插入和从列表头部删除元素的时间恒定；\n具有可靠的性能特性。\n\n\n如上图所示，链表的结构是一个节点结构。节点具有两个功能：\n\n保存值；\n保存下一个节点的指针。nil节点表示链表的结尾。\n\n\n\n\n\n\n\n\n\n\n\n链表分为单向链表和双向链表，双向链表的每个阶段，还具有指向前一个节点的指针。\n在本文中，将学习链表的Swift实现，以及关于链表的一些通用的操作。将了解每个操作的时间复杂性，并实现一个整洁的小 Swift 功能，称为写入时复制。\n节点（Node）首先我们需要定义节点的数据结构，使用Xcode的新建Playground，并在Sources目录下新建Node.swift文件。根据对节点功能的了解，在Node的结构中，应该有至少两个数据属性，一个用来存储，一个用于指向，如下：\npublic class Node&lt;Value&gt; &#123;\n    public var value: Value\n    public var next: Node?\n    \n    public init(value: Value, next: Node? &#x3D; nil) &#123;\n        self.value &#x3D; value\n        self.next &#x3D; next\n    &#125;\n&#125;\n\nextension Node: CustomStringConvertible &#123;\n    public var description: String &#123;\n        guard let next &#x3D; next else &#123;\n            return &quot;\\(value)&quot;\n        &#125;\n        return &quot;\\(value) -&gt;&quot; + String(describing: next) + &quot; &quot;\n    &#125;\n&#125;\n\n以上便定义好了一个单向链表的节点结构。为了能够在测试方便，可以添加如下工具函数：\n\n\n\n\n\n\n\n\n\n新建helper.swift文件，编写工具类函数：\npublic func example(of description: String, action: () -&gt; Void) &#123;\n print(&quot;---Example of \\(description)---&quot;)\n action()\n print()\n&gt;&#125;\n此时，回到主Playground，定义一个链表结构的示例，如下：\nexample(of: &quot;creating and linking nodes&quot;) &#123;\n    let node1 &#x3D; Node(value: 1)\n    let node2 &#x3D; Node(value: 2)\n    let node3 &#x3D; Node(value: 3)\n    \n    node1.next &#x3D; node2\n    node2.next &#x3D; node3\n    \n    print(node1)\n&#125;\n\n&#x2F;&#x2F; ---Example of creating and linking nodes---\n&#x2F;&#x2F; 1 -&gt;2 -&gt;3 \n\n示例所定义的链表结构，图示如下：\n\n一个单向链表，包含了三个值分别为1、2、3的节点。这样的链表定义似乎已经完成了，但是当节点的数量上升后，我们就需要每个节点都进行赋值和指针指向的定义，显然这样的方式即笨重且不灵活。就实用性而言，目前的结构还需要进行优化，缓解此问题的常用方法是构建一个专门管理Node节点对象的链表结构，如下：\nLinkedListSources目录下新建LinkedList.swift文件。\npublic struct LinkedList&lt;Value&gt; &#123;\n    public var head: Node&lt;Value&gt;?\n    public var tail: Node&lt;Value&gt;?\n    \n    public init() &#123;&#125;\n    \n    public var isEmpty: Bool &#123;\n        return head &#x3D;&#x3D; nil\n    &#125;\n&#125;\n\n\nextension LinkedList: CustomStringConvertible &#123;\n    public var description: String &#123;\n        guard let head &#x3D; head else &#123;\n            return &quot;Empty Linked List&quot;\n        &#125;\n        return String(describing: head)\n    &#125;\n&#125;\n\n该结构下的链表具有头和尾概念，分别指向链表的第一个节点和末尾节点。\n\n向链表中添加值有了节点管理形式的链表后，需要为该链表添加头结点，追加末尾节点，以及插入节点，因此需要定义三个通用的方法：\n\npush：在链表的头部添加值；\nappend：在链表的末尾添加值；\n**insert(after:)**：在链表的特定节点后添加值。\n\npush操作在链表的头部位置添加值，也就是头插法，其时间复杂度为**O(1)**。其实现较为简单，如下：\npublic mutating func push(_ value: Value) &#123;\n    head &#x3D; Node(value: value, next:head)\n    if tail &#x3D;&#x3D; nil &#123;\n        tail &#x3D; head\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\nstruct 和 enum 的值在内部是不能修改的, 如果要修改需要在方法前面添加 mutating 修饰符\n对于一个空的链表来说，头节点也是尾节点，采用头插法插入值后，每次插入的值都会放在链表的头部。\n回到主Playground，进行链表的push操作：\nexample(of: &quot;push&quot;) &#123;\n    var list &#x3D; LinkedList&lt;Int&gt;()\n    \n    list.push(3)\n    list.push(2)\n    list.push(1)\n    \n    print(list)\n&#125;\n\n&#x2F;&#x2F; ---Example of push---\n&#x2F;&#x2F; 1 -&gt;2 -&gt;3 \n\nappend操作在链表的尾部位置添加值，也就是尾插法，其时间复杂度**O(1)**。实现如下：\npublic mutating func append(_ value: Value) &#123;\n    &#x2F;&#x2F; 如果链表尾空，使用push操作新建节点，更新链表的头节点和尾节点。\n    guard !isEmpty else &#123;\n        push(value)\n        return\n    &#125;\n    &#x2F;&#x2F; 创建一个新节点，赋值为尾部节点的下一个节点，将节点连接起来。\n    tail!.next &#x3D; Node(value: value)\n    &#x2F;&#x2F; 因为是尾部拼接节点，所以新的节点将成为尾部节点\n    tail &#x3D; tail!.next\n&#125;\n\n回到主Playground，进行链表的append操作：\nexample(of: &quot;append&quot;) &#123;\n    var list &#x3D; LinkedList&lt;Int&gt;()\n    \n    list.append(1)\n    list.append(2)\n    list.append(3)\n    \n    print(list)\n&#125;\n\n&#x2F;&#x2F; ---Example of append---\n&#x2F;&#x2F; 1 -&gt;2 -&gt;3 \n\ninsert(after:) 操作插入操作是指在链表的特定节点位置，插入一个新的节点。该操作需要两个步骤完成：\n\n查找特定节点\n插入新的节点\n\n首先需要根据给定的索引，查找特定的节点：\npublic func node(at index: Int) -&gt; Node&lt;Value&gt;? &#123;\n    &#x2F;&#x2F; 由于只能从头部遍历链表，因此先创建当前节点和索引的引用\n    var currentNode &#x3D; head\n    var currentIndex &#x3D; 0\n    &#x2F;&#x2F; 使用while循环，将引用向下移动到列表中，直到达到所需的索引。 空列表或越界索引将导致nil返回值。\n    while currentNode !&#x3D; nil &amp;&amp; currentIndex &lt; index &#123;\n        currentNode &#x3D; currentNode!.next\n        currentIndex +&#x3D; 1\n    &#125;\n        \n    return currentNode\n&#125;\n\n这里需要说明的是，我们针对的是单向链表，链表节点的访问只能从头节点依次向后访问，在实现节点的查找时，必须使用迭代的方式进行节点遍历。\n找到了特定索引的节点后，接下来就是插入一个新的节点了。\n@discardableResult\npublic mutating func insert(_ value: Value, after node: Node&lt;Value&gt;) -&gt; Node&lt;Value&gt; &#123;\n    &#x2F;&#x2F; 如果要插入新节点的位置是尾节点，则直接使用append操作，添加新的尾节点\n    guard tail !&#x3D;&#x3D; node else &#123;\n        append(value)\n        return tail!\n    &#125;\n        \n    &#x2F;&#x2F; 否则新建节点，并赋值为查找节点的下一个节点，将节点进行连接\n    node.next &#x3D; Node(value: value, next: node.next)\n        \n    return node.next!\n&#125;\n\n\n\n\n\n\n\n\n\n\n@discardableResult指的是接口的调用者忽略此方法的返回值，而编译器不会向上和向下跳过警告。\n完成逻辑编写后，回到主Playground，进行链表的**insert(after:)**操作：\nexample(of: &quot;inserting at a particular index&quot;) &#123;\n    var list &#x3D; LinkedList&lt;Int&gt;()\n    \n    list.push(3)\n    list.push(2)\n    list.push(1)\n    \n    print(&quot;Before inserting: \\(list)&quot;)\n    \n    let middleNode &#x3D; list.node(at: 1)!\n    for _ in 1 ... 3 &#123;\n        list.insert(-1, after: middleNode)\n    &#125;\n    print(&quot;After inserting: \\(list)&quot;)\n&#125;\n\n&#x2F;&#x2F; ---Example of inserting at a particular index---\n&#x2F;&#x2F; Before inserting: 1 -&gt;2 -&gt;3  \n&#x2F;&#x2F; After inserting: 1 -&gt;2 -&gt;-1 -&gt;-1 -&gt;-1 -&gt;3 \n\n性能分析 — 时间复杂度\n从链表中删除值对应向链表中添加值，从链表中删除值同样对应三个主要的方法：\n\npop：从链表头部删除值；\nremoveLast：从链表尾部删除值；\n**remove(after:)**：删除指定位置的节点值。\n\npop 操作从链表的头部直接删除值的操作和给链表头部添加值的操作push有点类似，其算法也相对简单，如下：\n@discardableResult\npublic mutating func pop() -&gt; Value &#123;\n    defer &#123;\n        head &#x3D; head?.next\n        if isEmpty &#123;\n            tail &#x3D; nil\n        &#125;\n    &#125;\n    return head?.value\n&#125;\n\npop方法的返回值是被删除的节点的值。该结果是一个可选值，因为链表有可能是一个空链表。\n将原链表的头节点向前移动一个位置即可，在ARC模式下，系统内存会在头部节点无任何引用的时候，自动清理原链表的头节点资源。如果移动头节点后，链表是一个空链表，需要将尾部节点重新置空。\n回到主Playground，尝试进行链表的pop操作：\nexample(of: &quot;pop&quot;) &#123;\n    var list &#x3D; LinkedList&lt;Int&gt;()\n    \n    list.push(3)\n    list.push(2)\n    list.push(1)\n    \n    print(&quot;Before popping list: \\(list)&quot;)\n    let poppedValue &#x3D; list.pop()\n    print(&quot;After popping list: \\(list)&quot;)\n    print(&quot;Popped value: &quot; + String(describing: poppedValue))\n&#125;\n\n&#x2F;&#x2F; ---Example of pop---\n&#x2F;&#x2F; Before popping list: 1 -&gt;2 -&gt;3  \n&#x2F;&#x2F; After popping list: 2 -&gt;3 \n&#x2F;&#x2F; Popped value: Optional(1)\n\nremoveLast 操作删除链表的尾部节点相对比较复杂，算法如下：\n@discardableResult\npublic mutating func removeLast() -&gt; Value? &#123;\n    &#x2F;&#x2F; 如果链表的头节点为nil，无节点移除，故返回nil\n    &#x2F;&#x2F; 这里也可以直接使用isEmpty进行判断\n    guard let head &#x3D; head else &#123;\n        return nil\n    &#125;\n    &#x2F;&#x2F; 如果链表仅有一个节点，头节点也是末尾节点，因此直接使用pop()操作即可\n    guard head.next !&#x3D; nil else &#123;\n        return pop()\n    &#125;\n    &#x2F;&#x2F; 创建节点的引用\n    var prev &#x3D; head\n    var current &#x3D; head\n    &#x2F;&#x2F; 遍历链表节点，直到当前节点的下一个节点为nil，则表明当前节点已经是末尾节点了\n    while let next &#x3D; current.next &#123;\n        prev &#x3D; current\n        current &#x3D; next\n    &#125;\n    &#x2F;&#x2F; 将当前节点的前一个节点的next指针值为nil，并更新末尾节点\n    prev.next &#x3D; nil\n    tail &#x3D; prev\n    &#x2F;&#x2F; 返回被删除的值\n    return current.value\n&#125;\n\n\n回到主Playground，尝试进行链表的removeLast操作：\nexample(of: &quot;removing the last node&quot;) &#123;\n    var list &#x3D; LinkedList&lt;Int&gt;()\n    \n    list.push(3)\n    list.push(2)\n    list.push(1)\n    \n    \n    print(&quot;Before remove last node: \\(list)&quot;)\n    let removedValue &#x3D; list.removeLast()\n    print(&quot;After remove last node: \\(list)&quot;)\n    print(&quot;Removed value: &quot; + String(describing: removedValue))\n&#125;\n\n&#x2F;&#x2F; ---Example of removing the last node---\n&#x2F;&#x2F; Before remove last node: 1 -&gt;2 -&gt;3  \n&#x2F;&#x2F; After remove last node: 1 -&gt;2 \n&#x2F;&#x2F; Removed value: Optional(3)\n\nremoveLast操作需要遍历整个链表，因此其时间复杂度为**O(n)**。\nremove(after:) 操作**remove(after:)操作类似insert(after:)**，首先需要找到特定位置的节点，然后执行删除操作。算法过程如下图：\n\n@discardableResult\npublic mutating func remove(after node: Node&lt;Value&gt;) -&gt; Value? &#123;\n    defer &#123;\n        if node.next &#x3D;&#x3D;&#x3D; tail &#123;\n            tail &#x3D; node\n        &#125;\n        node.next &#x3D; node.next?.next\n    &#125;\n    return node.next?.value\n&#125;\n\n节点的引用清理放在defer区块内，当删除的节点无任何引用的时候，系统内存会自动清理其占用资源。\n回到主Playground，尝试进行链表的**remove(after:)**操作：\nexample(of: &quot;removing a node after a particular node&quot;) &#123;\n    var list &#x3D; LinkedList&lt;Int&gt;()\n    \n    list.push(3)\n    list.push(2)\n    list.push(1)\n    \n    print(&quot;Before removing at particular index: \\(list)&quot;)\n    let index &#x3D; 1\n    let node &#x3D; list.node(at: index - 1)!\n    let removedValue &#x3D; list.remove(after: node)\n    print(&quot;After removing at index \\(index): \\(list)&quot;)\n    print(&quot;Removed value: &quot; + String(describing: removedValue))\n&#125;\n\n&#x2F;&#x2F; ---Example of removing a node after a particular node---\n&#x2F;&#x2F; Before removing at particular index: 1 -&gt;2 -&gt;3  \n&#x2F;&#x2F; After removing at index 1: 1 -&gt;3 \n&#x2F;&#x2F; Removed value: Optional(2)\n\n性能分析 — 时间复杂度\n阶段性总结支持关于LinkedList的定义和基本操作就完成了，对于链表而言，单向链表只是一个开始，这里没有涉及到双向链表。\n\n链表是有一个个节点链接而成的，每个节点具有保存值和下一个节点索引的属性；\n链表中节点值的添加涉及头尾和指定位置，在指定位置插入需要两步操作，首先找到给定位置的节点，然后删除其后的一个节点并重建链接；\n链表中节点值的删除同样涉及头尾和指定位置；\n在进行链表的操作时，需要时刻记住在必须的时机更新链表的节点指向指针，保证链表的链接性。\n\n","slug":"2019-12-03-Data-Structures-&-Algorithms-in-Swift-04","date":"2023-05-13T11:29:06.795Z","categories_index":"Data Structures & Algorithms in Swift","tags_index":"Swift中的数据结构与算法"},{"id":"ed1a650be4c536b8ed544197809a0599","title":"\\#3\\ 关于时间复杂度和大O符号","content":"算法复杂度的衡量问题在软件开发的诞生早起就已经被提出来，并且有多个方面具体的问题。例如，从系统的架构来看，可伸缩性的架构设计和算法实现，应用程序是如何在数据特征增加的情况下被合理有效地激活的；从数据库的角度来看，数据库的处理能力是否能够应对越来越多的数据和用户行为等。\n对于算法而言，可伸缩性指的是算法是否能够随着输入体量的变化，算法在执行时间和内存使用上的变现。\n当你面对的是小体量的数据输入时，算法可能运行良好，执行快速，内存使用良好。但是随着数据输入体量的增加，算法的表现可能越来越糟糕，但是具体有多糟糕呢？掌握如何衡量一个算法的优劣是程序开发者的一项重要的技能。\n在本篇内容中，我们将从两个角度 — 时间维度和内存使用维度 观察算法的大O符号问题。\n时间复杂度对于小体量的数据来说，大多数的既定算法能够即快速且高效地在目标设备环境中执行，但是随着数据量的增大、业务逻辑的变化，算法的表现可能会越来越差。时间复杂度（Time complexity）是衡量一个算法随着输入大小的改变，其运行耗时的衡量标准，时间复杂度本质上是一个函数，一个关于输入大小和耗时之间的相关性模型。\n恒定时间复杂度恒定时间复杂度指的是，算法的执行耗时并不会随着输入体量的改变而改变。例如：\nfunc checkFirst(names: [String]) &#123;\n    if let first &#x3D; names.first &#123;\n        print(first)\n    &#125;else&#123;\n        print(&quot;no names&quot;)\n    &#125;\n&#125;\n\n对于上述函数来说，输入names的大小并不会影响该函数的执行时间，无论names中有10个元素还是10万个元素，该函数仅仅检查数组中的第一个元素。对于恒定时间复杂度的算法来说，其时间复杂度可视化后如下图：\n\n在程序员的时间，通常使用大O符号来表示一个算法的时间复杂度，对于恒定时间复杂度的算法，表示为**O(1)**。\n线性时间复杂度假设有如下的一个函数：\nfunc printNames(names: [String]) &#123;\n    for name in names &#123;\n        print(name)\n    &#125;\n&#125;\n\n该函数打印字符串数组中的每一个元素。随着输入体量的增加，for循环的次数也随之增加，并且两者之间呈现线性的关系。线性时间复杂度的图像可表示为：\n\n线性时间复杂度相对较为简单且易于理解。当输入的数据体量增大时，算法的执行耗时会同时增加，这也是其图像是一条直线的原因。对于线性时间复杂度的算法，大O符号表示为**O(n)**。\n二次时间复杂度二次时间复杂度通常也被称为n平方时间复杂度，是指算法的执行耗时随着输入体量的增加而呈现二次方。例如下方示例代码：\nfunc printNames(names: [String]) &#123;\n    for _ in names &#123;\n        for name in names &#123;\n            print(name)\n        &#125;\n    &#125;\n&#125;\n\n上述示例代码的耗时是数组遍历中再次对数组进行全量遍历的时间总和。如果原始数组中有10个元素，则会打印10个元素10次，总共100次打印操作。\n如果输入增加一个单位，则上述打印操作需要执行 11 * 11 次，即总共121次。可视化后的图像如下：\n\n使用大O符号表示为**O(n^2)**。\n对数时间复杂度到目前为止，已经了解了线性和二次时间复杂性，其中输入的每个元素至少检查一次。但是，在某些情况下，只需要检查输入的子集，从而加快运行速度。\n属于此类别的时间复杂性的算法是可以通过对输入数据进行一些假设来利用一些快捷方式的算法。例如，如果您有一个已排序的整数数组，那么查找是否存在特定值的最快方法是什么？\n一个普遍的解决方案是从头到尾检查数组，在得出结论之前检查每个元素，由于您检查每个元素一次，这将是一个 O（n） 算法，线性时间相当不错，但你可以做得更好，由于输入数组已排序，因此可以进行优化。例如以下代码：\nlet numbers &#x3D; [1, 3, 56, 66, 68, 80, 99, 105, 450]\n\nfunc naiveContains(_ value: Int, in array: [Int]) -&gt; Bool &#123;\n    for element in array &#123;\n        if element &#x3D;&#x3D; value &#123;\n            return true\n        &#125;\n    &#125;\n    return false\n&#125;\n\n如果你检查458是否在上述数组中的时候，算法将会遍历数组中的每一个元素。假设数组是已经排序好的，你可以尝试使用二分查找的方式，提高算法的执行效率，例如：\nfunc naiveContains(_ value: Int, in array: [Int]) -&gt; Bool &#123;\n    guard !array.isEmpty else &#123; return false &#125;\n    let middleIndex &#x3D; array.count &#x2F; 2\n    \n    if value &lt;&#x3D; array[middleIndex] &#123;\n        for index in 0 ..&lt; middleIndex &#123;\n            if array[index] &#x3D;&#x3D; value &#123;\n                return true\n            &#125;\n        &#125;\n    &#125;else&#123;\n        for index in middleIndex ..&lt; array.count &#123;\n            if array[index] &#x3D;&#x3D; value &#123;\n                return true\n            &#125;\n        &#125;\n    &#125;\n    return false\n&#125;\n\n上述算法仅仅是进行了一个小的优化，即可将耗时减小一半，说明该优化是有意义的。\n该算法首先检查数组的中间值，如果中间值大于目标值，曾说明目标值在数组的前半部分，否则在后半部分。每次只需要检查原有数组的一半的位置即可，这样即节省了内存空间，而且从算法的执行效率或者算法的响应能力上来说，算是一个成功的算法优化。\n该算法可以重复有效地丢弃一半的数据，从而提高算法执行效率。对数时间复杂度可视化可表示为：\n\n随着输入的增加，耗时的增加相对比较缓慢。如果仔细观察该图像，可以发现耗时呈现不温不火的现象，因为在算法的具体执行中，输入的一半已经被丢弃，算法并不关心他们。\n如果你有100个元素，那么算法最终会压缩到50个元素进行检索，如果有100000个元素，最终执行时，算法只关心50000个元素而已。数据越多，丢弃的元素也就越多，最终的执行耗时和数据的输入大小之间便呈现了如上图所示的关系。对数时间复杂度使用大O符号表示为**O(log n)**。\n准线性时间复杂度另一个常见时间复杂度是准线性时间复杂度。准线性时间算法的性能比线性时间差，但明显优于二次时间复杂度。在Swift中典型的算法是数组的sort算法。\n准线性时间复杂度的大O表示是O（n log n），它是线性和对数时间的乘积。因此，准线性拟合与对数时间与线性时间不相契合；它比线性时间差一个量级，但仍比接下来您将看到的许多其他复杂性要好。下图：\n\n准线性时间复杂性与二次时间有着类似的曲线，但对大型数据集的弹性更大。\n其他时间复杂度上述五种时间复杂度是程序开发中经常遇到的，还有其他的一些时间复杂度，例如多项式时间、指数时间、因子时间等。但是需要说明的是，时间复杂度并不能判断算法的执行速度，两种算法可能具有相同的时间复杂度，但是其中一种可能仍比其他算法快得多，对于小型数据集，时间复杂度可能不是实际算法执行时间的准确衡量。\n例如，如果数据集较小，则插入排序等二次算法可能比准线性算法（如合并排序）更快。这是因为插入排序不需要分配额外的内存来执行算法，而合并排序需要分配多个数组。对于小型数据集，相对于算法需要接触的元素数，内存分配可能会非更加昂贵。\n时间复杂度的比较假设你编写了一个求从 1 到 n 和的算法，如下：\nfunc sumFromOne(upto n: Int) -&gt; Int &#123;\n    var result &#x3D; 0\n    for i in 1 ... n &#123;\n        result +&#x3D; i\n    &#125;\n    return result\n&#125;\n\nsumFromOne(upto: 10000)\n\n上述代码中的循环将执行10000次，最终得到结果50005000。该算法是O(n)时间复杂度。但是如何改进一下该算法如下：\nfunc sumFromOne2(upto n: Int) -&gt; Int &#123;\n    return (1 ... n).reduce(0, +)\n&#125;\n\nsumFromOne2(upto: 10000)\n\n解决同样的问题，但是该实现的执行上会比上面循环的代码快很多，但是这里的时间复杂度依然是O(n)。使用reduce时，系统内部会执行 n次加法，但是调用的是Swift标准库中已经编译的代码，因此省去了很大一部分代码的编译时间。\n继续优化上述代码，如下：\nfunc sumFromOne3(upto n: Int) -&gt; Int &#123;\n    return (n + 1) * n &#x2F; 2\n&#125;\n\nsumFromOne3(upto: 10000)\n\n整个版本的算法使用了弗雷德里克·高斯算法，可以使用简单的算术计算总和。该算法的最时间复杂度是O（1），属于恒定时间算法。也是该特定问题在时间复杂度上的的最优算法。\n空间复杂度算法的时间复杂度有助于预测算法的可伸缩性，但它并不是唯一的指标。空间复杂性是算法运行所需的资源的度量。 对于计算机而言，内存一直是昂贵而紧俏的资源。假设有以下代码：\nfunc printSorted(_ array: [Int]) &#123;\n    let sorted &#x3D; array.sorted()\n    for element in sorted &#123;\n        print(element)\n    &#125;\n&#125;\n\n上述代码创建了一个排序后的数组拷贝并遍历该数据，打印其中元素。为了计算其空闲复杂度，需要分析该函数的内存开辟情况。\n**array.sorted()**方法的调用系统会新建一个和原数组同样大小和类型的新数组，因此printSorted函数的空间复杂度是 **O(n)**。当然对于在内存中开辟尽量小的空间而言，该函数是简单而轻量的。可以将上述函数修改为如下方式：\nfunc printSorted2(_ array: [Int]) &#123;\n    &#x2F;&#x2F; 1\n    guard !array.isEmpty else &#123; return &#125;\n    \n    &#x2F;&#x2F; 2\n    var currentCount &#x3D; 0\n    var minValue &#x3D; Int.min\n    \n    &#x2F;&#x2F; 3\n    for value in array &#123;\n        if value &#x3D;&#x3D; minValue &#123;\n            print(value)\n            currentCount +&#x3D; 1\n        &#125;\n    &#125;\n    \n    while currentCount &lt; array.count &#123;\n        &#x2F;&#x2F; 4\n        var currentValue &#x3D; array.max()!\n        \n        for value in array &#123;\n            if value &lt; currentValue &amp;&amp; value &gt; minValue &#123;\n                currentValue &#x3D; value\n            &#125;\n        &#125;\n        \n        &#x2F;&#x2F; 5\n        for value in array &#123;\n            if value &#x3D;&#x3D; currentValue &#123;\n                print(value)\n                currentCount +&#x3D; 1\n            &#125;\n        &#125;\n        \n        &#x2F;&#x2F; 6\n        minValue &#x3D; currentValue\n    &#125;\n&#125;\n\n此实现尊重空间限制。总体目标是多次遍历迭代数组，为每个迭代打印下一个最小值。\n\n检查是否数组为空的情况。如果是，则不打印内容。\n\ncurrentCount跟踪打印语句的数量。minValue 存储最后一个打印值。\n\n算法首先打印出与 minValue  匹配的所有值，并根据打印语句的数量更新当前计数。\n\n使用 while 循环，算法查找大于 minValue  的最小值并将其存储在当前值中。\n\n然后，该算法在更新currentCount的同时打印数组内所有currentValue的值。\n\nminValue 设置为currentValue，因此下一次迭代将尝试查找下一个最小值。\n\n\n上述算法仅分配内存以跟踪几个变量，因此空间复杂性为 **O(1)**。这与前面的函数不同，后者分配整个数组以创建源数组的排序表示形式。\n\n\n\n\n\n\n\n\n\nPS: 在实际开发中并不会为了追求类似的空间，而将代码写成上述样子，上述代码仅仅是为了说明代码的不同写法，会导致算法的空间复杂度有质的飞跃。\n关键点总结\n时间复杂度是对输入大小增加时，算法运行时间的衡量；\n空间复杂度是对算法运行时，对资源使用情况的衡量；\n大O符号表示法是用于表示时间和空间复杂性的一般形式；\n时间和空间复杂性是可伸缩性的高级度量，它们不测量算法本身的实际速度；\n对于小型数据集，时间复杂性通常无关紧要。准线性算法可能比线性算法慢。\n\n","slug":"2019-12-02-Data-Structures-&-Algorithms-in-Swift-03","date":"2023-05-13T11:29:06.795Z","categories_index":"Data Structures & Algorithms in Swift","tags_index":"Swift中的数据结构与算法"},{"id":"87b78748d49eafbc45cf485f76a0100a","title":"\\#6\\ Linked List 挑战","content":"本文内容将针对LinkedList的五大通用性场景问题，进行求解。这些问题相比多数挑战来说相对简单，主要是为了巩固关于LinkedList的知识。\nChallenge 1：创建按照反向顺序打印链表元素的函数。&#x2F;&#x2F; LinkedList\n1 -&gt; 2 -&gt; 3 -&gt; nil\n\n&#x2F;&#x2F; outut\n3\n2\n1\n\n\n\n\n\n\n\n\n\n\n 解决此问题最简单直接的方式就是使用递归。由于递归允许构建回调堆栈，因此我们可以在递归的回调中调用print打印节点元素值。\n&#x2F;&#x2F; 递归调用\nprivate func printInReverse&lt;T&gt;(_ node: Node&lt;T&gt;?) &#123;\n    guard let node &#x3D; node else &#123;\n        return\n    &#125;\n    printInReverse(node.next)\n    print(node.value)\n&#125;\n\n\nfunc printInReverse&lt;T&gt;(_ list: LinkedList&lt;T&gt;) &#123;\n    printInReverse(list.head)\n&#125;\n测试和结果检查：\nexample(of: &quot;printing in reverse&quot;) &#123;\n    var list &#x3D; LinkedList&lt;Int&gt;()\n    list.push(3)\n    list.push(2)\n    list.push(1)\n    \n    print(&quot;Original list: \\(list)&quot;)\n    print(&quot;Printing in reverse: &quot;)\n    printInReverse(list)\n&#125;\n\n&#x2F;&#x2F; ---Example of printing in reverse---\n&#x2F;&#x2F; Original list: 1 -&gt;2 -&gt;3  \n&#x2F;&#x2F; Printing in reverse: \n&#x2F;&#x2F; 3\n&#x2F;&#x2F; 2\n&#x2F;&#x2F; 1\n\n该算法的核心在于递归调用的部分，当节点存在的情况下，继续遍历当前节点的下一个节点，否则就是已经到了末尾节点，在递归的过程回调堆栈中打印节点值。该算法时间复杂度为**O(n)**。\nChallenge 2：创建返回链表中间节点值的函数。&#x2F;&#x2F; LinkedList\n1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; nil\n&#x2F;&#x2F; middle is 3\n\n1 -&gt; 2 -&gt; 3 -&gt; nil\n&#x2F;&#x2F; middle is 2\n\n\n\n\n\n\n\n\n\n\n 该问题的解决思路是利用双指针位移的偏移量的方式来进行求解，也就是说分别定义两个初始位置相同的指针，然后对链表进行遍历，遍历的过程中，其中一个针对每次位移两个位置，另一个位移一个位置，位移快的那个移动到链表末尾时，慢的那个正好是链表的中间位置。\nfunc getMiddle&lt;T&gt;(_ list: LinkedList&lt;T&gt;) -&gt; Node&lt;T&gt;? &#123;\n    var fast &#x3D; list.head\n    var slow &#x3D; list.head\n    \n    while let nextFast &#x3D; fast?.next &#123;\n        fast &#x3D; nextFast.next\n        slow &#x3D; slow?.next\n    &#125;\n    return slow\n&#125;\n\n\n测试和结果检查：\nexample(of: &quot;getting the middle node&quot;) &#123;\n    var list &#x3D; LinkedList&lt;Int&gt;()\n    list.push(3)\n    list.push(2)\n    list.push(1)\n       \n    print(&quot;Original list: \\(list)&quot;)\n    if let middleNode &#x3D; getMiddle(list) &#123;\n        print(middleNode.value)\n    &#125;\n&#125;\n\n&#x2F;&#x2F; ---Example of getting the middle node---\n&#x2F;&#x2F; Original list: 1 -&gt;2 -&gt;3  \n&#x2F;&#x2F; 2\n\n该算法的时间复杂度是**O(n)。也可以使用另一种解法，先遍历依次整个链表，记录节点总数，然后取链表节点总数的一半，再次进行遍历，获取中间值，但是这样的解法需要遍历两次，时间复杂度为O(n^2)**。\nChallenge 3：创建反转链表的函数。&#x2F;&#x2F; LinkedList\n&#x2F;&#x2F; Before\n1 -&gt; 2 -&gt; 3 -&gt; nil\n\n&#x2F;&#x2F; After\n3 -&gt; 2 -&gt; 1 -&gt; nil\n\n\n\n\n\n\n\n\n\n\n该问题简单的解决方案是，新建一个LinkedList，然后遍历原LinkedList，将节点一个一个的push到新的LinkedList，最后更新原LinkedList的头节点即可。但是这样的方式会有一个性能问题，就是每次调用push方法的时候，都需要分配新的节点，造成了绝大的资源成本。另一种代码较为复杂，但是性能上却相当好的方案是，构建两个变量，分别指向当前节点和上一个节点，然后遍历LinkedList，依次向后交换当前节点和上一个节点的指向，直到当前节点为nil时结束，这样就完全避免了每次新建节点的资源消耗问题。\n&#x2F;&#x2F; Reverse solution 1\nmutating func reverseSolutionOne() &#123;\n    var tempList &#x3D; LinkedList&lt;Value&gt;()\n    for value in self &#123;\n        tempList.push(value)\n    &#125;\n    head &#x3D; tempList.head\n&#125;\n\n&#x2F;&#x2F; Reverse solution 2\npublic mutating func reverseSolutionTwo() &#123;\n    tail &#x3D; head\n    var prev &#x3D; head\n    var current &#x3D; head?.next\n    prev?.next &#x3D; nil\n        \n    while current !&#x3D; nil &#123;\n        let next &#x3D; current?.next\n        current?.next &#x3D; prev\n        prev &#x3D; current\n        current &#x3D; next\n    &#125;\n    head &#x3D; prev\n&#125;\n\n虽然两种解决方案都是完整该挑战，但是在时间复杂度相同的情况下，空间复杂度更好的解决方案2，是应该遵循且掌握的方式。算法2的思路图示如下：\n\n测试算法及检验结果：\nexample(of: &quot;reverse the list solution 2&quot;) &#123;\n    var list &#x3D; LinkedList&lt;Int&gt;()\n    list.push(3)\n    list.push(2)\n    list.push(1)\n    \n    print(&quot;Original list: \\(list)&quot;)\n    list.reverseSolutionTwo()\n    print(&quot;Reversed list: \\(list)&quot;)\n&#125;\n\n&#x2F;&#x2F; ---Example of reverse the list solution 2---\n&#x2F;&#x2F; Original list: 1 -&gt;2 -&gt;3  \n&#x2F;&#x2F; Reversed list: 3 -&gt;2 -&gt;1 \n\nChallenge 4：创建一个函数，该函数接收两个已排序的链表，并合并到单个排序的链表中。&#x2F;&#x2F; list1\n1 -&gt; 4 -&gt; 10 -&gt; 11\n\n&#x2F;&#x2F; list2\n-1 -&gt; 2 -&gt; 3 -&gt; 6\n\n&#x2F;&#x2F; merged list\n-1 -&gt; 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 6 -&gt; 10 -&gt; 11\n\n\n\n\n\n\n\n\n\n\n此问题的解决方案是不断从两个已排序的列表中摘取节点，并将它们添加到新列表中。由于两个列表已经排序，因此可以比较两个列表的下一个节点，以查看哪个节点应该是要添加到新列表的下一个节点。\nfunc mergeSort&lt;T: Comparable&gt;(_ left: LinkedList&lt;T&gt;, _ right:LinkedList&lt;T&gt;) -&gt; LinkedList&lt;T&gt; &#123;\n    &#x2F;&#x2F; 检查输入的两个链表是否为空，如果其中一个为空，则直接返回另一个\n    guard !left.isEmpty else &#123;\n        return right\n    &#125;\n    guard !right.isEmpty else &#123;\n        return left\n    &#125;\n    \n    &#x2F;&#x2F; 结果链表的head、tail定义\n    var newHead: Node&lt;T&gt;?\n    var tail: Node&lt;T&gt;?\n    \n    var currentLeft &#x3D; left.head\n    var currentRight &#x3D; right.head\n    &#x2F;&#x2F; 检查left、right的首个节点，并将小的节点赋值给newHead\n    if let leftNode &#x3D; currentLeft, let rightNode &#x3D; currentRight &#123;\n        if leftNode.value &lt; rightNode.value &#123;\n            newHead &#x3D; leftNode\n            currentLeft &#x3D; leftNode.next\n        &#125; else &#123;\n            newHead &#x3D; rightNode\n            currentRight &#x3D; rightNode.next\n        &#125;\n        tail &#x3D; newHead\n    &#125;\n    &#x2F;&#x2F; 合并\n    &#x2F;&#x2F; 遍历left、right，尝试挑选能够加入新链表的节点，直到其中一个链表到达末尾节点\n    while let leftNode &#x3D; currentLeft, let rightNode &#x3D; currentRight &#123;\n        &#x2F;&#x2F; 比较节点值大小，并将小的链接到tail.next\n        if leftNode.value &lt; rightNode.value &#123;\n            tail?.next &#x3D; leftNode\n            currentLeft &#x3D; leftNode.next\n        &#125; else &#123;\n            tail?.next &#x3D; rightNode\n            currentRight &#x3D; rightNode.next\n        &#125;\n        tail &#x3D; tail?.next\n    &#125;\n    &#x2F;&#x2F; 上个while循环同时以来currentLeft和currentRight，因此即使链表中还有节点，循坏也可能提前终止。需要将剩余的节点链接到处理单元中\n    if let leftNodes &#x3D; currentLeft &#123;\n        tail?.next &#x3D; leftNodes\n    &#125;\n    \n    if let rightNodes &#x3D; currentRight &#123;\n        tail?.next &#x3D; rightNodes\n    &#125;\n    \n    &#x2F;&#x2F; 创建结果链表，这里不使用push或者append的方式，而是直接指定链表的head、tail\n    &#x2F;&#x2F; head只有一个节点，直接复制，tail包含了很多节点，需要一个一个地进行链接\n    var list &#x3D; LinkedList&lt;T&gt;()\n    list.head &#x3D; newHead\n    list.tail &#x3D; &#123;\n        while let next &#x3D; tail?.next &#123;\n            tail &#x3D; next\n        &#125;\n        return tail\n    &#125;()\n    return list\n&#125;\n\n算法求解过程的图示：\n\nexample(of: &quot;merging two sorted list&quot;) &#123;\n    var list1 &#x3D; LinkedList&lt;Int&gt;()\n    list1.push(3)\n    list1.push(2)\n    list1.push(1)\n    \n    var list2 &#x3D; LinkedList&lt;Int&gt;()\n    list2.push(-1)\n    list2.push(-2)\n    list2.push(-3)\n    \n    print(&quot;First list: \\(list1)&quot;)\n    print(&quot;Second list: \\(list2)&quot;)\n    let mergedList &#x3D; mergeSort(list1, list2)\n    print(&quot;Merged list: \\(mergedList)&quot;)\n&#125;\n\n&#x2F;&#x2F; ---Example of merging two sorted list---\n&#x2F;&#x2F; First list: 1 -&gt;2 -&gt;3  \n&#x2F;&#x2F; Second list: -3 -&gt;-2 -&gt;-1  \n&#x2F;&#x2F; Merged list: -3 -&gt;-2 -&gt;-1 -&gt;1 -&gt;2 -&gt;3 \n\nChallenge 5：创建从链表中删除特定元素的所有匹配项的函数。&#x2F;&#x2F; original list\n1 -&gt; 3 -&gt; 3 -&gt; 3 -&gt; 4\n\n&#x2F;&#x2F; list after removing all occurrences of 3\n1 -&gt; 4\n\nextension LinkedList where Value: Equatable &#123;\n    public mutating func removeAll(_ value: Value) &#123;\n        while let head &#x3D; self.head, head.value &#x3D;&#x3D; value &#123;\n            self.head &#x3D; head.next\n        &#125;\n        \n        var prev &#x3D; head\n        var current &#x3D; head?.next\n        while let currentNode &#x3D; current &#123;\n            guard currentNode.value !&#x3D; value else &#123;\n                prev?.next &#x3D; currentNode.next\n                current &#x3D; prev?.next\n                continue\n            &#125;\n            prev &#x3D; current\n            current &#x3D; current?.next\n        &#125;\n        \n        tail &#x3D; prev\n    &#125;\n&#125;\n\n\n测试算法及检验结果：\nexample(of: &quot;deleting duplicate nodes&quot;) &#123;\n    var list1 &#x3D; LinkedList&lt;Int&gt;()\n    list1.push(3)\n    list1.push(2)\n    list1.push(2)\n    list1.push(2)\n    list1.push(1)\n    list1.push(1)\n    \n    print(&quot;Origin list: \\(list1)&quot;)\n    list1.removeAll(2)\n    print(&quot;Delete duplicate list: \\(list1)&quot;)\n&#125;\n\n&#x2F;&#x2F; ---Example of deleting duplicate nodes---\n&#x2F;&#x2F; Origin list: 1 -&gt;1 -&gt;2 -&gt;2 -&gt;2 -&gt;3     \n&#x2F;&#x2F; Delete duplicate list: 1 -&gt;1 -&gt;3 \n\n","slug":"2019-12-05-Data-Structures-&-Algorithms-in-Swift-06","date":"2023-05-13T11:29:06.795Z","categories_index":"Data Structures & Algorithms in Swift","tags_index":"Swift中的数据结构与算法"},{"id":"d2a03c6015acad9ab2a35a4a08b03676","title":"\\#7\\ Stack & Stack Simple Challenges","content":"栈（Stack）是一个常见的基础类型数据结构，在生活中经常也能看到栈的身影，例如一本书、一叠现金等等。栈的数据结构在概念上和对象的物理存储栈相同。再向栈添加元素时，需要将其放在栈顶，通俗称压栈，而从站内删除元素时，始终删除的是栈顶的元素，又称为出栈，而这种进栈和出栈的特性使得栈属于一种受限的线性表结构。栈的操作特性通常被称为**后进先出(LIFO-last in first out)的方式，另一种数据结构队列的操作特性与栈有着不同，通常称为先进先出(FIFO-first in first out)**。\n栈的一般操作栈是一种很有用，但是相对简单的数据结构。构建栈类型数据结构的主要目标是数据的访问权限和方式问题。相比于链表而言，栈并没有链表那个复杂和琐碎。\n对于栈来说，主要的操作有两个，即上述所说的压栈和出栈的操作：\n\npush：添加一个元素到栈顶；\npop：从栈顶删除一个元素\n\n也就是说，对于栈而言，只能从栈的一边添加或者移除元素，也就是上述所说的**后进先出(LIFO-last in first out)**的方式。在计算机编程中，栈的身影无处不在，例如下面几个场景中，都是栈的理念和其应用的结果：\n\n在iOS中,导航控制器的作用是将视图控制器的视图弹出或者弹入，并且最新弹出的总是最后弹入的视图控制器视图；\n内存分配在体系结构级别使用堆栈。局部变量的内存也使用堆栈进行管理；\nSearch和conquer算法，例如从迷宫中寻找路径，均使用堆栈来方便回溯。\n\n栈数据结构实现首先定义栈的基础结构，对于栈而言，其核心就是一个列表，只是再具体的操作时有LIFO的限制。\npublic struct Stack&lt;Element&gt; &#123;\n    private var storage: [Element] &#x3D; []\n    \n    public init() &#123;&#125;\n&#125;\n\nextension Stack: CustomStringConvertible &#123;\n    public var description: String &#123;\n        let topDivider &#x3D; &quot;---- top ----\\n&quot;\n        let bottomDivider &#x3D; &quot;\\n -----------&quot;\n        \n        let stackElements &#x3D; storage\n            .map &#123; &quot;\\($0)&quot; &#125;\n            .reversed()\n            .joined(separator: &quot;\\n&quot;)\n        return topDivider + stackElements + bottomDivider\n    &#125;\n&#125;\n\n另外，在栈的数据结构中使用列表的方式进行数据存储，是因为对于列表来说，在其一端进行操作 — append 和popLast，都属于恒定时间的复杂度O(1)。也更是促进了栈的进栈和出栈特性的性能表现。\npush &amp; pop 操作在栈的数据结构定义中，增加基本的压栈和出栈操作，压栈操作直接使用列表的append，出栈使用popLast：\n&#x2F;&#x2F; push\npublic mutating func push(_ element: Element) &#123;\n    storage.append(element)\n&#125;\n    \n&#x2F;&#x2F; pop\n@discardableResult\npublic mutating func pop() -&gt; Element? &#123;\n    return storage.popLast()\n&#125;\n\n对于这两个基本操作来说，实现也非常直截了当。接下来对其进行实际测试，在主Playground中，进行测试代码编写。\n\n\n\n\n\n\n\n\n\n在进行测试前，可以将\\#4\\ Linked List 的Swift实现\n中的Helper.swift拷贝到当前工程中。\nexample(of: &quot;using a stack&quot;) &#123;\n    var stack &#x3D; Stack&lt;Int&gt;()\n    stack.push(1)\n    stack.push(2)\n    stack.push(3)\n    stack.push(4)\n    \n    print(stack)\n    \n    if let poppedElement &#x3D; stack.pop() &#123;\n        assert(4 &#x3D;&#x3D; poppedElement)\n        print(&quot;Popped: \\(poppedElement)&quot;)\n    &#125;\n&#125;\n\n&#x2F;* \n---Example of using a stack---\n---- top ----\n4\n3\n2\n1\n -----------\nPopped: 4\n*&#x2F;\n\n扩展性操作对于栈来说，除了常用的push和pop操作之外，还有一些额外的操作，能够提高对栈的使用等。\n&#x2F;&#x2F; peek\npublic func peek() -&gt; Element? &#123;\n    return storage.last\n&#125;\n    \n&#x2F;&#x2F; isEmpty\npublic var isEmpty: Bool &#123;\n    return peek() &#x3D;&#x3D; nil\n&#125;\n\n\npeek()：获取栈顶元素\nisEmpty：判断栈是否为空\n\nLess is more在链表的实现中，我们使用了Swift标准库中的Collection协议，那么在栈的实现中是否也能够使用Collection协议呢？栈的目的是有限制的访问数据，通过迭代或者下标的方式即可实现该目标，但是对于Collection协议来说，并不止于此，因此在栈上使用Collection协议和栈的最初目标是相互制约的。在这种情况下，少即是多！\n您可能希望采用现有数组并将其转换为栈，以便保证访问顺序，也可以循环遍历数组元素以及添加元素。对于栈来说，为了能够对栈的操作有一个统一的初始化存储方式，可以定义其初始化方式：\npublic init(_ elements: [Element]) &#123;\n    storage &#x3D; elements\n&#125;\n\nexample(of: &quot;initializing a stack from a array&quot;) &#123;\n    let array &#x3D; [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;]\n    var stack &#x3D; Stack(array)\n    print(stack)\n    \n    if let poppedElement &#x3D; stack.pop() &#123;\n        print(&quot;Popped: \\(poppedElement)&quot;)\n    &#125;\n&#125;\n\n&#x2F;*\n---Example of initializing a stack from a array---\n---- top ----\nD\nC\nB\nA\n -----------\nPopped: D\n*&#x2F;\n\n上述实现中，将一个数组转化为了栈，并且栈中元素的数据类型是String，也就意味着栈中可以放置多种类型的数据元素。\n既然可以使用数组直接转化为栈，那么是否可以直接使用数组的方式初始化栈呢？\nextension Stack: ExpressibleByArrayLiteral &#123;\n    public init(arrayLiteral elements: Element...) &#123;\n        storage &#x3D; elements\n    &#125;\n&#125;\n\nexample(of: &quot;initializing a stack from an array literal&quot;) &#123;\n    var stack: Stack &#x3D; [1.0, 2.0, 3.0, 4.0]\n    print(stack)\n    if let poppedElement &#x3D; stack.pop() &#123;\n        print(&quot;Popped: \\(poppedElement)&quot;)\n    &#125;\n&#125;\n\n&#x2F;*\n---Example of initializing a stack from an array literal---\n---- top ----\n4.0\n3.0\n2.0\n1.0\n -----------\nPopped: 4.0\n*&#x2F;\n\n在搜索树和图的问题求解中，栈至关重要。例如在查找迷宫的路径方法中，每次叨叨左、右、前或后的决策点时，都可以将所有可能的决策点压入栈中，当栈顶的路径是一个死胡同时，只需要从栈中弹出并继续下一个判断，直到走出迷宫即可。\n关键点总结\n栈的数据结构虽然非常简单，但栈是解决很多问题的关键性数据结构；\n对于栈爱说，只有两个基本操作，分别是压栈push和出栈pop。\n\n栈的挑战Challenge 1：在不适用递归的情况下，反向打印一个单向链表的节点。\n\n\n\n\n\n\n\n\n在\\#6\\ Linked List 挑战中我们使用了递归的方式，反向打印了一个链表的节点。在这里将使用栈的结构进行，避免递归调用。\nprivate func printInReverseNoRecursion&lt;T&gt;(_ list: LinkedList&lt;T&gt;) &#123;\n    var current &#x3D; list.head\n    var stack &#x3D; Stack&lt;T&gt;()\n    \n    while let node &#x3D; current &#123;\n        stack.push(node.value)\n        current &#x3D; node.next\n    &#125;\n    \n    while let value &#x3D; stack.pop() &#123;\n        print(value)\n    &#125;\n&#125;\n\nexample(of: &quot;Print Linkedlist reverse without recursion&quot;) &#123;\n    var list &#x3D; LinkedList&lt;Int&gt;()\n    list.push(3)\n    list.push(2)\n    list.push(1)\n    \n    print(&quot;Original list: \\(list)&quot;)\n    print(&quot;Printing in reverse: &quot;)\n    printInReverseNoRecursion(list)\n&#125;\n\n&#x2F;*\n---Example of Print Linkedlist reverse without recursion---\nOriginal list: 1 -&gt;2 -&gt;3  \nPrinting in reverse: \n3\n2\n1\n*&#x2F;\n\n\nChallenge 2：检查括号是否平衡。给定一个字符串，检查是否有 （ 和 ） 字符，如果字符串中的括号是平衡的，则返回 true。例如：&#x2F;&#x2F; 1 h((e))llo(world)() &#x2F;&#x2F; balanced parentheses\n\n&#x2F;&#x2F; 2 (hello world &#x2F;&#x2F; unbalanced parentheses\n\nfunc checkParentheses(_ string: String) -&gt; Bool &#123;\n    var stack &#x3D; Stack&lt;Character&gt;()\n    \n    for character in string &#123;\n        if character &#x3D;&#x3D; &quot;(&quot; &#123;\n            stack.push(character)\n        &#125; else if character &#x3D;&#x3D; &quot;)&quot; &#123;\n            if stack.isEmpty &#123;\n                return false\n            &#125;else &#123;\n                stack.pop()\n            &#125;\n        &#125;\n    &#125;\n    return stack.isEmpty\n&#125;\n\nexample(of: &quot;check parentheses&quot;) &#123;\n    let string &#x3D; &quot;h((e))llo(world)())&quot;\n    \n    let result &#x3D; checkParentheses(string)\n    \n    print(&quot;\\(result)&quot;)\n&#125;\n\n&#x2F;*\n---Example of check parentheses---\nfalse\n*&#x2F;","slug":"2019-12-08-Data-Structures-&-Algorithms-in-Swift-07","date":"2023-05-13T11:29:06.795Z","categories_index":"Data Structures & Algorithms in Swift","tags_index":"Swift中的数据结构与算法"},{"id":"69dccdbf9286082e902aaae1dff82001","title":"\\#8\\ 队列的Swift实现与操作定义","content":"在生活中，人人都熟悉排队等待。无论你是在排队购买喜欢的电影的电影票，还是排队等待打印一份文件等等，这些都是队列（Queue）数据结构。在上文\\#7\\ Stack &amp; Stack Simple Challenges中已经提到过队列和栈属于基本的数据结构类型，但是其在应用层面非常有效。\n队列（Queue）是一种FIFO(ﬁrst-in ﬁrst-out)型的数据操作特性，和栈的LIFO形成鲜明的对比。FIFO意味着首先进入队列的元素，也是第一个推出队列的元素。在项目中，如果要维护一个有顺序的数据并稍后处理，队列是无二之选。\n在本内容中，我们将学习关于队列的常见操作，以及使用Swift语言实现这些操作，衡量这些操作的时间复杂度等。\n一般性操作实现由于队列的操作特性较多，在这里我们可以使用Swift的面向协议的编程思想进行实现，首先我们定义一个关于操作的协议，如下：\npublic protocol Queue &#123;\n    associatedtype  Element\n    mutating func enqueue(_ element: Element) -&gt; Bool\n    mutating func dequeue() -&gt; Element?\n    var isEmpty: Bool &#123; get &#125;\n    var peek: Element? &#123; get &#125;\n&#125;\n\n\nenqueue： 向队列的尾部插入一个元素，如果该操作成功，则返回true，反之返回false；\ndequeue： 从队列的头部删除一个元素，并返回被删除的元素；\nisEmpty： 检查队列是否为空；\npeek： 返回队列头部的元素，和dequeue的区别在于，该操作并不删除元素。\n\n通过操作类型的定义可以看到，队列有两个普遍的操作，在队列的尾部插入元素和从队列的头部删除元素，而并不需要关心队列的中间元素，如果需要关心中间元素，你可能需要使用数组。\n一个队列的例子理解队列最简单的方式是通过实际的示例了解队列的工作原理。假设在影院门口，很多人在排队购买电影票：\n\n队伍中有Ray、Brian、Sam和Mic四人，当Ray买到了电影票后，他就会从队伍中退出，相当于调用了**dequeue()**，从队伍的头部删除了一个元素类似。\n此时，调用peek将返回队列中此刻的头元素Brain。\n如果来了一个新的人Vicki，加入到了队伍中，等待购买电影票，她站到了队伍的尾部。相当于调用了**enqueue(“Vicki”)**。\n这就是队列的一般性工作原理，接下来我们将使用四种不同的基础数据结构来创建队列以及队列的一般性操作。分别为：\n\n使用数组（Array）\n使用双向链表（Double LinkedList）\n使用环形缓冲器（Ring buffer）\n使用两个栈（two stacks）\n\n基于Array的队列Swift标准库中继承了大量高度优化的核心数据结构，利用这些数据结构可以构建更高级别的抽象，例如基础数据结构Array，用于存储连续的有序元素列表。在本节中，将使用Array来构建队列，并实现队列的基础操作等。\n\npublic struct QueueArray&lt;T&gt;: Queue &#123;\n    private var array: [T] &#x3D; []\n    public init() &#123;&#125;\n&#125;\n\n这里定义了一个采用Queue协议的通用型QueueArray结构体，在Queue协议中定义的关联类型Element这里由T推断。\n接下来实现Queue协议中的定义等，使得QueueArray符合Queue协议。\n数组检查首先添加如下两个协议属性的实现：\npublic var isEmpty: Bool &#123;\n    return array.isEmpty\n&#125;\n    \npublic var peek: T? &#123;\n    return array.first\n&#125;\n\n因为这里使用的是数组，因此在实现isEmpty和peek时，均可直接使用数组的内置属性，简洁方便。其中peek返回的是队列的头部元素，也就是数组的第一个元素。\n这连个操作的时间复杂度均为**O(1)**。\n入队入队就是将元素添加到队列的末尾。使用数组实现也非常方便，只要进行append操作即可。\npublic mutating func enqueue(_ element: T) -&gt; Bool &#123;\n    array.append(element)\n    return true\n&#125;\n\n入队的操作，无论数组的大小如何，该操作的时间复杂度都是**O(1)**。这是因为在数组的末尾，存在着空白空间。\n\n在上例中，当添加了Mic元素之后，数组还剩下两个空白空间。当添加了多个元素之后，数组的空白空间将会被填满，继续添加元素的时候，则要使用超出数组原始分配空间的空间，进而必须调整数组大小以增加空间。\n\n在数组进行大小重新调整的时候，其时间复杂度为O(n)，数组大小重组意味着数组需要重新分配内存空间，并将原数据元素拷贝到新的数组中，因为这样的调整并不是经常性的，因此入队操作的时间复杂度仍可认为是**O(1)**。\n出队出队操作是将队列头节点的元素移出队列，可使用数组的removeFirst操作即可。\npublic mutating func dequeue() -&gt; T? &#123;\n    return isEmpty ? nil : array.removeFirst()\n&#125;\n\n如果数组为空，则出队操作后返回nil，否则返回出队的元素。\n\n从队列中头部移除元素的操作属于O(n)时间复杂度，在上述方式中就是从数组中移除第一个元素。这始终是一个线性的时间度量，因为在内存中，当移除一个元素后，其他所有的元素都需要移动其位置。\n调试与测试对于调试目的来说，Swift中提供了专用的协议CustomStringConvertible，为了调试的方便，我们需要添加如下的代码：\nextension QueueArray: CustomDebugStringConvertible &#123;\n    public var description: String &#123;\n        return String(describing: array)\n    &#125;\n&#125;\n\n接下来进行队列的调试，调试代码如下：\nexample(of: &quot;Debug the Queue with Array&quot;) &#123;\n    var queue &#x3D; QueueArray&lt;String&gt;()\n    queue.enqueue(&quot;Ray&quot;)\n    queue.enqueue(&quot;Brian&quot;)\n    queue.enqueue(&quot;Eric&quot;)\n    print(queue)\n    queue.dequeue()\n    print(queue)\n    queue.dequeue()\n    print(queue.peek ?? &quot;&quot;)\n&#125;\n\n&#x2F;*\n---Example of Debug the Queue with Array---\n[&quot;Ray&quot;, &quot;Brian&quot;, &quot;Eric&quot;]\n[&quot;Brian&quot;, &quot;Eric&quot;]\nEric\n*&#x2F;\n\n由于是使用Array来进行队列的设计，因此操作方式非常类似于Array，上述打印结果也符合队列的先进先出的原则。\n优势和劣势上述就是基于数组的队列的一般操作的算法实现，大多数的操作都是恒定时间复杂度的，例如*dequeue()*操作，属于线性时间，内存空间也是线性的。\n\n基于数组的队列相对是简单的，也是因为数组的append操作，使得入队操作是恒定的时间复杂度O(1)。然而在实施中却有一些明显的缺点，出队的操作是从队列的头部移除元素，移除后，其他的所有元素都需要向前移动一个位置，对于队列来说影响算是非常大的。一旦队列已满，队列就必须调整其大小，调整完后，队列中很容易存在未使用的空间，随着时间的推移，未使用空间越来越多，这可能增加内存的占用率。\n基于双向链表（Double LinkedList）的队列在\\#5\\ Swift集合协议在Linked List上的应用中我们已经了解了单向链表，双向链表则是每个节点不仅包含指向下一个节点的指针，还包含指向上一个节点的指针。\npublic class LinkedListNode&lt;T&gt; &#123;\n    var value: T\n    var next: LinkedListNode? &#x2F;&#x2F; 指向下一个节点。尾节点为nil\n    weak var previous: LinkedListNode? &#x2F;&#x2F; 指向上一个节点。头节点为nil\n        \n    public init(value: T) &#123;\n        self.value &#x3D; value\n    &#125;\n&#125;\n\n利用双向链表实现队列如下：\npublic class QueueLinkedList&lt;T&gt;: Queue &#123;\n    private var list &#x3D; DoublyLinkedList&lt;T&gt;()\n    public init() &#123;&#125;\n    \n    public func enqueue(_ element: T) -&gt; Bool &#123;\n        list.append(element)\n        return true\n    &#125;\n    \n    public func dequeue() -&gt; T? &#123;\n        guard !list.isEmpty, let _ &#x3D; list.first else &#123;\n            return nil\n        &#125;\n        return list.remove(at: 0)\n    &#125;\n    \n    public var peek: T? &#123;\n        return list.head?.value\n    &#125;\n    \n    public var isEmpty: Bool &#123;\n        return list.isEmpty\n    &#125;\n&#125;\n\n入队操作由于链表中实现了能够直接添加元素到链表尾部的操作，因此入队操作相当于链表的追加操作。\npublic func enqueue(_ element: T) -&gt; Bool &#123;\n    list.append(element)\n    return true\n&#125;\n\n\n基于双向链表的队列入队时，其内部需要转换节点的两个指针的指向，上一个节点中指向下一个节点的指针指向该新节点，该新节点的上一个节点指向上一个节点。同时tail节点的上一个节点指针也需要更新。\n出队操作出队列操作前，需要检查队列是否为空队列，如果是空队列的时候，直接返回nil，否则移除链表中索引为0的元素即可。\npublic func dequeue() -&gt; T? &#123;\n    guard !list.isEmpty, let _ &#x3D; list.first else &#123;\n        return nil\n    &#125;\n    return list.remove(at: 0)\n&#125;\n\n\n出队需要更新head节点的指针指向，将head的next指针的指向原来队列的第二个节点即可。\n调试与测试同样调试模式下，我们实现CustomStringConvertible协议。\nextension QueueLinkedList: CustomStringConvertible &#123;\n    public var description: String &#123;\n        return String(describing: list)\n    &#125;\n&#125;\n\n在测试程序中实现和基于数组的队列相同的逻辑。\nexample(of: &quot;Debug the Queue with Doubly Linkedlist&quot;) &#123;\n    let queue &#x3D; QueueLinkedList&lt;String&gt;()\n    queue.enqueue(&quot;Ray&quot;)\n    queue.enqueue(&quot;Brian&quot;)\n    queue.enqueue(&quot;Eric&quot;)\n    print(queue)\n    queue.dequeue()\n    print(queue)\n    queue.dequeue()\n    print(queue.peek ?? &quot;&quot;)\n&#125;\n\n&#x2F;*\n---Example of Debug the Queue with Doubly Linkedlist---\n[Ray, Brian, Eric]\n[Brian, Eric]\nEric\n*&#x2F;\n\n优势和劣势基于双向链接的队列，各个操作的最佳时间复杂度和最差时间复杂度如下图所示：\n\n基于数组的队列在出队操作上是一个线性的操作，使用链表的队列，出队操作简化为了恒定时间复杂，每次出队操作只需要更新节点的上一个和下一个指针即可。\n从上表中可以看出，基于链表的队列的弱点并不明显，但是O(1)的时间复杂度却只是表面性能，操作在执行的时候，需要很高的内存开销，每个元素的操作都必须有额外的空间以供前向指针和后向指针引用，此外，每次创建新元素都需要进行昂贵的内存动态分配，相比之下，基于数组的队列进行的是批量的内存分配，速度更快。\n基于环形缓冲器的队列环形缓冲区也称为循环缓冲区，是一个固定大小的数组，当数组末尾没有要删除的元素时，环形缓冲区会从策略绕到数组开头。那么环形缓冲区是如何实现队列的操作的呢？\n\n首先创建一个固定大小为4的缓冲区，在该缓冲区中同时含有两个指针，分别追踪不同的事情：\n\nread指针追踪队列的头部\nwrite指针追踪下一个可写的空间指针，这样就能够重写已读过的元素了。\n\n进行入队操作，如：\n\n每次添加一个元素到队列的时候，write指针加一。\n\n上图中，write指针又移动了两个位置，而且其位置位于read指针的前面，也意味着队列是非空队列。\n接下来，进行两次出队的操作：\n\n出队操作的是read指针，read指针向后移动，指向第三个元素的位置即可。接下来在进行入队操作，将队列填充满：\n\n当write指针到达队列的末尾是，环形缓冲区会重新转换该指针到队列的开始位置。\n最后，在出队两个队列中的元素：\n\n此时read指针也指向了队列的开始位置。最后一次出队操作后，read指针和write指针都指向了队列的开始位置，这也意味着队列中已经无元素了，为空的队列。\n上述就是RingBuffer的基本数据结构和工作原理，接下来进行数据结构的实现和基本操作的实现。\n首先定义所需的变量，包括了数据存储的结构，这里使用Array即可，还有两个基本的指针read和write，为了方便对数据进行检验，增加辅助检查可写空间大小和可读空间大小的变量，以及是否为空和是否已满的变量：\npublic struct RingBuffer&lt;T&gt; &#123;\n    public var array: [T?]\n    public var readIndex &#x3D; 0\n    public var writeIndex &#x3D; 0\n    \n    public init(count: Int) &#123;\n        array &#x3D; [T?](repeating: nil, count: count)\n    &#125;\n    \n    public var availableSpaceForReading: Int &#123;\n      return writeIndex - readIndex\n    &#125;\n\n    public var isEmpty: Bool &#123;\n      return availableSpaceForReading &#x3D;&#x3D; 0\n    &#125;\n\n    public var availableSpaceForWriting: Int &#123;\n      return array.count - availableSpaceForReading\n    &#125;\n\n    public var isFull: Bool &#123;\n      return availableSpaceForWriting &#x3D;&#x3D; 0\n    &#125;\n&#125;\n\n由于RingBuffer是固定大小的数据结构，因此在可读可写空间判断的时候，直接使用减法的方式即可获取到可用空间大小。接下来就是基本的read操作和write操作的实现，在实现这两个操作时需要检查缓存区是否已满和是否为空：\n@discardableResult\npublic mutating func write(_ element: T) -&gt; Bool &#123;\n    guard !isFull else &#123; return false &#125;\n    defer &#123;\n        writeIndex +&#x3D; 1\n    &#125;\n    array[wrapped: writeIndex] &#x3D; element\n    return true\n&#125;\n\npublic mutating func read() -&gt; T? &#123;\n    guard !isEmpty  else &#123; return nil &#125;\n    defer &#123;\n        array[wrapped: readIndex] &#x3D; nil\n        readIndex +&#x3D; 1\n    &#125;\n    return array[wrapped: readIndex]\n&#125;\n\n另外在操作中使用了Array的subscript操作属性，但是原始的subscript并不符合RingBuffer的定义，因此还需要重写subscript操作如下：\nprivate extension Array &#123;\n    subscript (wrapped index: Int) -&gt; Element &#123;\n        get &#123;\n            return self[index % count]\n        &#125;\n        set &#123;\n            self[index % count] &#x3D; newValue\n        &#125;\n    &#125;\n&#125;\n\n另由于RingBuffer还应该支持序列的可遍历迭代操作，因此定义RingBuffer的Iterator操作：\nextension RingBuffer: Sequence &#123;\n    public func makeIterator() -&gt; AnyIterator&lt;T&gt; &#123;\n        var index &#x3D; readIndex\n        return AnyIterator &#123;\n            guard index &lt; self.writeIndex else &#123; return nil &#125;\n            defer &#123;\n                index +&#x3D; 1\n            &#125;\n            return self.array[wrapped: index]\n        &#125;\n    &#125;\n&#125;\n\n完成了RingBuffer的定义之后，就可以实现基于RingBuffer的队列定义和实现了。\npublic struct QueueRingBuffer&lt;T&gt;: Queue &#123;\n    \n    private var ringBuffer: RingBuffer&lt;T&gt;\n    \n    public init(count: Int) &#123;\n        ringBuffer &#x3D; RingBuffer&lt;T&gt;(count: count)\n    &#125;\n    \n    public var isEmpty: Bool &#123;\n        return ringBuffer.isEmpty\n    &#125;\n    \n    public var peek: T? &#123;\n        return ringBuffer.first as? T\n    &#125;\n    \n    \n    public mutating func enqueue(_ element: T) -&gt; Bool &#123;\n        return ringBuffer.write(element)\n    &#125;\n    \n    public mutating func dequeue() -&gt; T? &#123;\n        return isEmpty ? nil : ringBuffer.read()\n    &#125;\n&#125;\n\n队列的定义都大同小异，同样对QueueRingBuffer进行测试如下：\nexample(of: &quot;Debug the Queue with RingBuffer&quot;) &#123;\n    var queue &#x3D; QueueRingBuffer&lt;String&gt;(count: 10)\n    queue.enqueue(&quot;Ray&quot;)\n    queue.enqueue(&quot;Brian&quot;)\n    queue.enqueue(&quot;Eric&quot;)\n    print(queue)\n    queue.dequeue()\n    print(queue)\n    queue.dequeue()\n    print(queue.peek ?? &quot;&quot;)\n&#125;\n\n&#x2F;*\n---Example of Debug the Queue with RingBuffer---\nRingBuffer&lt;String&gt;(array: [Optional(&quot;Ray&quot;), Optional(&quot;Brian&quot;), Optional(&quot;Eric&quot;), nil, nil, nil, nil, nil, nil, nil], readIndex: 0, writeIndex: 3)\nRingBuffer&lt;String&gt;(array: [nil, Optional(&quot;Brian&quot;), Optional(&quot;Eric&quot;), nil, nil, nil, nil, nil, nil, nil], readIndex: 1, writeIndex: 3)\n*&#x2F;\n\n优缺点\n基于环形缓冲区的队列具有相同的时间复杂性，和链表的入队和出队类似。唯一的区别是空间复杂度。环形缓冲区的大小是固定的，这意味着排队可能会失败。\n到目前为止，您已经看到了三种实现：简单数组、双链表和环形缓冲区。\n尽管它们看起来非常有用，但接下来您将看到使用两个栈实现的队列。您将看到它的空间位置如何远远优于链接列表。它也不需要像环形缓冲区那样的固定大小。\n基于双栈的队列public struct QueueStack&lt;T&gt;: Queue &#123;\n    private var leftStack: [T] &#x3D; []\n    private var rightStack: [T] &#x3D; []\n    public init() &#123;&#125;\n&#125;\n\n双栈的思路其实很简单，无论何时加入元素都是讲元素添加到rightStack。当需要进行出队操作时，反转rightStack并将元素加入到leftStack中，然后在leftStack中即可使用FIFO原则进行出队操作了。\n\n根据上图双栈的工作原理，实现队列的基本操作：\npublic var isEmpty: Bool &#123;\n    return leftStack.isEmpty &amp;&amp; rightStack.isEmpty\n&#125;\n\npublic var peek: T?&#123;\n    return !leftStack.isEmpty ? leftStack.last : rightStack.first\n&#125;\n\npublic mutating func enqueue(_ element: T) -&gt; Bool &#123;\n    rightStack.append(element)\n    return true\n&#125;\n\npublic mutating func dequeue() -&gt; T? &#123;\n    if leftStack.isEmpty &#123;\n        leftStack &#x3D; rightStack.reversed()\n        rightStack.removeAll()\n    &#125;\n    return leftStack.popLast()\n&#125;\n\n入队操作\n\n出队操作\n\n测试代码如下：\nexample(of: &quot;Debug the Queue with Double Stack&quot;) &#123;\n    var queue &#x3D; QueueStack&lt;String&gt;()\n    queue.enqueue(&quot;Ray&quot;)\n    queue.enqueue(&quot;Brian&quot;)\n    queue.enqueue(&quot;Eric&quot;)\n    print(queue)\n    queue.dequeue()\n    print(queue)\n    queue.dequeue()\n    print(queue.peek ?? &quot;&quot;)\n&#125;\n\n&#x2F;*\n---Example of Debug the Queue with Double Stack---\n[&quot;Ray&quot;, &quot;Brian&quot;, &quot;Eric&quot;]\n[&quot;Brian&quot;, &quot;Eric&quot;]\nEric\n*&#x2F;\n\n优缺点\n与基于数组的实现相比，通过利用两个堆栈，您可以将出队操作转换为分步的O(1)操作。\n此外，两个栈实现是完全动态的，并且没有基于环形缓冲区的队列所具有的固定大小限制。\n最后，它在空间位置方面胜过了链表。这是因为数组元素在内存块中彼此相邻。因此，在第一次访问时，大量元素将加载到缓存中。\n基于双栈的队列\n\n基于链表的队列\n\n关键点总结\n队列是一个FIFO的结构；\n入队操作必须在队列的末尾；\n出队操作必须在队列的开端；\n数组中的元素在内存中是连续的，链表是分散的，并且链表的内存存储方式可能导致缓存未命中；\n基于环形缓冲区的队列适用于固定大小的队列结构；\n相比其他的数据结构，双栈结构的队列能够将出栈操作分散为O(1)的时间复杂度；\n双栈的操作在空间复杂度上由于链表结构。\n\n","slug":"2019-12-10-Data-Structures-&-Algorithms-in-Swift-08","date":"2023-05-13T11:29:06.795Z","categories_index":"Data Structures & Algorithms in Swift","tags_index":"Swift中的数据结构与算法"},{"id":"ad7db3b90885866da085b02a06020b3f","title":"\\#9\\ 一般树与树节点遍历","content":"在计算机编程的世界中，树是一种非常重要的数据结构。树用于解决很多计算机编程世界的挑战，例如：\n\n等级关系的描述\n分类数据的管理\n分类查找操作\n\n在计算机算法中，树有很多种，每一种都有其特有的形状和大小。在本文中将学习关于树的基础知识，以及使用Swfit编程语言实现树结构等。\n术语关于树的术语有很多，只有将各个术语的含义弄清楚之后，才能够实现树，并利用树来解决问题。\n节点类似链表，树也是由节点构成的。\n\n每一个节点会封装一些数据，并链接着其孩子。\n父节点和子节点树的结构是从顶部延伸到底部的，看起来像一颗反过来的真实的树。\n在树的结构中，除了最上方的节点之外，每一个节点都链接着它上面的节点，这个节点称之为父节点。除了最下方的节点之外，每一个节点都连接着它下面的节点，这个节点称之为子节点。在树中，每一个子节点只有一个父节点。\n\n根节点树结构中，最顶端的节点称为根节点。根节点再无父节点，并且一颗树中有且仅有一个根节点。\n\n叶子节点没有子节点的节点，称之为叶子节点。\n\nSwift树结构实现public class TreeNode&lt;T&gt; &#123;\n    public var value: T\n    public var children: [TreeNode] &#x3D; []\n    \n    public init(_ value: T) &#123;\n        self.value &#x3D; value\n    &#125;\n&#125;\n\n对于一棵树来说，最为重要的便是树的节点，每一个节点都有两个主要功能，封装数据和链接其他节点。在上述实现中，创建类TreeNode来对节点的结构进行封装，并且在节点的结构中，其所有的子节点使用了数组进行封装，数组中依然是节点结构。\n对于一棵树来说，树中的节点可以进行添加，即为某个节点添加新的节点，因此添加如下方法：\n&#x2F;&#x2F; 为节点添加新的子节点\npublic func add(_ child: TreeNode) &#123;\n    children.append(child)\n&#125;\n\nTime to give it a whirl.\nexample(of: &quot;Create a tree&quot;) &#123;\n    let beverages &#x3D; TreeNode(&quot;Beverages&quot;)\n    let hot &#x3D; TreeNode(&quot;Hot&quot;)\n    let cold &#x3D; TreeNode(&quot;Cold&quot;)\n    \n    beverages.add(hot)\n    beverages.add(cold)\n    \n    print(beverages.value)\n    print(beverages.children[0].value)\n    print(beverages.children[1].value)\n&#125;\n\n&#x2F;*\n---Example of Create a tree---\nBeverages\nHot\nCold\n*&#x2F;\n\n树的结构属于层级结构，上述Demo中为根节点Beverages增加了两个子节点Hot和Cold。\n\n遍历算法线性集合（如数组、链表）的遍历相对简单，因为他们都有清晰的起点和终点。\n\n然而遍历一颗树相对较为复杂一点，对于一颗树来说，其起点和终点并不明晰。\n\n由于在树种，是优先遍历左边的节点还是右边的节点，并不明确，只因面对的问题不同而策略不同。对于不同的树有着不同的遍历策略。\n深度优先遍历这是一种从根节点开始，直到回溯之前尽可能的遍历到树的叶子节点。\nextension TreeNode &#123;\n    public func forEachDepthFirst(visit: (TreeNode) -&gt; Void) &#123;\n        visit(self)\n        children.forEach &#123;\n            $0.forEachDepthFirst(visit: visit)\n        &#125;\n    &#125;\n&#125;\n\n这里使用的是递归的方式进行节点的遍历，如果不想使用递归，可以将children变量设置为栈类型。为了测试，首先我们构建一颗比较大的树：\nfunc makeBeverageTree() -&gt; TreeNode&lt;String&gt; &#123;\n    let tree &#x3D; TreeNode(&quot;Beverages&quot;)\n    let hot &#x3D; TreeNode(&quot;hot&quot;)\n    let cold &#x3D; TreeNode(&quot;cold&quot;)\n    \n    let tea &#x3D; TreeNode(&quot;tea&quot;)\n    let coffee &#x3D; TreeNode(&quot;coffee&quot;)\n    let chocolate &#x3D; TreeNode(&quot;cocoa&quot;)\n    \n    let blackTea &#x3D; TreeNode(&quot;black&quot;)\n    let greenTea &#x3D; TreeNode(&quot;green&quot;)\n    let chaiTea &#x3D; TreeNode(&quot;chai&quot;)\n    \n    let soda &#x3D; TreeNode(&quot;sida&quot;)\n    let milk &#x3D; TreeNode(&quot;milk&quot;)\n    \n    let gingerAle &#x3D; TreeNode(&quot;ginger ale&quot;)\n    let bitterLemon &#x3D; TreeNode(&quot;bitter lemon&quot;)\n    \n    tree.add(hot)\n    tree.add(cold)\n    \n    hot.add(tea)\n    hot.add(coffee)\n    hot.add(chocolate)\n    \n    cold.add(soda)\n    cold.add(milk)\n    \n    tea.add(blackTea)\n    tea.add(greenTea)\n    tea.add(chaiTea)\n    \n    soda.add(gingerAle)\n    soda.add(bitterLemon)\n    \n    return tree\n&#125;\n\n该树的形态如下：\n\n接下来在这棵树上测试深度优先遍历。\nexample(of: &quot;depth-first traversal&quot;) &#123;\n    let tree &#x3D; makeBeverageTree()\n    tree.forEachDepthFirst &#123;\n        print($0.value)\n    &#125;\n&#125;\n\n&#x2F;*\n---Example of depth-first traversal---\nBeverages\nhot\ntea\nblack\ngreen\nchai\ncoffee\ncocoa\ncold\nsida\nginger ale\nbitter lemon\nmilk\n*&#x2F;\n\n从上述测试打印的结果和树的形态图可以看出，深度优先遵循从左至右的原则。\n广度优先遍历广度优先遍历又称为水平顺序遍历，其算法如下：\nextension TreeNode &#123;\n    public func forEachLevelOrder(visit: (TreeNode) -&gt; Void) &#123;\n        visit(self)\n        var queue &#x3D; Array&lt;TreeNode&gt;()\n        children.forEach &#123;\n            queue.append($0)\n        &#125;\n        \n        while let node &#x3D; queue.isEmpty ? nil : queue.removeFirst() &#123;\n            visit(node)\n            node.children.forEach &#123;\n                queue.append($0)\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n这里的实现采用了数组作为临时变量，存储元素，也可以直接使用队列。\n\nexample(of: &quot;level-order traversal&quot;) &#123;\n    let tree &#x3D; makeBeverageTree()\n    tree.forEachLevelOrder &#123;\n        print($0.value)\n    &#125;\n&#125;\n\n&#x2F;*\n---Example of level-order traversal---\nBeverages\nhot\ncold\ntea\ncoffee\ncocoa\nsida\nmilk\nblack\ngreen\nchai\nginger ale\nbitter lemon\n*&#x2F;\n\n节点搜索上面实现了树的两种遍历算法 — 深度优先和广度优先，分别针对了不同的特定问题。有了遍历的算法之后，针对节点的搜索而言，便无需太过复杂的算法了。\nextension TreeNode where T: Equatable &#123;\n    public func search(_ value: T) -&gt; TreeNode? &#123;\n        var result: TreeNode?\n        forEachLevelOrder &#123; node in\n            if node.value &#x3D;&#x3D; value &#123;\n                result &#x3D; node\n            &#125;\n        &#125;\n        return result\n    &#125;\n&#125;\n\n在这个搜索算法中，使用了广度优先的遍历算法，也可使用深度优先的遍历算法。但是如果在树种有多个相匹配的节点，搜索算法最终保存的是最后一个节点。\nexample(of: &quot;searching for a node&quot;) &#123;\n    let tree &#x3D; makeBeverageTree()\n    \n    if let searchResult1 &#x3D; tree.search(&quot;ginger ale&quot;) &#123;\n        print(&quot;Found node: \\(searchResult1.value)&quot;)\n    &#125;\n    \n    if let searchResult2 &#x3D; tree.search(&quot;WKD Blue&quot;) &#123;\n        print(searchResult2.value)\n    &#125; else &#123;\n      print(&quot;Couldn&#39;t find WKD Blue&quot;)\n    &#125;\n&#125;\n\n&#x2F;*\n---Example of searching for a node---\nFound node: ginger ale\nCouldn&#39;t find WKD Blue\n*&#x2F;\n\n关键点总结\n树结构和链表类似，但是链表的每一个节点只能链接到另一个节点，而树的一个节点可以链接多个节点；\n针对树来说，有一些特定的术语，如根节点、子节点、叶子节点等；\n节点的遍历 — 深度优先和广度优先并只是应用在一般的树中，其他树的结构也可使用，只不过会根据树的不同而策略不同。\n\nChallenge打印树中同一层级的元素，每个相同层级的元素打印在一行中。例如：\n\n打印的结果应该是：\n15 \n1 17 20 \n1 5 0 2 5 7\n\nfunc printEachLevel&lt;T&gt;(for tree: TreeNode&lt;T&gt;) &#123;\n    var queue &#x3D; Array&lt;TreeNode&lt;T&gt;&gt;()\n    var nodesLeftInCurrentLevel &#x3D; 0\n    queue.append(tree)\n    \n    while !queue.isEmpty &#123;\n        nodesLeftInCurrentLevel &#x3D; queue.count\n        while nodesLeftInCurrentLevel &gt; 0 &#123;\n            guard let node &#x3D; queue.isEmpty ? nil : queue.removeFirst()  else &#123; break &#125;\n            print(&quot;\\(node.value)&quot;, terminator: &quot; &quot;)\n            node.children.forEach &#123; queue.append($0) &#125;\n            nodesLeftInCurrentLevel -&#x3D; 1\n        &#125;\n        print()\n    &#125;\n&#125;","slug":"2019-12-23-Data-Structures-&-Algorithms-in-Swift-09","date":"2023-05-13T11:29:06.795Z","categories_index":"Data Structures & Algorithms in Swift","tags_index":"Swift中的数据结构与算法"},{"id":"0e0f6f0242f4e4a48493fd0fe5fe0ab7","title":"\\#10\\ 二叉树及其有序、前序和后序遍历","content":"在上一文中认识了一般树结构，其每一个节点可能会有多个子节点。二叉树也是树型结构，只不过其每一个节点最多只有两个节点，通常称为左节点和右节点。\n\n二叉树的Swift实现首先定义二叉树的基本属性，如下：\npublic class BinaryNode&lt;Element&gt; &#123;\n    public var value: Element\n    public var leftChild: BinaryNode?\n    public var rightChild: BinaryNode?\n    \n    public init(_ value: Element) &#123;\n        self.value &#x3D; value\n    &#125;\n&#125;\n\n有了二叉树的基本属性之后，就可以定义一颗二叉树了，如下：\nvar tree: BinaryNode&lt;Int&gt; &#x3D; &#123;\n    let zero &#x3D; BinaryNode(value: 0)\n    let one &#x3D; BinaryNode(value: 1)\n    let five &#x3D; BinaryNode(value: 5)\n    let seven &#x3D; BinaryNode(value: 7)\n    let eight &#x3D; BinaryNode(value: 8)\n    let nine &#x3D; BinaryNode(value: 9)\n    \n    seven.leftChild &#x3D; one\n    one.leftChild &#x3D; zero\n    one.rightChild &#x3D; five\n    seven.rightChild &#x3D; nine\n    nine.leftChild &#x3D; eight\n    \n    return seven\n&#125;()\n\n该二叉树的形态即如下图：\n\n二叉树图数据结构的图像化能够帮助进一步理解数据结构，为了能够更加清晰的查看二叉树的树形结构，这里我们构造一个打印函数，以在Console中打印出二叉树的树形结构图。\nextension BinaryNode: CustomStringConvertible &#123;\n    public var description: String &#123;\n        return diagram(for: self)\n    &#125;\n    \n    private func diagram(for node: BinaryNode?,\n                         _ top: String &#x3D; &quot;&quot;,\n                         _ root: String &#x3D; &quot;&quot;,\n                         _ bottom: String &#x3D; &quot;&quot;) -&gt; String &#123;\n        guard let node &#x3D; node else &#123;\n            return root + &quot;nil \\n&quot;\n        &#125;\n        if node.leftChild &#x3D;&#x3D; nil &amp;&amp; node.rightChild &#x3D;&#x3D; nil &#123;\n            return root + &quot;\\(node.value)\\n&quot;\n        &#125;\n        return diagram(for: node.rightChild,\n                       top + &quot; &quot;,\n                       top + &quot;┌──&quot;,\n                       top + &quot;│ &quot;) + root + &quot;\\(node.value)\\n&quot; + diagram(for: node.leftChild,\n                                                                          bottom + &quot;│ &quot;,\n                                                                          bottom + &quot;└──&quot;,\n                                                                          bottom + &quot; &quot;)\n    &#125;\n&#125;\n\n然后对前面构建的二叉树进行打印，输出如下：\n---Example of tree diagram---\n ┌──nil \n┌──9\n│ └──8\n7\n│ ┌──5\n└──1\n └──0\n\n遍历算法在一般树中学习了深度优先和广度优先两种树型结构的遍历算法，经过小小的改动后，这两种遍历算法同样适用于二叉树的遍历。但是在二叉树结构中，更加关注的是另外三种遍历算法：有序、前序和后序遍历。\n有序遍历有序遍历按照如下的顺序遍历节点：\n\n如果当前节点有左节点，则递归访问该节点的子节点；\n然后访问当前节点\n如果当前节点有有节点，则继续递归遍历该节点的子节点。\n\n\n算法实现如下：\nextension BinaryNode &#123;\n    public func traverseInOrder(visit: (Element) -&gt; Void) &#123;\n        leftChild?.traverseInOrder(visit: visit)\n        visit(value)\n        rightChild?.traverseInOrder(visit: visit)\n    &#125;\n&#125;\n\nexample(of: &quot;in-order traversal&quot;) &#123;\n    tree.traverseInOrder &#123;\n        print($0)\n    &#125;\n&#125;\n\n&#x2F;*\n---Example of in-order traversal---\n0\n1\n5\n7\n8\n9\n*&#x2F;\n\n前序遍历前序遍历总是先访问当前节点，然后递归遍历左节点和有节点。\n\npublic func traversePreOrder(visit: (Element) -&gt; Void) &#123;\n    visit(value)\n    leftChild?.traversePreOrder(visit: visit)\n    rightChild?.traversePreOrder(visit: visit)\n&#125;\n\nexample(of: &quot;pre-order traversal&quot;) &#123;\n    tree.traversePreOrder &#123;\n        print($0)\n    &#125;\n&#125;\n&#x2F;*\n---Example of ore-order traversal---\n7\n1\n0\n5\n9\n8\n*&#x2F;\n\n后序遍历后序遍历总是先递归访问当前节点的左节点和右节点，然后在访问当前节点。\n\npublic func traversePostOrder(visit: (Element) -&gt; Void) &#123;\n    leftChild?.traversePostOrder(visit: visit)\n    rightChild?.traversePostOrder(visit: visit)\n    visit(value)\n&#125;\n\nexample(of: &quot;post-order traversal&quot;) &#123;\n    tree.traversePostOrder &#123;\n        print($0)\n    &#125;\n&#125;\n&#x2F;*\n---Example of post-order traversal---\n0\n5\n1\n8\n9\n7\n*&#x2F;\n\n关键点总结\n二叉树数据结构是其他树形数据结构的基础，很多类型的树例如二叉搜索树、AVL树等，都以二叉树为基础，并在其上增加插入和删除等操作行为；\n有序、前序和后序并不仅仅针对二叉树非常重要，在其他的树形结构中，这些遍历算法依然有效且重要。\n\n","slug":"2019-12-25-Data-Structures-&-Algorithms-in-Swift-10","date":"2023-05-13T11:29:06.795Z","categories_index":"Data Structures & Algorithms in Swift","tags_index":"Swift中的数据结构与算法"},{"id":"1c072eaf9d0ebbcfebf6203a3cb43879","title":"\\#11\\ 二叉搜索树","content":"二叉搜索树又称为二叉查找树（BST），是一种支持快速查找、插入和删除操作的树结构，例如下方的决策树，其中选择一方而放弃另一方的所有可能性，从而将问题减半。\n\n在决策树中，一旦做出了决定并选择了某个分支，便不能回头，在选择的分支上一直查找直到叶子节点，得到最终决定。二叉搜索树在上一文中的二叉树的基础上增加了以下两个规则：\n\n左节点的值必须小于父节点的值；\n同样的，右节点的值必须大于等于其父节点的值。\n\n二叉搜索树使用这两个规则可避免执行不必要的检查，其查找、插入和删除的平均时间复杂度为O(log n)，比线性结构快的多。\nArray vs. BST例如有如下的两种结构的集合：\n\n上面的结构为数组，下方的为二叉搜索树结构。\n搜索对于未排序的数组来说，搜索只能从开头到结尾，例如搜索元素105。\n\n这也是为什么*array.contains(:)*操作为O(n)的原因。\n\n使用二叉搜索树的数据结构，搜索同样的元素105，简单且高效的多。因为搜索算法每次访问节点的时候，都会遵循如下两个原则：\n\n如果目标搜索值小于当前节点的值，那么目标搜索值一定在当前节点的左树中；\n如果目标搜索值大于当前节点的值，那么目标搜索值一定在当前节点的右树中。\n\n通过BST的这些搜索原则，可以避免一些数据项检查，减半搜索空间，这也是BST中搜索算法的时间复杂度为O(log n)的原因。\n插入对于数组来说，如果要插入一个元素，需要将插入位置之后的所有元素向后移动一个位置，这也是为什么对于数组的插入算法，时间复杂度为O(n)的原因。\n\n而对于二叉搜索树来说，插入一个新的元素，相对舒服的多。\n\n由于二叉搜索树的规则，小于当前节点元素值的节点一定在当前节点的左树或左节点，因此插入一个新的元素的时候，可以减少一半的检查时间。例如上图中，在现有的二叉搜索树中插入新的元素1。二叉搜索树的插入算法，时间复杂度应该为O(log n)。\n移除和插入类似，数组的元素移除同样需要移动删除目标元素之后的所有元素的位置，因此其时间复杂度依然是O(n)。\n\n对于二叉搜索树来说，会由两种情况，当删除的节点是叶子节点的时候，相对较为简单，但是如果待删除的节点有子节点的时候，相对要进行一些复杂的管理工作。\n\n结构与算法实现public struct BinarySearchTree&lt;Element: Comparable&gt; &#123;\n    public private(set) var root: BinaryNode&lt;Element&gt;?\n    public init() &#123;&#125;\n&#125;\n\nextension BinarySearchTree: CustomStringConvertible &#123;\n    public var description: String &#123;\n        guard let root &#x3D; root else &#123;\n            return &quot;Empty tree&quot;\n        &#125;\n        return String(describing: root)\n    &#125;\n&#125;\n\n二叉搜索树的本质是二叉树，因此在二叉搜索树的内部，定义的节点类型为BinaryNode，并且二叉搜索树中的元素时可比较的。\n插入算法二叉树的基本准则是：\n\n左节点的值必须小于父节点的值；\n同样的，右节点的值必须大于等于其父节点的值。\n\n依据这两个准则，即可实现二叉搜索树的插入算法：\nextension BinarySearchTree &#123;\n    public mutating func insert(_ value: Element) &#123;\n        root &#x3D; insert(from: root, value: value)\n    &#125;\n    \n    private func insert(from node: BinaryNode&lt;Element&gt;?, value: Element) -&gt; BinaryNode&lt;Element&gt; &#123;\n        &#x2F;&#x2F; 如果是空的树，则直接使用当前值构建一个节点返回\n        guard let node &#x3D; node else &#123;\n            return BinaryNode(value: value)\n        &#125;\n        &#x2F;&#x2F; 插入到左树\n        if value &lt; node.value &#123;\n            node.leftChild &#x3D; insert(from: node.leftChild, value: value)\n        &#125; else &#123;\n            &#x2F;&#x2F; 插入到右树\n            node.rightChild &#x3D; insert(from: node.rightChild, value: value)\n        &#125;\n        return node\n    &#125;\n&#125;\n\nexample(of: &quot;building a BST&quot;) &#123;\n    var bst &#x3D; BinarySearchTree&lt;Int&gt;()\n    for i in 0 ..&lt; 5 &#123;\n        bst.insert(i)\n    &#125;\n    print(bst)\n&#125;\n\n&#x2F;*\n---Example of building a BST---\n   ┌──4\n  ┌──3\n  │ └──nil \n ┌──2\n │ └──nil \n┌──1\n│ └──nil \n0\n└──nil \n*&#x2F;\n\n\n然而，对于上述构建的BST，貌似是不平衡的，二叉树的节点均在根节点的右树上，而理想的状态应该是上图中右侧的部分。如果此时插入新的元素5，则会出现如下情况：\n\n\n\n\n\n\n\n\n\n\n解决方案是构建自平衡树的结构，自平衡树这里不进行详述。\n为了防止树结构的不平衡，这里仅仅使用最为笨重的方式构建一个平衡的二叉树。\nvar exampleTree: BinarySearchTree&lt;Int&gt; &#123;\n    var bst &#x3D; BinarySearchTree&lt;Int&gt;()\n    bst.insert(3)\n    bst.insert(1)\n    bst.insert(4)\n    bst.insert(0)\n    bst.insert(2)\n    bst.insert(5)\n    return bst\n&#125;\n\nexample(of: &quot;building a balanced BST&quot;) &#123;\n    print(exampleTree)\n&#125;\n\n&#x2F;*\n---Example of building a balanced BST---\n ┌──5\n┌──4\n│ └──nil \n3\n│ ┌──2\n└──1\n └──0\n*&#x2F;\n\n元素搜索二叉搜索树元素的搜索需要遍历二叉树的各个节点，因此可以使用上一文中实现的二叉树相关遍历算法 — 有序、前序和后序。\nextension BinarySearchTree &#123;\n    public func contains(_ value: Element) -&gt; Bool &#123;\n        guard let root &#x3D; root else &#123;\n            return false\n        &#125;\n        var found &#x3D; false\n        root.traverseInOrder &#123;\n            if $0 &#x3D;&#x3D; value &#123;\n                found &#x3D; true\n            &#125;\n        &#125;\n        return found\n    &#125;\n&#125;\n\n例如搜索上述二叉搜索树中是否包含元素5：\nexample(of: &quot;finding a node&quot;) &#123;\n    if exampleTree.contains(5) &#123;\n        print(&quot;Found 5!&quot;)\n    &#125; else &#123;\n      print(&quot;Couldn&#39;t find 5&quot;)\n    &#125;\n&#125;\n\n&#x2F;*\n---Example of finding a node---\nFound 5!\n*&#x2F;\n\n这里的元素搜索算法使用了有序遍历的方法，因此其时间复杂度也为O(n)。但是该复杂度的搜索算法存在可优化的空间，由于二叉搜索树有左节点小于父节点，右节点大于父节点的特性，因此在元素搜索的时候，可以利用该属性减少搜索检查的范围，进一步优化搜索耗时等。\n优化元素的搜索算法如下：\npublic func containsOpt(_ value: Element) -&gt; Bool &#123;\n    var current &#x3D; root\n    while let node &#x3D; current &#123;\n        if node.value &#x3D;&#x3D; value &#123;\n            return true\n        &#125;\n        \n        if value &lt; node.value &#123;\n            current &#x3D; node.leftChild\n        &#125; else &#123;\n            current &#x3D; node.rightChild\n        &#125;\n    &#125;\n    return false\n&#125;\n\n优化的算法时间复杂度为O(log n)。\n移除元素二叉搜索树元素的移除相对元素的搜索和插入复杂一些，有如下三种场景需要考虑：\nCase 1：叶子节点\n对于待删除的元素所在的节点为叶子节点时，是最为简单直接的场景，直接分类该节点和其父节点的链接即可。\n\nCase 2：有一个子节点的节点\n当待删除的元素所在的节点拥有一个子节点的时候，不仅仅要删除该节点，还需要将该节点的字节点和树的其余节点进行重新链接，一般情况下，会重新和删除节点的原始父节点进行链接。\n\nCase 3：有两个子节点的节点\n当待删除节点拥有两个子节点的时候，删除操作相对较为复杂一点。例如下图二叉搜索树，想要删除的元素为25：\n\n如果只是简单的删除节点25，如下：\n\n此时虽然删除掉了节点25，但是带来了另一个问题。当删除掉节点25之后，会出现两个需要重建链接的节点12和37，此时原节点25的父节点却只有一个子节点的空间，如果如上图那样建立链接的话，会导致该二叉搜索树不成立。为了解决此问题，需要对节点的链接进行交换，使得删除节点后的二叉搜索树依然成立。\n方法就是，删除拥有两个节点的节点之后，使用其右侧子树中最小的节点替换删除的节点，根据二叉搜索树的特点，最小的节点即为右侧子树中最左的节点。\n\n这样进行节点交换之后，二叉搜索树依然有效，因为新节点是右子树中的最小节点，所以右子树中的所有节点仍将大于或等于新节点。并且由于新节点来自右子树，因此左子树中的所有节点都小于新节点。\n算法实现\nprivate extension BinaryNode &#123;\n    var min: BinaryNode &#123;\n        return leftChild?.min ?? self\n    &#125;\n&#125;\n\nextension BinarySearchTree &#123;\n    public mutating func remove(_ value: Element) &#123;\n        root &#x3D; remove(node: root, value: value)\n    &#125;\n    \n    private func remove(node: BinaryNode&lt;Element&gt;?, value: Element) -&gt; BinaryNode&lt;Element&gt;? &#123;\n        guard let node &#x3D; node else &#123;\n            return nil\n        &#125;\n        \n        if value &#x3D;&#x3D; node.value &#123;\n            if node.leftChild &#x3D;&#x3D; nil &amp;&amp; node.rightChild &#x3D;&#x3D; nil &#123;\n                return nil\n            &#125;\n            if node.leftChild &#x3D;&#x3D; nil &#123;\n                return node.rightChild\n            &#125;\n            if node.rightChild &#x3D;&#x3D; nil &#123;\n                return node.leftChild\n            &#125;\n            node.value &#x3D; node.rightChild!.min.value\n            node.rightChild &#x3D; remove(node: node.rightChild, value: node.value)\n        &#125; else if value &lt; node.value &#123;\n            node.leftChild &#x3D; remove(node: node.leftChild, value: value)\n        &#125; else &#123;\n            node.rightChild &#x3D; remove(node: node.rightChild, value: value)\n        &#125;\n        return node\n    &#125;\n&#125;\n\nexample(of: &quot;removing a node&quot;) &#123;\n    var tree &#x3D; exampleTree\n    print(&quot;Tree before removal:&quot;)\n    print(tree)\n    tree.remove(3)\n    print(&quot;Tree after removing root:&quot;)\n    print(tree)\n&#125;\n\n&#x2F;*\n---Example of removing a node---\nTree before removal:\n ┌──5\n┌──4\n│ └──nil \n3\n│ ┌──2\n└──1\n └──0\n\nTree after removing root:\n┌──5\n4\n│ ┌──2\n└──1\n └──0\n*&#x2F;\n\n关键点总结\n二叉搜索树是一种存储排序数据的数据结构；\n二叉搜索树的插入、移除和查找算法的平均时间复杂度为O(log n)；\n当树不平衡的时候，时间复杂度会降低到O(n)。\n\n","slug":"2019-12-25-Data-Structures-&-Algorithms-in-Swift-11","date":"2023-05-13T11:29:06.795Z","categories_index":"Data Structures & Algorithms in Swift","tags_index":"Swift中的数据结构与算法"},{"id":"4085c41c06b2e3ba45ef163b731b2c76","title":"\\#12\\ 自平衡二叉搜索树（AVL Trees）","content":"在上文中，已经了解二叉搜索树的O(log n)性能特征，但是当二叉搜索树节点删除中，可能会出现不平衡的树，并降低树的性能到O(n)。这一文的内容将学习另一种改进了的二叉搜索树 — 自平衡二叉搜索树。\n\n\n\n\n\n\n\n\n\n1962年，Georgy Adelson-Velsky和Evgenii Landis提出了第一个自平衡二进制搜索树：AVL树。\n理解什么是平衡自平衡二叉搜索树，简称平衡树，是在二叉搜索树的基础上改进的，首先了解一下平衡树的三种平衡状态。\n完全平衡树\n二叉搜索树的理想形式便是完全平衡状态，也就是说二叉搜索树的每个层级从上之下均存在节点。\n\n完全平衡树不仅仅整棵树是对称的，而且最底部的叶子都均存在节点。\n“够好”的平衡树\n尽管完全平衡是理想的平衡树状态，但是在现实中往往难以实现，要达到完全平衡的树结构，需要节点有确切的数量，才有可能达到完全平衡，因此只有一定数量的元素才能平衡。\n例如一棵树有1个、3个、4个节点的时候，是可以达到完全平衡的，但是当树有2个、4个、5个或6个节点的时候，却不能达到完全平衡，因为树的最后一层无法完全被填满。\n\n平衡树的定义是树的每一个层级必须被填满（底部层级除外）。在大多数情况下，二叉树是可以做到的最好的结构。\n不平衡树\n最后一种状态是不平衡的状态，二叉搜索树的不平衡状态会带来各种等级的性能损失。\n\n保持树的平衡会带来查找、插入和移除元素操作O(log n)的时间复杂度。当树的结构不平衡是，AVL树会自动调整树的结构，使得树结构保持平衡，从而带来良好地时间复杂度等。\n实现AVL树和二叉搜索树有很多地方都是相同的实现，但是为了便于区分，我们将新建文件重新编写关于AVL树的实现。\n平衡度衡量要确保二叉树的平衡，就需要一种能够衡量二叉树是否平衡的方法。在AVL树中，每个节点都有一个 height 属性，该属性描述了当前节点到叶子节点的最长距离。\n\n我们新建AVLNode类，添加存储节点高度的变量：\npublic var height &#x3D; 0\n\n在使用中，将使用节点的相对高度来确定节点是否平衡。\nAVL树中左节点和有节点的高度差最多相差1，这个差值称之为平衡因子。为了计算的方便，对节点增加如下变量：\npublic var balanceFactor: Int &#123;\n    return leftHeight - rightHeight\n&#125;\n    \npublic var leftHeight: Int &#123;\n    return leftChild?.height ?? -1\n&#125;\n    \npublic var rightHeight: Int &#123;\n    return rightChild?.height ?? -1\n&#125;\n\nbalanceFactor平衡因子计算的是左树和右树的高度差，如果子节点为nil，则节点的高度为-1。例如：\n\n该树是一个平衡的二叉树，但是如果增加一个节点40的话，就会改变为不平衡的树：\n\n从图中的平衡因子即可判断出该树处于一个不平衡的状态。为了使得不平衡树改变形态，而成为平衡树，需要进一步的操作。\n旋转应用于二叉搜索树，使得其平衡的操作称之为旋转。共有四种选装的操作，分别是左旋转、左-右旋转、右旋转、右-左旋转。\n左旋转\n例如上述不平衡的二叉树中，插入节点40导致树处于不平衡的状态，而是用左旋转可以解决此不平衡问题。左旋转的工作原理如下图：\n\n树在旋转前后会由两点不同之处：\n\n树节点的有序遍历保持不变；\n旋转后，树的深度减少一级。\n\nprivate func leftRotate(_ node: AVLNode&lt;Element&gt;) -&gt; AVLNode&lt;Element&gt; &#123;\n    let pivot &#x3D; node.rightChild!\n    node.rightChild &#x3D; pivot.leftChild\n    pivot.leftChild &#x3D; node\n    \n    node.height &#x3D; max(node.leftHeight, node.rightHeight) + 1\n    pivot.height &#x3D; max(pivot.leftHeight, pivot.rightHeight) + 1\n    \n    return pivot\n&#125;\n\n\n右旋转\n右旋转和左旋转类似，如果是由于左节点导致了树不平衡，则使用右旋转的方式，其原理如下：\n\nprivate func rightRotate(_ node: AVLNode&lt;Element&gt;) -&gt; AVLNode&lt;Element&gt; &#123;\n    let pivot &#x3D; node.leftChild!\n    node.leftChild &#x3D; pivot.rightChild\n    pivot.rightChild &#x3D; node\n        \n    node.height &#x3D; max(node.leftHeight, node.rightHeight) + 1\n    pivot.height &#x3D; max(pivot.leftHeight, pivot.rightHeight) + 1\n    \n    return pivot\n&#125;\n\n右-左旋转\n左旋转和右旋转的操作都有一个特点是：均平衡了树的左节点或右节点。假设有如下的不平衡树：\n\n单纯使用左旋转不能得到平衡树，针对此种情况可以先进行右旋转，使得节点均有右节点，然后再使用左旋转，以达到平衡树状态。\n\nprivate func rightLeftRotate(_ node: AVLNode&lt;Element&gt;) -&gt; AVLNode&lt;Element&gt; &#123;\n    guard let rightChild &#x3D; node.rightChild else &#123;\n        return node\n    &#125;\n    \n    node.rightChild &#x3D; rightRotate(rightChild)\n    return leftRotate(node)\n&#125;\n\n左-右旋转\n左-右旋转和右-左旋转针对的情形类似，当单纯使用左旋转无法达到平衡的时候，根据节点的情况，再次进行右旋转，以达到平衡状态。\n\nprivate func leftRightRotate(_ node: AVLNode&lt;Element&gt;) -&gt; AVLNode&lt;Element&gt; &#123;\n    guard let leftChild &#x3D; node.leftChild else &#123;\n        return node\n    &#125;\n    \n    node.leftChild &#x3D; leftRotate(leftChild)\n    return rightRotate(node)\n&#125;\n\n平衡进行了树的节点旋转后，虽然形态上会达到平衡，但是某些节点可能破坏了二叉搜索树的特性，因此还需要根据不同的情形，对数的节点进行交换，这里交换的根据是根据节点的平衡因子进行不同的操作。算法结构如下：\nprivate func balanced(_ node: AVLNode&lt;Element&gt;) -&gt; AVLNode&lt;Element&gt; &#123;\n  switch node.balanceFactor &#123;\n  case 2:\n    &#x2F;&#x2F; ...\n  case -2:\n    &#x2F;&#x2F; ...\n  default:\n    return node\n  &#125;\n&#125;\n\n该算法会根据三种情况进行节点的转换：\n\n平衡因子balanceFactor为2的时候，表示节点的左子节点多于右子节点，意味着节需要使用右旋或者左-右旋转；\n平衡因子balanceFactor为-2的时候，表示节点的右子节点多于左子节点，意味着需要使用左旋或者右-左旋转；\n除了这两种情况之外，表示当前节点处于平衡状态，不需要进行任何的转换。\n\n平衡因子balanceFactor符号能够确定需要使用单旋还是双旋。\n\n完整的算法如下：\nprivate func balanced(_ node: AVLNode&lt;Element&gt;) -&gt; AVLNode&lt;Element&gt; &#123;\n    switch node.balanceFactor &#123;\n    case 2:\n        if let leftChild &#x3D; node.leftChild, leftChild.balanceFactor &#x3D;&#x3D; -1 &#123;\n            return leftRightRotate(node)\n        &#125; else &#123;\n            return rightRotate(node)\n        &#125;\n    case -2:\n        if let rightChild &#x3D; node.rightChild, rightChild.balanceFactor &#x3D;&#x3D; 1 &#123;\n            return rightLeftRotate(node)\n        &#125; else &#123;\n            return leftRotate(node)\n        &#125;\n    default:\n        return node\n    &#125;\n&#125;\n\n节点的插入至此，节点调整，使得树平衡的工作已经完成了，而该平衡操作大部分情况下是在向树插入新的节点的时候进行的，因此完成插入算法如下：\npublic mutating func insert(_ value: Element) &#123;\n    root &#x3D; insert(from: root, value: value)\n&#125;\n    \nprivate func insert(from node: AVLNode&lt;Element&gt;?, value: Element) -&gt; AVLNode&lt;Element&gt; &#123;\n    guard let node &#x3D; node else &#123;\n        return AVLNode(value: value)\n    &#125;\n    if value &lt; node.value &#123;\n        node.leftChild &#x3D; insert(from: node.leftChild, value: value)\n    &#125; else &#123;\n        node.rightChild &#x3D; insert(from: node.rightChild, value: value)\n    &#125;\n        \n    let balancedNode &#x3D; balanced(node)\n    balancedNode.height &#x3D; max(balancedNode.leftHeight, balancedNode.rightHeight) + 1\n    return balancedNode\n&#125;\n\n节点的插入算法也适用于新建一颗AVL树，例如：\nexample(of: &quot;repeated insertions in sequence&quot;) &#123;\n    var tree &#x3D; AVLTree&lt;Int&gt;()\n    for i in 0 ..&lt; 15 &#123;\n        tree.insert(i)\n    &#125;\n    print(tree)\n&#125;\n\n&#x2F;*\n---Example of repeated insertions in sequence---\n  ┌──14\n ┌──13\n │ └──12\n┌──11\n│ │ ┌──10\n│ └──9\n│  └──8\n7\n│  ┌──6\n│ ┌──5\n│ │ └──4\n└──3\n │ ┌──2\n └──1\n  └──0\n*&#x2F;\n\n节点的移除移除树中的节点，也会导致树不平衡，因此在移除算法中也需要对树的平衡性进行调整。\npublic mutating func remove(_ value: Element) &#123;\n    root &#x3D; remove(from: root, value: value)\n&#125;\n\nprivate func remove(from node: AVLNode&lt;Element&gt;?, value: Element) -&gt; AVLNode&lt;Element&gt;? &#123;\n    guard let node &#x3D; node else &#123;\n        return nil\n    &#125;\n        \n    if value &#x3D;&#x3D; node.value &#123;\n        if node.leftChild &#x3D;&#x3D; nil &amp;&amp; node.rightChild &#x3D;&#x3D; nil &#123;\n            return nil\n        &#125;\n        if node.leftChild &#x3D;&#x3D; nil &#123;\n            return node.rightChild\n        &#125;\n        if node.rightChild &#x3D;&#x3D; nil &#123;\n            return node.leftChild\n        &#125;\n        node.value &#x3D; node.rightChild!.min.value\n        node.rightChild &#x3D; remove(from: node.rightChild, value: node.value)\n    &#125; else if value &lt; node.value &#123;\n        node.leftChild &#x3D; remove(from: node.leftChild, value: value)\n    &#125; else &#123;\n        node.rightChild &#x3D; remove(from: node.rightChild, value: value)\n    &#125;\n        \n    let balancedNode &#x3D; balanced(node)\n    balancedNode.height &#x3D; max(balancedNode.leftHeight, balancedNode.rightHeight) + 1\n    return balancedNode\n&#125;\n\n测试如下：\nexample(of: &quot;removing a vaue&quot;) &#123;\n    var tree &#x3D; AVLTree&lt;Int&gt;()\n    tree.insert(15)\n    tree.insert(10)\n    tree.insert(16)\n    tree.insert(18)\n    print(tree)\n    \n    tree.remove(10)\n    print(tree)\n&#125;\n\n&#x2F;*\n---Example of removing a vaue---\n ┌──18\n┌──16\n│ └──nil \n15\n└──10\n\n┌──18\n16\n└──15\n*&#x2F;\n\n移除了元素10之后，树进行了平衡调整（左旋），依然保持树的平衡性。由于节点的插入和移除操作同于二叉搜索树，因此其时间复杂度依然是O(log n)。\n关键点总结\n自平衡树在节点的插入和移除过程中，增加平衡性调节操作，保持其执行效率不会降低；\nAVL树在树不平衡的情况下，通过重新调整树的部分节点，而使得树保持平衡。\n\n","slug":"2019-12-27-Data-Structures-&-Algorithms-in-Swift-12","date":"2023-05-13T11:29:06.795Z","categories_index":"Data Structures & Algorithms in Swift","tags_index":"Swift中的数据结构与算法"},{"id":"7c0350b0f98d8a7fc26f52b6c73852fb","title":"\\#13\\ 字典树（Tries Tree）","content":"Tries 是一颗用于存储可以表示为集合的数据的树，又称前缀树或字典树，是一种有序树，用于保存关联数组，其中的键通常是字符串。与二叉查找树不同，键不是直接保存在节点中，而是由节点在树中的位置决定。一个节点的所有子孙都有相同的前缀，也就是这个节点对应的字符串，而根节点对应空字符串。一般情况下，不是所有的节点都有对应的值，只有叶子节点和部分内部节点所对应的键才有相关的值。\n例如利用Tries表示一个英语单词，可以表示如下：\n\n字符串中的每一个字符被表示为一个节点，字符串中最后的节点会使用带有点号标识来标记为终止节点。通过在前缀匹配的上下文中查看字典树，会发现字典树的众多优点。\nExample假设有一个字符串的集合，该如何构建每一个字符串的前缀匹配逻辑呢？\nclass EnglishDictionary &#123;\n    private var words: [String]\n    \n    func words(matching prefix: String) -&gt; [String] &#123;\n        return words.filter &#123; $0.hasPrefix(prefix) &#125;\n    &#125;\n&#125;\n\n*words(matching:)*方法将会遍历字符串集合并返回与预设前缀匹配的字符串。\n当words数组中的字符串个数比较少的时候，上述方法是可行且高效的，但是当字符串集合中的字符串数量到达几千，上述方法仅仅在数组的遍历上就会形成性能瓶颈。上述方法的时间复杂度为O(k * n)，其中k为字符串集合中最长的字符串，n 为字符串集合中需要检查的字符串数量。\n对于此类问题，Tries数据结构有着出色的性能表现，作为具有支持多个子节点的节点的树，每个节点可以代表一个字符。通过跟踪从根节点到用点号标识的特殊终止节点的集合，形成一系列的单词组合。Tries的特点也是多个预表示的结果会共享节点集合。\n为了进一步的了解和说明Tries的性能，假设已有如下的Tries结构，从中找出前缀CU代表的单词。\n\n首先，从根节点出发，找到包含字符C的节点，找到后，就可以排除一些其他的子树，例如上图中根节点的两个子树。\n然后，需要以C节点开始，在其子节点中寻找包含字符U的节点，如下：\n\n既然匹配的是前缀，因此在上图中以CU为前缀的节点将会被返回，上例中将返回CUT或CUTE。想象如果有上百上千的字符串，需要匹配前缀CU，Tries的数据结构可以避免多次的数据比较，提高匹配性能等。\n\n结构实现Tries本质上也是树型数据结构，因此会有节点，首先实现其节点的数据结构。\nTrieNodepublic class TrieNode&lt;Key: Hashable&gt; &#123;\n    public var key: Key?\n    public weak var parent: TrieNode?\n    public var children: [Key: TrieNode] &#x3D; [:]\n    public var isTerminating &#x3D; false\n    \n    public init(key: Key?, parent: TrieNode?) &#123;\n        self.key &#x3D; key\n        self.parent &#x3D; parent\n    &#125;\n&#125;\n\nTries的节点结构和其他树型数据结构有明显的不同。\n\nkey： 存储节点的数据。由于根节点不存储数据，因此该属性为optional类型；\nparent：当前节点父节点的弱引用，在节点的删除中将会利用此属性高效完成节点删除操作；\nchildren：在BST中，一个节点拥有左节点和右节点，在Tries中，一个节点会持有多个不同的元素，因此children被定义为字典类型；\nisTerminating：标记当前节点是否是集合的终止节点。\n\nTriepublic class Trie&lt;CollectionType: Collection&gt; where CollectionType.Element: Hashable&#123;\n    \n    public typealias Node &#x3D; TrieNode&lt;CollectionType.Element&gt;\n    private let root &#x3D; Node(key: nil, parent: nil)\n    \n    public init() &#123;&#125;\n&#125;\n Trie类是为所有采用Collection协议的类型构建的，包括String。除此之外，集合中的每一个元素都是可哈希的，因为集合中的每一个元素都会作为TrieNode中children的key。\n 基本的结构完成了，接下来就是为Trie实现基本的节点操作方法，包括insert、contains、remove以及前缀匹配算法。\n操作算法实现InsertTrie结构可以适用于任何Collection的类型，Trie采用集合并将集合中的每一个元素表示为一个节点，节点和元素之间形成映射的关系。\npublic func insert(_ collection: CollectionType) &#123;\n    var current &#x3D; root\n        \n    for element in collection &#123;\n        if current.children[element] &#x3D;&#x3D; nil &#123;\n            current.children[element] &#x3D; Node(key: element, parent: current)\n        &#125;\n        current &#x3D; current.children[element]!\n    &#125;\n        \n    current.isTerminating &#x3D; true\n&#125;\n\n\ncurrent 变量保持着对遍历进度的追踪，开始于Trie树的根节点;\nTrie树的每一个节点与集合中的每一个元素相对应。对于集合中的每一个元素，首先要检查子节点字典中是否存在当前元素，如果不存在，则创建一个新节点，之后将循环移至下一个分支节点；\nfor循环迭代完成之后，current指向集合中最后一个元素，也就是current节点已经是终止节点了，此时设置其终止标志isTerminating为true。\n\n该操作的时间复杂度为O(k)，其中 k 是待插入元素的集合中元素的个数。因为在插入算法中，需要遍历集合中的每一个元素，并可能为每一个元素创建新的节点。\nContainscontains 非常类似于 insert 算法，其目标是检查集合中的元素在Trie中是否存在。\nextension Trie &#123;\n    public func contains(_ collection: CollectionType) -&gt; Bool &#123;\n        var current &#x3D; root\n        \n        for element in collection &#123;\n            guard let child &#x3D; current.children[element] else &#123;\n                return false\n            &#125;\n            \n            current &#x3D; child\n        &#125;\n        return current.isTerminating\n    &#125;\n&#125;\n\n对集合的遍历类似于insert，如果集合中的元素在Trie中不存在，则直接返回，否则依次移动current至子节点，继续遍历检查，直到元素遍历完成，此时current节点是否为终止节点，即为返回结果。如果最终所有的元素都没有在Trie树中找到，则该集合并没有添加到Trie树中，可能其只是更大集合的一个子集而已。\n该操作的时间复杂度为O(k)，同样的 k 是待查找的集合中元素的个数。因为需要对集合中的每一个元素进行遍历，以检查其是否处于Trie树中。\nexample(of: &quot;insert and contains&quot;) &#123;\n    let trie &#x3D; Trie&lt;String&gt;()\n    trie.insert(&quot;cute&quot;)\n    trie.insert(&quot;cut&quot;)\n    if trie.contains(&quot;cute&quot;) &#123;\n        print(&quot;cute is in the trie&quot;)\n    &#125;\n&#125;\n\n&#x2F;*\n---Example of insert and contains---\ncute is in the trie\n*&#x2F;\n\n\nRemove移除Trie树中的一个节点相对复杂一点，尤其当一个节点被两个不同的集合所共享的时候，需要更加的小心。\nextension Trie &#123;\n    public func remove(_ collection: CollectionType) &#123;\n        var current &#x3D; root\n        for element in collection &#123;\n            guard let child &#x3D; current.children[element] else &#123;\n                return\n            &#125;\n            current &#x3D; child\n        &#125;\n        \n        guard current.isTerminating else &#123;\n            return\n        &#125;\n        current.isTerminating &#x3D; false\n        while let parent &#x3D; current.parent, current.children.isEmpty &amp;&amp; !current.isTerminating &#123;\n            parent.children[current.key!] &#x3D; nil\n            current &#x3D; parent\n        &#125;\n    &#125;\n&#125;\n\n\n准备移除之前的检查工作，类似于contains操作。在这里是为了检查集合是否存在于Trie树中，以及将current指向集合的最后一个节点；\n设置current节点的isTerminating为false，目的是为了在下一次的循环中，节点能够被移除掉；\n最后的while循环是相对棘手的部分。因为节点是可以被共享的，因此不希望在删除节点时误删掉另一个集合中的节点，如果当前节点再无子节点，则说明其他集合不依赖当前节点。同时还需检查当前节点是否为终止节点，如果是终止节点，则说明当前节点属于另一个集合，不能进行删除，如果不是终止节点，就可以不断的使用回溯父节点属性，并进行对应元素的删除。\n\n该操作的时间复杂度为O(k)，其中 k  是待删除集合中元素的个数。\nexample(of: &quot;remove&quot;) &#123;\n    let trie &#x3D; Trie&lt;String&gt;()\n    trie.insert(&quot;cut&quot;)\n    trie.insert(&quot;cute&quot;)\n    \n    print(&quot;\\n*** Before removeing ***&quot;)\n    assert(trie.contains(&quot;cut&quot;))\n    print(&quot;\\&quot;cut\\&quot; is in the trie&quot;)\n    assert(trie.contains(&quot;cute&quot;))\n    print(&quot;\\&quot;cute\\&quot; is in the trie&quot;)\n    \n    print(&quot;\\n*** After removing cut ***&quot;)\n    trie.remove(&quot;cut&quot;)\n    assert(!trie.contains(&quot;cut&quot;))\n    assert(trie.contains(&quot;cute&quot;))\n    print(&quot;\\&quot;cute\\&quot; is still in the trie&quot;)\n&#125;\n\n&#x2F;*\n---Example of remove---\n\n*** Before removeing ***\n&quot;cut&quot; is in the trie\n&quot;cute&quot; is in the trie\n\n*** After removing cut ***\n&quot;cute&quot; is still in the trie\n*&#x2F;\n\nPrefix matchingTrie树最具标志性的算法是前缀匹配算法。\nextension Trie where CollectionType: RangeReplaceableCollection &#123;\n    \n&#125;\n\n首先对CollectionType进行RangeReplaceableCollection限制，因为在实际的操作中，需要使用RangeReplaceableCollection中的append方法。\npublic func collections(startingWith prefix: CollectionType) -&gt; [CollectionType] &#123;\n    var current &#x3D; root\n    for element in prefix &#123;\n        guard let child &#x3D; current.children[element] else &#123;\n            return []\n        &#125;\n        current &#x3D; child\n    &#125;\n    \n    return collections(startingWith: prefix, after: current)\n&#125;\n\n\n首先检查Trie树中是否包含预检索的前缀，如果不包含则返回空数组；\n当检查得到预检索的前缀后，将其所在的节点传递给辅助方法*collections(startingWith:after:)*，递归查找所有顺序。\n\nprivate func collections(startingWith prefix: CollectionType, after node: Node) -&gt; [CollectionType] &#123;\n    \n    var results: [CollectionType] &#x3D; []\n    \n    if node.isTerminating &#123;\n        results.append(prefix)\n    &#125;\n    \n    for child in node.children.values &#123;\n        var prefix &#x3D; prefix\n        prefix.append(child.key!)\n        results.append(contentsOf: collections(startingWith: prefix, after: child))\n    &#125;\n    return results\n&#125;\n\n\n首先构建一个空的数组变量，以保存输出结果。如果当前节点是终止节点，则直接添加当前节点到结果数组中，因为预检索前缀所在的节点此时也是一个结果；\n接下来，需要检查当前节点的子节点，针对每一个子节点，递归调用*collections(startingWith:after:)*方法，寻找其他终止节点。\n\n*collections(startingWith:)*方法的时间复杂度为O(k * m)，其中 k 表示与前缀匹配最长的集合，m 表示与前缀匹配的集合数。数组的时间复杂度为O（k *n），其中n是集合中元素的数量。\n对于每个集合中均匀分布的大量数据，与使用数组进行前缀匹配相比，Trie的性能要好得多。\nexample(of: &quot;prefix matching&quot;) &#123;\n    let trie &#x3D; Trie&lt;String&gt;()\n    trie.insert(&quot;car&quot;)\n    trie.insert(&quot;card&quot;)\n    trie.insert(&quot;care&quot;)\n    trie.insert(&quot;cared&quot;)\n    trie.insert(&quot;cars&quot;)\n    trie.insert(&quot;carbs&quot;)\n    trie.insert(&quot;carapace&quot;)\n    trie.insert(&quot;cargo&quot;)\n    \n    print(&quot;\\nCollections starting with \\&quot;car\\&quot;&quot;)\n    let prefixedWithCar &#x3D; trie.collections(startingWith: &quot;car&quot;)\n    print(prefixedWithCar)\n    \n    print(&quot;\\nCollections starting with \\&quot;care\\&quot;&quot;)\n    let prefixedWithCare &#x3D; trie.collections(startingWith: &quot;care&quot;)\n    print(prefixedWithCare)\n&#125;\n\n&#x2F;*\n---Example of prefix matching---\n\nCollections starting with &quot;car&quot;\n[&quot;car&quot;, &quot;cars&quot;, &quot;card&quot;, &quot;carbs&quot;, &quot;cargo&quot;, &quot;care&quot;, &quot;cared&quot;, &quot;carapace&quot;]\n\nCollections starting with &quot;care&quot;\n[&quot;care&quot;, &quot;cared&quot;]\n*&#x2F;\n\n关键点总结\nTrie树在前缀匹配上有着卓越的性能表现；\nTries具有相对较高的内存效率，因为各个节点可以在许多不同的值之间共享。例如，“car”，“carbs”和“care”可以共享单词的前三个字母。\n\n","slug":"2020-01-06-Data-Structures-&-Algorithms-in-Swift-13","date":"2023-05-13T11:29:06.795Z","categories_index":"Data Structures & Algorithms in Swift","tags_index":"Swift中的数据结构与算法"},{"id":"193dbb4158d425c4c3d00532baa1c670","title":"\\#14\\ 二分查找（Binary Search）","content":"二分查找是时间复杂度为O(log n)的搜索算法中较为高效的算法之一，这一点和在平衡的二叉搜索树中搜索元素的时间复杂度相当。在使用二分查找之前，有两个条件需要预先满足：\n\n集合必须是在恒定的时间内执行索引操作，意味着集合必须是RandomAccessCollection类型的；\n集合必须是sorted的。\n\nExample在Swift标准库中的Array结构中，通过*index(of:)*来实现线性的元素搜索，也就是意味着Array中的元素搜索需要遍历整个数组。\n\n\n\n\n\n\n\n\n\n在Swift 5中index(of:) 已经废弃，取而代之的为*firstIndex(of:)*。\n\n而二分查找则是在已排序的数组上，以不同的处理方式进行元素的搜索。例如下图所示，在已排序的数组中搜索元素31：\n\n和一般的数组元素查找不同的是，二分查找按照如下的步骤进行元素的搜索：\nStep 1：找到中间位置的索引\n二分查找第一步，便是找到集合中间位置，这一步非常直接，通过集合的元素总数进行计算获得：\n\nStep 2：检查中间索引位置的元素\n下一步则是检查中间位置的元素，如果和预检索的元素匹配，则直接返回索引，如果不相符，则继续第三步，继续检索元素。\nStep 3：递归进行二分查找\n最后一步是递归调用二分查找，但是这时，仅仅需要检索的是集合中间索引左侧或者右侧，而非整个集合。当中间位置的元素小于预检索的元素时，则检索中间位置右侧，反之，检索中间位置左侧。\n二分查找每一步的检索之后，都会减少一半的检索范围，这样大大的减小了检索的时间耗时，提高检索效率。\n在上述例子中，为了检索元素31，由于中间位置的元素为22，小于预检索的元素31，因此将继续检索中间位置元素22的右侧元素：\n\n二分查找从大的方面来说，每一次的元素检索只需要三步，直到无法将集合再次进行左右划分或者找到元素为止。\n二分查找的时间复杂度为O(log n)。\n算法实现首先定义二分查找使用范围，以及集合元素的可比较性：\npublic extension RandomAccessCollection where Element: Comparable &#123;\n    func binarySearch(for value: Element, in range: Range&lt;Index&gt;? &#x3D; nil) -&gt; Index? &#123;\n        \n    &#125;\n&#125;\n\n\n\n由于二分查找仅仅适用于集合类型RandomAccessCollection，并且其中的元素需要可比较的特性，因此针对该类型进行扩展并设定元素可比较性，并添加二分查找方法的定义；\n二分查找在运行过程中需要递归调用，因此在函数定义中要执行每一次递归的范围，参数range是可选类型，在首次进行二分查找的时候，不需要传入range，故其默认值为nil。\n\npublic extension RandomAccessCollection where Element: Comparable &#123;\n    func binarySearch(for value: Element, in range: Range&lt;Index&gt;? &#x3D; nil) -&gt; Index?&#123;\n        \n        let range &#x3D; range ?? startIndex ..&lt; endIndex\n\n        guard range.lowerBound &lt; range.upperBound else &#123;\n            return nil\n        &#125;\n        \n        let size &#x3D; distance(from: range.lowerBound, to: range.upperBound)\n        let middle &#x3D; index(range.lowerBound, offsetBy: size &#x2F; 2)\n        \n        if self[middle] &#x3D;&#x3D; value &#123;\n            return middle\n        &#125; else if self[middle] &gt; value &#123;\n            return binarySearch(for: value, in: range.lowerBound ..&lt; middle)\n        &#125; else &#123;\n            return binarySearch(for: value, in: middle ..&lt; range.upperBound)\n        &#125;\n    &#125;\n&#125;\n\n\n首先检查range是否为nil，如果为nil，则获取集合完整的索引范围startIndex ..&lt; endIndex；\n检查集合是否为空，这里的检查方式是通过集合的最小边界和最大边界进行判断集合是否至少有一个元素，否则直接返回nil；\n通过集合的最小边界和最大边界，获取集合的长度，之后使用*index(offsetBy:)*方法获取集合中间位置的索引；\n如果中间位置的元素就是我们要查找的元素，则直接返回中间位置索引；\n如果中间位置的元素大于预查找的元素，则说明预查找元素在集合中间位置的左侧，递归调用*binarySearch(for:range:)*方法，继续查找；\n如果中间位置的元素小于预查找的元素，则说明预查找的元素在集合中间位置的右侧，递归调用*binarySearch(for:range:)*方法，继续查找。\n\nexample(of: &quot;binary search&quot;) &#123;\n    let array &#x3D; [1, 5, 15, 17, 19, 22, 24, 31, 105, 150]\n    \n    let search31 &#x3D; array.firstIndex(of: 31)\n    let binarySearch31 &#x3D; array.binarySearch(for: 31)\n    \n    print(&quot;index(of:): \\(String(describing: search31))&quot;)\n    print(&quot;binarySearch(of:): \\(String(describing: binarySearch31))&quot;)\n&#125;\n\n&#x2F;*\n---Example of binary search---\nindex(of:): Optional(7)\nbinarySearch(of:): Optional(7)\n*&#x2F;\n\n二分查找是一种强大的算法，每当某些场景下，集合的元素时已排序的情况下，都可以考虑使用二分查找的方法。另外，如果遇到的问题似乎进行元素搜索需要O(n^2)的时间复杂度，可以考虑先对集合进行前期的排序，然后采用二分查找的方法将时间复杂度降低到O(n log n)的程度。\n关键点总结\n二分查找仅仅对已排序的集合有效；\n有时候，对集合进行排序后，再使用二分查找是有益的；\n对于集合本身，其sorted方法的时间复杂度为O(n)，而二分查找的时间复杂度为O(log n)，对于大型数据集合来说，二分查找的可伸缩性更好。\n\n\n\n\n\n\n\n\n\n\n二分查找思想典型的应用场景就是在Bug原因的追查上面，当面对一个无从知晓其最终的引发点的时候，可以尝试使用二分查找的思想，分段校验代码的执行结果，逐步缩小Bug追查的范围，提高Bug原因的追查效率等。\n","slug":"2020-01-07-Data-Structures-&-Algorithms-in-Swift-14","date":"2023-05-13T11:29:06.795Z","categories_index":"Data Structures & Algorithms in Swift","tags_index":"Swift中的数据结构与算法"},{"id":"4a00ba60db357b4d5652c54beb6b2091","title":"\\#15\\ 堆数据结构（The Heap Data Structure）","content":"想必抓娃娃机如今没有人不知道其实什么了，抓娃娃机的爪子总是那么的难以控制，总是看起来容易的机会却难以如愿。抓抓机的爪子其实就工作在一个堆数据结构之上，爪子每次抓的几乎都是那边一堆玩具最上面的那一个，只有这样机会才会更大一些。\n\n在本文中将学习关于堆（Heap）的基础知识，包含如何创建一个堆数据结构，如果从堆数据结构中获取最大和最小元素等。\n什么是堆？堆是一个使用数组构建的完整二叉树，也称为二叉堆。\n\n\n\n\n\n\n\n\n\n这里的堆和内存堆是完全不同的一个概念，需要区分。在计算机科学中，经常有一些术语被重复使用，但是涵义却有所不同，本文不会对内存堆进行阐述。\n堆有两种类型：\n\n最大堆：堆中元素越大，其优先级越高；\n最小堆：堆中元素越小，其优先级越高。\n\n堆属性一个堆结构，有着必须始终满足的重要特征，称之为堆不变式或堆属性。\n\n在最大堆中，父节点必须包含一个大于等于其子节点的值，根节点包含最大的值。\n在最小堆中，父节点必须包含一个小于等于其子节点的值，根节点包含最小的值。\n\n另一个堆的必须属性是堆是一个完全二叉树。意味着树除了叶子节点层之外，其他每一层都必须被填充，有点类似某些闯关类游戏，本关没有完成，则下一关无法开始。\n堆的应用堆在很多场景下都被广泛的应用，例如：\n\n计算集合中最小元素和最大元素；\n堆排序\n优先级队列构造\n构造图算法，例如普林演算法 (Prim’s algorithm)或狄克斯特拉算法（Dijkstra’s algorithm）等。\n\n常用的堆操作首先定义Heap的数据结构：\nstruct Heap&lt;Element: Equatable&gt; &#123;\n    var elements: [Element] &#x3D; []\n    let sort: (Element, Element) -&gt; Bool\n    \n    init(sort: @escaping (Element, Element) -&gt; Bool) &#123;\n        self.sort &#x3D; sort\n    &#125;\n&#125;\n\n在Heap的数据结构中，包含一个数组elemtns用来保存堆元素，一个sort函数定义堆中集合如何排序的排序函数。构造器接收一个适当的参数，后续用来构建最大和最小堆。\n如何表示堆？树型结构中的节点能够保存值和其子节点的索引，二叉树同时保存左子树和右子树的引用。堆本质上是一颗二叉树，但是可以使用简单的数组进行表示。利用数组表示堆的好处是良好的时间复杂度和空间复杂度，因为这样堆中的元素保存在内存里，堆元素的交换等能够有良好的的性能表现，与使用二叉树来表示堆，使用数组更加的容易。接下来了解使用数组如何表示一个堆。\n\n为了使用数组表示堆，只需要从左至右一层一层迭代元素即可。\n\n当遍历进入高层级的时候，所需要遍历节点数可能会成倍的增加。\n现在可以轻松访问堆中的任何节点。您可以将这一点与访问数组中元素的方式进行比较：无需向下遍历左分支或右分支，只需使用简单公式访问数组中的节点即可。\n例如给定一个以零为开始索引的 i 对应的节点：\n\n当前节点的左子树能够使用 2i + 1 进行访问；\n当前节点的右子树能够使用 2i + 2 进行访问；\n\n如下图：\n\n如果需要访问节点的父节点，依然可以使用索引值 i 求解，例如在索引为 i 的节点上，其父节点索引可通过 *floor( (i - 1) &#x2F; 2)*求得。\n\n\n\n\n\n\n\n\n\n在二叉树中，左子树和右子树的节点搜索需要O(log n)时间复杂度，但是通过数组的方式获取的时候，时间复杂度仅为O(1)。\n了解了堆的知识后，即可继续完善堆的数据结构，并为其添加一些方便的方法：\nvar isEmpty: Bool &#123;\n    return elements.isEmpty\n&#125;\n\nvar count: Int &#123;\n    return elements.count\n&#125;\n\nfunc peek() -&gt; Element? &#123;\n    return elements.first\n&#125;\n\nfunc leftChildIndex(ofParentAt index: Int) -&gt; Int &#123;\n    return (2 * index) + 1\n&#125;\n\nfunc rightChildIndex(ofParentAt index: Int) -&gt; Int &#123;\n    return (2 * index) + 2\n&#125;\n\nfunc parentIndex(ofChildAt index: Int) -&gt; Int &#123;\n    return (index - 1) &#x2F; 2\n&#125;\n\n从堆中移除元素最基本的元素节点移除操作是移除根节点，例如下图所示的移除最大堆中的根节点10：\n\n此时，移除操作将移除位于根节点的集合最大值。首先要使用堆中最末尾的元素和根节点进行交换，一旦交换了元素，就可以删除位于叶子节点上的需要删除的元素了。\n\n但是，删除后的堆还是最大堆结构么？需要注意的是，最大堆的原则或者规则是每一个子节点的值都小于或等于父节点的值，一旦不符合这个规则，则需要进行节点的sift down调整。（最大堆调整算法称为sift down，最小堆调整算法称为** sift up**）\n\n针对上图所示，sift down调整的方法是，获取根节点元素3，判断和其左子节点和右子节点的大小，如果左子节点的值大于当前节点，则进行节点的交换，如果左子节点和右子节点均大于该值，则使用子节点中大的那个值和当前节点进行交换。\n\n继续使用sift down调整法，调整节点，直到所有的节点满足最大堆的规则。\n\n算法实现mutating func remove() -&gt; Element? &#123;\n    guard !isEmpty else &#123;\n        return nil\n    &#125;\n    \n    elements.swapAt(0, count - 1)\n    \n    defer &#123;\n        siftSown(from: 0)\n    &#125;\n    return elements.removeLast()\n&#125;\n\n\n首先检查堆是否为空，如果为空，则返回nil；\n交换根节点和堆中最后的元素位置；\n移除集合中最后一个元素并返回该元素（最后一个元素不是最大值就是最小值）；\n移除后，堆可能不符合最大堆或最小堆的原则，需要继续采用siftDown或者siftUp方法进行调整，直到符合堆的规则。\n\nmutating func siftSown(from index: Int) &#123;\n    var parent &#x3D; index\n    while true &#123;\n        let left &#x3D; leftChildIndex(ofParentAt: parent)\n        let right &#x3D; rightChildIndex(ofParentAt: parent)\n        var candidate &#x3D; parent\n        \n        if left &lt; count &amp;&amp; sort(elements[left], elements[candidate]) &#123;\n            candidate &#x3D; left\n        &#125;\n        if right &lt; count &amp;&amp; sort(elements[right], elements[candidate]) &#123;\n            candidate &#x3D; right\n        &#125;\n        if candidate &#x3D;&#x3D; parent &#123;\n            return\n        &#125;\n        elements.swapAt(parent, candidate)\n        parent &#x3D; candidate\n    &#125;\n&#125;\n\n**siftDown(from:)**接受任意的索引，并将其视为根节点，该方法的工作原理是：\n\n临时保存索引到变量parent；\n一直进行sifting操作，直到return（while true）；\n获取parent索引所在节点的左节点和右节点对应的索引；\n使用临时变量candidate追踪和父节点进行交换的节点索引；\n如果是左节点，并且左节点相比父节点有更高的优先级，则candidate为左节点；\n如果是右节点，并且右节点相比父节点有更高的优先级，则candidate为右节点；\n如果candidate依然是parent，说明已经调整到末尾，再无sifting的必要了；\n一轮sifting结束时，重新设定parent为候选的candidate，进行下一轮的sifting。\n\n向堆中插入元素假设需要向如下的堆中插入元素7：\n\n首先将待插入的元素添加到堆的末端：\n\n之后，检查最大堆的堆属性。和siftdown不同的是，此时使用siftup方法，工作原理类似于siftdown，通过比较当前节点和其父节点进行节点的交换。\n\n\n算法实现extension Heap &#123;\n    mutating func insert(_ element: Element) &#123;\n        elements.append(element)\n        siftUp(from: elements.count - 1)\n    &#125;\n    \n    mutating func siftUp(from index: Int) &#123;\n        var child &#x3D; index\n        var parent &#x3D; parentIndex(ofChildAt: child)\n        while child &gt; 0 &amp;&amp; sort(elements[child], elements[parent]) &#123;\n            elements.swapAt(child, parent)\n            child &#x3D; parent\n            parent &#x3D; parentIndex(ofChildAt: child)\n        &#125;\n    &#125;\n&#125;\n\n插入算法相较于移除算法，更为直接：\n\n首先直接向数组中追加待插入的元素，之后进行 sift up 调整；\nsiftUp比较当前节点和其父节点，并进行条件进行交换，直到该节点有一个比其父节点更高的优先级为止。\n\n在从堆中移除元素的时候，删除算法只是移除了堆的根节点，但是非根节点的元素移除可能更加的符合实际的场景。\n从任意索引中删除extension Heap &#123;\n    mutating func remove(at index: Int) -&gt; Element? &#123;\n        guard index &lt; elements.count else &#123;\n            return nil\n        &#125;\n        \n        if index &#x3D;&#x3D; elements.count - 1 &#123;\n            return elements.removeLast()\n        &#125; else &#123;\n            elements.swapAt(index, elements.count - 1)\n            defer &#123;\n                siftSown(from: index)\n                siftUp(from: index)\n            &#125;\n            return elements.removeLast()\n        &#125;\n    &#125;\n&#125;\n\n\n检查待删除的索引是否在集合的边界之内，如果不在，返回nil；\n如果删除的是堆中最末尾的元素，则直接进行删除，类似remove；\n如果是非末尾的元素，首先交换待删除索引和末尾索引；\n之后删除末尾的元素，并返回该元素\n最后，调用siftDown和siftUp进行堆节点调整\n\n\n\n但是为什么要同时调用siftDown和siftUp呢？\n\n例如上图所示的堆中，想要删除元素5，首先交换5和最末尾的元素8，之后删除元素5。此时需要使用sift up对最大堆属性进行调整。\n\n例如上图，想要删除元素7，需要和末尾元素1进行交换后删除，删除后，需要使用sift down进行调整。\n在堆中搜索元素在删除元素之前，首先要通过索引查找对应的元素，此时需要进行堆元素的搜索。不过，堆本身并没有设计快速的搜索，对于一颗二叉搜索树来说，搜索元素有O(log n)的时间复杂度，但是对于使用数组构建的堆，数组中的元素进行排序确实不同于二叉搜索树的，此时并不能使用二分查找。\n\n\n\n\n\n\n\n\n\n在堆中搜索元素最差的情况下有O(n)的时间复杂度，因此在搜索的时候，可能要检查数组中的每一个元素。\nextension Heap &#123;\n    func index(of element: Element, startingAt i: Int) -&gt; Int? &#123;\n        if i &gt;&#x3D; count &#123;\n            return nil\n        &#125;\n        if sort(element, elements[i]) &#123;\n            return nil\n        &#125;\n        if element &#x3D;&#x3D; elements[i] &#123;\n            return i\n        &#125;\n        if let j &#x3D; index(of: element, startingAt: leftChildIndex(ofParentAt: i)) &#123;\n            return j\n        &#125;\n        if let j &#x3D; index(of: element, startingAt: rightChildIndex(ofParentAt: i)) &#123;\n            return j\n        &#125;\n        return nil\n    &#125;\n&#125;\n\n\n如果索引i大于或者等于堆元素个数，则搜索失败，返回nil；\n判断当前元素是否比索引i所对应的元素有更高的优先级，如果是，则所搜索的元素不可能在堆的更低的索引；\n如果所搜索的元素和索引i所对应的元素相等，则待删除元素所在的索引就是i；\n递归的搜索左子树从索引i开始的元素；\n递归的搜索右子树从索引i开始的元素；\n如果上述过程全部搜索失败，则整个搜索失败。\n\n构建堆至此，已经有足够的工具针对堆进行各类操作了，但是还有一个问题就是，如果使用已存在的数组构建一个堆？在开始定义堆数据结构的时候，我们使用了一个非常简单的构造器，对其进行改造如下：\ninit(sort: @escaping (Element, Element) -&gt; Bool, elements: [Element] &#x3D; []) &#123;\n    self.sort &#x3D; sort\n    self.elements &#x3D; elements\n    \n    if !elements.isEmpty &#123;\n        for i in stride(from: elements.count &#x2F; 2 - 1, through: 0, by: -1) &#123;\n            siftSown(from: i)\n        &#125;\n    &#125;\n&#125;\n\n构造器现在能够接收一个额外的参数，如果传入一个非空的数组，将会使用该数组构建堆，为了使得堆满足堆属性，从第一个非叶节点开始向后循环数组，然后筛选所有父节点。您只遍历了一半的元素，因为筛选叶节点没有点，只有父节点。\n\n测试example(of: &quot;building a heap with array&quot;) &#123;\n    var heap &#x3D; Heap(sort: &gt;, elements: [1, 12, 3, 4, 1, 6, 8, 7])\n    \n    while !heap.isEmpty  &#123;\n        print(heap.remove()!)\n    &#125;\n&#125;\n\n&#x2F;*\n---Example of building a heap with array---\n12\n8\n7\n6\n4\n3\n1\n1\n*&#x2F;\n\n关键点总结\n对于堆的各类操作，有着不同的时间复杂度，具体如下：  \n堆数据结构非常适合维护优先级最高或最低优先级的元素。\n每次从堆中插入或删除项时，都必须检查它是否符合优先级的规则。\n\n","slug":"2020-01-10-Data-Structures-&-Algorithms-in-Swift-15","date":"2023-05-13T11:29:06.795Z","categories_index":"Data Structures & Algorithms in Swift","tags_index":"Swift中的数据结构与算法"},{"id":"5d749126a5c6ef9bea973d557d834975","title":"\\#16\\ 优先级队列","content":"队列是一种先进先出（FIFO）的数据结构，而优先级队列是另一种队列结构，其可替代队列的先进先出顺序，该队列中的元素有着优先级的顺序。一个优先级队列也可以是：\n\n最大优先级队列：队列中最前面的元素具有最高优先级；\n最小优先级队列：队列中最前面的元素具有最低优先级。\n\n当需要在给定的元素列表中取标定最大元素和最小元素时，优先级队列将是非常合适的一种数据结构。\n优先级队列的典型应用\n迪克斯特拉的算法（Dijkstra’s algorithm），使用优先级队列计算最小代价。\nA*路径寻找算法，使用优先级队列跟踪对位置路径进行探索的最短路径。\n堆排序，可以使用优先级队列实现。\n哈夫曼编码会构建一个压缩树。最小优先级队列用于重复查找两个频率最小的节点，这些节点未具有父节点。\n\n优先级队列的应用范围很广，远不止上述列举的部分。\n一般操作在 #8\\ 队列的Swift实现与操作定义中我们为队列定义了如下的一个协议：\npublic protocol Queue &#123;\n    associatedtype  Element\n    mutating func enqueue(_ element: Element) -&gt; Bool\n    mutating func dequeue() -&gt; Element?\n    var isEmpty: Bool &#123; get &#125;\n    var peek: Element? &#123; get &#125;\n&#125;\n\n优先级队列和普通队列同样有着相同的操作，只是具体的实现会有所不同。\n对于优先级队列而言，同样对遵循协议Queue，并实现一些一般性的操作如下：\n\nenqueue：插入一个元素到队列，如果操作成功，则返回true；\ndequeue：移除具有最高优先级的元素，并返回它，如果队列为空，则返回nil；\nisEmpty：检查队列是否为空；\npeek：返回具有最高优先级的队列，但并不进行删除，如果队列为空，则返回nil。\n\n算法实现构建优先级队列的方式有以下几种：\n\n已排序数组：在获取最大值或最小值的时间复杂度均为O(1)，使用此数据构建优先级队列非常有效，但是其插入算法却比较慢，会达到O(n)的时间复杂度。\n平衡二叉搜索树：在创建双端优先级队列时，使用平衡二叉搜索树最为有利，此时获取最小值和最大值的时间复杂度均在_O(log n)，插入算法比排序的数组会更好，在O(log n)。\n堆：优先级队列最佳的选择，堆结构比排序的数组更为有效，因为堆只需要部分排序，除了从最小堆中获取最小值和从最大堆中获取最大值为O(1)的快速外，其他的操作均为O(log n)的时间复杂度。\n\nstruct PriorityQueue&lt;Element: Equatable&gt;: Queue &#123;\n    private var heap: Heap&lt;Element&gt;\n    \n    init(sort: @escaping (Element, Element) -&gt; Bool, elements: [Element] &#x3D; []) &#123;\n        heap &#x3D; Heap(sort: sort, elements: elements)\n    &#125;\n&#125;\n\n\nPriorityQueue 遵循队列协议Queue。泛型参数元素必须遵循Equatable，因为在元素的操作中需要能够进行元素间的比较。\n使用堆数据结构实现优先级队列；\n传递合适的参数到初始化构造函数，PriorityQueue可根据参数构建最小和最大优先级队列。\n\n为了遵循Queue协议，需要增加如下的协议方法：\npublic var isEmpty: Bool &#123;\n    return heap.isEmpty\n&#125;\n\npublic var peek: Element? &#123;\n    return heap.peek()\n&#125;\n\npublic mutating func enqueue(_ element: Element) -&gt; Bool &#123;\n    heap.insert(element)\n    return true\n&#125;\n\npublic mutating func dequeue() -&gt; Element? &#123;\n    return heap.remove()\n&#125;\n\n在实践中优先级队列上，堆是最为完美的选择，只需要调用堆的各种方法即可实现优先级队列的各种操作。\n测试example(of: &quot;priorityQueue&quot;) &#123;\n    var priorityQueue &#x3D; PriorityQueue(sort: &gt;, elements: [1, 12, 3, 4, 1, 6, 8, 7])\n    while !priorityQueue.isEmpty &#123;\n        print(priorityQueue.dequeue()!)\n    &#125;\n&#125;\n\n&#x2F;*\n---Example of priorityQueue---\n12\n8\n7\n6\n4\n3\n1\n1\n*&#x2F;\n\n关键点总结\n一个优先级队列通常使用优先级顺序进行元素的查找；\n能够通过关注队列的关键操作而排除堆数据结构提供的其他功能，从而创建抽象层。\n使得优先级队列的意图清晰而简洁。唯一的工作是排队和取消排队元素。\n\n","slug":"2020-01-12-Data-Structures-&-Algorithms-in-Swift-16","date":"2023-05-13T11:29:06.795Z","categories_index":"Data Structures & Algorithms in Swift","tags_index":"Swift中的数据结构与算法"},{"id":"8ac62db54bf242691e8bc332c52f0b5b","title":"\\#17\\ 排序算法O(n^2)","content":"**O(n^2)**的时间复杂度并不是一个最佳的性能表现，但是在某些情况下，该类别的排序算法非常有用，此类算法的空间复杂度表现良好，仅仅需要O(1)的恒定的额外内存空间，对于小型数据集来说，此类排序算法比更为复杂的排序算法更为有利。\n在本文中，将学习饿三种不同的、O(n^2)时间复杂度的排序算法：\n\n冒泡排序\n选择排序\n插入排序\n\n这些算法均是基于比较的方法，他们依赖比较的运算，比如小于或等于运算符等，对数据进行排序。比较操作的调用次数是衡量此类算法技术总体性能的一般方法。\n冒泡排序（Bubble Sort）冒泡排序是相对简单的一种排序方法，在排序的过程中，重复比较两个数据的大小，并进行数据交换。其中较大的数值会类似气泡上升一样上升到集合的尾部。\n示例\n例如上图所示的四张扑克，其顺序为*[9， 4， 10， 3]*，现在需要对其从小到大进行排序，需要如下几个步骤：\n\n从集合最前端开始，比较扑克牌9和扑克牌4，由于9比4大，因此需要进行位置交换，交换后，顺序变为*[4， 9， 10， 3]*；\n完成了第一步后，比较的锚点移动到集合的下一个索引处，即此时的扑克牌9，比较9和10，符合小的在前，大的在后，顺序不变；\n继续移动到下一个索引，扑克牌10，比较10和3，不符合从小到大的原则，进行位置交换，交换后，集合变为*[4， 9， 3， 10]*。\n\n集合遍历第一遍后，往往很难使得集合达到预期的目标，但是对于上述集合来说，最大的扑克牌10，已经冒泡移动到了集合的最末端。\n接下来进行第二遍遍历，此时比较扑克牌4和9:\n\n只有当集合不用进行再进行交换的时候，整个集合才算所排序完成。最差的情况下，堆集合的遍历需要n - 1次，其中 n 为集合元素的个数。\n算法实现public func bubbleSort&lt;Element&gt;(_ array: inout [Element]) where Element: Comparable &#123;\n    guard array.count &gt;&#x3D; 2 else &#123;\n        return\n    &#125;\n    \n    for end in (1 ..&lt; array.count).reversed() &#123;\n        var swapped &#x3D; false\n        \n        for current in 0 ..&lt; end &#123;\n            if array[current] &gt; array[current + 1] &#123;\n                array.swapAt(current, current + 1)\n                swapped &#x3D; true\n            &#125;\n        &#125;\n        if !swapped &#123;\n            return\n        &#125;\n    &#125;\n&#125;\n\n\n对集合进行元素个数检查，如果元素的个数小于2，则不需要进行排序；\n进行外层循环，首次循环之后，最大的元素将会移至集合的末尾，下次循环的时候，总是会比上一次少一个元素，因此，每次循环基本上都会少一次比较；\n进行元素间的比较和交换。比较当前元素和下一个元素的大小，如果当前元素大于下一个元素，则进行位置的交换；\n如果再无元素需要交换，则说明集合已经排序完成，排序退出。\n\nexample(of: &quot;bubble sort&quot;) &#123;\n    var array &#x3D; [9, 4, 10, 3]\n    print(&quot;Original: \\(array)&quot;)\n    bubbleSort(&amp;array)\n    print(&quot;Bubble sorted: \\(array)&quot;)\n&#125;\n\n&#x2F;*\n---Example of bubble sort---\nOriginal: [9, 4, 10, 3]\nBubble sorted: [3, 4, 9, 10]\n*&#x2F;\n\n冒泡排序最好的时间复杂度为O(n)，最差时间复杂度为O(n^2)。\n选择排序（Selection sort）选择排序遵循冒泡排序的基本思想，但是优化了元素位置交换的数量，选择排序仅在每次传递结束之后才进行元素的交换。\n示例假设有如下数量的扑克牌：\n\n每轮传递之后，选择排序将找到最小的未排序的元素，并对其进行位置交换：\n\n首先，发现扑克3是最小的，因此和扑克9交换位置；\n下一个最小的扑克是4，其已经在正确地位置；\n最后，最小的未扑克9，和扑克10交换。\n\n\n算法实现public func selectionSort&lt;Element&gt;(_ array: inout [Element]) where Element: Comparable &#123;\n    guard array.count &gt;&#x3D; 2 else &#123;\n        return\n    &#125;\n    \n    for current in 0 ..&lt; (array.count - 1) &#123;\n        var lowest &#x3D; current\n        \n        for other in (current + 1) ..&lt; array.count &#123;\n            if array[lowest] &gt; array[other] &#123;\n                lowest &#x3D; other\n            &#125;\n        &#125;\n        if lowest !&#x3D; current &#123;\n            array.swapAt(lowest, current)\n        &#125;\n    &#125;\n&#125;\n\n\n遍历除了集合最后一个元素之外的其他元素，因为如果其他的元素都在正确地位置了，那么最后一个元素也是正确位置了；\n再次遍历除当前索引之前的其他所有元素，寻找子集合中最小值的元素；\n如果当前元素的索引并不是最小元素对应的索引，则进行元素位置的交换。\n\nexample(of: &quot;selection sort&quot;) &#123;\n    var array &#x3D; [9, 4, 10, 3]\n    print(&quot;Original: \\(array)&quot;)\n    selectionSort(&amp;array)\n    print(&quot;Selection sorted: \\(array)&quot;)\n&#125;\n\n&#x2F;*\n---Example of selection sort---\nOriginal: [9, 4, 10, 3]\nSelection sorted: [3, 4, 9, 10]\n*&#x2F;\n\n类似冒泡排序，选择排序的最好、最坏和平均时间复杂度为O(n^2)，虽然有点让人沮丧，但是相比冒泡排序而言，选择排序的确表现的更好一些。\n插入排序插入排序是更加有用的排序算法。像冒泡排序和选择排序，插入排序的平均时间复杂度依然为O(n^2)，但是插入排序的性能不同。越多的数据需要进行排序，选择排序会带来事半功倍的效果。在集合已经排序好的情况下，插入排序能达到最好时间复杂度O(n)。在Swift标准库中的排序算法使用的是混合排序的方式，当未排序的区间元素个数小于20个元素的时候，会采用插入排序的方式。\n示例同上，加入有如下的扑克牌：\n\n插入排序将会从左至右遍历扑克一次，每张扑克均向左移动，直到其所在位置正确位置：\n\n\n在遍历时，最左边的扑克可以忽略，因为在其前面再无其他扑克牌；\n接下来，比较扑克9和扑克4，因为扑克4较小，因此和扑克9进行位置交换；\n扑克10此时不需要移动，因为再其前面的扑克为9，说明扑克10在正确地位置上；\n最后，扑克3前面的所有扑克均比扑克3大，因此一次交换扑克3到最首位置。\n\n插入排序最佳的时间复杂度为O(n)，其发生在进行排序的集合元素预先是排序好的，这样在进行插入排序的时候无序进行任何左移操作。\n算法实现public func insertionSort&lt;Element&gt;(_ array: inout [Element]) where Element: Comparable &#123;\n    guard array.count &gt;&#x3D; 2 else &#123;\n        return\n    &#125;\n    \n    for current in 1 ..&lt; array.count &#123;\n        for shifting in (1 ... current).reversed() &#123;\n            if array[shifting] &lt; array[shifting - 1] &#123;\n                array.swapAt(shifting, shifting - 1)\n            &#125;else &#123;\n                break\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n\n插入排序需要遍历集合中的每一个元素，因此第一个for循环从左至右遍历集合，这里忽略了首个位置的元素；\n从当前索引向前遍历元素，比较当前索引元素和前一个索引元素，如果位置不正确则进行位置交换；\n一直交换，直到所有索引位置的元素均在正确地位置为止。如果位置正确，则跳出当前循环，进行下一个索引元素的检查。\n\nexample(of: &quot;insertion sort&quot;) &#123;\n    var array &#x3D; [9, 4, 10, 3]\n    print(&quot;Original: \\(array)&quot;)\n    insertionSort(&amp;array)\n    print(&quot;Insertion sorted: \\(array)&quot;)\n&#125;\n\n&#x2F;*\n---Example of insertion sort---\nOriginal: [9, 4, 10, 3]\nInsertion sorted: [3, 4, 9, 10]\n*&#x2F;\n\n算法泛化在本内容中，将对现有的排序算法进行优化，因为现有的算法接受的集合仅仅为Array，对于其他的集合类型并不适用，因此将对算法进行升级，有增强算法的泛化能力，具体有如下三方面：\n\n对于插入排序而言，需要对集合进行前向遍历和元素交换，因此接受的参数集合应该是双向集合类型BidirectionalCollection；\n冒泡排序和选择排序仅仅对集合进行从前向后的遍历，因此集合参数仅仅需要符合集合类型Collection；\n无论哪一种情况下，集合必须是MutableCollection可变集合类型，因为需要在遍历过程中进行元素的交换；\n\n优化后的冒泡排序\npublic func bubbleSort&lt;T&gt;(_ collection: inout T) where T: MutableCollection, T.Element: Comparable &#123;\n    guard collection.count &gt;&#x3D; 2 else &#123;\n        return\n    &#125;\n    \n    for end in collection.indices.reversed() &#123;\n        var swapped &#x3D; false\n        var current &#x3D; collection.startIndex\n        while current &gt; end &#123;\n            let next &#x3D; collection.index(after: current)\n            if collection[current] &gt; collection[next] &#123;\n                collection.swapAt(current, next)\n                swapped &#x3D; true\n            &#125;\n            current &#x3D; next\n        &#125;\n        if !swapped &#123;\n            return\n        &#125;\n    &#125;\n&#125;\n\n优化后的选择排序\npublic func selectionSort&lt;T&gt;(_ collection: inout T) where T: MutableCollection, T.Element: Comparable &#123;\n    guard collection.count &gt;&#x3D; 2 else &#123;\n        return\n    &#125;\n    \n    for current in collection.indices &#123;\n        var lowest &#x3D; current\n        var other &#x3D; collection.index(after: current)\n        while other &lt; collection.endIndex &#123;\n            if collection[lowest] &gt; collection[other] &#123;\n                lowest &#x3D; other\n            &#125;\n            other &#x3D; collection.index(after: other)\n        &#125;\n        if lowest !&#x3D; current &#123;\n            collection.swapAt(lowest, current)\n        &#125;\n    &#125;\n&#125;\n\n优化后的插入排序\npublic func insertionSort&lt;T&gt;(_ collection: inout T) where T: BidirectionalCollection &amp; MutableCollection, T.Element: Comparable &#123;\n    guard collection.count &gt;&#x3D; 2 else &#123;\n        return\n    &#125;\n    \n    for current in collection.indices &#123;\n        var shifting &#x3D; current\n        while shifting &gt; collection.startIndex &#123;\n            let previous &#x3D; collection.index(before: shifting)\n            if collection[shifting] &lt; collection[previous] &#123;\n                collection.swapAt(shifting, previous)\n            &#125; else &#123;\n                break\n            &#125;\n            shifting &#x3D; previous\n        &#125;\n    &#125;\n&#125;\n\n关键点总结\nn²算法通常名声不太那么好，在性能消耗方面总是会带来更大消耗，但是在合理的数据量下，此类算法也可解决一些排序问题；\n插入排序是最好的排序算法之一，在进行排序之前，需要了解数据是否已经是排序的。\n\n","slug":"2020-01-15-Data-Structures-&-Algorithms-in-Swift-17","date":"2023-05-13T11:29:06.795Z","categories_index":"Data Structures & Algorithms in Swift","tags_index":"Swift中的数据结构与算法"},{"id":"05deaa37bb6b9b668ab83d05b4918b64","title":"\\#18\\ 归并排序（Merge Sort）","content":"归并排序[Merge Sort]是最有效的排序算法之一，它的时间复杂度为O(n log n)，是所有通用排序算法中速度最快的一种。归并排序背后的思想是分而治之，即将一个大问题分解成多个更小、更易于解决的问题，然后将各个小问题的结果合并为最终结果。归并排序的终极秘诀是先拆分后合并。\n例如，有如下未排序的扑克牌：\n\n针对上述问题，归并排序的工作原理如下：\n\n对扑克牌进行对半拆分，拆分后会有两大部分：\n\n\n\n对上一步的拆分结果继续进行拆分：\n\n\n直到无法再拆分为止\n\n\n最后，将拆分的每一部分进行反向的合并，每次合并时，将不同的部分按照顺序进行排序。\n\n\n算法实现归并排序的思想是分而治之，因此首先要进行问题的拆解，之后再进行合并。\n拆分public func mergeSort&lt;Element&gt;(_ array: [Element]) -&gt; [Element] where Element: Comparable &#123;\n    let middle &#x3D; array.count &#x2F; 2\n    let left &#x3D; Array(array[..&lt;middle])\n    let right &#x3D; Array(array[middle...])\n    \n    &#x2F;&#x2F; ... more to come\n&#125;\n\n首先对待排序集合进行了对半拆分，但是仅仅一次拆分并不能满足归并排序的思想，需要持续拆分，直到集合再无法进行拆分为止，因此更新上述代码如下：\npublic func mergeSort&lt;Element&gt;(_ array: [Element]) -&gt; [Element] where Element: Comparable &#123;\n    guard array.count &gt; 1 else &#123;\n        return array\n    &#125;\n    \n    let middle &#x3D; array.count &#x2F; 2\n    let left &#x3D; mergeSort(Array(array[..&lt;middle]))\n    let right &#x3D; mergeSort(Array(array[middle...]))\n    \n    &#x2F;&#x2F; ... more to come\n&#125;\n\n\n首先确定算法可进入的条件，如果不符合基本的条件，则算法退出。这里的退出条件是待排序集合中仅有一个元素或无元素时，算法退出；\n使用递归的方式进行拆分，直至无法再次拆分为止。\n\n合并完全拆分后，则进入到了归并排序的最后一步，将所拆分的左右部分进行合并，此时新建函数merge进行合并操作：\nprivate func merge&lt;Element&gt;(_ left: [Element], _ right: [Element]) -&gt; [Element] where Element: Comparable &#123;\n    var leftIndex &#x3D; 0\n    var rightIndex &#x3D; 0\n    var result: [Element] &#x3D; []\n    \n    while leftIndex &lt; left.count &amp;&amp; rightIndex &lt; right.count &#123;\n        let leftElement &#x3D; left[leftIndex]\n        let rightElement &#x3D; right[rightIndex]\n        \n        if leftElement &lt; rightElement &#123;\n            result.append(leftElement)\n            leftIndex +&#x3D; 1\n        &#125; else if leftElement &gt; rightElement &#123;\n            result.append(rightElement)\n            rightIndex +&#x3D; 1\n        &#125; else &#123;\n            result.append(leftElement)\n            leftIndex +&#x3D; 1\n            result.append(rightElement)\n            rightIndex +&#x3D; 1\n        &#125;\n    &#125;\n    if leftIndex &lt; left.count &#123;\n        result.append(contentsOf: left[leftIndex...])\n    &#125;\n    if rightIndex &lt; right.count &#123;\n        result.append(contentsOf: right[rightIndex...])\n    &#125;\n    return result\n&#125;\n\n\nleftIndex和rightIndex两个变量用于对遍历过程进行索引追踪；\nresult变量为最终的合并结果；\n使用while循环对左右集合进行遍历和元素比较，直到到达集合末尾位置；\n在遍历过程中，对元素进行比较，更小的元素或相等的元素均将追加到结果result并对索引进行移动；\nwhile循环结束后，left和right两个集合均是已经排序了的，确保了剩下的元素都是大于或等于result中已存在的元素。此种情况下，可以直接将其追加到结果集合中。\n\n整合合并工作使用了单独的函数完成，此时整合拆分和合并，最终归并排序算法如下：\npublic func mergeSort&lt;Element&gt;(_ array: [Element]) -&gt; [Element] where Element: Comparable &#123;\n    guard array.count &gt; 1 else &#123;\n        return array\n    &#125;\n    \n    let middle &#x3D; array.count &#x2F; 2\n    let left &#x3D; mergeSort(Array(array[..&lt;middle]))\n    let right &#x3D; mergeSort(Array(array[middle...]))\n    return merge(left, right)\n&#125;\n\n总结一下归并排序的关键流程：\n\n归并排序的核心思想是分而治之，即将大问题拆分成多个小问题，依次对各个小问题进行求解，最后在合并各个结果；\n归并排序算法有两个核心的职责：一个是递归拆分初始集合的方法，另一个是合并两个集合的方法；\n合并函数应该使用两个排序的数组并生成一个排序的数组。\n\nexample(of: &quot;merge sort&quot;) &#123;\n    let array &#x3D; [7, 2, 6, 3, 9]\n    print(&quot;Original: \\(array)&quot;)\n    print(&quot;Merge sorted: \\(mergeSort(array))&quot;)\n&#125;\n\n&#x2F;*\n---Example of merge sort---\nOriginal: [7, 2, 6, 3, 9]\nMerge sorted: [2, 3, 6, 7, 9]\n*&#x2F;\n\n性能归并排序有着并不太坏的时间复杂度，其最好、最坏和平均时间复杂度为O(n log n)。\n\n在递归的时候，需要将一个集合拆分成更小的集合，这意味着大小为2的集合需要一次递归，大小为4的集合需要两次递归，大小为8的集合需要三次递归等等。一般情况下，如果集合的大小为n，则要拆分的层级数就是log2(n)；\n一个递归级别将合并n个元素。不管合并的规模是大是小;每一层合并的元素数量仍然是n。这意味着一个递归的代价是O(n)。\n\n那么拆分和合并的总体消耗为 *O(log n) x O(n) &#x3D; O(n log n)*。\n关键点总结\n归并排序的核心思想是分而治之的原则；\n归并排序算法的实现由多种方式，不同的实现可能带来不同的性能体现。\n\n","slug":"2020-01-30-Data-Structures-&-Algorithms-in-Swift-18","date":"2023-05-13T11:29:06.795Z","categories_index":"Data Structures & Algorithms in Swift","tags_index":"Swift中的数据结构与算法"},{"id":"1eff6ae9330e74043f153497674d46df","title":"\\#19\\ 基数排序（Radix Sort）","content":"**基数排序[Radix Sort]**是一种在线性时间内对整数进行排序的非比较算法。\n为了简单起见，在本文中将关注以10为基数的整数排序，以及基数排序中的*最小有效位[LSD]*的变体等。\n示例为了进行基数排序的工作方式，假设需要对如下的集合进行排序：\nvar array &#x3D; [88, 410, 1772, 20]\n\n基数排序依赖于整数的位置表示法，如下：\n\n首先，按照最小有效位—个位对集合中的元素进行拆分：\n\n然后按照个位数从小至大的顺序对上图元素进行排序，结果如下：\narray &#x3D; [410, 20, 1772, 88]\n\n接下来，重复上述步骤，按照十位对集合中的元素进行拆分：\n\n此时按照十位拆分后再进行排序后，和按照个位排序的结果相同，因此此时不进行重排。\n继续按照百位堆集合中的元素进行拆解，拆解后如下：\n\n有一些元素可能没有百位数，或者其他位也可能没有数，此时拆解时将其赋值为0即可。按照百位重新对集合元素进行排序，结果如下：\narray &#x3D; [20, 88, 410, 1772]\n\n最后，在堆集合中的元素进行千位拆解：\n\n重新按照千位拆解结果进行排序，结果如下：\narray &#x3D; [20, 88, 410, 1772]\n\n当多个数组出现在拆解后的结果中时，则其排序不需要更改。例如在百位拆解中，20在88之前，因为在十位拆解时，20的拆解结果2和88的拆解结果8已经决定了20在88之前。\n算法实现extension Array where Element &#x3D;&#x3D; Int &#123;\n    public mutating func radixSort() &#123;\n        let base &#x3D; 10\n        var done &#x3D; false\n        var digits &#x3D; 1\n        while !done &#123;\n            &#x2F;&#x2F; more to come\n        &#125;\n    &#125;\n&#125;\n\n基数排序针对的是整数集合，因此在算法实现中直接对集合类型Array进行扩展，并制定元素类型为Int。上述函数定义和相关变量和逻辑相对简单，具体如下：\n\n使用10为基数堆整数进行拆解和排序。因为在算法执行过程中需要多次使用这个基数，因此使用变量base进行存储；\n使用两个变量是否结束done和数字digit变量对执行过程进行追踪。基数排序在执行过程中有多次的遍历，done变量以标识整个遍历过程是否结束，digit变量用来标识当前所处理的数字。\n\n接下来需要编写的是针对每一步进行排序的逻辑算法，可称之为**桶排序[Bucket Sort]**。\nBucket Sort此排序算法主要是在while循环体中执行，具体如下：\nvar buckets: [[Int]] &#x3D; .init(repeating: [], count: base)\n            \nforEach &#123;\n    number in\n    let remainingPart &#x3D; number &#x2F; digits\n    let digit &#x3D; remainingPart % base\n    buckets[digit].append(number)\n&#125;\n\ndigits *&#x3D; base\nself &#x3D; buckets.flatMap &#123; $0 &#125;\n\n\n使用二维数组的方式初始化buckets。因为使用的基数是10，因此拆解后会有10个buckets；\n对集合中的每一个元素进行拆分，并放置在对应的bucket中；\n使用digit的内容更新为希望检查和更新数组的的下一个数字。flatMap方法将二维数组变成一维数组，即将每一部分bucket排序装进数组。\n\n循环何时结束？\n上述实现虽然逻辑上能够很好的拆解元素，并进行排序，但是对于while循环并没有机会符合退出条件，因此会进入无限循环状态。要符合退出条件，添加如下条件：\n\n在while循环的开始，添加done &#x3D; true；\n在forEach闭包结构中，增加如下语句：\n\nif remainingPart &gt; 0 &#123;\n    done &#x3D; false\n&#125;\n\n只要还有未排序的数字，forEach就会一直迭代，直到再无未排序的部分，forEach执行完毕。\nexample(of: &quot;radix sort&quot;) &#123;\n    var array &#x3D; [88, 410, 1772, 20]\n    print(&quot;Original: \\(array)&quot;)\n    array.radixSort()\n    print(&quot;Radix sorted: \\(array)&quot;)\n&#125;\n\n&#x2F;*\n---Example of radix sort---\nOriginal: [88, 410, 1772, 20]\nRadix sorted: [20, 88, 410, 1772]\n*&#x2F;\n\n基数排序是最快速的排序算法之一，其平均时间复杂度为O(kn)，其中k为最大数字的有效位数，n*为数组中整数的个数。\n基数排序在k为常数时最有效，当数组中所有数字的有效位数都相同时，基数排序最有效。它的时间复杂度变成了O(n)，基数排序也会带来O(n)空间复杂度。\n关键点总结\n不像之前的排序算法，基数排序是一种非比较性排序，它不依赖于两个值之间的比较。基数排序利用桶排序，桶排序类似于筛选值的筛子；\n\n基数排序是最快速的排序算法之一，利用了数字的位置等；\n\n本文讨论了最小有效数字基数排序。另一种实现基数排序的方法是最有效的数字形式。这种形式通过优先排列最有效的数字而不是最不重要的数字进行排序。\n\n\n","slug":"2020-02-01-Data-Structures-&-Algorithms-in-Swift-19","date":"2023-05-13T11:29:06.795Z","categories_index":"Data Structures & Algorithms in Swift","tags_index":"Swift中的数据结构与算法"},{"id":"b14270b802509aef1b418b7534f574dc","title":"\\#20\\ 堆排序（Heap Sort）","content":"**堆排序[Heap Sort]**是另一种基于比较的排序算法，其利用堆对数组进行升序排序。关于堆数据结构，可以查看\\#15\\ 堆数据结构（The Heap Data Structure）中的介绍。\n堆排序使用的是堆的优势，根据堆的定义，一个部分排序的二叉树具有如下的特质：\n\n在最大堆中，所有的父节点均大于其孩子节点；\n在最小堆中，所有的父节点均小于其孩子节点。\n\n最大堆和最小堆的图示如下：\n\n示例对于给定的未排序的数组，从小到大进行排序，堆排序都必须首先将该数组转换为最大堆结构。\n\n对上述数组通过筛选所有父节点进行转换，此时使用sift-down方式，最终转换后的结果如下：\n\n对应的数组为：\n\n由于单次sift-down操作的时间复杂度为O(log n)，因此构建一个堆的整体时间复杂度为O(n log n)。\n堆排序是将数组元素进行升序排序。因为在最大堆中，最大的元素通常位于根节点，因此可以使用索引0的元素和索引n-1的元素进行直接交换。这样交换后，数组最后的元素便位于正确地位置，但是此时堆已经不符合堆的规则了。下一步对新的根节点元素进行sift-down操作，使得堆成立。（此时进行sift-down的时候，需要将排除部分已排序好的元素）\n\n对元素5进行sift-down之后，新的根节点为原始堆中第二大的元素21，此时同样和末尾元素6进行交换，交换后继续对新的根节点6进行sift-down操作，再次使得堆成立。\n\n上述过程其实形成了一种模式，堆排序简单直接，每次交换首末两个元素，较大的元素依次被交换到数组的后面，多次交换完成后，数组变成了从小到大的顺序，也完成了堆排序。\n\n算法实现堆排序的实现是基于堆的数据结构基础上的，是对堆结构的一种功能扩展。\nextension Heap &#123;\n    \n    mutating func siftSown(from index: Int, upTo size: Int) &#123;\n           var parent &#x3D; index\n           while true &#123;\n               let left &#x3D; leftChildIndex(ofParentAt: parent)\n               let right &#x3D; rightChildIndex(ofParentAt: parent)\n               var candidate &#x3D; parent\n               \n               if left &lt; size &amp;&amp; sort(elements[left], elements[candidate]) &#123;\n                   candidate &#x3D; left\n               &#125;\n               if right &lt; size &amp;&amp; sort(elements[right], elements[candidate]) &#123;\n                   candidate &#x3D; right\n               &#125;\n               if candidate &#x3D;&#x3D; parent &#123;\n                   return\n               &#125;\n               elements.swapAt(parent, candidate)\n               parent &#x3D; candidate\n           &#125;\n       &#125;\n    \n    func sorted() -&gt; [Element] &#123;\n        var heap &#x3D; Heap(sort: sort, elements: elements)\n        for index in heap.elements.indices.reversed() &#123;\n            heap.elements.swapAt(0, index)\n            heap.siftSown(from: 0, upTo: index)\n        &#125;\n        return heap.elements\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\n需要对原来Heap结构的sift-down方法进行改造，增加参数size以标记当前集合的大小。\n堆排序算法工作流程如下：\n\n首先对原有堆进行一个拷贝。因为在堆排序堆元素集合进行排序后，原有的堆结构将不再成立，为了保持堆结构成立，这里使用其拷贝进行排序；\n从集合末尾元素开始，对集合进行遍历；\n交换首末位置的元素，此次交换后，最大的元素将位于集合的末尾；\n交换元素位置后，堆结构已经不成立了，因此需要使用sift-down方法对集合重新调整，已重生合法的堆结构，完成后，新的根节点将是原集合中第二大的元素。重复第三步即可。\n\nexample(of: &quot;heap sort&quot;) &#123;\n    let heap &#x3D; Heap(sort: &gt;, elements: [6, 12, 2, 26, 8, 18, 21, 9, 5])\n    print(heap.sorted())\n&#125;\n\n&#x2F;*\n---Example of heap sort---\n[2, 5, 6, 8, 9, 12, 18, 21, 26]\n*&#x2F;\n\n性能堆排序的最佳、最差和平均性能都是O(n log n)。因为必须遍历整个列表一次，并且每次交换元素时，都必须执行向下筛选sift-down操作，这是一个O(log n)操作。\n堆排序也不是一种稳定的排序，因为它取决于元素如何布局和放入堆中。例如，如果您正在根据一副纸牌的等级对其进行堆排序，您可能会看到它们的套件相对于原始纸牌的顺序发生了变化。\n关键点总结\n堆排序利用最大堆数据结构对数组中的元素进行排序。\n\n","slug":"2020-02-03-Data-Structures-&-Algorithms-in-Swift-20","date":"2023-05-13T11:29:06.795Z","categories_index":"Data Structures & Algorithms in Swift","tags_index":"Swift中的数据结构与算法"},{"id":"efbbbd2e93d0b6b1478e69b9a9de5940","title":"iOS内存管理小结","content":"内存管理是指软件运行时对计算机内存资源的分配和使用的技术。其最主要的目的是如何高效，快速的分配，并且在适当的时候释放和回收内存资源。在早起的iOS开发中多采用MRC（手动引用计数）来进行内存管理，iOS 5引入了ARC（自动引用计数），90%以上的内存管理问题都交给了系统去进行，但是ARC并不是万能的，有些框架中和某些使用到C语言的场景中还是需要开发者手动对内存进行管理。\niOS 中的内存管理模型对于面向过程的C语言而言，在内存管理的设计上也较为直接，内存的申请和释放都由开发者手动管理。这种管理方式虽然简单，但是大大的增加了编码的工作量，也增加了代码的复杂度。\n在面向对象语言中，内存管理通常会由模型机制来完成，常见的内存管理模型机制有垃圾回收机制和引用计数机制两种，Objective-C语言采用的则是引用计数的内存管理模型。\n内存的管理其实就是管理程序代码和相关数据对内存的消耗，在iOS中，内存通常被分为5个特定的功能性区域：\n\n栈区：存储局部变量，或自动变量，在作用域结束后内存会被回收；栈区也保存了函数调用的现场；\n堆区：存储OC对象，需要开发者手动申请和释放，通常使用malloc、realloc、alloc等函数控制的变量，均存储在堆上，堆在所有的线程，共享库和动态加载的模块中被共享使用；\nBSS区：即Block Started by Symbol，用来存储未初始化的全局变量和静态变量；\n数据区：用来存储已经初始化的全局变量、静态变量和常量；\n代码区：加载程序代码。\n\n在5个内存区域中，除了堆区需要开发者手动进行内存的管理外，其他区域均由系统自动进行管理。\n引用计数是Objective-C语言提供的内存管理技术，每一个Objective-C对象都有一个retainCount属性，该属性便是引用计数机制的根本。一个Objective-C对象是否应该被释放，取决于retainCount是否为0。\n关于MRCMRC内存管理有如下两个原则：\n\n谁持有对象，谁负责释放，不是自己持有的不能释放；\n当对象不再被需要时，需要主动释放。\n\n在OC中，会对对象进行持有的方法有alloc、new、copy、mutableCopy、retain。其中retain是对当前对象进行持有，使得引用计数加1，其余四个是创建新的对象，创建后引用计数加1。\n关于ARCARC是Xcode编译器的功能，ARC并没有改变MRC内存管理的两个原则，也并没有在运行时增加新的特性，ARC仅仅是在编译时帮助开发者将retain和release方法给补上。\nARC下，有几个关键的修饰符：**__strong、__weak、__unsafe_unretained、__autoreleasing，被称为所有权修饰符，在开发中，开发者所使用的指针默认使用__strong**修饰符。\n__strong修饰符通常是对变量进行强引用，主要有三方面的作用：\n\n使用__strong修饰的变量如果是自己生成的，则会被添加进自动释放池，在作用域结束后，会被release一次；\n使用__strong修饰的变量如果不是自己生成的，则会被强引用，即会被持有使其引用计数加1，在离开作用域之后，会被release一次；\n使用__strong修饰的变量如果重新赋值或者置为nil，则变量会被release一次。\n\n__weak修饰符通常用来对变量进行弱引用，最大的用途是避免ARC环境下的循环引用问题。循环引用问题是ARC中造成内存泄漏的主要问题。__weak修饰符主要有两个作用：\n\n被__weak修饰的变量仅提供弱引用，不会使其引用计数增加。变量对象如果是自己生成的，则会被添加到自动释放池，会在离开作用域是被release一次，如果不是自己生成的，则在离开作用域后，不会进行release操作；\n被__weak修饰的变量指针，变量如果失效，则指针会被自动置为nil，否则可能会造成野指针异常。\n\n__unsafe_unretained修饰符是不全安的，该修饰符的作用也是对变量进行弱引用，和__weak不同的是，当变量失效后，其指针不会被自动置为nil。__unsafe_unretained修饰符的主要作用：\n\n被__unsafe_unretained修饰的变量仅提供弱引用，不会使其引用计数增加。变量对象如果是自己生成的，则会在离开作用域后release一次，如果不是自己生成的，则在离开作用域后，不进行release操作；\n被__unsafe_unretained修饰的变量，当变量失效后，被修饰指针不会被安全处理为nil，即旧地址依然保存。\n\n__autoreleasing修饰符与自动释放池有关。\n在使用ARC时，有以下几条原则：\n\n不能使用retain、release、autorelease函数，不可访问retainCount属性\n不能调用dealloc函数，可以覆写dealloc函数，但是在其视线中不可调用父类的dealloc函数\n不能使用NSAutoreleasePool，可以使用@autoreleasepool代替\n对象类型变量不能作为C语言的结构体\n\n属性修饰符类是属性和方法的集合。属性用来存储类中的数据，方法用来描述类的行为。\n属性在声明时会默认添加修饰符。在MRC环境下，默认的属性修饰符为atomic，readWrite，retain，在ARC下，默认的属性修饰符为atomic，readWrite，strong\\assign。\n通常情况下，在声明属性时会使用@property，此时编译器或自动帮助声明和实现属性的Setter方法和Getter方法。\n关于内存管理相关的属性修饰符有如下几种：\n\n        \n            修饰符\n            作用\n        \n        \n            assign\n            直接赋值，和引用计数无关，用来声明简单数据类型的属性，例如int\n        \n        \n            retain\n            对旧对象进行释放，并强引用新的对象，使其引用计数加1，用在MRC中\n        \n        \n            strong\n            对新对象进行强引用，释放旧对象，使其引用计数加1，作用与retain相似，用在ARC中\n        \n        \n            copy\n            在实现Setter方法时，采用copy函数，会生成新的对象，并被自己持有\n        \n        \n            weak\n            弱引用，不对所赋值的对象进行持有，但是是安全的，对对象不可用时，会被置为nil，用在ARC中\n        \n        \n            unsafe_unreatined\n            弱引用，和weak不同的是，如果引用的对象不可用，则当前指针不会被置为nil，会产生野指针\n        \n    \n\n自动释放内存在iOS中，对象的创建除了使用alloc、new等函数创建外，还可使用对象的对象方法来创建，但此时对象的创建方式并不符合“谁持有对象，谁负责释放”的原则，此类方式创建的对象在内存管理上，则将管理权移交给了自动释放池。\n我们知道，release函数的作用是对当前对象进行一次引用计数减1，当引用计数为0时，才真实释放对象所使用的内存。而autorelease，其本质上是使release函数的调用进行延迟调用了。可以简单的把autorelease方法的对象成为自动释放对象，自动释放对象的内存管理是提交给自动释放池处理的。\n自动释放池@autoreleasepool{}标识就是自动释放池，当自动释放池操作结束后，其会向被添加进自动释放池的所有对象发送release消息。@autoreleasepool{}的写法是ARC下的下发，在MRC坏境下，需要创建自动释放池对象，然后进行使用。\nNSAutoreleasePool *pool &#x3D; [[NSAutoreleasePool alloc] init];\n&#x2F;&#x2F; 添加进自动释放池的对象\n[pool release];\n\n另外，在iOS系统运行应用程序时，会自动创建一些线程，每个线程都默认拥有自己的自动释放池。还有，在每次执行时间循环时，都活将其自动释放池清空。因此，在大多数情况下，开发者不需要手动创建自动释放池，例外的是，系统的自动释放池会在每次时间循环结束后清空，如果代码中有大量的循环，会生成大量的自动释放对象，则可能会导致内存消耗瞬时增长。\n杜绝内存泄漏内存泄漏的核心问题是循环引用。\n循环引用：在OC设计中，对象会对其内部的属性进行持有，当一个对象的引用计数为0，将其内存回收时，这个对象会向其内的所有属性发送release消息，让其中的属性对象进行释放。如果对象内的某个属性再次对当前的对象进行了持有，则会产生循环引用。\nBlock与循环引用Block是OC中一种十分强大的语法。使用Block，可以将代码块作为属性、参数以及变量来使用，并且可以灵活地执行这块代码。Block的实质是一段可执行的代码块，对于Block类型的属性和变量，可以对其进行赋值。但究其根本，Block的本质还是对象。\n对于Block的使用，有一些有趣的地方，在Block中访问Block外的数据时没有问题的，无论是对象数据还是基本数据类型数据，但是如果要在Block中修改Block外的数据，可能会发生异常，可变字符串等外部数据的修改不会发生异常。\n其实并不是Block对外部数据修改有什么特殊的设计，而是因为在Block中，任何外部数据都是不允许被修改的，可变类型数据能够被修改，是因为对象指针所指向的内存存放的只是对象数据的地址，并不是对象数据本身，只要地址不被修改，只修改对象的数据是没有问题的。\n在Block内部无法修改外部数据的根本原因在于，Block中访问外部变量时，都会对其进行拷贝和强引用，这里的拷贝是直接拷贝，如果在Block外部和内部分别打印对象，会看到对象的地址是不同的。\n如果要保证在Block内部可以自由修改外部的数据，OC提供了__block关键字，使用该关键字修饰的变量，可以在Block中直接访问原始变量，而没有拷贝。\nself.myblock &#x3D; ^BOOL(int param)&#123;\n    NSLog(@&quot;%@&quot;, self);\n    return YES;\n&#125;;\n上述代码是Block中循环引用的经典例子。其中myblock和self之间产生的循环引用。要解决Block中的循环引用，只需要在Block中使用弱引用的指针即可，这样在Block的作用域结束后，其对外部变量的引用也会自然切换，避免循环引用。\n代理与循环引用代理是另一种可能会产生循环引用的场景。在iOS中，除了系统的一些原生的组件需要通过代理函数来进行回调外，开发者也经常使用代理来进行传值、逻辑回调、组件配置等。有时，开发者会使用代理来进行反向传值，而反向传值的时候需要在视图控制器中设置代理，如果代理属性采用了strong修饰符，则视图控制器对代理对象是强应用，而定义代理的类可能又是视图控制器的属性，造成了循环引用，造成内存泄漏，因此在使用代理模式的时候，设置代理属性一般采用如下修饰符：\n@property (nonatomic, weak) id&lt;CustomeDelegate&gt; delegate;\n\n\n定时器引起的内存泄漏定时器通产个用来进行循环任务的执行，NSTimer是iOS中极易产生循环引用的一个类。通常在使用定时器时，会定义一个定时器对象如下：\n@property (nonatomic, strong) NSTimer * timer;\n\n再具体使用定时器时，如下：\nself.timer &#x3D; [NSTimer scheduledTimerWithTimeInterval: 1 target: self selector:@selector(timerRun) userinfo: nil repeat: YES];\n\n当定时器对象所在的视图控制器被dismiss之后，视图控制器并没有执行dealloc函数，原因在于定时器对象实际上持有了视图控制器，只有当定时器失效后，其才会释放所持有的视图控制器。因此，在视图控制器返回前，开发者可以手动调用invalidate方法使得定时器失效，已避免循环引用。\n\n\n\n\n\n\n\n\n\niOS 10 SDK 中已经提供了避免循环引用的NSTimer 新 API。\n“僵尸”对象首先，僵尸对象和内存泄漏无任何关系。但是产生僵尸对象也属于内存管理问题。当一个对象被释放后，如果其指针没有置空，则这个指针就变成了野指针，此时该对象被称为僵尸对象。\n僵尸对象的捕获在OC中，内存的使用包含如下几个阶段：\n\n请求创建对象，向系统申请一块内存空间，在申请完成后，这块内存空间不能在做他用；\n对象被释放，此时这块内存空间变为闲置，可以被再次申请使用；\n在此块内存重新被申请使用之前，这块内存中的数据依然存在；\n此时如果依然有指针指向这块内存，则此指针为野指针；\n当野指针对这块内存进行访问时，如果这块内存已经被重新分配，则会出现系统问题，如果没有被分配，则不会出现系统问题。\n\n在MRC下，当一个对象被release后，再去访问这个对象的时候，就会出现异常，出现僵尸对象。而在ARC下,Xcode也提供了捕获僵尸对象的选项，供开发者使用。Zombie Objects选项\n处理僵尸对象一般在开发中，僵尸对象一旦出现，大多数情况是代码逻辑的问题，但是如果做到万无一失，避免由于僵尸对象带来应用程序的崩溃呢？\n在OC中，向空指针发送任何消息都是无效的。因此，访问到僵尸对象的根本问题是野指针的问题。在ARC中，使用__weak和__strong修饰的变量指针，在对象释放后被自动置为nil，这就大大减少了野指针的问题。另外一种方式就是使用OC的消息机制来规避所有的僵尸对象问题。\nCoreFoundation框架中的内存管理CoreFoundation框架是由C语言实现的一组编程接口，与Foundation框架提供类似的基础功能，不同的是Foundation框架是由OC语言实现的，CoreFoundation也提供了字符串、数组、集合、颜色、时间和URL等对象。\nCoreFoundation框架中依然采用引用计数的方式进行内存管理，但并不支持ARC。\n在CoreFoundation框架中，有几条内存管理法则：\n\n自己创建的对象要自己负责释放；\n如果使用别人创建的对象，要保证其可用，则需要对对象进行持有；\n如果对对象进行了持有，则当不在需要此对象时，要进行释放。\n\n在CoreFoundation框架中，使用带有Create、Copy此类字段的函数获取的对象会被认为是自己创建的对象，要负责这些对象的释放。当使用滴啊有Get这样的字段的函数获取对象时，默认并不对此对象进行持有，可以手动调用CFRetain()函数进行持有。\n总结\nOC是面向对象的语言，但是对象仅仅是引用层面的一种抽象，抛开其华丽的外衣，底层依然是最为朴素的结构体和指针。\nOC语言采用了引用计数的内存管理模型，对内存进行管理；\n除了用户自建的内存管理池意外，系统在每个线程都维护了一个系统级别的自动释放池；\nOC语言的类型检查都是编译时的特性；\nOC语言的数据传递是运行时决定的。\n\n","slug":"2020-06-17-iOS-memory-manage-tips","date":"2023-05-13T11:29:06.795Z","categories_index":"","tags_index":"开发知识 iOS"},{"id":"6fca2ac91a092d45af749e0779750e56","title":"Runtime剖析01 --- 基本数据结构：objc_object & objc_class","content":"众所周知，Objective-C语言是一门动态性很强的语言，与C、C++等语言有着很大的不同。Objective-C语言的动态性基本上都是由Runtime机制进行支撑和实现的，Runtime的实现，融合了C、C++，以及汇编语言。\n什么是Runtime？C、C++等静态语言中的各种数据结构都是在编译期已经决定了，不能被修改，而Objective-C作为动态性语言，在程序的运行期，可以动态修改一个类的结构，例如修改方法的实现，变量的绑定等等。\nObjective-C语言作为动态语言，将原本编译期决定的事情推迟到运行期，仅仅采用编译器是无法完成的，因此就需要运行期有一套自己的运行时系统，而这个系统就是Runtime，也是Runtime存在的意义，以及Objective-C语言运行框架的基石。\n在实际的开发中，与Runtime交互的情况大致有三种：\n\nObjective-C源码：大多数情况下，开发者采用的都是直接使用Objective-C语言进行编码，而在Objective-C语言源码的背后，都是由Runtime进行底层支撑，Objective-C语言中所使用的数据类型，在Runtime中都有对应的C语言结构体，甚至汇编语言的实现等。\n通过NSObject：在Cocoa中，大部分的类都继承自NSObject，而NSObject的定义是Runtime决定的。以及NSObject中的大多数方法，都是运行时动态决定的，背后其实是Runtime对应数据结构的支持。例如常用的isKindOfClass和isMemberOfClass检查类是否属于指定的Class的继承体系中；responderToSelector 检查对象是否能响应指定的消息；conformsToProtocol 检查对象是否遵循某个协议；methodForSelector返回指定方法实现的地址等。\n直接调用Runtime API：Runtime是一个由一系列函数和数据机构组成，具有公共接口的动态共享库。很多函数的功能和Objective-C语言中的含有具有同等的功能。一般情况下不会直接访问Runtime的API，但是当有一些底层的需求需要实现时，例如为现有类动态添加属性等。Objective-C Runtime Reference\n\nObjective-C语言中的各种黑魔法，其实都是在Runtime的基础上，对底层数据机构的各类应用。\nNSObject解析在Objective-C中，几乎所有的类的基类，都是NSObject。因此要深入了解Objective-C类的相关结构，先从NSObject类开始。\n在iOS SDK中，对于NSObject类的定义如下：\n@interface NSObject &lt;NSObject&gt; &#123;\n#pragma clang diagnostic push\n#pragma clang diagnostic ignored &quot;-Wobjc-interface-ivars&quot;\n    Class isa  OBJC_ISA_AVAILABILITY;\n#pragma clang diagnostic pop\n&#125;\n\nNSObject类仅有一个实例变量isa，并且遵循NSObject协议。先说说NSObject协议，在该协议中，定义了NSObject类的一些通用方法，例如performSelector：、isMemberOfClass、superclass等等，使用协议去定义通用的一些方法，也让类的扩展更加的容易。\nNSObject类的变量仅有Class isa，变量的类型Class定义如下：\ntypedef struct objc_class *Class;\n\nClass本质是指向objc_class结构体的指针，而objc_class结构体的定义如下：\nstruct objc_class : objc_object &#123;\n    &#x2F;&#x2F; Class ISA;\n    Class superclass;\n    cache_t cache;             &#x2F;&#x2F; formerly cache pointer and vtable\n    class_data_bits_t bits;    &#x2F;&#x2F; class_rw_t * plus custom rr&#x2F;alloc flags\n\n    &#x2F;&#x2F; 省略其他方法\n    ...\n&#125;\n\nobjc_class可以看到objc_class继承自objc_object，即在Runtime中，class本质也是一个对象。在objc_class结构体的定义中，有三个成员变量：\n\nClass superclass： 表示当前类的父类对象，类型同样是Class；\ncache_t cache： Objective-C方法调用的优化结构体。对应的数据结构如下：\n\nstruct cache_t &#123;\n\tstruct bucket_t *buckets();\n    mask_t mask();\n    mask_t occupied();\n    void incrementOccupied();\n    void setBucketsAndMask(struct bucket_t *newBuckets, mask_t newMask);\n    void initializeToEmpty();\n\n    unsigned capacity();\n    bool isConstantEmptyCache();\n    bool canBeFreed();\n\n    &#x2F;&#x2F; 省略其他方法\n    ...\n&#125;\n\nstruct bucket_t &#123;\n\texplicit_atomic&lt;uintptr_t&gt; _imp;\n    explicit_atomic&lt;SEL&gt; _sel;\npublic:\n\tinline SEL sel() const &#123; return _sel.load(memory_order::memory_order_relaxed); &#125;\n\n    inline IMP imp(Class cls) const &#123;\n        uintptr_t imp &#x3D; _imp.load(memory_order::memory_order_relaxed);\n        if (!imp) return nil;\n#if CACHE_IMP_ENCODING &#x3D;&#x3D; CACHE_IMP_ENCODING_PTRAUTH\n        SEL sel &#x3D; _sel.load(memory_order::memory_order_relaxed);\n        return (IMP)\n            ptrauth_auth_and_resign((const void *)imp,\n                                    ptrauth_key_process_dependent_code,\n                                    modifierForSEL(sel, cls),\n                                    ptrauth_key_function_pointer, 0);\n#elif CACHE_IMP_ENCODING &#x3D;&#x3D; CACHE_IMP_ENCODING_ISA_XOR\n        return (IMP)(imp ^ (uintptr_t)cls);\n#elif CACHE_IMP_ENCODING &#x3D;&#x3D; CACHE_IMP_ENCODING_NONE\n        return (IMP)imp;\n#else\n#error Unknown method cache IMP encoding.\n#endif\n    &#125;\n\n    template &lt;Atomicity, IMPEncoding&gt;\n    void set(SEL newSel, IMP newImp, Class cls);\n&#125;\n\ncache结构体的核心是类型为bucket_t的指针，指向以**_imp和_sel**对应的缓存点。\n\n\n\n\n\n\n\n\n\nuintptr_t数据类型定义为：\n#ifndef _UINTPTR_T\n#define _UINTPTR_T\ntypedef unsigned long           uintptr_t;\n#endif &#x2F;* _UINTPTR_T *&#x2F;\n\n本质类型为无符号长整型数据类型，在runtime中，大多数基本数据类型均为无符号长整型，例如**void ***。\n上文已经提到，cache的存在是为了优化方法的调用，在Runtime中方法的调用流程：\n\n当要调用一个方法时，首先去当前类的cache方法缓存中寻找，如果存在，则直接执行；\n如果cache中不存在，则会去当前类的方法列表中寻找，找到后执行并将该方法按照实现**_imp和方法签名_sel存放在cache**中，以便下次快速调用。\n\n\nclass_data_bits_t bits：该变量可以说是Class的核心成员变量，本质是一个可以被Mask的指针类型。根据不同的Mask，取出不同的值。\n\nstruct class_data_bits_t &#123;\n    friend objc_class;\n\n    &#x2F;&#x2F; Values are the FAST_ flags above.\n    uintptr_t bits;\npublic:\n    class_rw_t* data() const &#123;\n        return (class_rw_t *)(bits &amp; FAST_DATA_MASK);\n    &#125;\n    void setData(class_rw_t *newData)\n    &#123;\n        ASSERT(!data()  ||  (newData-&gt;flags &amp; (RW_REALIZING | RW_FUTURE)));\n        &#x2F;&#x2F; Set during realization or construction only. No locking needed.\n        &#x2F;&#x2F; Use a store-release fence because there may be concurrent\n        &#x2F;&#x2F; readers of data and data&#39;s contents.\n        uintptr_t newBits &#x3D; (bits &amp; ~FAST_DATA_MASK) | (uintptr_t)newData;\n        atomic_thread_fence(memory_order_release);\n        bits &#x3D; newBits;\n    &#125;\n    &#x2F;&#x2F; 省略其他方法\n    ...\n&#125;\n\nclass_data_bits_t bits仅仅包含一个成员变量bits，该变量不仅包含指针，同时包含Class的各种异或flag，当需要取出信息时，需要用对应的FAST_前缀开头的flag掩码对bits进行按位与操作。\n例如，在获取信息的方法\nclass_rw_t* data() const &#123;\n    return (class_rw_t *)(bits &amp; FAST_DATA_MASK);\n&#125;\n\n中，通过对bits进行FAST_DATA_MASK的与操作，返回class_rw_t *。class_rw_t以及class_ro_t可以说是Class中的核心结构，其定义如下：\nstruct class_rw_t &#123;\n    &#x2F;&#x2F; Be warned that Symbolication knows the layout of this structure.\n    uint32_t flags;\n    uint16_t witness;\n\n    Class firstSubclass;\n    Class nextSiblingClass;\n\n    &#x2F;&#x2F; 方法列表\n    const method_array_t methods();\n    &#x2F;&#x2F; 属性列表\n    const property_array_t properties();\n    &#x2F;&#x2F; 协议列表\n    const protocol_array_t protocols();\n\n    &#x2F;&#x2F; 省略其他方法\n    ...\n&#125;\n\nstruct class_ro_t &#123;\n    uint32_t flags;\n    uint32_t instanceStart;\n    uint32_t instanceSize;\n    const uint8_t * ivarLayout;\n    \n    const char * name;\n    method_list_t * baseMethodList;\n    protocol_list_t * baseProtocols;\n    const ivar_list_t * ivars;\n\n    const uint8_t * weakIvarLayout;\n    property_list_t *baseProperties;\n\n    &#x2F;&#x2F; 省略其他方法\n    ...\n&#125;\n\n在class_rw_t结构体中，方法列表method_array_t、属性列表property_array_t、协议列表protocol_array_t是可以被Runtime修改和扩展的。\n而在class_ro_t结构体中包含了类的名称name、方法列表method_list_t、属性列表property_list_t、协议列表protocol_list_t等类的基本信息，class_ro_t中的信息时不允许修改，并且不可扩展的。\nobjc_class  &lt;-   class_data_bits_t  -&gt;  FAST_DATA_MASK  &lt;-  class_rw_t   &lt;-  class_ro_t\nrealizeClassstatic Class realizeClassWithoutSwift(Class cls, Class previously)\n&#123;\n    &#x2F;&#x2F; 省略\n    ...\n\n    auto ro &#x3D; (const class_ro_t *)cls-&gt;data();\n    auto isMeta &#x3D; ro-&gt;flags &amp; RO_META;\n    if (ro-&gt;flags &amp; RO_FUTURE) &#123;\n        &#x2F;&#x2F; This was a future class. rw data is already allocated.\n        rw &#x3D; cls-&gt;data();\n        ro &#x3D; cls-&gt;data()-&gt;ro();\n        ASSERT(!isMeta);\n        cls-&gt;changeInfo(RW_REALIZED|RW_REALIZING, RW_FUTURE);\n    &#125; else &#123;\n        &#x2F;&#x2F; Normal class. Allocate writeable class data.\n        rw &#x3D; objc::zalloc&lt;class_rw_t&gt;();\n        rw-&gt;set_ro(ro);\n        rw-&gt;flags &#x3D; RW_REALIZED|RW_REALIZING|isMeta;\n        cls-&gt;setData(rw);\n    &#125;\n\n    &#x2F;&#x2F; 省略\n    ...\n&#125;\n\nrealizeClass是Runtime构造一个完整的类的入口，在没有调用realizeClass之前，类是不完整的。上述函数中，最开始返回的仅仅是class_ro_t类的基本信息，在进行realizeClass时，将类的Category中定义的各种扩展附加到类上，同时改写data()的返回值为class_rw_t类型。\n因此一个类的完整信息保存在结构class_rw_t中，class_ro_t结构仅仅保存类的基本信息。\nobjc_object上述objc_class继承自objc_object，也就是说在Objective-C中，类也是一个对象，而对象在runtime中被定义为objc_object结构体。\nstruct objc_object &#123;\nprivate:\n    isa_t isa;\n\npublic:\n\n    &#x2F;&#x2F; ISA() assumes this is NOT a tagged pointer object\n    Class ISA();\n\n    &#x2F;&#x2F; rawISA() assumes this is NOT a tagged pointer object or a non pointer ISA\n    Class rawISA();\n\n    &#x2F;&#x2F; getIsa() allows this to be a tagged pointer object\n    Class getIsa();\n    \n    &#x2F;&#x2F; 省略其他方法\n    ...\n&#125;\n\nobjc_object结构体的定义相对较为简单，其中仅包含一个isa_t的联合体类型。\nunion isa_t &#123;\n    isa_t() &#123; &#125;\n    isa_t(uintptr_t value) : bits(value) &#123; &#125;\n\n    Class cls;\n    uintptr_t bits;\n&#125;;\n\nisa_t是一个联合体，可以表示Class或者uintptr_t类型，在Objective-C 2.0 中大多数使用的是uintptr_t类型。其中bits是一个64位的数据，每一位或者几位都表示了关于当前对象的信息。\n再探objc_object和objc_classobjc_class继承自objc_object，说明在objc_class中也有一个isa属性，此时这个属性表示当前类属于哪个类，而这种说明类是属于哪个类的类，称之为元类（meta-class）。\n元类并不是类的父类，元类在Objective-C的消息转发机制中会由详解，此时，只需要直到，每一个类都有一个与之对应的元类。\nid在Objective-C 中，id类型经常会被使用到，它表示任意类型的类实例变量，在Runtime中，id的定义如下：\ntypedef struct objc_object *id;\n\n其实id类型就是一个objc_object *，因为objc_object的isa的存在，所有Runtime是可以知道id类型对应的真实类型的。\n\n\n\n\n\n\n\n\n\n**Void ***表示任意类型的指针。\n总结本文中，从开发者常用的NSObject出发，了解了Objective-C语言中类和对象所对应的数据结构objc_class和objc_object。可以使用一张图了解这三者之间的关系。\n\n","slug":"2020-06-23-iOS-runtime-basic-structure","date":"2023-05-13T11:29:06.795Z","categories_index":"","tags_index":"Runtime"},{"id":"3007adc9b3f366505974b3565c38f1eb","title":"Runtime剖析02 --- 消息与消息发送机制","content":"在Objective-C中，消息发送指Runtime会根据SEL查找对应的IMP，当查找到，则调用函数指针进行方法调用，若查找不到，则进入动态消息解析和消息转发流程，如果动态解析和消息转发失败，则程序会崩溃。\n消息相关数据结构SELSEL称之为消息选择器，相当于一个key，在类的消息列表中，可以根据这个key查找对应的消息实现IMP。\n在Runtime中，SEL的定义如下：\n&#x2F;&#x2F;&#x2F; An opaque type that represents a method selector.\ntypedef struct objc_selector *SEL;\n\n可以看到SEL其实是一个objc_selector *结构体指针，但是在苹果开源的runtime中并没有其定义，目前SEL仅是一个字符串。\n虽然SEL可以作为key对消息进行查找，但是当不同的类有着相同的SEL的时候，再进行消息实现查找时，可能无法确定消息实现真实的归属，因此在进行消息实现查找时，会结合消息发送的目标Class，才能找到具体的最终的IMP。\nmethod_t开篇已说，runtime会根据SEL查找对应的实现IMP。具体地说，runtime会在Class的方法列表中查找方法的实现，在方法列表中方法的实现是以method_t结构体的形式存储的。\nstruct method_t &#123;\n    SEL name;\n    const char *types;\n    MethodListIMP imp;\n\n    struct SortBySELAddress :\n        public std::binary_function&lt;const method_t&amp;,\n                                    const method_t&amp;, bool&gt;\n    &#123;\n        bool operator() (const method_t&amp; lhs,\n                         const method_t&amp; rhs)\n        &#123; return lhs.name &lt; rhs.name; &#125;\n    &#125;;\n&#125;;\n\nmethod_t结构体重包含了SEL的名称，以及指向对应试下的imp指针，另外types指的是方法的返回值和参数类型，其格式一般为v24@0:8@16，此种格式被称为Type Encodings，对应的解释说明详见Type Encodings。\nIMPIMP本质上是一个函数指针，用于指向方法的具体实现，在runtime中，其定义如下：\n&#x2F;&#x2F;&#x2F; A pointer to the function of a method implementation. \n#if !OBJC_OLD_DISPATCH_PROTOTYPES\ntypedef void (*IMP)(void &#x2F;* id, SEL, ... *&#x2F; ); \n#else\ntypedef id _Nullable (*IMP)(id _Nonnull, SEL _Nonnull, ...); \n#endif\n\n\n\n\n\n\n\n\n\n\nIMP是由编译器生成的，如果知道了IMP的地址，就可以绕过runtime的消息发送过程，直接调用函数实现。\n在消息发送过程中，runtime会根据id和SEL来唯一确定IMP并进行调用。\n消息在Objective-C中，函数的调用被称为消息发送。在进行代码编译时，代码会被修改为objc_msgSend的格式。\nOBJC_EXPORT id _Nullable\nobjc_msgSend(id _Nullable self, SEL _Nonnull op, ...)\n    OBJC_AVAILABLE(10.0, 2.0, 9.0, 1.0, 2.0);\n\n**objc_msgSend()**形式即为Objective-C中的消息发送的入口，该函数的具体实现是由汇编语言实现的，其目的一是为了提高执行效率，二是因为该函数的返回值类型是可变的，汇编正好具有返回值类型多样性的特性。\n除了**objc_msgSend()**之外，编译器还会根据具体的情况，将消息转发改写为如下形式之一：\n\nobjc_msgSend\nobjc_msgSend_stret\nobjc_msgSendSuper\nobjc_msgSendSuper_stret\n\n当消息发送给当前类的Super Class的时候，编译器会将消息发送改写为objc_msgSendSuper的格式。\nOBJC_EXPORT id _Nullable\nobjc_msgSendSuper(struct objc_super * _Nonnull super, SEL _Nonnull op, ...)\n    OBJC_AVAILABLE(10.0, 2.0, 9.0, 1.0, 2.0);\n\n在objc_msgSendSuper函数的参数中，第一个参数不再是当前类的指针，而变为objc_super *结构体指针，objc_super结构体包含两个数据，receiver指调用super方法的对象，即消息接收者，而super_class表示当前子类的父类对象。\nstruct objc_super &#123;\n    &#x2F;&#x2F;&#x2F; Specifies an instance of a class.\n    __unsafe_unretained _Nonnull id receiver;\n    &#x2F;&#x2F;&#x2F; Specifies the particular superclass of the instance to message. \n    __unsafe_unretained _Nonnull Class super_class;\n&#125;;\n\n\n\n\n\n\n\n\n\n\n带有**_stret**的函数，表示方法返回的是结构体类型。\nobjc_msgSend\tENTRY _objc_msgSend\n\tUNWIND _objc_msgSend, NoFrame\n\n\tcmp\tp0, #0\t\t\t&#x2F;&#x2F; nil check and tagged pointer check\n#if SUPPORT_TAGGED_POINTERS\n\tb.le\tLNilOrTagged\t\t&#x2F;&#x2F;  (MSB tagged pointer looks negative)\n#else\n\tb.eq\tLReturnZero\n#endif\n\tldr\tp13, [x0]\t\t&#x2F;&#x2F; p13 &#x3D; isa\n\tGetClassFromIsa_p16 p13\t\t&#x2F;&#x2F; p16 &#x3D; class\nLGetIsaDone:\n\t&#x2F;&#x2F; calls imp or objc_msgSend_uncached\n\tCacheLookup NORMAL, _objc_msgSend\n\n#if SUPPORT_TAGGED_POINTERS\nLNilOrTagged:\n\tb.eq\tLReturnZero\t\t&#x2F;&#x2F; nil check\n&#x2F;&#x2F; 省略其他\n\n\n进入objc_msgSend后，首先通过cmp\tp0, #0检查函数参数receiver是否为nil，如果为nil，则进入LReturnZero，返回0；\n如果不为nil，则将receiver的isa存储在p13寄存器；\n在寄存器p13中，取出isa对应的Class，存储到p16寄存器；\nClass获取完成后，调用CacheLookup NORMAL函数，查找Class的方法缓存列表，如果命中，则调用**_objc_msgSend，如果未命中，则调用objc_msgSend_uncached**。\n\nobjc_msgSend_uncached也是汇编语言实现，作用是为方法缓存列表中未查找到方法缓存时，在Class的方法列表中进行查找。\nSTATIC_ENTRY __objc_msgSend_uncached\n\tUNWIND __objc_msgSend_uncached, FrameWithNoSaves\n\n\t&#x2F;&#x2F; THIS IS NOT A CALLABLE C FUNCTION\n\t&#x2F;&#x2F; Out-of-band p16 is the class to search\n\t\n\tMethodTableLookup\n\tTailCallFunctionPointer x17\n\n\tEND_ENTRY __objc_msgSend_uncached\n\nobjc_msgSend_uncached内部调用了MethodTableLookup，MethodTableLookup是一个汇编实现的宏定义，其内部调用了C语言函数lookUpImpOrForward。\nlookUpImpOrForwardextern IMP lookUpImpOrForward(id obj, SEL, Class cls, int behavior);\n\nlookUpImpOrForward函数的目的是根据Class和SEL，在当前类或者当前类的父类中找到方法对应的IMP，同时，缓存找到的对应IMP到当前类的方法缓存列表中。如果没有找到对应的IMP，则会进入到消息转发流程。\nIMP lookUpImpOrForward(id inst, SEL sel, Class cls, int behavior)\n&#123;\n    const IMP forward_imp &#x3D; (IMP)_objc_msgForward_impcache;\n    IMP imp &#x3D; nil;\n    Class curClass;\n\n    runtimeLock.assertUnlocked();\n\n    &#x2F;&#x2F; Optimistic cache lookup\n    &#x2F;&#x2F; 首先在根据class和sel在方法缓存中查找imp\n    if (fastpath(behavior &amp; LOOKUP_CACHE)) &#123;\n        imp &#x3D; cache_getImp(cls, sel);\n        &#x2F;&#x2F; 如果查找到，则直接进入到done_nolock\n        if (imp) goto done_nolock;\n    &#125;\n\n    &#x2F;&#x2F; runtimeLock is held during isRealized and isInitialized checking\n    &#x2F;&#x2F; to prevent races against concurrent realization.\n\n    &#x2F;&#x2F; runtimeLock is held during method search to make\n    &#x2F;&#x2F; method-lookup + cache-fill atomic with respect to method addition.\n    &#x2F;&#x2F; Otherwise, a category could be added but ignored indefinitely because\n    &#x2F;&#x2F; the cache was re-filled with the old value after the cache flush on\n    &#x2F;&#x2F; behalf of the category.\n\n    runtimeLock.lock();\n\n    &#x2F;&#x2F; We don&#39;t want people to be able to craft a binary blob that looks like\n    &#x2F;&#x2F; a class but really isn&#39;t one and do a CFI attack.\n    &#x2F;&#x2F;\n    &#x2F;&#x2F; To make these harder we want to make sure this is a class that was\n    &#x2F;&#x2F; either built into the binary or legitimately registered through\n    &#x2F;&#x2F; objc_duplicateClass, objc_initializeClassPair or objc_allocateClassPair.\n    &#x2F;&#x2F;\n    &#x2F;&#x2F; TODO: this check is quite costly during process startup.\n    checkIsKnownClass(cls);\n\n    &#x2F;&#x2F; 如果class还未realize，先进行realize\n    if (slowpath(!cls-&gt;isRealized())) &#123;\n        cls &#x3D; realizeClassMaybeSwiftAndLeaveLocked(cls, runtimeLock);\n        &#x2F;&#x2F; runtimeLock may have been dropped but is now locked again\n    &#125;\n\t&#x2F;&#x2F; 如果class还未initialize，先进行initialize\n    if (slowpath((behavior &amp; LOOKUP_INITIALIZE) &amp;&amp; !cls-&gt;isInitialized())) &#123;\n        cls &#x3D; initializeAndLeaveLocked(cls, inst, runtimeLock);\n        &#x2F;&#x2F; runtimeLock may have been dropped but is now locked again\n\n        &#x2F;&#x2F; If sel &#x3D;&#x3D; initialize, class_initialize will send +initialize and \n        &#x2F;&#x2F; then the messenger will send +initialize again after this \n        &#x2F;&#x2F; procedure finishes. Of course, if this is not being called \n        &#x2F;&#x2F; from the messenger then it won&#39;t happen. 2778172\n    &#125;\n\n    runtimeLock.assertLocked();\n    curClass &#x3D; cls;\n\n    &#x2F;&#x2F; The code used to lookpu the class&#39;s cache again right after\n    &#x2F;&#x2F; we take the lock but for the vast majority of the cases\n    &#x2F;&#x2F; evidence shows this is a miss most of the time, hence a time loss.\n    &#x2F;&#x2F;\n    &#x2F;&#x2F; The only codepath calling into this without having performed some\n    &#x2F;&#x2F; kind of cache lookup is class_getInstanceMethod().\n    &#x2F;&#x2F; 在当前class中没有找到imp，则依次向上查找super class的方法列表\n    for (unsigned attempts &#x3D; unreasonableClassCount();;) &#123;\n        &#x2F;&#x2F; curClass method list.\n        &#x2F;&#x2F; 首先获取当前类的方法体\n        Method meth &#x3D; getMethodNoSuper_nolock(curClass, sel);\n        if (meth) &#123;\n            imp &#x3D; meth-&gt;imp;\n            goto done;\n        &#125;\n        &#x2F;&#x2F; 通过继承链，向上查找IMP\n        if (slowpath((curClass &#x3D; curClass-&gt;superclass) &#x3D;&#x3D; nil)) &#123;\n            &#x2F;&#x2F; No implementation found, and method resolver didn&#39;t help.\n            &#x2F;&#x2F; Use forwarding.\n            imp &#x3D; forward_imp;\n            break;\n        &#125;\n\n        &#x2F;&#x2F; Halt if there is a cycle in the superclass chain.\n        if (slowpath(--attempts &#x3D;&#x3D; 0)) &#123;\n            _objc_fatal(&quot;Memory corruption in class list.&quot;);\n        &#125;\n\n        &#x2F;&#x2F; Superclass cache.\n        &#x2F;&#x2F; 父类缓存\n        imp &#x3D; cache_getImp(curClass, sel);\n        if (slowpath(imp &#x3D;&#x3D; forward_imp)) &#123;\n            &#x2F;&#x2F; Found a forward:: entry in a superclass.\n            &#x2F;&#x2F; Stop searching, but don&#39;t cache yet; call method\n            &#x2F;&#x2F; resolver for this class first.\n            break;\n        &#125;\n        &#x2F;&#x2F; 找到父类的IMP，并缓存\n        if (fastpath(imp)) &#123;\n            &#x2F;&#x2F; Found the method in a superclass. Cache it in this class.\n            goto done;\n        &#125;\n    &#125;\n\n    &#x2F;&#x2F; No implementation found. Try method resolver once.\n    &#x2F;&#x2F; 没有查找到IMP，进入动态方法解析流程\n    if (slowpath(behavior &amp; LOOKUP_RESOLVER)) &#123;\n        behavior ^&#x3D; LOOKUP_RESOLVER;\n        return resolveMethod_locked(inst, sel, cls, behavior);\n    &#125;\n\n done:\n \t&#x2F;&#x2F; 记录并缓存IMP\n    log_and_fill_cache(cls, imp, sel, inst, curClass);\n    runtimeLock.unlock();\n done_nolock:\n \t&#x2F;&#x2F; 未找到对应的IMP，返回nil\n    if (slowpath((behavior &amp; LOOKUP_NIL) &amp;&amp; imp &#x3D;&#x3D; forward_imp)) &#123;\n        return nil;\n    &#125;\n    return imp;\n&#125;\n\nlookUpImpOrForward工作流程：\n\n尝试在当前receiver对应class的cache中查找imp，如果查找到，则调用；\n如果在cache中为查找到imp，则在class的方法列表中查找imp；\n尝试在class的所有super class中查找imp。（首先在super class的cache中查找，如果为找到，则在super class的方法列表中查找）；\n如果还未找到imp，则尝试进行动态方法解析SEL；\n动态解析失败，则尝试进入消息转发流程，让其他class处理SEL。\n\n在查找class的方法列表中是否有SEL对应的IMP时，调用的是**getMethodNoSuper_nolock()**：\nstatic method_t *\ngetMethodNoSuper_nolock(Class cls, SEL sel)\n&#123;\n    runtimeLock.assertLocked();\n\n    ASSERT(cls-&gt;isRealized());\n    &#x2F;&#x2F; fixme nil cls? \n    &#x2F;&#x2F; fixme nil sel?\n\n    auto const methods &#x3D; cls-&gt;data()-&gt;methods();\n    for (auto mlists &#x3D; methods.beginLists(),\n              end &#x3D; methods.endLists();\n         mlists !&#x3D; end;\n         ++mlists)\n    &#123;\n        &#x2F;&#x2F; &lt;rdar:&#x2F;&#x2F;problem&#x2F;46904873&gt; getMethodNoSuper_nolock is the hottest\n        &#x2F;&#x2F; caller of search_method_list, inlining it turns\n        &#x2F;&#x2F; getMethodNoSuper_nolock into a frame-less function and eliminates\n        &#x2F;&#x2F; any store from this codepath.\n        method_t *m &#x3D; search_method_list_inline(*mlists, sel);\n        if (m) return m;\n    &#125;\n\n    return nil;\n&#125;\n\n首先取出class的方法列表method_array_t，然后调用search_method_list_inline()，根据SEL查找对应的method_t。\nALWAYS_INLINE static method_t *\nsearch_method_list_inline(const method_list_t *mlist, SEL sel)\n&#123;\n    int methodListIsFixedUp &#x3D; mlist-&gt;isFixedUp();\n    int methodListHasExpectedSize &#x3D; mlist-&gt;entsize() &#x3D;&#x3D; sizeof(method_t);\n    \n    if (fastpath(methodListIsFixedUp &amp;&amp; methodListHasExpectedSize)) &#123;\n        return findMethodInSortedMethodList(sel, mlist);\n    &#125; else &#123;\n        &#x2F;&#x2F; Linear search of unsorted method list\n        for (auto&amp; meth : *mlist) &#123;\n            if (meth.name &#x3D;&#x3D; sel) return &amp;meth;\n        &#125;\n    &#125;\n    return nil;\n&#125;\n\n在方法查找的时候，会分为两种方式：\n\n如果方法列表是有序的，则使用findMethodInSortedMethodList进行前向查找，使用二分查找方式\n否则直接进行遍历\n\nobjc_msgSendSuper上文已经提到，当消息发送给当前类的Super Class的时候，编译器会将消息发送改写为objc_msgSendSuper的格式。\nOBJC_EXPORT id _Nullable\nobjc_msgSendSuper(struct objc_super * _Nonnull super, SEL _Nonnull op, ...)\n    OBJC_AVAILABLE(10.0, 2.0, 9.0, 1.0, 2.0);\n\n在实际开发中，当使用super关键字调用方法时，编译器则会将代码编译为objc_msgSendSuper的格式。\nsuper关键字本质上类似一个“语法糖”，在代码编译时，编译器会将其替换为objc_super指针类型，来传入到objc_msgSendSuper方法中，而并不是父类的意思。\nstruct objc_super &#123;\n    &#x2F;&#x2F;&#x2F; Specifies an instance of a class.\n    &#x2F;&#x2F; 消息的接收者，一般为当前类的实例对象。\n    __unsafe_unretained _Nonnull id receiver;\n\n    &#x2F;&#x2F;&#x2F; Specifies the particular superclass of the instance to message. \n    &#x2F;&#x2F; 告知查找方法IMP的去向，当前类实例的父类对象。\n    __unsafe_unretained _Nonnull Class super_class;\n&#125;;\n\n当使用super关键字调用方法时，runtime会到当前类的父类中查找对应IMP，然后将消息发送到当前类的实例上。\n这也解释了为什么**[self class] 和 [super class]**会输出同样结果的原因。\n同样objc_msgSendSuper也是由汇编语言实现的，实现如下：\nENTRY _objc_msgSendSuper\n\nldr\tr9, [r0, #CLASS]\t&#x2F;&#x2F; r9 &#x3D; struct super-&gt;class\nCacheLookup NORMAL, _objc_msgSendSuper\n&#x2F;&#x2F; cache hit, IMP in r12, eq already set for nonstret forwarding\nldr\tr0, [r0, #RECEIVER]\t&#x2F;&#x2F; load real receiver\nbx\tr12\t\t\t&#x2F;&#x2F; call imp\n\nCacheLookup2 NORMAL, _objc_msgSendSuper\n&#x2F;&#x2F; cache miss\nldr\tr9, [r0, #CLASS]\t&#x2F;&#x2F; r9 &#x3D; struct super-&gt;class\nldr\tr0, [r0, #RECEIVER]\t&#x2F;&#x2F; load real receiver\nb\t__objc_msgSend_uncached\n\nEND_ENTRY _objc_msgSendSuper\n\n寄存器r9中保存的是当前实例的父类对象，获取到对应的父类后，调用CacheLookup在方法缓存中查找对应imp，缓存命中后，取出receiver，调用imp。如果未在缓存中命中IMP，则调用**__objc_msgSend_uncached，传入super class**进行方法查找。\n动态解析如果在类的继承链中没有找到对应的IMP，runtime则会进入消息的动态解析流程，即进入到lookUpImpOrForward中的resolveMethod_locked函数调用中。\nif (slowpath(behavior &amp; LOOKUP_RESOLVER)) &#123;\n       behavior ^&#x3D; LOOKUP_RESOLVER;\n       return resolveMethod_locked(inst, sel, cls, behavior);\n   &#125;\n\n动态解析，就是将方法实现在运行时动态的添加到当前类中。之后runtime会重新尝试消息查找。\nstatic NEVER_INLINE IMP\nresolveMethod_locked(id inst, SEL sel, Class cls, int behavior)\n&#123;\n    runtimeLock.assertLocked();\n    ASSERT(cls-&gt;isRealized());\n\n    runtimeLock.unlock();\n\n    if (! cls-&gt;isMetaClass()) &#123;\n        &#x2F;&#x2F; try [cls resolveInstanceMethod:sel]\n        resolveInstanceMethod(inst, sel, cls);\n    &#125; \n    else &#123;\n        &#x2F;&#x2F; try [nonMetaClass resolveClassMethod:sel]\n        &#x2F;&#x2F; and [cls resolveInstanceMethod:sel]\n        resolveClassMethod(inst, sel, cls);\n        if (!lookUpImpOrNil(inst, sel, cls)) &#123;\n            resolveInstanceMethod(inst, sel, cls);\n        &#125;\n    &#125;\n\n    &#x2F;&#x2F; chances are that calling the resolver have populated the cache\n    &#x2F;&#x2F; so attempt using it\n    return lookUpImpOrForward(inst, sel, cls, behavior | LOOKUP_CACHE);\n&#125;\n\n在resolveMethod_locked中，runtime会根据调用的是实例方法还是类方法，进入到不同的处理逻辑中。\n\n动态解析实例方法： **resolveInstanceMethod()**用来动态解析实例方法，在运行时可以动态的将对应的方法实现添加到类实例所对应的类的消息列表中。\n动态解析类方法： **resolveClassMethod()**用来动态解析类方法，同样可以在运行时动态的将对应的类方法添加到类的消息列表中。\n\n举例：\n+ (BOOL)resolveInstanceMethod:(SEL)sel&#123;\n    if (sel &#x3D;&#x3D; @selector(test)) &#123;\n        class_addMethod([self class], sel, class_getMethodImplementation([self class], @selector(testInstanceMethod)), &quot;v@:&quot;);\n        return YES;\n    &#125;\n    return [super resolveInstanceMethod:sel];\n&#125;\n\n- (void)testInstanceMethod&#123;\n    NSLog(@&quot;%s&quot;, __func__);\n&#125;\n\n+ (BOOL)resolveClassMethod:(SEL)sel&#123;\n    if (sel &#x3D;&#x3D; @selector(test)) &#123;\n        class_addMethod(object_getClass(self), sel, class_getMethodImplementation(object_getClass(self), @selector(testClassMehotd)), &quot;v@:&quot;);\n        return YES;\n    &#125;\n    return [super resolveClassMethod:sel];\n&#125;\n\n+ (void)testClassMehotd&#123;\n    NSLog(@&quot;%s&quot;, __func__);\n&#125;\n\n在示例中，test()方法仅仅声明，没有实现。在运行时，runtime则会进入到消息的动态解析。需要注意的是，动态解析类方法时，方法class_addMethod(Class _Nullable cls, SEL _Nonnull name, IMP _Nonnull imp, const char * _Nullable types)中的第一个参数，需要使用object_getClass()进行获取后传参。因为在动态解析类方法时，需要将方法的实现添加到当前类的isa指向类中，而类的指向类为元类。\n\n当self是实例对象时，**[self class]** 和 **object_getClass(self)**等价，因为前者会直接调用后者，都是返回对象实例所对应的类。\n当self是类对象时，**[self class]返回类对象本身，而object_getClass(self)**返回类对应的元类。\n\n消息转发当动态解析依然失败，runtime则进入到消息转发流程。消息转发，是将当前消息转发到其他对象进行处理。 在NSObject中，针对消息转发提供了专门的API来处理。\n&#x2F;&#x2F; 转发类方法，id返回的是类对象\n+ (id)forwardingTargetForSelector:(SEL)sel;\n&#x2F;&#x2F; 转发实例方法，id返回的是实例对象\n- (id)forwardingTargetForSelector:(SEL)sel;\n\n消息转发示例\n- (id)forwardingTargetForSelector:(SEL)aSelector&#123;\n    if (aSelector &#x3D;&#x3D; @selector(test)) &#123;\n        return testForward;\n    &#125;\n    return [super forwardingTargetForSelector:aSelector];\n&#125;\n\n其中testForward为实现了test方法的实例对象。如果没有实现forwardingTargetForSelector，或者该方法返回nil或者self，则runtime会进入到另一个转发流程。此时runtime会依次调用**- (NSMethodSignature )methodSignatureForSelector:(SEL)aSelector，获取方法签名，然后根据方法签名，包装成了一个NSInvocation*对象，并调用- (void)forwardInvocation:(NSInvocation *)anInvocation**，此时无论转发的消息是否实现，系统都会默认消息已经得到了解析，从而避免崩溃。\n\n消息转发实际上是将消息转发给另一个对象进行处理，而消息动态解析是在当前类的范围内进行处理。\n消息转发与多继承通过消息转发流程，可以模拟实现Objective-C语言的多继承机制，具体可查看Runtime官方文档。\n总结在Objective-C语言中，方法调用实现的底层机制为消息发送机制。在开发中，类的实例对象不能调用类方法，原因是类的实例对象在查找消息IMP的流程仅仅是查找类的方法列表，而对于类方法而言，其实现存放在元类的方法列表中，因此实例对象通过objc_msgSend方法是找不到对应类消息的IMP的。\n类大多数情况下是不能调用实例方法的，除非实例方法定义在根类中，即NSObject中。因为当调用类方法是，会在元类的继承链的方法列表中查找对应的IMP，而跟元类对应的父类是NSObject，因此在NSObject中定义的实例方法，其实是可以通过类方法形式来调用的。\n","slug":"2020-06-24-iOS-runtime-message-forward","date":"2023-05-13T11:29:06.795Z","categories_index":"","tags_index":"Runtime"},{"id":"c17c44d6d8996ee062f87af24348061f","title":"Runtime剖析03 --- “黑魔法” Method Swizzling","content":"方法替换，又称为Method Swizzling，是Objective-C语言中比较流行的“黑魔法”。动态替换方法实现，大多数情况下使用在一些检测类的业务逻辑中，同时，方法替换也带给开发者更多可能的新的开发方式。在简单剖析**Method Swizzling **前，先看看方法替换场景中两种经常遇到的情况。\n\n需要替换的方法在目标类中有实现；\n需要替换的方法在目标类中没有实现，但再其父类中有实现。\n\n对于第一种情况，直接可以使用runtime提供的method_exchangeImplementations即可。\n&#x2F;&#x2F; 方法定义\nOBJC_EXPORT void\nmethod_exchangeImplementations(Method _Nonnull m1, Method _Nonnull m2) \n    OBJC_AVAILABLE(10.5, 2.0, 9.0, 1.0, 2.0);\n\n&#x2F;&#x2F; 方法实现\nvoid method_exchangeImplementations(Method m1, Method m2)\n&#123;\n    if (!m1  ||  !m2) return;\n    &#x2F;&#x2F; 加锁\n    mutex_locker_t lock(runtimeLock);\n    &#x2F;&#x2F; 方法交换\n    IMP m1_imp &#x3D; m1-&gt;imp;\n    m1-&gt;imp &#x3D; m2-&gt;imp;\n    m2-&gt;imp &#x3D; m1_imp;\n\n    &#x2F;&#x2F; 缓存清理\n    flushCaches(nil);\n    &#x2F;&#x2F; 设定标识\n    adjustCustomFlagsForMethodChange(nil, m1);\n    adjustCustomFlagsForMethodChange(nil, m2);\n&#125;\n\n对于第二种情况，稍微复杂一点。由于在目标类中并没有待替换方法的实现，而再其父类中有实现，那么其实要交换的是目标类父类中的实现，但是这样一替换后，其他调用父类这个方法的地方，也会被转发到所替换的方法中，这样明显是不合理的。\n为了避免这种情况，在进行方法替换前，首先要检查目标类中是否有对应方法的实现，如果没有，则要将方法动态添加进当前类的方法列表中。\n+ (void)load &#123;\n    static dispatch_once_t onceToken;\n    dispatch_once(&amp;onceToken, ^&#123;\n        &#x2F;&#x2F; When swizzling a Instance method, use the following:\n        Class class &#x3D; [self class];\n        \n        &#x2F;&#x2F; When swizzling a class method, use the following:\n        &#x2F;&#x2F; Class class &#x3D; object_getClass((id)self);\n        \n        SEL originalSelector &#x3D; @selector(systemMethod_PrintLog);\n        SEL swizzledSelector &#x3D; @selector(swizzledMethod_PrintLog);\n        \n        Method originalMethod &#x3D; class_getInstanceMethod(class, originalSelector);\n        Method swizzledMethod &#x3D; class_getInstanceMethod(class, swizzledSelector);\n        \n        BOOL didAddMethod &#x3D; class_addMethod(class, originalSelector, method_getImplementation(swizzledMethod), method_getTypeEncoding(swizzledMethod));\n        \n        if (didAddMethod) &#123;\n            class_replaceMethod(class, swizzledSelector, method_getImplementation(originalMethod), method_getTypeEncoding(originalMethod));\n        &#125;else&#123;\n            method_exchangeImplementations(originalMethod, swizzledMethod);\n        &#125;\n    &#125;);\n&#125;\n\n\n直接使用class_addMethod()检查目标class中是否有方法实现，如果目标类中没有对应方法的实现，didAddMethod会返回true，同时会将originalSelector添加到目标类中，如果目标类中已经有了方法的实现，didAddMethod会返回false，那么直接调用**method_exchangeImplementations()**交换即可；\n在进行class_addMethod()的时候，SEL传入的是待替换的originalSelector，但是IMP传入的是swizzledMethod的实现，在完成**class_addMethod()**后，即完成了方法实现的替换，即使用了替换方法的实现，替换了原始方法的实现。\n当class_addMethod()完成后，然后调用class_replaceMethod()对swizzledSelector的实现进行替换。在class_replaceMethod()的内部实现中，首先会尝试调用class_addMethod()，将方法添加到类中，如果添加失败，则说明class中已经有了该方法，此时会调用method_setImplementation设置方法的IMP。\n\n另外，class的获取，如果替换的是实例方法，则直接使用**Class class &#x3D; [self class];获取实例对象，如果替换的是类方法，则需要使用Class class &#x3D; object_getClass((id)self);**获取类对象。\n方法替换的时机一般情况下在**+ (void)load **方法中进行，因为该方法在runtime将class加载进内存时，其加载时机比较靠前，能够保证方法替换成功后，调用的逻辑符合预期。\nMethod swizzling 如何工作的号称Objective-C中的黑魔法 — Method swizzling，其本质是基于runtime底层数据结构体的应用。  因此了解runtime底层数据结构有助于理解该黑魔法的工作原理等。\nclass &amp; object_getClass首先从上文中的class对象的获取说起：\n&#x2F;&#x2F; When swizzling a Instance method, use the following:\nClass class &#x3D; [self class];\n        \n&#x2F;&#x2F; When swizzling a class method, use the following:\nClass class &#x3D; object_getClass((id)self);\n\nclass\n在NSObject的定义中，class的定义有两个，一个是实例方法，一个是类方法。\n+ (Class)class &#123;\n    return self;\n&#125;\n\n- (Class)class &#123;\n    return object_getClass(self);\n&#125;\n\n当调用者是类对象时，返回的是类对象本身，而调用者是实例对象时，会调用runtime的object_getClass方法，该方法中具体做了什么呢？\nobject_getClass\nClass object_getClass(id obj)\n&#123;\n    if (obj) return obj-&gt;getIsa();\n    else return Nil;\n&#125;\n\nobject_getClass的内部实现非常简单，就是获取对象的isa指针。如果对象时实例对象，isa返回的是实例对象所对应的类对象；如果是类对象，isa返回的是类对象对应的元类对象。\n\n\n\n\n\n\n\n\n\n方法替换中，如果替换的是实例方法，则需要修改实例对象所对应的类对象的方法列表，如果是类方法，则需要修改类对象所对应的元类对象的方法列表。\nclass_getInstanceMethod在确认了目标类之后，接下来就是要准备方法替换的原始方法和替换方法：originalMethod、swizzledMethod。Method数据类型的定义如下：\ntypedef struct method_t *Method;\n\nstruct method_t &#123;\n    SEL name;  &#x2F;&#x2F; 方法名\n    const char *types; &#x2F;&#x2F; 方法返回值类型和参数类型，TypeEncoding\n    MethodListIMP imp; &#x2F;&#x2F; 方法实现\n\n    struct SortBySELAddress :\n        public std::binary_function&lt;const method_t&amp;,\n                                    const method_t&amp;, bool&gt;\n    &#123;\n        bool operator() (const method_t&amp; lhs,\n                         const method_t&amp; rhs)\n        &#123; return lhs.name &lt; rhs.name; &#125;\n    &#125;;\n&#125;;\n\n在方法列表中，存储的既是method_t结构体类型。通过class_getInstanceMethod取出方法，既是通过SEL在指定类对象的方法列表中查找对应的Method。\nMethod class_getInstanceMethod(Class cls, SEL sel)\n&#123;\n    if (!cls  ||  !sel) return nil;\n\n    &#x2F;&#x2F; This deliberately avoids +initialize because it historically did so.\n\n    &#x2F;&#x2F; This implementation is a bit weird because it&#39;s the only place that \n    &#x2F;&#x2F; wants a Method instead of an IMP.\n        \n    &#x2F;&#x2F; Search method lists, try method resolver, etc.\n    lookUpImpOrForward(nil, sel, cls, LOOKUP_RESOLVER);\n    return _class_getMethod(cls, sel);\n&#125;\n\nclass_getInstanceMethod中调用了lookUpImpOrForward进行imp的搜索以及方法缓存构建，之后会调用**_class_getMethod方法，根据目标cls和sel查找对应的Method**。\nstatic Method _class_getMethod(Class cls, SEL sel)\n&#123;\n    mutex_locker_t lock(runtimeLock);\n    return getMethod_nolock(cls, sel);\n&#125;\n\nstatic method_t *\ngetMethod_nolock(Class cls, SEL sel)\n&#123;\n    method_t *m &#x3D; nil;\n\n    runtimeLock.assertLocked();\n\n    &#x2F;&#x2F; fixme nil cls?\n    &#x2F;&#x2F; fixme nil sel?\n\n    ASSERT(cls-&gt;isRealized());\n\n    while (cls  &amp;&amp;  ((m &#x3D; getMethodNoSuper_nolock(cls, sel))) &#x3D;&#x3D; nil) &#123;\n        cls &#x3D; cls-&gt;superclass;\n    &#125;\n\n    return m;\n&#125;\n\nstatic method_t *\ngetMethodNoSuper_nolock(Class cls, SEL sel)\n&#123;\n    runtimeLock.assertLocked();\n\n    ASSERT(cls-&gt;isRealized());\n    &#x2F;&#x2F; fixme nil cls? \n    &#x2F;&#x2F; fixme nil sel?\n\n    auto const methods &#x3D; cls-&gt;data()-&gt;methods();\n    for (auto mlists &#x3D; methods.beginLists(),\n              end &#x3D; methods.endLists();\n         mlists !&#x3D; end;\n         ++mlists)\n    &#123;\n        &#x2F;&#x2F; &lt;rdar:&#x2F;&#x2F;problem&#x2F;46904873&gt; getMethodNoSuper_nolock is the hottest\n        &#x2F;&#x2F; caller of search_method_list, inlining it turns\n        &#x2F;&#x2F; getMethodNoSuper_nolock into a frame-less function and eliminates\n        &#x2F;&#x2F; any store from this codepath.\n        method_t *m &#x3D; search_method_list_inline(*mlists, sel);\n        if (m) return m;\n    &#125;\n\n    return nil;\n&#125;\n\n_class_getMethod方法直接调用getMethod_nolock方法，在该方法中验证类的继承链，向上查找SEL对应对应的method，其搜索条件是通过cls和sel在cls的方法列表中，查找对应的method。\nclass_addMethod在获取到目标类和方法之后，首先尝试的是调用class_addMethod将swizzledMethod添加到目标类的方法列表中。\n目的在于，如果目标类中没有要替换的originalMethod，则直接将swizzledMethod作为originalMethod的实现添加到目标类中，如果目标类中存在originalMethod的实现，则class_addMethod方法会添加失败，返回false，此时调用method_exchangeImplementations直接替换originalMethod的实现为swizzledMethod的实现即可。\nclass_addMethod方法的实现如下：\nBOOL \nclass_addMethod(Class cls, SEL name, IMP imp, const char *types)\n&#123;\n    if (!cls) return NO;\n\n    mutex_locker_t lock(runtimeLock);\n    return ! addMethod(cls, name, imp, types ?: &quot;&quot;, NO);\n&#125;\n\nstatic IMP \naddMethod(Class cls, SEL name, IMP imp, const char *types, bool replace)\n&#123;\n    IMP result &#x3D; nil;\n\n    runtimeLock.assertLocked();\n\n    checkIsKnownClass(cls);\n    \n    ASSERT(types);\n    ASSERT(cls-&gt;isRealized());\n\n    method_t *m;\n    if ((m &#x3D; getMethodNoSuper_nolock(cls, name))) &#123;\n        &#x2F;&#x2F; already exists\n        if (!replace) &#123;\n            result &#x3D; m-&gt;imp;\n        &#125; else &#123;\n            result &#x3D; _method_setImplementation(cls, m, imp);\n        &#125;\n    &#125; else &#123;\n        auto rwe &#x3D; cls-&gt;data()-&gt;extAllocIfNeeded();\n\n        &#x2F;&#x2F; fixme optimize\n        method_list_t *newlist;\n        newlist &#x3D; (method_list_t *)calloc(sizeof(*newlist), 1);\n        newlist-&gt;entsizeAndFlags &#x3D; \n            (uint32_t)sizeof(method_t) | fixed_up_method_list;\n        newlist-&gt;count &#x3D; 1;\n        newlist-&gt;first.name &#x3D; name;\n        newlist-&gt;first.types &#x3D; strdupIfMutable(types);\n        newlist-&gt;first.imp &#x3D; imp;\n\n        prepareMethodLists(cls, &amp;newlist, 1, NO, NO);\n        rwe-&gt;methods.attachLists(&amp;newlist, 1);\n        flushCaches(cls);\n\n        result &#x3D; nil;\n    &#125;\n\n    return result;\n&#125;\n\nclass_addMethod方法中调用addMethod方法，并设定参数replace为NO，即不进行替换，仅仅添加，这也揭示了为什么当存在method的实现时，该方法会返回false。\naddMethod方法中，首先会检查锁提供的method是否在cls的方法列表中存在，如果存在则直接获取，如果不存在，则会根据现有方法列表的数据重新创建一个方法列表对象method_list_t，并将提供的method追加到该方法列表中，最后刷新设定类的方法列表，完成方法的添加。\nclass_replaceMethod如果上一步class_addMethod返回成功，则说明在目标类中添加SEL为originalMethod，IMP为swizzledMethod的方法，那么接下来就剩下对方法的实现进行替换了，此时调用class_replaceMethod。\nclass_replaceMethod方法中还是调用addMethod方法，但是参数replace设定为YES，表示执行替换的逻辑。并且此时，在方法列表中是确定存在对应的方法的，因此会直接调用**_method_setImplementation**方法，设定方法实现。\nmethod_exchangeImplementations如果class_addMethod返回失败，说明目标类中的originalMethod已经存在，此时直接对其实现进行交换即可，交换方法的实现调用method_exchangeImplementations。\nvoid method_exchangeImplementations(Method m1, Method m2)\n&#123;\n    if (!m1  ||  !m2) return;\n\n    mutex_locker_t lock(runtimeLock);\n\n    IMP m1_imp &#x3D; m1-&gt;imp;\n    m1-&gt;imp &#x3D; m2-&gt;imp;\n    m2-&gt;imp &#x3D; m1_imp;\n\n\n    &#x2F;&#x2F; RR&#x2F;AWZ updates are slow because class is unknown\n    &#x2F;&#x2F; Cache updates are slow because class is unknown\n    &#x2F;&#x2F; fixme build list of classes whose Methods are known externally?\n\n    flushCaches(nil);\n\n    adjustCustomFlagsForMethodChange(nil, m1);\n    adjustCustomFlagsForMethodChange(nil, m2);\n&#125;\n\nmethod_exchangeImplementations方法的核心其实就是交换两个方法的实现imp。\n注意点在使用Method Swizzlings的时候，有几个要注意的地方：\n1. 加载时机\nswizzling应该只在**+load**中完成。 \n在 Objective-C 的运行时中，每个类有两个方法都会自动调用。+load 是在一个类被初始装载时调用，+initialize 是在应用第一次调用该类的类方法或实例方法前调用的。两个方法都是可选的，并且只有在方法被实现的情况下才会被调用。\n2. 单例\nswizzling 应该只在 dispatch_once 中完成, 由于 swizzling 改变了全局的状态，所以我们需要确保每个预防措施在运行时都是可用的。原子操作就是这样一个用于确保代码只会被执行一次的预防措施，就算是在不同的线程中也能确保代码只执行一次s。Grand Central Dispatch 的 dispatch_once 满足了所需要的需求，并且应该被当做使用 swizzling 的初始化单例方法的标准。\n3. _cmd调用\n通常在swizzling交换后的方法中，还需要再调用一次本方法，这样做并不会产生递归调用，因为此时调用的已经是交换后的方法，而再次调用的目的是触发交换的方法实现执行。\n","slug":"2020-06-30-iOS-runtime-method-swizzling","date":"2023-05-13T11:29:06.795Z","categories_index":"","tags_index":"Runtime"},{"id":"c6997d59d32873c326b54f9cbde95646","title":"Runtime剖析04 --- 深入理解Category","content":"在Objective-C中，可以通过Category添加属性、方法、协议，在Runtime中Class和Category都是通过结构体实现的。和Category相似的还有Extension，二者的区别在于，Extension在编译期就直接和原类编译在一起，而Category是在运行时动态添加到原类中的。\nCategory的数据结构在Runtime中，Category的数据结构是基本的结构体，其定义如下：\ntypedef struct category_t *Category;\n\nstruct category_t &#123;\n    const char *name;\n    classref_t cls;\n    struct method_list_t *instanceMethods;\n    struct method_list_t *classMethods;\n    struct protocol_list_t *protocols;\n    struct property_list_t *instanceProperties;\n    &#x2F;&#x2F; Fields below this point are not always present on disk.\n    struct property_list_t *_classProperties;\n\n    method_list_t *methodsForMeta(bool isMeta) &#123;\n        if (isMeta) return classMethods;\n        else return instanceMethods;\n    &#125;\n\n    property_list_t *propertiesForMeta(bool isMeta, struct header_info *hi);\n    \n    protocol_list_t *protocolsForMeta(bool isMeta) &#123;\n        if (isMeta) return nullptr;\n        else return protocols;\n    &#125;\n&#125;;\n\nCategory的定义中，为每一种可添加的元素提供了属性，添加实例方法的instanceMethods、添加类方法的classMethods、添加协议的protocols、添加实例属性的instanceProperties，并且提供了添加方法、属性和协议的可行性判断方法。\nCategory的加载首先，Category数据会被保存在Mach-O中的**__data段，当Objective-C被dyld加载的时候，Objective-C开始进入其入口函数_objc_init()**。\nvoid _objc_init(void)\n&#123;\n    static bool initialized &#x3D; false;\n    if (initialized) return;\n    initialized &#x3D; true;\n    \n    &#x2F;&#x2F; fixme defer initialization until an objc-using image is found?\n    environ_init();\n    tls_init();\n    static_init();\n    runtime_init();\n    exception_init();\n    cache_init();\n    _imp_implementationWithBlock_init();\n\n    _dyld_objc_notify_register(&amp;map_images, load_images, unmap_image);\n\n#if __OBJC2__\n    didCallDyldNotifyRegister &#x3D; true;\n#endif\n&#125;\n\n在入口函数**_objc_init()中，会进行各种初始化操作，例如runtime、exception、cache等等的初始化，其中_dyld_objc_notify_register()**注册函数会向dyld注册监听Mach-O中Objective-C相关的section被载入和载出内存的事件。该函数有三个回调事件：\n\n对应&amp;map_images回调**_dyld_objc_notify_mapped**：当dyld已经将images加载进内存时；\n对应load_images回调**_dyld_objc_notify_init**：当dyld初始化image后；\n对应unmap_image回调**_dyld_objc_notify_unmapped**：当dyld将image移除内存时。\n\n将Category写入到目标类的方法列表，发生在**_dyld_objc_notify_mapped，即Mach-O相关的sections都加载到内存之后发生。此时的回调函数为map_images，该函数中最终调用的是_read_images**：\nif (hCount &gt; 0) &#123;\n     _read_images(hList, hCount, totalClasses, unoptimizedTotalClasses);\n&#125;\n\n&#x2F;&#x2F; objc&#x2F;Source&#x2F;objc-os.mm\n\n在**_read_images**中，又调取了\nif (didInitialAttachCategories) &#123;\n    for (EACH_HEADER) &#123;\n        load_categories_nolock(hi);\n    &#125;\n&#125;\n &#x2F;&#x2F; objc&#x2F;Source&#x2F;objc-runtime-new.mm\n\n最终，关于Category的读取转向了函数load_categories_nolock，在这个函数中，将对Category的属性、方法、协议等进行读取，最终通过unattachedCategories方法添加到目标类的方法列表中。\nstatic void load_categories_nolock(header_info *hi) &#123;\n    bool hasClassProperties &#x3D; hi-&gt;info()-&gt;hasCategoryClassProperties();\n\n    size_t count;\n    auto processCatlist &#x3D; [&amp;](category_t * const *catlist) &#123;\n        for (unsigned i &#x3D; 0; i &lt; count; i++) &#123;\n            category_t *cat &#x3D; catlist[i];\n            Class cls &#x3D; remapClass(cat-&gt;cls);\n            locstamped_category_t lc&#123;cat, hi&#125;;\n\n            if (!cls) &#123;\n                &#x2F;&#x2F; Category&#39;s target class is missing (probably weak-linked).\n                &#x2F;&#x2F; Ignore the category.\n                if (PrintConnecting) &#123;\n                    _objc_inform(&quot;CLASS: IGNORING category \\?\\?\\?(%s) %p with &quot;\n                                 &quot;missing weak-linked target class&quot;,\n                                 cat-&gt;name, cat);\n                &#125;\n                continue;\n            &#125;\n\n            &#x2F;&#x2F; Process this category.\n            if (cls-&gt;isStubClass()) &#123;\n                &#x2F;&#x2F; Stub classes are never realized. Stub classes\n                &#x2F;&#x2F; don&#39;t know their metaclass until they&#39;re\n                &#x2F;&#x2F; initialized, so we have to add categories with\n                &#x2F;&#x2F; class methods or properties to the stub itself.\n                &#x2F;&#x2F; methodizeClass() will find them and add them to\n                &#x2F;&#x2F; the metaclass as appropriate.\n                if (cat-&gt;instanceMethods ||\n                    cat-&gt;protocols ||\n                    cat-&gt;instanceProperties ||\n                    cat-&gt;classMethods ||\n                    cat-&gt;protocols ||\n                    (hasClassProperties &amp;&amp; cat-&gt;_classProperties))\n                &#123;\n                    objc::unattachedCategories.addForClass(lc, cls);\n                &#125;\n            &#125; else &#123;\n                &#x2F;&#x2F; First, register the category with its target class.\n                &#x2F;&#x2F; Then, rebuild the class&#39;s method lists (etc) if\n                &#x2F;&#x2F; the class is realized.\n                if (cat-&gt;instanceMethods ||  cat-&gt;protocols\n                    ||  cat-&gt;instanceProperties)\n                &#123;\n                    if (cls-&gt;isRealized()) &#123;\n                        attachCategories(cls, &amp;lc, 1, ATTACH_EXISTING);\n                    &#125; else &#123;\n                        objc::unattachedCategories.addForClass(lc, cls);\n                    &#125;\n                &#125;\n\n                if (cat-&gt;classMethods  ||  cat-&gt;protocols\n                    ||  (hasClassProperties &amp;&amp; cat-&gt;_classProperties))\n                &#123;\n                    if (cls-&gt;ISA()-&gt;isRealized()) &#123;\n                        attachCategories(cls-&gt;ISA(), &amp;lc, 1, ATTACH_EXISTING | ATTACH_METACLASS);\n                    &#125; else &#123;\n                        objc::unattachedCategories.addForClass(lc, cls-&gt;ISA());\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n    &#125;;\n\n    processCatlist(_getObjc2CategoryList(hi, &amp;count));\n    processCatlist(_getObjc2CategoryList2(hi, &amp;count));\n&#125;\n\n\n首先调用**_getObjc2CategoryList读取__objc_catlist** section下所有记录的category，并存放在**category_t * const *catlist**数组中；\n遍历**category_t * const *catlist**数组；\n对每一个*category_t *cat &#x3D; catlist[i];，先调用remapClass**获取*Category**所属的类；\n找到Category对应的类对象cls后，开始对cls进行修改工作。首先，如果category中有实例方法、协议，以及实例属性的话，则直接对cls进行操作，如果category中包含了类方法、协议或属性之一的话，还需要对cls所对应的元类（cls-&gt;ISA()）进行操作；\n无论是对cls还是cls的元类进行操作，都调用方法attachCategories，修改class的方法列表结构。\n\nattachCategoriesstatic void\nattachCategories(Class cls, const locstamped_category_t *cats_list, uint32_t cats_count,\n                 int flags)\n&#123;\n    if (slowpath(PrintReplacedMethods)) &#123;\n        printReplacements(cls, cats_list, cats_count);\n    &#125;\n    if (slowpath(PrintConnecting)) &#123;\n        _objc_inform(&quot;CLASS: attaching %d categories to%s class &#39;%s&#39;%s&quot;,\n                     cats_count, (flags &amp; ATTACH_EXISTING) ? &quot; existing&quot; : &quot;&quot;,\n                     cls-&gt;nameForLogging(), (flags &amp; ATTACH_METACLASS) ? &quot; (meta)&quot; : &quot;&quot;);\n    &#125;\n\n    &#x2F;*\n     * Only a few classes have more than 64 categories during launch.\n     * This uses a little stack, and avoids malloc.\n     *\n     * Categories must be added in the proper order, which is back\n     * to front. To do that with the chunking, we iterate cats_list\n     * from front to back, build up the local buffers backwards,\n     * and call attachLists on the chunks. attachLists prepends the\n     * lists, so the final result is in the expected order.\n     *&#x2F;\n    constexpr uint32_t ATTACH_BUFSIZ &#x3D; 64;\n    method_list_t   *mlists[ATTACH_BUFSIZ];\n    property_list_t *proplists[ATTACH_BUFSIZ];\n    protocol_list_t *protolists[ATTACH_BUFSIZ];\n\n    uint32_t mcount &#x3D; 0;\n    uint32_t propcount &#x3D; 0;\n    uint32_t protocount &#x3D; 0;\n    bool fromBundle &#x3D; NO;\n    bool isMeta &#x3D; (flags &amp; ATTACH_METACLASS);\n    auto rwe &#x3D; cls-&gt;data()-&gt;extAllocIfNeeded();\n\n    for (uint32_t i &#x3D; 0; i &lt; cats_count; i++) &#123;\n        auto&amp; entry &#x3D; cats_list[i];\n\n        method_list_t *mlist &#x3D; entry.cat-&gt;methodsForMeta(isMeta);\n        if (mlist) &#123;\n            if (mcount &#x3D;&#x3D; ATTACH_BUFSIZ) &#123;\n                prepareMethodLists(cls, mlists, mcount, NO, fromBundle);\n                rwe-&gt;methods.attachLists(mlists, mcount);\n                mcount &#x3D; 0;\n            &#125;\n            mlists[ATTACH_BUFSIZ - ++mcount] &#x3D; mlist;\n            fromBundle |&#x3D; entry.hi-&gt;isBundle();\n        &#125;\n\n        property_list_t *proplist &#x3D;\n            entry.cat-&gt;propertiesForMeta(isMeta, entry.hi);\n        if (proplist) &#123;\n            if (propcount &#x3D;&#x3D; ATTACH_BUFSIZ) &#123;\n                rwe-&gt;properties.attachLists(proplists, propcount);\n                propcount &#x3D; 0;\n            &#125;\n            proplists[ATTACH_BUFSIZ - ++propcount] &#x3D; proplist;\n        &#125;\n\n        protocol_list_t *protolist &#x3D; entry.cat-&gt;protocolsForMeta(isMeta);\n        if (protolist) &#123;\n            if (protocount &#x3D;&#x3D; ATTACH_BUFSIZ) &#123;\n                rwe-&gt;protocols.attachLists(protolists, protocount);\n                protocount &#x3D; 0;\n            &#125;\n            protolists[ATTACH_BUFSIZ - ++protocount] &#x3D; protolist;\n        &#125;\n    &#125;\n\n    if (mcount &gt; 0) &#123;\n        prepareMethodLists(cls, mlists + ATTACH_BUFSIZ - mcount, mcount, NO, fromBundle);\n        rwe-&gt;methods.attachLists(mlists + ATTACH_BUFSIZ - mcount, mcount);\n        if (flags &amp; ATTACH_EXISTING) flushCaches(cls);\n    &#125;\n\n    rwe-&gt;properties.attachLists(proplists + ATTACH_BUFSIZ - propcount, propcount);\n\n    rwe-&gt;protocols.attachLists(protolists + ATTACH_BUFSIZ - protocount, protocount);\n&#125;\n\n在该方法中，会完成对category中方法、协议、属性的加载，最终添加到对应class的方法、协议以及属性列表中。最终会调用attachLists方法，进行原类和分类列表的合并。\nvoid attachLists(List* const * addedLists, uint32_t addedCount) &#123;\n    if (addedCount &#x3D;&#x3D; 0) return;\n\n    if (hasArray()) &#123;\n        &#x2F;&#x2F; many lists -&gt; many lists\n        uint32_t oldCount &#x3D; array()-&gt;count;\n        uint32_t newCount &#x3D; oldCount + addedCount;\n        setArray((array_t *)realloc(array(), array_t::byteSize(newCount)));\n        array()-&gt;count &#x3D; newCount;\n        memmove(array()-&gt;lists + addedCount, array()-&gt;lists, \n                oldCount * sizeof(array()-&gt;lists[0]));\n        memcpy(array()-&gt;lists, addedLists, \n               addedCount * sizeof(array()-&gt;lists[0]));\n    &#125;\n    else if (!list  &amp;&amp;  addedCount &#x3D;&#x3D; 1) &#123;\n        &#x2F;&#x2F; 0 lists -&gt; 1 list\n        list &#x3D; addedLists[0];\n    &#125; \n    else &#123;\n        &#x2F;&#x2F; 1 list -&gt; many lists\n        List* oldList &#x3D; list;\n        uint32_t oldCount &#x3D; oldList ? 1 : 0;\n        uint32_t newCount &#x3D; oldCount + addedCount;\n        setArray((array_t *)malloc(array_t::byteSize(newCount)));\n        array()-&gt;count &#x3D; newCount;\n        if (oldList) array()-&gt;lists[addedCount] &#x3D; oldList;\n        memcpy(array()-&gt;lists, addedLists, \n               addedCount * sizeof(array()-&gt;lists[0]));\n    &#125;\n&#125;\n\n\n在合并的时候，会采用头插法将新的列表插入到原始列表中，也就是新的列表会位于原始列表的头部位置。这也就解释了为什么category中的方法，会覆盖class的原始方法。严格说并不是覆盖，而是因为category中定义的方法会排列在方法列表的前面，在进行方法查找的时候，会优先被找到，从而调用，而原始方法位置相对靠后，导致没有查找到，因此没有被调动。\nCategory和+load方法+load方法在Objective-C中被调用的时机相对较早，因此Category中定义的方法需要在调用**+load**方法之前就被附加到类的方法列表中，否则可能导致调用无效的情况，实际上，Runtime中也是真么保证的。\nvoid _objc_init(void)\n&#123;\n    static bool initialized &#x3D; false;\n    if (initialized) return;\n    initialized &#x3D; true;\n    \n    &#x2F;&#x2F; fixme defer initialization until an objc-using image is found?\n    environ_init();\n    tls_init();\n    static_init();\n    runtime_init();\n    exception_init();\n    cache_init();\n    _imp_implementationWithBlock_init();\n\n    _dyld_objc_notify_register(&amp;map_images, load_images, unmap_image);\n    \n    didCallDyldNotifyRegister &#x3D; true;\n&#125;\n\n在**_dyld_objc_notify_register中，runtime向dyld中注册了三个事件监听：map_images、load_images、unmap_image。在map_images事件中，runtime会读取Mach-O文件中的oc sections，并根据这些信息初始化runtime环境，在这一步包含了category的加载等。之后当runtime环境初始化完成后，会进行dyld的load_images，这一步会调用+load**方法。\nCategory Associate在项目开发中，经常会使用到Category，有时候会遇到向Category中添加属性的需求，但是在Category中不能直接添加属性，而是要借助Runtime提供的Associated相关的API，例如：\n&#x2F;&#x2F; 声明\n@interface NSObject (TestCategory)\n@property (nonatomic, strong) NSObject *object;\n@end\n\n&#x2F;&#x2F; 实现\n#import &lt;objc&#x2F;runtime.h&gt;\n\nstatic void *const kAssociatedObjectKey &#x3D; (void *)&amp;kAssociatedObjectKey;\n\n@implementation NSObject (TestCategory)\n\n\n- (NSObject *)object&#123;\n    return objc_getAssociatedObject(self, kAssociatedObjectKey);\n&#125;\n\n- (void)setObject:(NSObject *)object&#123;\n    objc_setAssociatedObject(self, kAssociatedObjectKey, object, OBJC_ASSOCIATION_RETAIN_NONATOMIC);\n&#125;\n\n@end\n\n在Category中添加属性后，默认是没有实现方法的，如果调用属性会发生崩溃，而且还会提示如下警告。\nProperty &#39;object&#39; requires method &#39;object&#39; to be defined - use @dynamic or provide a method implementation in this category\n\nProperty &#39;object&#39; requires method &#39;setObject:&#39; to be defined - use @dynamic or prov ide a method implementation in this category\n\n这里提出objc_getAssociatedObject的runtime源码，如下：\nid\n_object_get_associative_reference(id object, const void *key)\n&#123;\n    ObjcAssociation association&#123;&#125;;\n\n    &#123;\n        AssociationsManager manager;\n        AssociationsHashMap &amp;associations(manager.get());\n        AssociationsHashMap::iterator i &#x3D; associations.find((objc_object *)object);\n        if (i !&#x3D; associations.end()) &#123;\n            ObjectAssociationMap &amp;refs &#x3D; i-&gt;second;\n            ObjectAssociationMap::iterator j &#x3D; refs.find(key);\n            if (j !&#x3D; refs.end()) &#123;\n                association &#x3D; j-&gt;second;\n                association.retainReturnedValue();\n            &#125;\n        &#125;\n    &#125;\n\n    return association.autoreleaseReturnedValue();\n&#125;\n\n从源码中可以看到，所有通过Associated添加的属性，都被存储在一个全局单独的AssociationsHashMap哈希表中，objc_getAssociatedObject和objc_setAssociatedObject本质都是在操作这个哈希表，通过对哈希表进行映射来存储对象。\n在Associated的API中还有一些内存管理相关的关键字，例如OBJC_ASSOCIATION_ASSIGN，这些关键字用来指定对象的内存管理方式，在runtime中会根据这些关键字进行不同的内存管理。\ntypedef OBJC_ENUM(uintptr_t, objc_AssociationPolicy) &#123;\n    OBJC_ASSOCIATION_ASSIGN &#x3D; 0,           &#x2F;**&lt; Specifies a weak reference to the associated object. *&#x2F;\n    OBJC_ASSOCIATION_RETAIN_NONATOMIC &#x3D; 1, &#x2F;**&lt; Specifies a strong reference to the associated object. \n                                            *   The association is not made atomically. *&#x2F;\n    OBJC_ASSOCIATION_COPY_NONATOMIC &#x3D; 3,   &#x2F;**&lt; Specifies that the associated object is copied. \n                                            *   The association is not made atomically. *&#x2F;\n    OBJC_ASSOCIATION_RETAIN &#x3D; 01401,       &#x2F;**&lt; Specifies a strong reference to the associated object.\n                                            *   The association is made atomically. *&#x2F;\n    OBJC_ASSOCIATION_COPY &#x3D; 01403          &#x2F;**&lt; Specifies that the associated object is copied.\n                                            *   The association is made atomically. *&#x2F;\n&#125;;\n\n","slug":"2020-07-01-iOS-runtime-category","date":"2023-05-13T11:29:06.795Z","categories_index":"","tags_index":"Runtime"},{"id":"e756f728cc576c6fe02245695ebbf9dd","title":"Runtime剖析05 --- 再议iOS内存管理","content":"我们都知道，iOS中进行内存管理的管理模型是引用计数，但是这属于上层应用的范畴，在系统底层，iOS会根据不同的数据结构或者不同的数据类型，进行系统内存的分区，在不同的分区中，管理着自己的内存，另外，iOS的内存管理并不直接管理硬件内存，而是管理着硬件内存之上的一个过渡内存—虚拟内存。关于虚拟内存，可参考iOS虚拟内存管理一文。\niOS 内存分区iOS的内存管理是基于虚拟内存的管理，虚拟内存能够让每一个进程都在逻辑上独占整个设备的内存。iOS又将虚拟内存按照地址由低到高划分为五大区：\n\n虚拟内中，最上方是系统内核区的内存，最下方是系统保留的内存空间，中间则是程序加载的内存空间。内存按照自下而上，由低地址到高地址的拓展，程序加载到内存分为三段：\n\n未初始化数据(.bss)：存放未进行初始化的静态变量、全局变量\n已初始化数据(.data)：存放已初始化的静态变量、全局变量\n代码段(.text)：存放代码的二进制代码\n\n\n\n\n其他内存段栈区和堆区，分别用于方法或函数的调用和开发者创建的对象等内存。也就是说，开发者所管理的内存是在堆区，堆地址的分配不连续，但是整体地址是由低到高拓展。栈区的内存管理是由系统自动管理，栈区的地址是连续的，其内存地址是由高向低拓展。在程序运行时，栈区和堆区的大小是变化的，只不过栈区是由系统管理的，堆区是通过引用计数的方式管理对象的，内存的管理也是由开发者管理的。\nTagged Pointer在开发的过程中，难免会有些数字需要进行存储，而在iOS中，通常使用NSNumber对象来表示数字，对于绝大多数程序而言，所使用到的数字并不会很大，也用不到上亿的数字，同样对于字符串类型，绝大多数情况下，字符的个数也在8个字节以内。在iPhone 5s之后，iOS的寻址地址扩大到了64位，可以使用63位来表示一个数字，一位用来作为符号位。此时如果存储一个数字，例如**NSNumber *num&#x3D;@10000**，远远达不到63位的内存，这样在内存中则会留下很多无用的空位，造成内存空间的浪费。\n针对上述问题，Apple引入了Tagged Pointer，一种特殊的指针，在该类型的指针中，存储的已经不是地址，而是真实的数据和一些附加信息。\n此部分内容不再详述，具体可查看深入理解 Tagged Pointer\n。\n在Runtime中，针对Tagged Pointer的辨别，首先需要一个标志位，用来判断当前指针是真正的指针还是Tagged Pointer，Runtime中使用了一个宏定义define _OBJC_TAG_MASK (1UL&lt;&lt;63)，表示如果64位数据中，最高位是1的话，则表明当前是一个Tagged Pointer类型。在Runtime中，不仅仅NSNumber有Tagged Pointer类型，还有NSString、NSIndexPath、NSDate等，具体如下定义：\n&#123;\n    &#x2F;&#x2F; 60-bit payloads\n    OBJC_TAG_NSAtom            &#x3D; 0, \n    OBJC_TAG_1                 &#x3D; 1, \n    OBJC_TAG_NSString          &#x3D; 2, \n    OBJC_TAG_NSNumber          &#x3D; 3, \n    OBJC_TAG_NSIndexPath       &#x3D; 4, \n    OBJC_TAG_NSManagedObjectID &#x3D; 5, \n    OBJC_TAG_NSDate            &#x3D; 6,\n\n    &#x2F;&#x2F; 60-bit reserved\n    OBJC_TAG_RESERVED_7        &#x3D; 7, \n\n    &#x2F;&#x2F; 52-bit payloads\n    OBJC_TAG_Photos_1          &#x3D; 8,\n    OBJC_TAG_Photos_2          &#x3D; 9,\n    OBJC_TAG_Photos_3          &#x3D; 10,\n    OBJC_TAG_Photos_4          &#x3D; 11,\n    OBJC_TAG_XPC_1             &#x3D; 12,\n    OBJC_TAG_XPC_2             &#x3D; 13,\n    OBJC_TAG_XPC_3             &#x3D; 14,\n    OBJC_TAG_XPC_4             &#x3D; 15,\n    OBJC_TAG_NSColor           &#x3D; 16,\n    OBJC_TAG_UIColor           &#x3D; 17,\n    OBJC_TAG_CGColor           &#x3D; 18,\n    OBJC_TAG_NSIndexSet        &#x3D; 19,\n\n    OBJC_TAG_First60BitPayload &#x3D; 0, \n    OBJC_TAG_Last60BitPayload  &#x3D; 6, \n    OBJC_TAG_First52BitPayload &#x3D; 8, \n    OBJC_TAG_Last52BitPayload  &#x3D; 263, \n\n    OBJC_TAG_RESERVED_264      &#x3D; 264\n&#125;;\n\n例如0xa转换为二进制，得到1010，其中高位1xxx表明是一个Tagged Pointer,而剩下的3位010,表示是一个NSString类型，即010转换为十进制为2，对应上述定义中的OBJC_TAG_NSString &#x3D; 2。\n对于字符串来说，只有小字符串会被存储为Tagged Pointer类型，那么到底要多小呢？能够想到的是，字符串在进行春初的时候，并不是存储着字符串本身，而是字符串中每个字符的ASCII码，在字符串长度增加到8个字符之前，字符串是按照小对象的方式存储的，更大的字符串则是使用传统的指针方式存储的。\nNSString *test_small &#x3D; @&quot;a&quot;;\nNSString *str &#x3D; [NSString stringWithFormat:@&quot;%@&quot;, test_small];\n\nNSNumber *number &#x3D; @1.0;\nNSNumber *number_large &#x3D; @3.1415926;\n\n\nisa\n从上述示例的结果中可以看到，当一个对象被存储未Tagged Pointer类型后，该对象的isa指针是0x0，指向空的，也就是说Tagged Pointer类型的对象，是没有isa属性的。在Runtime中，获取一个对象的isa指针定义如下：\ninline Class \nobjc_object::getIsa() \n&#123;\n    if (fastpath(!isTaggedPointer())) return ISA();\n\n    extern objc_class OBJC_CLASS_$___NSUnrecognizedTaggedPointer;\n    uintptr_t slot, ptr &#x3D; (uintptr_t)this;\n    Class cls;\n\n    slot &#x3D; (ptr &gt;&gt; _OBJC_TAG_SLOT_SHIFT) &amp; _OBJC_TAG_SLOT_MASK;\n    cls &#x3D; objc_tag_classes[slot];\n    if (slowpath(cls &#x3D;&#x3D; (Class)&amp;OBJC_CLASS_$___NSUnrecognizedTaggedPointer)) &#123;\n        slot &#x3D; (ptr &gt;&gt; _OBJC_TAG_EXT_SLOT_SHIFT) &amp; _OBJC_TAG_EXT_SLOT_MASK;\n        cls &#x3D; objc_tag_ext_classes[slot];\n    &#125;\n    return cls;\n&#125;\n\nstatic inline bool \n_objc_isTaggedPointer(const void * _Nullable ptr)\n&#123;\n    return ((uintptr_t)ptr &amp; _OBJC_TAG_MASK) &#x3D;&#x3D; _OBJC_TAG_MASK;\n&#125;\n\n当获取一个对象的isa指针式，如果是tagged pointer类型，则会取出高4位的内容，进行对象类型的确定。\nNONPOINTER_ISANONPOINTER_ISA是iOS中另一种内存管理的方式，即对象的isa指针，该指针用来表明对象属性和类类型。Apple同样优化了该中方式的内存管理方式，在isa中，不仅表明了属性属于那个类，还附加了引用计数extra_rc、是否weak引用weakly_referenced、是否有附加属性has_assoc等附加信息。\n@interface NSObject &lt;NSObject&gt; &#123;\n    Class isa  OBJC_ISA_AVAILABILITY;\n&#125;\n\ntypedef struct objc_class *Class;\n\nstruct objc_class : objc_object &#123;\n    Class superclass;\n    cache_t cache;             &#x2F;&#x2F; formerly cache pointer and vtable\n    class_data_bits_t bits;    &#x2F;&#x2F; class_rw_t * plus custom rr&#x2F;alloc flags\n&#125;\n \nstruct objc_object &#123;\nprivate:\n    isa_t isa;\n&#125;\n\nunion isa_t \n&#123;\n    isa_t() &#123; &#125;\n    isa_t(uintptr_t value) : bits(value) &#123; &#125;\n\n    Class cls;\n    uintptr_t bits;\n#if defined(ISA_BITFIELD)\n    struct &#123;\n        ISA_BITFIELD;  &#x2F;&#x2F; defined in isa.h\n    &#125;;\n#endif\n\n# if __arm64__\n#   define ISA_MASK        0x0000000ffffffff8ULL\n#   define ISA_MAGIC_MASK  0x000003f000000001ULL\n#   define ISA_MAGIC_VALUE 0x000001a000000001ULL\n    struct &#123;\n        uintptr_t nonpointer        : 1;\n        uintptr_t has_assoc         : 1;\n        uintptr_t has_cxx_dtor      : 1;\n        uintptr_t shiftcls          : 33; &#x2F;&#x2F; MACH_VM_MAX_ADDRESS 0x1000000000\n        uintptr_t magic             : 6;\n        uintptr_t weakly_referenced : 1;\n        uintptr_t deallocating      : 1;\n        uintptr_t has_sidetable_rc  : 1;\n        uintptr_t extra_rc          : 19;\n#       define RC_ONE   (1ULL&lt;&lt;45)\n#       define RC_HALF  (1ULL&lt;&lt;18)\n    &#125;;\n&#125;\n\nisa指针其本质是isa_t 联合类型。联合类型的作用在于用更少的空间，表示更多可能的类型，但是类型之间是不能共存的。\n在isa_t的定义中，有两个重要的成员变量cls和struct，并且struct部分是在定义了ISA_BITFIELD之后才会使用的，也就是说，只有符合ISA_BITFIELD的时候，才会使用struct结构体，即采用了优化的isa策略时，isa_t类型并不等同于Class，而是一个struct结构。这个结构共占用了64个字节，从低位的nonpointer到高位的extra_rc，定义中中**:**表示该成员占用几个字节。\n各成员的含义如下表所示：\n\n\n\n成员变量\n占用位(单位：bit)\n含义\n备注\n\n\n\nnonpointer\n1\n标志位。1 代表开启了isa优化，0 代表未开启isa优化\n可根据此位判断对象是否启用了isa优化。\n\n\nhas_assoc\n1\n标志位。标识该对象是否有关联对象。\n对象没有关联对象时，其内存释放更快。\n\n\nhas_cxx_dtor\n1\n标志位。标识对象是否有C++或ARC析构函数。\n无析构函数时，内存释放更快。\n\n\nshiftcls\n33\n类指针的非零位。\n\n\n\nmagic\n6\n“魔法”位。固定值0x1a，用于调试时区分对象是否已经初始化。\n\n\n\nweakly_referenced\n1\n标志位。标识对象是否被别的对象弱引用。\n没有弱引用的对象内存释放更快。\n\n\ndeallocating\n1\n标志位。标识对象是否正在被释放。\n\n\n\nhas_sidetable_rc\n1\n标志位。标识对象当前的引用计数是否过大，如果过大则需要使用sidetable存储引用计数。\n\n\n\nextra_rc\n19\n记录当前对象的引用计数。\n\n\n\n其中和对象引用计数相关的有has_sidetable_rc和extra_rc，如上所述，当对象引用计数过大时，has_sidetable_rc会被设定为1，并启用sidetable来存储引用计数。\nSideTableSideTable是一个全局的引用计数表，其中存储了项目中所有对象的引用计数。在弄清楚SideTable和extra_rc之间的关系之前，先了解一下Runtime是如何添加对象的引用计数的。\nALWAYS_INLINE id \nobjc_object::rootRetain(bool tryRetain, bool handleOverflow)\n&#123;\n\t&#x2F;&#x2F; 如果是Tagged Pointer类型，直接返回this。因为TaggedPointer类型不使用引用计数管理内存\n    if (isTaggedPointer()) return (id)this;\n\n    bool sideTableLocked &#x3D; false;\n    &#x2F;&#x2F; 标记 extra_rc 是否溢出，默认false\n    bool transcribeToSideTable &#x3D; false;\n\n    &#x2F;&#x2F; 临时变量，用于isa_t的存储方式切换\n    isa_t oldisa;\n    isa_t newisa;\n\n    do &#123;\n        transcribeToSideTable &#x3D; false;\n        &#x2F;&#x2F; 先取出isa_t\n        oldisa &#x3D; LoadExclusive(&amp;isa.bits);\n        newisa &#x3D; oldisa;\n        &#x2F;&#x2F; 如果没有启用isa优化，则返回对应的sidetable记录\n        if (slowpath(!newisa.nonpointer)) &#123;\n            ClearExclusive(&amp;isa.bits);\n            if (rawISA()-&gt;isMetaClass()) return (id)this;\n            if (!tryRetain &amp;&amp; sideTableLocked) sidetable_unlock();\n            if (tryRetain) return sidetable_tryRetain() ? (id)this : nil;\n            else return sidetable_retain();\n        &#125;\n        &#x2F;&#x2F; don&#39;t check newisa.fast_rr; we already called any RR overrides\n        &#x2F;&#x2F; 如果对象正在析构，则返回nil\n        if (slowpath(tryRetain &amp;&amp; newisa.deallocating)) &#123;\n            ClearExclusive(&amp;isa.bits);\n            if (!tryRetain &amp;&amp; sideTableLocked) sidetable_unlock();\n            return nil;\n        &#125;\n        &#x2F;&#x2F; 是否溢出标记\n        uintptr_t carry;\n        &#x2F;&#x2F; 调用 addc 函数 对 extra_rc 执行 ++ 操作，返回 carry\n        newisa.bits &#x3D; addc(newisa.bits, RC_ONE, 0, &amp;carry);  &#x2F;&#x2F; extra_rc++\n        &#x2F;&#x2F; 如果有溢出，则表明extra_rc已经溢出。\n        &#x2F;&#x2F; 1. 先将 extra_rc 减半\n        &#x2F;&#x2F; 2. 然后将另一半转存至sidetable\n        if (slowpath(carry)) &#123;\n            &#x2F;&#x2F; newisa.extra_rc++ overflowed\n            &#x2F;&#x2F; 如果本次不处理溢出，则递归调用一次，并设置handleOverflow为true，下次处理\n            if (!handleOverflow) &#123;\n                ClearExclusive(&amp;isa.bits);\n                return rootRetain_overflow(tryRetain); &#x2F;&#x2F; return rootRetain(tryRetain, true);\n            &#125;\n            &#x2F;&#x2F; Leave half of the retain counts inline and \n            &#x2F;&#x2F; prepare to copy the other half to the side table.\n            &#x2F;&#x2F; 进行具体的溢出处理：\n            &#x2F;&#x2F; 1. 使用 RC_HALF 宏定义，对 extra_rc 进行减半操作\n            &#x2F;&#x2F; 2. 设置has_sidetable_rc标记为true\n            &#x2F;&#x2F; 3. transcribeToSideTable 标记为true\n            if (!tryRetain &amp;&amp; !sideTableLocked) sidetable_lock();\n            sideTableLocked &#x3D; true;\n            transcribeToSideTable &#x3D; true;\n            newisa.extra_rc &#x3D; RC_HALF;\n            newisa.has_sidetable_rc &#x3D; true;\n        &#125;\n    &#125; while (slowpath(!StoreExclusive(&amp;isa.bits, oldisa.bits, newisa.bits)));\n\n    &#x2F;&#x2F; transcribeToSideTable为true时，将extra_rc减半的一部分，转存到sidetable中\n    if (slowpath(transcribeToSideTable)) &#123;\n        &#x2F;&#x2F; Copy the other half of the retain counts to the side table.\n        sidetable_addExtraRC_nolock(RC_HALF);\n    &#125;\n\n    if (slowpath(!tryRetain &amp;&amp; sideTableLocked)) sidetable_unlock();\n    return (id)this;\n&#125;\n\n在Runtime中，通过SideTable来管理对象的引用计数和弱引用。SideTable中会包含三部分内容：自旋锁、引用计数表和弱引用表。\nstruct SideTable &#123;\n    spinlock_t slock; &#x2F;&#x2F; 自旋锁\n    RefcountMap refcnts; &#x2F;&#x2F; 引用计数表\n    weak_table_t weak_table; &#x2F;&#x2F; 弱引用表\n\n    SideTable() &#123;\n        memset(&amp;weak_table, 0, sizeof(weak_table));\n    &#125;\n\n    ~SideTable() &#123;\n        _objc_fatal(&quot;Do not delete SideTable.&quot;);\n    &#125;\n\n    void lock() &#123; slock.lock(); &#125;\n    void unlock() &#123; slock.unlock(); &#125;\n    void forceReset() &#123; slock.forceReset(); &#125;\n\n    &#x2F;&#x2F; Address-ordered lock discipline for a pair of side tables.\n\n    template&lt;HaveOld, HaveNew&gt;\n    static void lockTwo(SideTable *lock1, SideTable *lock2);\n    template&lt;HaveOld, HaveNew&gt;\n    static void unlockTwo(SideTable *lock1, SideTable *lock2);\n&#125;;\n\nSideTable本质上也是一个结构体，多个SideTable会构成一个集合，一张SideTable会管理多个对象，因此通常被称为SideTables，在系统中是全局唯一的。\nstatic objc::ExplicitInit&lt;StripedMap&lt;SideTable&gt;&gt; SideTablesMap;\n\nstatic StripedMap&lt;SideTable&gt;&amp; SideTables() &#123;\n    return SideTablesMap.get();\n&#125;\n\nSideTables被包裹在StripedMap类中，每个对象在进行引用计数管理时，都需要通过StripedMap的哈希算法，找到对应的SideTable表，之后再对引用计数进行管理。\n&#x2F;&#x2F; StripedMap 哈希算法\nstatic unsigned int indexForPointer(const void *p) &#123;\n    uintptr_t addr &#x3D; reinterpret_cast&lt;uintptr_t&gt;(p);\n    return ((addr &gt;&gt; 4) ^ (addr &gt;&gt; 9)) % StripeCount;\n&#125;\n\n从SideTable的定义中得知，引用计数表refcnts的数据类型为RefcountMap，而RefcountMap实际上是一个模板类 DenseMap。\ntypedef objc::DenseMap&lt;DisguisedPtr&lt;objc_object&gt;,size_t,RefcountMapValuePurgeable&gt; RefcountMap;\n\n简单理解DenseMap就是一个map，其中key是DisguisedPtr，value是对应的引用计数，另外在该map中会检测引用计数，当引用计数为0时，会自动将对象的引用计数数据清空。\nvoid shrink_and_clear() &#123;\n    unsigned OldNumEntries &#x3D; NumEntries;\n    this-&gt;destroyAll();\n\n    &#x2F;&#x2F; Reduce the number of buckets.\n    unsigned NewNumBuckets &#x3D; 0;\n    if (OldNumEntries)\n      NewNumBuckets &#x3D; std::max(MIN_BUCKETS, 1 &lt;&lt; (Log2_32_Ceil(OldNumEntries) + 1));\n    if (NewNumBuckets &#x3D;&#x3D; NumBuckets) &#123;\n      this-&gt;BaseT::initEmpty();\n      return;\n    &#125;\n\n    operator delete(Buckets);\n    init(NewNumBuckets);\n  &#125;\n\n在Objective-C中，当要获取一个对象的引用计数时，Runtime会分为三种情况进行获取，分别对应Tagged Pointer、优化的isa和未优化的isa。\ninline uintptr_t \nobjc_object::rootRetainCount()\n&#123;\n\t&#x2F;&#x2F; 如果是Tagged Pointer，则直接返回this\n    if (isTaggedPointer()) return (uintptr_t)this;\n\n    sidetable_lock();\n    isa_t bits &#x3D; LoadExclusive(&amp;isa.bits);\n    ClearExclusive(&amp;isa.bits);\n    &#x2F;&#x2F; 如果是优化的isa_t\n    if (bits.nonpointer) &#123;\n        uintptr_t rc &#x3D; 1 + bits.extra_rc;\n        &#x2F;&#x2F; 如果使用了sidetable，则从sidetable中获取引用计数\n        if (bits.has_sidetable_rc) &#123;\n        \t&#x2F;&#x2F; 总的引用计数 &#x3D; rc部分 + sidetable部分\n            rc +&#x3D; sidetable_getExtraRC_nolock();\n        &#125;\n        sidetable_unlock();\n        return rc;\n    &#125;\n\n    sidetable_unlock();\n    &#x2F;&#x2F; 如果是未优化的isa_t，则返回sidetable中的数据\n    return sidetable_retainCount();\n&#125;\n\n在获取优化的isa_t类型对象的引用计数时，注意是要取两部分的记录，然后进行汇总，对应添加引用计数的步骤。在取SideTable部分记录的引用计数时，需要注意在记录中并不是直接获取，而是要根据存储的情况进行获取。\nsize_t \nobjc_object::sidetable_getExtraRC_nolock()\n&#123;\n    ASSERT(isa.nonpointer);\n    SideTable&amp; table &#x3D; SideTables()[this];\n    &#x2F;&#x2F; 找到对应的引用计数表\n    RefcountMap::iterator it &#x3D; table.refcnts.find(this);\n    &#x2F;&#x2F; 如果表为空，则返回0\n    if (it &#x3D;&#x3D; table.refcnts.end()) return 0;\n    &#x2F;&#x2F; 否则先进行移位操作，然后返回结果\n    else return it-&gt;second &gt;&gt; SIDE_TABLE_RC_SHIFT;\n&#125;\n\n#define SIDE_TABLE_RC_SHIFT 2宏定义直接使用在引用计数的获取流程中，是因为在引用计数表的低2位的位置存储的并不是引用计数，而是记录当前对象是否有弱引用，以及是否正在deallocing。\n弱引用表在SideTable的定义中，还有一个非常重要的属性weak_table_t weak_table，前文已经了解，weak_table是当前对象的弱引用表，存储着弱引用相关的信息，在Runtime中，其定义如下：\nstruct weak_table_t &#123;\n    weak_entry_t *weak_entries; &#x2F;&#x2F; hash数组，存储弱引用对象的信息\n    size_t    num_entries; &#x2F;&#x2F; hash数组中元素个数\n    uintptr_t mask; &#x2F;&#x2F; hash数组长度-1，参与hash计算 \n    uintptr_t max_hash_displacement; &#x2F;&#x2F; 发生hash冲突的最大次数\n&#125;;\n\nweak_table_t中相对重要的是weak_entry_t类型的数组部分，可通过hash算法找到对应的对象在数组中的index，另外，weak_table_t具有动态扩容的特性，而sidetables的大小是固定64个。\nweak_entries本质上是一个hash数组，数组中存储着weak_entry_t类型的元素。weak_entry_t定义如下：\n&#x2F;**\n * The internal structure stored in the weak references table. \n * It maintains and stores\n * a hash set of weak references pointing to an object.\n * If out_of_line_ness !&#x3D; REFERRERS_OUT_OF_LINE then the set\n * is instead a small inline array.\n *&#x2F;\n#define WEAK_INLINE_COUNT 4\n\n&#x2F;&#x2F; out_of_line_ness field overlaps with the low two bits of inline_referrers[1].\n&#x2F;&#x2F; inline_referrers[1] is a DisguisedPtr of a pointer-aligned address.\n&#x2F;&#x2F; The low two bits of a pointer-aligned DisguisedPtr will always be 0b00\n&#x2F;&#x2F; (disguised nil or 0x80..00) or 0b11 (any other address).\n&#x2F;&#x2F; Therefore out_of_line_ness &#x3D;&#x3D; 0b10 is used to mark the out-of-line state.\n#define REFERRERS_OUT_OF_LINE 2\n\nstruct weak_entry_t &#123;\n    DisguisedPtr&lt;objc_object&gt; referent; &#x2F;&#x2F; 弱引用对象\n\n    &#x2F;&#x2F; 联合体，引用该对象的对象列表。\n    &#x2F;&#x2F; 引用个数小于4，使用inline_referrers数组\n    &#x2F;&#x2F; 引用个数大于4，使用weak_referrer_t *referrers动态数组\n    union &#123;\n        struct &#123;\n            weak_referrer_t *referrers; &#x2F;&#x2F; 弱引用该对象的对象数组，动态\n            uintptr_t        out_of_line_ness : 2; &#x2F;&#x2F; 是否使用动态数组的标记\n            uintptr_t        num_refs : PTR_MINUS_2; &#x2F;&#x2F; 动态数组中的元素个数\n            uintptr_t        mask; &#x2F;&#x2F; 参与hash计算，大小为数组大小-1，最终确定数组index\n            uintptr_t        max_hash_displacement; &#x2F;&#x2F; 最大hash冲突次数\n        &#125;;\n        struct &#123;\n            &#x2F;&#x2F; out_of_line_ness field is low bits of inline_referrers[1]\n            weak_referrer_t  inline_referrers[WEAK_INLINE_COUNT];\n        &#125;;\n    &#125;;\n\n    bool out_of_line() &#123;\n        return (out_of_line_ness &#x3D;&#x3D; REFERRERS_OUT_OF_LINE);\n    &#125;\n\n    weak_entry_t&amp; operator&#x3D;(const weak_entry_t&amp; other) &#123;\n        memcpy(this, &amp;other, sizeof(other));\n        return *this;\n    &#125;\n\n    weak_entry_t(objc_object *newReferent, objc_object **newReferrer)\n        : referent(newReferent)\n    &#123;\n        inline_referrers[0] &#x3D; newReferrer;\n        for (int i &#x3D; 1; i &lt; WEAK_INLINE_COUNT; i++) &#123;\n            inline_referrers[i] &#x3D; nil;\n        &#125;\n    &#125;\n&#125;;\n\n在查找弱引用对象的时候，始终使用的是hash定位的方式，在runtime中，弱引用所使用的hash定位算法如下：\nstatic weak_entry_t *\nweak_entry_for_referent(weak_table_t *weak_table, objc_object *referent)\n&#123;\n    ASSERT(referent);\n\n    &#x2F;&#x2F; 获取弱引用表中所有弱引用对象\n    weak_entry_t *weak_entries &#x3D; weak_table-&gt;weak_entries;\n\n    if (!weak_entries) return nil;\n    &#x2F;&#x2F; 确定hash值对应数组的开始索引，内部调用 ptr_hash 函数\n    &#x2F;&#x2F; 1. 获取到对象的hash指针\n    &#x2F;&#x2F; 2. 与如引用表的 mask 进行 位与 运算\n    &#x2F;&#x2F; 这样的目的是为了减小数值，便于计算。1000...000类型转变为 011...1 的形式\n    size_t begin &#x3D; hash_pointer(referent) &amp; weak_table-&gt;mask;\n    size_t index &#x3D; begin;\n    size_t hash_displacement &#x3D; 0;\n    &#x2F;&#x2F; 遍历对象数组\n    while (weak_table-&gt;weak_entries[index].referent !&#x3D; referent) &#123;\n    \t&#x2F;&#x2F; 加入位与运算，防止数组下标越界\n        index &#x3D; (index+1) &amp; weak_table-&gt;mask;\n        &#x2F;&#x2F; 寻找一轮后，没有找到对应元素，触发 bad_weak_table\n        if (index &#x3D;&#x3D; begin) bad_weak_table(weak_table-&gt;weak_entries);\n        &#x2F;&#x2F; hash冲突增加\n        hash_displacement++;\n        &#x2F;&#x2F; 如果hash冲突大于最大可能冲突次数，说明目标元素不在数组中，返回nil\n        if (hash_displacement &gt; weak_table-&gt;max_hash_displacement) &#123;\n            return nil;\n        &#125;\n    &#125;\n\n    return &amp;weak_table-&gt;weak_entries[index];\n&#125;\n\nstatic inline uint32_t ptr_hash(uint64_t key)\n&#123;\n    key ^&#x3D; key &gt;&gt; 4;\n    key *&#x3D; 0x8a970be7488fda55;\n    key ^&#x3D; __builtin_bswap64(key);\n    return (uint32_t)key;\n&#125;\n\n在进行hash定位的时候，有一个巧妙的操作语句：\nindex &#x3D; (index+1) &amp; weak_table-&gt;mask;\n\n该语句会在当前位置的下一个相邻位置进行查找，同时当查找到最后一个位置时，会自动从数组的第一个位置开始查找，也就是巧妙的实现了数组的轮转查找，也保证了数组下表不会越界。\n由于弱引用表的大小不是固定的，而是随着元素的插入和删除进行动态调整大小的，因此关键在于学习Runtime是如何对其进行动态大小调整的。\n动态扩容扩容主要发生在表格容量满的时候，而进行扩容前，而在Runtime中会进行提前扩容，需要先判断存储表是否需要进行扩容，判断方法如下：\n#define TABLE_SIZE(entry) (entry-&gt;mask ? entry-&gt;mask + 1 : 0)\n\n&#x2F;&#x2F; Grow the given zone&#39;s table of weak references if it is full.\nstatic void weak_grow_maybe(weak_table_t *weak_table)\n&#123;\n    size_t old_size &#x3D; TABLE_SIZE(weak_table);\n\n    &#x2F;&#x2F; Grow if at least 3&#x2F;4 full.\n    if (weak_table-&gt;num_entries &gt;&#x3D; old_size * 3 &#x2F; 4) &#123;\n        weak_resize(weak_table, old_size ? old_size*2 : 64);\n    &#125;\n&#125;\n\n判断的依据在于 weak_table-&gt;num_entries &gt;&#x3D; old_size * 3 &#x2F; 4，即当当前存储表的容量仅剩下1&#x2F;4的时候，会进行扩容操作。具体的扩容操作是在weak_resize中进行的，也就是后文所说的容量重置部分。\n进行扩容后，存储表的容量会比原有容量大一倍，这么做的目的在于，放置后序频繁的进行内存申请，以及既然这次要扩容，后序扩容的几率会更大，不如一次扩多点。\n动态收缩存储表容量的压缩通常发生在删除了其中一些元素之后，此时系统会调用weak_compact_maybe判断当前存储表是否需要收缩：\n&#x2F;&#x2F; Shrink the table if it is mostly empty.\nstatic void weak_compact_maybe(weak_table_t *weak_table)\n&#123;\n    size_t old_size &#x3D; TABLE_SIZE(weak_table);\n\n    &#x2F;&#x2F; Shrink if larger than 1024 buckets and at most 1&#x2F;16 full.\n    if (old_size &gt;&#x3D; 1024  &amp;&amp; old_size &#x2F; 16 &gt;&#x3D; weak_table-&gt;num_entries) &#123;\n        weak_resize(weak_table, old_size &#x2F; 8);\n        &#x2F;&#x2F; leaves new table no more than 1&#x2F;2 full\n    &#125;\n&#125;\n\n此时判断的依据是old_size &gt;&#x3D; 1024  &amp;&amp; old_size &#x2F; 16 &gt;&#x3D; weak_table-&gt;num_entries，即容量已经超过1024字节以及存储表容量最多只使用了1&#x2F;16的时候，会进行容量收缩处理，而收缩是按照现有容量的八倍大小进行收缩的。\n容量重置无论是扩容，还是收缩，都调用了weak_resize进行容量的处理。\nstatic void weak_resize(weak_table_t *weak_table, size_t new_size)\n&#123;\n    size_t old_size &#x3D; TABLE_SIZE(weak_table);\n    &#x2F;&#x2F; 取出原始数据\n    weak_entry_t *old_entries &#x3D; weak_table-&gt;weak_entries;\n    &#x2F;&#x2F; 给新的容量申请内存\n    weak_entry_t *new_entries &#x3D; (weak_entry_t *)\n        calloc(new_size, sizeof(weak_entry_t));\n    &#x2F;&#x2F; 重置weak_table容量相关属性\n    weak_table-&gt;mask &#x3D; new_size - 1; &#x2F;&#x2F; 数组大小-1\n    weak_table-&gt;weak_entries &#x3D; new_entries; &#x2F;&#x2F; 元素\n    weak_table-&gt;max_hash_displacement &#x3D; 0; &#x2F;&#x2F; 最大hash冲突重置\n    weak_table-&gt;num_entries &#x3D; 0;  &#x2F;&#x2F; restored by weak_entry_insert below\n    \n    if (old_entries) &#123;\n        weak_entry_t *entry;\n        weak_entry_t *end &#x3D; old_entries + old_size;\n        &#x2F;&#x2F; 遍历元素数组，将元素重新插入到新的存储表中\n        for (entry &#x3D; old_entries; entry &lt; end; entry++) &#123;\n            if (entry-&gt;referent) &#123;\n                weak_entry_insert(weak_table, entry);\n            &#125;\n        &#125;\n        &#x2F;&#x2F; 最后释放掉老的内存空间\n        free(old_entries);\n    &#125;\n&#125;\n\n&#x2F;&#x2F; 元素的插入操作\nstatic void weak_entry_insert(weak_table_t *weak_table, weak_entry_t *new_entry)\n&#123;\n    weak_entry_t *weak_entries &#x3D; weak_table-&gt;weak_entries;\n    ASSERT(weak_entries !&#x3D; nil);\n\n    size_t begin &#x3D; hash_pointer(new_entry-&gt;referent) &amp; (weak_table-&gt;mask);\n    size_t index &#x3D; begin;\n    size_t hash_displacement &#x3D; 0;\n    while (weak_entries[index].referent !&#x3D; nil) &#123;\n        index &#x3D; (index+1) &amp; weak_table-&gt;mask;\n        if (index &#x3D;&#x3D; begin) bad_weak_table(weak_entries);\n        hash_displacement++;\n    &#125;\n\n    weak_entries[index] &#x3D; *new_entry;\n    weak_table-&gt;num_entries++;\n\n    if (hash_displacement &gt; weak_table-&gt;max_hash_displacement) &#123;\n        weak_table-&gt;max_hash_displacement &#x3D; hash_displacement;\n    &#125;\n&#125;\n\n也就是说，弱引用存储表的容量在扩容的时候，并不是在原有存储表上进行直接扩容的，而是根据新的大小开辟了一块新的内存空间，同时将老的数据完整迁移到新的内存空间上，然后释放掉老的存储表。\nautoreleasepool在iOS中，第三种内存管理的方式是autoreleasepool，在ARC中，通常直接使用**@autoreleasepool{}**的方式使用，其中包裹的对象的内存管理工作就交给了自动释放池进行管理。\n关于autoreleasepool这里不再详述，具体可查看开源项目objc。\n","slug":"2020-07-13-iOS-memory-manager","date":"2023-05-13T11:29:06.795Z","categories_index":"","tags_index":"Runtime"},{"id":"e82075038d4d045b9b352d5ca62ff95f","title":"《实现模式》读书小记","content":"《实现模式》一书作者Kent Beck，软件开发方法学的泰山北斗，是最早研究软件开发模式和重构方法论的先导者之一，是敏捷开发的开创者之一，更是极限编程和测试驱动开发的创始人。该书是一本关于如何撰写代码的书。本书中的模式，是基于 Kent 对现存代码的阅读以及他自己的编程习惯而形成的。这些模式来自他早年使用 Smalltalk 模式通过代码与其他开发人员进行沟通的过程。它们的级别相对设计模式较低，与 Larman 提出的 GRASP 模式处于同一粒度。本书中的模式试图为如何撰写大家都能看得懂的代码提供一个清晰明确的视角，并告诉你这些代码如何为人的需要和降低成本的需求提供保障。\n模式编程中很多决策是无法复制的，但是当决策的内容越接近技术化，其中的相似性也越多。\n大多数的程序都遵循一组简单的法则：\n\n更多的时候，程序是在被阅读，而不是被编写；\n在软件编码中，无绝对的“完成”一说，修改程序的投入可能会远远大于最初编写程序的投入；\n程序是由一组基本的语句和控制流概念组合而成的；\n程序的阅读者需要理解程序 — 既从细节上，也从概念上。有时从细节开始，逐渐理解概念，有时从概念开始，逐渐理解细节。\n\n模式则是基于上述共性的法则而衍生的。而这些法则在编写程序的时候，则悄无声息的转变为编写者的压力（force），影响着每个程序的编写方式，因此模式的本质其实是压力（force）的模式。 \n\n\n一种编程理论在现实生活中，哪怕在巨细靡遗的模式列表，也不可能涵盖编程中所遇到的每一种情况，你避免不了（甚至经常）会遇到上穷碧落，也找不到对应现成解决方案的情况。每一种模式都承载着一点点理论，但实际编程中存在一些更加深广的影响力，是孤立的模式所不能概括的。而价值观、原则、模式这三种元素组成的开发方式，相对比较稳定，更能契合大多数的解决方案。\n贯穿于编程中的横切概念：价值观和原则。\n\n价值观： 是编程过程中的统一支配性主题。沟通、简单和灵活\n原则： 在价值观和模式之间搭建桥梁。编程原则可以演变出解决问题的方案等\n\n模式表述要什么，价值观提供了动机，原则把动机转化成了实际行动。\n价值观有三种与价值观血脉相连的价值观，分别是：沟通、简单和灵活。看似有些互相矛盾，但是更多的时候却相得益彰，优秀的程序往往会为未来的扩展留下充分的选择余地，不包含不相关的元素，容易理解，便于阅读。\n沟通如果说人类的语言是为了加强联系，那么程序的阅读难易程度便是人类与程序世界沟通的桥梁。一份更加干净易读的程序，会更加高效清晰的表达编写者的想法，减轻阅读者的压力。那些把别人当做空气一样的编程方式，使得程序以及编写者慢慢退去颜色，就算耗尽心力搭建的城堡，也会无人问津。\n程序应该读起来想读一本书，需要有情节和韵律，句子间应该有优雅的笑笑跌宕起伏。 — Knuth\n在软件的生命周期内，第一次的部署决定着软件的绝大部分成本，对既有代码的阅读要比编写全新的代码耗时更长。因此注重代码的沟通力可以帮助我们改进思想，一方面投入更多的思考，阅读的同时调用脑细胞思考原有逻辑以及编写者是怎么想的；另一方面则是由于压力的减轻，因为在改变既有代码或者按照合适的方式编写代码的时候，自己知道是在务正业，做的是对的，自我认可感强。\n简单在代码中，有复杂的，有简单的，而却出复杂性可以让阅读者、使用者以及后来修改代码的人更加理解，避免陷入猜想（猜想是代码修改者最痛恨，也最难受的）。但是在软件开发中，有些复杂性是难以避免的，这些复杂性反映出所要解决的问题的复杂性。但是有些复杂性的产生时因为我们忙着让程序运行起来，这种多余的复杂性降低了软件的价值，正确运行的可能性也降低了，在未来的改动中，改正确的成功率也降低了，回顾自己做过的事情，把麦子和糠分开，是编程不可或缺的一部分。\n秉承在各个层次上都应该要求简单。对代码进行调整，删除所有不提供信息的代码。设计中不出现无关元素。对需求提出质疑，找出最本质的概念。去掉多余的复杂性后，就好像有一束光照亮余下的代码，你就有机会用全新的视角来处理它们。\n灵活在三种价值观中，灵活是衡量那些低效编码与设计实践的一把标尺。例如常量不应该使用环境变量去定义等等，程序是灵活的，但只有在发生变化的时候才可能真实需要某些设计。\n灵活性的提高可能以复杂性的提高为代价。例如给用户提供一个自定义配置的选择，以提高灵活性，但是因为多了一个配置文件，编程时就要考虑这一点，所以也就变得复杂了。然而简单也可以促进灵活，例如如果可以找到取消配置选项但又不丧失价值的方式，那么程序的后续改动就更加简单了。\n增进软件的沟通效果同样会提高灵活性，能够快速阅读、理解和修改你代码的人越多，它将来发生变化的选择就越多，即软件的灵活度也就提升了。\n原则原则是另一个层次上的通用思想，比价值观更贴近与编程实际，同时又是模式的基础。原则可以解释模式背后的动机，它是有普遍意义的。\n在对立模式间进行选择时，最好的方式就是用原则来说话，而不是让模式去争宠。\n例如在学习新的编程语言，不必盲目的模仿现有的编程方式，更不用拘泥于其他语言中形成的习惯，可以根据自己对原则的理解快速去学习，即使在新鲜局面下仍能一以贯之。\n局部化影响在组织代码结构时，要保证变化只会产生局部化影响。 \n把修改的影响范围缩小到最小，代码就会有极佳的沟通效果，可被逐步理解，而不用一开始鸟瞰全景。\n在实现模式的背后，最主要的动机就是减少变化所引起的代价，所以局部化影响这条原则也是很多模式的形成缘由之一。\n最小化重复最小化重复有助于保证局部化影响。   \n复制代码只是重复的一种形势，并行的类层次结构也是其一，同样破坏了局部化影响。如果出现修改一处概念需要同时修改两个或更多的类层级结构，就代表变化的影响已经扩散了，此时应该及时止损，停止一味地修改，而去重新组织代码，让变化只对局部产生影响。\n重复往往不易被预见到，又是在出现很长时间后才会被察觉，重复不是错误也不是罪过，只是增加了变化的开销，提高了各类成本等。\n\n\n\n\n\n\n\n\n\n重复解决：拆分程序为更小的单元 —- 小段语句、小段方法、小型对象和小型包等，从而慢慢消除重复。 大段逻辑很容易与其他大段逻辑出现重复的代码片段，于是就有了模式诞生的可能。\n将逻辑和数据捆绑局部化影响的必然结果就是将逻辑与数据捆绑。 把逻辑与逻辑所处理的数据放在一起，如果有可能放在一个方法中，或者放到一个对象中，最次放在一个包下，如果发生了变化，逻辑和数据很可能会同事被改动，如果放在一起，那么修改它们所造成的影响就会只停留在局部。\n但是在一开始编程前，可能意识不到逻辑和数据的依赖，慢慢的演进中，发现此依赖彼，彼依赖其他的问题，此时就要考虑改如果组织代码结构，或者使用辅助类来解决依赖等。\n\n\n\n\n\n\n\n\n\n未完待续\n对称性声明式表达变化率动机类状态行为方法容器改进框架总结","slug":"2022-05-01-iOS-implementation-patterns-tips","date":"2023-05-13T11:29:06.795Z","categories_index":"读书小记","tags_index":"读书小记"},{"id":"f0b7ed12bc36c7022d00f8d1ca004b00","title":"如何进行 Git 仓库瘦身","content":"对 Git 仓库的维护通常是为了减少仓库的大小。如果你从另外一个版本控制系统导入了一个仓库，你可能需要在导入后清除掉不必要的文件。本文着重于从一个 Git 仓库中删除大文件，并且包含下列主题：\n\n理解从 Git 的历史记录中删除文件\n使用 BFG 重写历史记录\n可选，使用 git filter-branch 重写历史记录\n垃圾回收\n\n请格外小心…..\n本文中的步骤和工具使用的高级技术涉及破坏性操作。确保您在开始之前仔细读过并备份了你的仓库，创建一个备份最容易的方式是使用 –mirror 标志对你的仓库克隆，然后对整个克隆的文件进行打包压缩。有了这个备份，如果在维护期间意外损坏了您的仓库的关键元素，那么你可以通过备份的仓库来恢复。\n请记住，仓库维护对仓库的用户可能会是毁灭性的。与你的团队或者仓库的关注者进行沟通会是一个不错的主意。确保每个人都已经检查了他们的代码，并且同意在仓库维护期间停止开发。\n理解从  Git  的历史记录中删除文件回想一下，克隆仓库会克隆整个历史记录——包括每个源代码文件的所有版本。如果一个用户提交了一个较大的文件，比如一个 JAR，则随后的每次克隆都会包含这个文件。即使用户最终在后面的某次提交中删除了这个文件，但是这个文件仍然存在于这个仓库的历史记录中。要想完全的从你的仓库中删除这个文件，你必须：\n\n从你的项目的当前的文件树中删除该文件;\n从仓库的历史记录中删除文件——重写 Git 历史记录，从包含该文件的所有的提交中删除这个文件;\n删除指向旧的提交历史记录的所有 reflog 历史记录;\n重新整理仓库，使用 git gc 对现在没有使用的数据进行垃圾回收。\n\n\n\nGit 的 &quot;gc&quot;（垃圾回收）将通过你的任何一个分支或者标签来删除仓库中所有的实际没用的或者以某种方式引用的数据。为了使其发挥作用，我们需要重写包含不需要的文件的所有 Git 仓库历史记录，仓库将不再引用它—— git gc 将会丢弃所有没用的数据。\n重写存储库历史是一个棘手的事情，因为每个提交都依赖它的父提交，所以任何一个很小的改变都会改变它的每一个随后的提交的提交 ID。有两个自动化的工具可以做到这：\n\nBFG Repo Cleaner 快速、简单且易于使用，需要 Java 6 或者更高版本的运行环境。\ngit filter-branch 功能强大、配置麻烦，用于大于仓库时速度较慢，是核心 Git 套件的一部分。\n\n切记，当你重写历史记录后，无论你是使用 BFG 还是使用 filter-branch，你都需要删除指向旧的历史记录的 reflog 条目，最后运行垃圾回收器来删除旧的数据。\n使用  BFG  重写历史记录BFG 是为将像大文件或者密码这些不想要的数据从 Git 仓库中删除而专门设计的，所以它有一一个简单的标志用来删除那些大的历史文件（不在当前的提交里面）：–strip-blobs-bigger-than\n\n$ java -jar bfg.jar –strip-blobs-than 100M\n\n大小超过 100MB 的任何文件（不包含在你最近的提交中的文件——因为 BFG 默认会保护你的最新提交的内容）将会从你的 Git 仓库的历史记录中删除。如果你想用名字来指明具体的文件，你也可以这样做：\n\n$ java -jar bfg.jar –delete-files *.mp4\n\nBFG 的速度要比 git filter-branch 快 10-1000 倍，而且通常更容易使用——查看完整的使用说明和示例获取更多细节。\n或者，使用  git filter-branch  来重写历史记录filter-branch 命令可以对 Git 仓库的历史记录重写，就像 BFG 一样，但是过程更慢和更手动化。如果你不知道这些大文件在哪里，那么你第一步就需要找到它们：\n手动查看你  Git  仓库中的大文件Antony Stubbs 写了一个可以很好地完成这个功能的 BASH 脚本。该脚本可以检查你的包文件的内容并列出大文件。在你开始删除文件之前，请执行以下操作获取并安装此脚本：\n1、 下载脚本到你的本地的系统。\n2、 将它放在一个可以访问你的 Git 仓库的易于找到的位置。\n3、 让脚本成为可执行文件：\n\n$ chmod 777 git_find_big.sh\n\n4、 克隆仓库到你本地系统。\n5、 改变当前目录到你的仓库根目录。\n6、 手动运行 Git 垃圾回收器：\n\ngit gc –auto\n\n7、 找出 .git 文件夹的大小\n\n$ du -hs .git&#x2F;objects\n45M .git&#x2F;objects\n\n注意文件大小，以便随后参考。\n8、 运行 git_find_big.sh 脚本来列出你的仓库中的大文件。\n\n$ git_find_big.sh\nAll sizes are in kB&#39;s. The pack column is the size of the object, compressed, inside the pack file.\nsize pack SHA                                       location\n592   580   e3117f48bc305dd1f5ae0df3419a0ce2d9617336 media&#x2F;img&#x2F;emojis.jar\n550   169   b594a7f59ba7ba9daebb20447a87ea4357874f43 media&#x2F;js&#x2F;aui&#x2F;aui-dependencies.jar\n518   514   22f7f9a84905aaec019dae9ea1279a9450277130 media&#x2F;images&#x2F;screenshots&#x2F;issue-tracker-wiki.jar\n337   92   1fd8ac97c9fecf74ba6246eacef8288e89b4bff5 media&#x2F;js&#x2F;lib&#x2F;bundle.js\n240   239   e0c26d9959bd583e5ef32b6206fc8abe5fea8624 media&#x2F;img&#x2F;featuretour&#x2F;heroshot.png\n\n大文件都是 JAR 文件，包的大小列是最相关的。aui-dependencies.jar 被压缩到 169kb，但是 emojis.jar 只压缩到 500kb。emojis.jar 就是一个待删除的对象。\n运行  filter-branch你可以给这个命令传递一个用于重写 Git 索引的过滤器。例如，一个过滤器可以可以将每个检索的提交删除。这个用法如下：\n\ngit filter-branch –index-filter &#39;git rm –cached –ignore-unmatch  _pathname_ &#39; commitHASH\n\n–index-filter 选项可以修改仓库的索引，–cached 选项从索引中而不是磁盘来删除文件。这样会更快，因为你不需要在运行这个过滤器前检查每个修订版本。git rm 中的 ignore-unmatch 选项可以防止在尝试移走不存在的文件 pathname 的时候命令失败。通过指定一个提交 HASH 值，你可以从每个以这个 HASH 值开始的提交中删除pathname。要从开始处删除，你可以省略这个参数或者指定为 HEAD。\n如果你的大文件在不同的分支，你将需要通过名字来删除每个文件。如果大文件都在一个单独的分支，你可以直接删除这个分支本身。\n选项  1** ：通过文件名删除文件**使用下面的步骤来删除大文件：\n1、 使用下面的命令来删除你找到的第一个大文件：\n\ngit filter-branch –index-filter &#39;git rm –cached –ignore-unmatch filename&#39; HEAD\n\n2、 重复步骤 1 找到剩下的每个大文件。\n3、 在你的仓库里更新引用。 filter-branch 会为你原先的引用创建一个 refs&#x2F;original&#x2F; 下的备份。一旦你确信已经删除了正确的文件，你可以运行下面的命令来删除备份文件，同时可以让垃圾回收器回收大的对象：\n\ngit filter-branch –index-filter &#39;git rm –cached –ignore-unmatch filename&#39; HEAD\n\n选项  2** ：直接删除分支**如果你所有的大文件都在一个单独的分支上，你可以直接删除这个分支。删除这个分支会自动删除所有的引用。\n1、 删除分支。\n\n$ git branch -D PROJ567bugfix\n\n2、 从后面的分支中删除所有的 reflog 引用。\n对不用的数据垃圾回收1、 删除从现在到后面的所有 reflog 引用（除非你明确地只在一个分支上操作）。\n\n$ git reflog expire –expire&#x3D;now –all\n\n2、 通过运行垃圾回收器和删除旧的对象重新打包仓库。\n\n$ git gc –prune&#x3D;now\n\n3、 把你所有的修改推送回仓库。\n\n$ git push –all –force\n\n4、 确保你所有的标签也是当前最新的:\n\n$ git push –tags –force\n\n","slug":"2022-05-20-how-to-reduce-git","date":"2023-05-13T11:29:06.795Z","categories_index":"开发知识","tags_index":"开发知识"},{"id":"93feab5362ca8ea100621030ee9dd628","title":"再议Objective-C 2.0 中的 Runtime","content":"绝大多数 iOS 开发者在学习 runtime 时都阅读过 runtime.h 文件中的这段代码:\nstruct objc_class &#123;\n    Class isa  OBJC_ISA_AVAILABILITY;\n\n#if !__OBJC2__\n    Class super_class                                        OBJC2_UNAVAILABLE;\n    const char *name                                         OBJC2_UNAVAILABLE;\n    long version                                             OBJC2_UNAVAILABLE;\n    long info                                                OBJC2_UNAVAILABLE;\n    long instance_size                                       OBJC2_UNAVAILABLE;\n    struct objc_ivar_list *ivars                             OBJC2_UNAVAILABLE;\n    struct objc_method_list **methodLists                    OBJC2_UNAVAILABLE;\n    struct objc_cache *cache                                 OBJC2_UNAVAILABLE;\n    struct objc_protocol_list *protocols                     OBJC2_UNAVAILABLE;\n#endif\n\n&#125; OBJC2_UNAVAILABLE;\n\n可以看到其中保存了类的实例变量，方法列表等信息。\n不知道有多少读者思考过 OBJC2_UNAVAILABLE 意味着什么。其实早在 2006 年，苹果在 WWDC 大会上就发布了 Objective-C 2.0，其中的改动包括 Max OS X 平台上的垃圾回收机制(现已废弃)，runtime 性能优化等。\n这意味着上述代码，以及任何带有 OBJC2_UNAVAILABLE 标记的内容，都已经在 2006 年就永远的告别了我们，只停留在历史的文档中。\nCategory 的原理虽然上述代码已经过时，但仍具备一定的参考意义，比如 methodLists 作为一个二级指针，其中每个元素都是一个数组，数组中的每个元素则是一个方法。\n接下来就介绍一下 category 的工作原理，在美团的技术博客 深入理解Objective-C：Category 中已经有了非常详细的解释，然而可能由于时间问题，其中的不少内容已经过时，我根据目前最新的版本(objc-680) 做一些简单的分析，为了便于阅读，在不影响代码逻辑的前提下有可能删除部分无关紧要的内容。\n\n\n概述首先 runtime 依赖于 dyld 动态加载，在 objc-os.mm 文件中可以找到入口，它的调用栈简单整理如下:\nvoid _objc_init(void)\n└──const char *map_2_images(...)\n    └──const char *map_images_nolock(...)\n        └──void _read_images(header_info **hList, uint32_t hCount)\n\n以上四个方法可以理解为 runtime 的初始化过程，我们暂且不深究。在 _read_images 方法中有如下代码:\nif (cat-&gt;classMethods  ||  cat-&gt;protocols  \n    &#x2F;* ||  cat-&gt;classProperties *&#x2F;) &#123;\n    addUnattachedCategoryForClass(cat, cls-&gt;ISA(), hi);\n    if (cls-&gt;ISA()-&gt;isRealized()) &#123;\n        remethodizeClass(cls-&gt;ISA());\n    &#125;\n&#125;\n\n根据注释可见苹果曾经计划利用 category 来添加属性。在 addUnattachedCategoryForClass 方法中会找到当前类的所有 category，然后在 remethodizeClass 真正的去做处理。不过到目前为止还没有接触到相关的 category 处理，我们继续沿着调用栈向下走:\nvoid _read_images(header_info **hList, uint32_t hCount)\n└──static void remethodizeClass(Class cls)\n    └──static void attachCategories(Class cls, category_list *cats, bool flush_caches)\n\n这里的 attachCategories 就是处理 category 的核心所在，不过在阅读这段代码之前，我们有必要先熟悉一下相关的数据结构。\nCategory 相关的数据结构首先来了解一下一个 Category 是如何存储的，在 objc-runtime-new.h 中可以看到如下定义，我只列出了其中成员变量:\nstruct category_t &#123;\n    const char *name;\n    classref_t cls;\n    struct method_list_t *instanceMethods;\n    struct method_list_t *classMethods;\n    struct protocol_list_t *protocols;\n    struct property_list_t *instanceProperties;\n&#125;;\n\n可见一个 category 持有了一个 method_list_t 类型的数组，method_list_t 又继承自 entsize_list_tt，这是一种泛型容器:\nstruct method_list_t : entsize_list_tt&lt;method_t, method_list_t, 0x3&gt; &#123;\n    &#x2F;&#x2F; 成员变量和方法\n&#125;;\n\ntemplate &lt;typename Element, typename List, uint32_t FlagMask&gt;\nstruct entsize_list_tt &#123;\n    uint32_t entsizeAndFlags;\n    uint32_t count;\n    Element first;\n&#125;;\n\n这里的 entsize_list_tt 可以理解为一个容器，拥有自己的迭代器用于遍历所有元素。 Element 表示元素类型，List 用于指定容器类型，最后一个参数为标记位。\n虽然这段代码实现比较复杂，但仍可了解到 method_list_t 是一个存储 method_t 类型元素的容器。method_t 结构体的定义如下:\nstruct method_t &#123;\n    SEL name;\n    const char *types;\n    IMP imp;\n&#125;;\n\n最后，我们还有一个结构体 category_list 用来存储所有的 category，它的定义如下:\nstruct locstamped_category_list_t &#123;\n    uint32_t count;\n    locstamped_category_t list[0];\n&#125;;\nstruct locstamped_category_t &#123;\n    category_t *cat;\n    struct header_info *hi;\n&#125;;\ntypedef locstamped_category_list_t category_list;\n\n除了标记存储的 category 的数量外，locstamped_category_list_t 结构体还声明了一个长度为零的数组，这其实是 C99 中的一种写法，允许我们在运行期动态的申请内存。\n以上就是相关的数据结构，只要了解到这个程度就可以继续读源码了。\n处理 Category对 Category 中方法的解析并不复杂，首先来看一下 attachCategories 的简化版代码:\nstatic void attachCategories(Class cls, category_list *cats, bool flush_caches) &#123;\n    if (!cats) return;\n    bool isMeta &#x3D; cls-&gt;isMetaClass();\n\n    method_list_t **mlists &#x3D; (method_list_t **)malloc(cats-&gt;count * sizeof(*mlists));\n    &#x2F;&#x2F; Count backwards through cats to get newest categories first\n    int mcount &#x3D; 0;\n    int i &#x3D; cats-&gt;count;\n    while (i--) &#123;\n        auto&amp; entry &#x3D; cats-&gt;list[i];\n\n        method_list_t *mlist &#x3D; entry.cat-&gt;methodsForMeta(isMeta);\n        if (mlist) &#123;\n            mlists[mcount++] &#x3D; mlist;\n        &#125;\n    &#125;\n\n    auto rw &#x3D; cls-&gt;data();\n\n    prepareMethodLists(cls, mlists, mcount, NO, fromBundle);\n    rw-&gt;methods.attachLists(mlists, mcount);\n    free(mlists);\n    if (flush_caches  &amp;&amp;  mcount &gt; 0) flushCaches(cls);\n&#125;\n\n首先，通过 while 循环，我们遍历所有的 category，也就是参数 cats 中的 list 属性。对于每一个 category，得到它的方法列表 mlist 并存入 mlists 中。\n换句话说，我们将所有 category 中的方法拼接到了一个大的二维数组中，数组的每一个元素都是装有一个 category 所有方法的容器。这句话比较绕，但你可以把 mlists 理解为文章开头所说，旧版本的 objc_method_list **methodLists。\n在 while 循环外，我们得到了拼接成的方法，此时需要与类原来的方法合并:\nauto rw &#x3D; cls-&gt;data();\nrw-&gt;methods.attachLists(mlists, mcount);\n\n这两行代码读不懂是必然的，因为在 Objective-C 2.0 时代，对象的内存布局已经发生了一些变化。我们需要先了解对象的布局模型才能理解这段代码。\nObjective-C 2.0 对象布局模型objc_class相信读到这里的大部分读者都学习过文章开头所说的对象布局模型，因此在这一部分，我们采用类比的方法，来看看 Objective-C 2.0 下发生了哪些改变。\n首先，Class 和 id 指针的定义并没有发生改变，他们一个指向类对应的结构体，一个指向对象对应的结构体:\n&#x2F;&#x2F; objc.h\ntypedef struct objc_class *Class;\ntypedef struct objc_object *id;\n\n比较有意思的一点是，objc_class 结构体是继承自 objc_object 的:\nstruct objc_object &#123;\n    Class isa  OBJC_ISA_AVAILABILITY;\n&#125;;\n\nstruct objc_class : objc_object &#123;\n    Class superclass;\n    cache_t cache;             &#x2F;&#x2F; formerly cache pointer and vtable\n    class_data_bits_t bits;    &#x2F;&#x2F; class_rw_t * plus custom rr&#x2F;alloc flags\n\n    class_rw_t *data() &#123; \n        return bits.data();\n    &#125;\n&#125;;\n\n这一点也很容易理解，早在 Objective-C 1.0 时代，我们就知道一个对象的结构体只有 isa 指针，指向它所属的类。而类的结构体也有 isa 指针指向它的元类。因此让类结构体继承自对象结构体就很容易理解了。 \n可见 Objective-C 1.0 的布局模型中，cache 和 super_class 被原封不动的移过来了，而剩下的属性则似乎消失不见。取而代之的是一个 bits 属性，以及 data() 方法，这个方法调用的其实是 bits 属性的 data() 方法，并返回了一个 class_rw_t 类型的结构体指针。 \nclass_data_bits_t以下是简化版 class_data_bits_t 结构体的定义:\nstruct class_data_bits_t &#123;\n    uintptr_t bits;\npublic:\n    class_rw_t* data() &#123;\n        return (class_rw_t *)(bits &amp; FAST_DATA_MASK);\n    &#125;\n&#125;\n\n可见这个结构体只有一个 64 位的 bits 成员，存储了一个指向 class_rw_t 结构体的指针和三个标志位。它实际上由三部分组成。首先由于 Mac OS X 只使用 47 位内存地址，所以前 17 位空余出来，提供给 retain/release 和 alloc/dealloc 方法使用，做一些优化。其次，由于内存对齐，指针地址的后三位都是 0，因此可以用来做标志位:\n&#x2F;&#x2F; class is a Swift class\n#define FAST_IS_SWIFT           (1UL&lt;&lt;0)\n&#x2F;&#x2F; class or superclass has default retain&#x2F;release&#x2F;autorelease&#x2F;retainCount&#x2F;\n&#x2F;&#x2F;   _tryRetain&#x2F;_isDeallocating&#x2F;retainWeakReference&#x2F;allowsWeakReference\n#define FAST_HAS_DEFAULT_RR     (1UL&lt;&lt;1)\n&#x2F;&#x2F; class&#39;s instances requires raw isa\n#define FAST_REQUIRES_RAW_ISA   (1UL&lt;&lt;2)\n&#x2F;&#x2F; data pointer\n#define FAST_DATA_MASK          0x00007ffffffffff8UL\n\n如果计算一下就会发现，FAST_DATA_MASK 这个 16 进制常量的二进制表示恰好后三位为0，且长度为47位: 11111111111111111111111111111111111111111111000，我们通过这个掩码做按位与运算即可取出正确的指针地址。\n引用 Draveness 在 深入解析 ObjC 中方法的结构 中的图片做一个总结:\n\nclass_rw_tbits 中包含了一个指向 class_rw_t 结构体的指针，它的定义如下:\nstruct class_rw_t &#123;\n    uint32_t flags;\n    uint32_t version;\n\n    const class_ro_t *ro;\n\n    method_array_t methods;\n    property_array_t properties;\n    protocol_array_t protocols;\n&#125;\n\n注意到有一个名字很类似的结构体 class_ro_t，这里的 ‘rw’ 和 ro’ 分别表示 ‘readwrite’ 和 ‘readonly’。因为  class_ro_t 存储了一些由编译器生成的常量。\n\n\n\n\n\n\n\n\n\nThese are emitted by the compiler and are part of the ABI. \n正是由于 class_ro_t 中的两个属性 instanceStart 和 instanceSize 的存在，保证了 Objective-C2.0 的 ABI 稳定性。因为即使父类增加方法，子类也可以在运行时重新计算 ivar 的偏移量，从而避免重新编译。\n关于 ABI 稳定性的问题，本文不做赘述，读者可以参考 Non Fragile ivars。\n如果阅读 class_ro_t 结构体的定义就会发现，旧版本实现中类结构体中的大部分成员变量现在都定义在 class_ro_t 和 class_rw_t 这两个结构体中了。感兴趣的读者可以自行对比，本文不再赘述。\nclass_rw_t 结构体中还有一个 methods 成员变量，它的类型是 method_array_t，继承自 list_array_tt。\nlist_array_tt 是一个泛型结构体，用于存储一些元数据，而它实际上是元数据的二维数组:\ntemplate &lt;typename Element, typename List&gt;&#123;\n    struct array_t &#123;\n        uint32_t count;\n        List* lists[0];\n    &#125;;\n&#125;\nclass method_array_t : public list_array_tt&lt;method_t, method_list_t&gt; \n\n其中 Element 表示元数据的类型，比如 method_t，而 List 则表示用于存储元数据的一维数组，比如 method_list_t。\nlist_array_tt 有三种状态:\n\n自身为空，可以类比为 [[]]\n它只有一个指针，指向一个元数据的集合，可以类比为 [[1, 2]]\n它有多个指针，指向多个元数据的集合，可以类比为 [[1, 2], [3, 4]]\n\n当一个类刚创建时，它可能处于状态 1 或 2，但如果使用 class_addMethod 或者 category 来添加方法，就会进入状态 3，而且一旦进入状态 3 就再也不可能回到其他状态，即使新增的方法后来又被移除掉。\n方法合并掌握了这些 runtime 的基础只是以后就可以继续钻研剩下的 category 的代码了:\nauto rw &#x3D; cls-&gt;data();\nrw-&gt;methods.attachLists(mlists, mcount);\n\n这是刚刚卡住的地方，现在来看，rw 是一个 class_rw_t 类型的结构体指针。根据 runtime 中的数据结构，它有一个 methods 结构体成员，并从父类继承了 attachLists 方法，用来合并 category 中的方法:\nvoid attachLists(List* const * addedLists, uint32_t addedCount) &#123;\n    if (addedCount &#x3D;&#x3D; 0) return;\n    uint32_t oldCount &#x3D; array()-&gt;count;\n    uint32_t newCount &#x3D; oldCount + addedCount;\n    setArray((array_t *)realloc(array(), array_t::byteSize(newCount)));\n    array()-&gt;count &#x3D; newCount;\n    memmove(array()-&gt;lists + addedCount, array()-&gt;lists, oldCount * sizeof(array()-&gt;lists[0]));\n    memcpy(array()-&gt;lists, addedLists, addedCount * sizeof(array()-&gt;lists[0]));\n&#125;\n\n这段代码很简单，其实就是先调用 realloc() 函数将原来的空间拓展，然后把原来的数组复制到后面，最后再把新数组复制到前面。\n在实际代码中，比上面略复杂一些。因为为了提高性能，苹果做了一些优化，比如当 List 处于第二种状态(只有一个指针，指向一个元数据的集合)时，其实并不需要在原地扩容空间，而是只要重新申请一块内存，并将最后一个位置留给原来的集合即可。\n这样只多花费了很少的内存空间，也就是原来二维数组占用的内存空间，但是 malloc() 的性能优势会更加明显，这其实是一个空间换时间的权衡问题。\n需要注意的是，无论执行哪种逻辑，参数列表中的方法都会被添加到二维数组的前面。而我们简单的看一下 runtime 在查找方法时的逻辑:\nstatic method_t *getMethodNoSuper_nolock(Class cls, SEL sel)&#123;\n    for (auto mlists &#x3D; cls-&gt;data()-&gt;methods.beginLists(), \n              end &#x3D; cls-&gt;data()-&gt;methods.endLists(); \n         mlists !&#x3D; end;\n         ++mlists) &#123;\n        method_t *m &#x3D; search_method_list(*mlists, sel);\n        if (m) return m;\n    &#125;\n\n    return nil;\n&#125;\n\nstatic method_t *search_method_list(const method_list_t *mlist, SEL sel) &#123;\n    for (auto&amp; meth : *mlist) &#123;\n        if (meth.name &#x3D;&#x3D; sel) return &amp;meth;\n    &#125;\n&#125;\n\n可见搜索的过程是按照从前向后的顺序进行的，一旦找到了就会停止循环。因此 category 中定义的同名方法不会替换类中原有的方法，但是对原方法的调用实际上会调用 category 中的方法。\n总结读完本文后，你应该对以下内容有比较深刻的理解，排名不分先后:\n\n定义在 runtime.h 中的数据结构，如果有 OBJC2_UNAVAILABLE 标记则表示已经废弃。\nObjective-C 2.0 中，类结构体的结构层次: objc_class -&gt; class_data_bits_t -&gt; class_rw_t -&gt; method_array_t。\nclass_ro_t 结构体的作用，与 class_rw_t 的区别，以及和 ABI 稳定性的关系。\ncategory 解析过程的调用栈以及基本的流程。\nmethod_array_t 为什么要设计成一种类似于二维数组的数据结构，以及它的三种状态之间的关系。\n\n参考资料\n深入理解Objective-C：Category\n从源代码看 ObjC 中消息的发送\n深入解析 ObjC 中方法的结构\nWhats is methodLists attribute of the structure objc_class for?\nObjc与C（C++）之亲缘关系（一） Class\nObjective-C Runtime\n\n","slug":"2022-05-25-runtime-again","date":"2023-05-13T11:29:06.795Z","categories_index":"开发知识","tags_index":"开发知识"},{"id":"af1206b3336cbf2448dc968e084c5e69","title":"或许是频繁切换git分支的救星--git worktree","content":"在实际的开发过程中，你是否也需要经常来回切换分支，如果是，那么这篇文章介绍的方法或者正合适你。\n频繁切换分支的情况\n场景1：协助同事\n\n第一种场景是你正在自己的分支feature-my上做着功能的开发，这时候你的同事给你发信息说，帮忙看一个问题，分支是：feature-abc,通常的情况，你会采用以下的步骤：\n\n通过 git stash --all 保存你的修改，或者通过 git commit -m a &quot;Temp&quot; 做一个临时提交\n通过vscode，或者命令行：git checkout -b feature-abc origin/feature-abc 或者 git swith feature-abc 切换分支\n等待分支切换完成\n接着就可以在feature-abc正常修改，提交，推送更新，完成之后就可以切回到feature-my继续之前的工作\n\n这些都是比较常规的步骤，其中感觉比较痛苦的是第三步，有的时候需要长时间地等待。\n\n场景2：修改bug\n\n你已经完成了一个功能的开发，代码都已经提交并推送到服务器了，你已经在做另一个功能了，但是发现上一个功能有一个bug，急需要修复，这个时候，你又要通过上面说的步骤进行分支的来回切换\n\n场景3：同时做着两个功能的开发\n\n同时做着多个功能的开发，本身就不符合常规的开发流程，我们不论这个流程的问题，就说这种场景，例如，如果你的工作会经常去优化可持续集成的构建代码，确保本地的修改是否符合要求，就需要去CI系统中进行测试验证 使用过CI的同事就会知道，CI分支通常的提交信息就像下面这个：\n\n\n\n每一个提交都是一个小小的改动，需要推送到服务器，等待CI构建的完成。根据CI构建环境的不同，需要等待反馈结果的时间也不同。\n在等待的过程中，我们还可以做着需求功能开发，于是就会切换到功能分支上进行开发，待CI构建结果出来后，又返回到CI分支上，去调整相关的修改，再次推送CI构建系统进行验证，接着有重复着上面的切换分支的流程，如此往复，是否觉得繁琐呢？\n同时在多个分支上开发\n方案1：再clone一次仓库\n\n同时在多个分支上进行开发，最原始的方式就是在另一个文件夹clone该项目，这样就可以在不同的clone下打开不同的分支。\n\n但是这种方式也有几个弊端；\n\n重复的文件，上图所示，每一个文件夹下都有.git文件夹，包含了项目的所有修改记录，但是他们的内容是一样的\n重复的更新操作，由于是在两个不同的文件夹，如果需要更新项目的时候，例如：git fetch或者git pull，必须重复这种操作\n不能共享本地的分支，比如，在test_one分支上修改了文件内容，不能在另一个文件夹的项目里看到，除非将这个更改同步到服务器端，然后再另一个文件夹的项目中进行更新操作，如此也就显得有点复杂了\n\n\n方案2：git worktree\n\n方案2就是使用git worktree, 与方案1非常类似，但是不存在上述的缺点，接下就展示如何通过git worktree，实现同时在两个分支上进行工作。\n\n\n\n\n\n\n\n\n\n关于git worktree的相关使用帮助，可参考：Git 官方文档。\n通过git worktree 实现同时多分支开发git本身就有工作树的概念，就像是你在一个目录下打开一个分支后看到的那些文件（当然不包括.git 文件夹），当你切换另一个分支时，git就会更新这个分支下的所有文件。一个仓库中可以有很多分支，但是只有一个当前分支，你可以在上面修改文件。\ngit worktree允许你同时checkout多个分支。每一个工作树都属于不同的文件夹，和多个克隆有点类似。但是不同的是，多个工作树都是链接到同一个仓库，接下来将简单地解释一下这个概念。\n通过git worktree管理工作树有很多种方式使用git worktree，这里我们只展示一些最基本的使用场景。\n通过一个现有的分支创建工作树\n在上面提到的场景中，你正在自己的分支上做着新功能的开发，这个时候你的同事需要你在他的分支上，帮他看一个问题，但是你又不像暂存你的更改，此时，你可以创建一个工作树。假如你同事的分支为other_feature，你可以在的项目根目录下，执行以下的命令：\ngit worktree add ..&#x2F;test_demo2 feature-test\n\n将会看到如下的输出信息：\nPreparing worktree (new branch &#39;feature-test&#39;)\nBranch &#39;feature-test&#39; set up to track remote branch &#39;feature-test&#39; from &#39;origin&#39;.\nHEAD is now at 22aa823 delete some unused files\n\ngit worktree 有三个参数：\n\nadd 表示创建一个新的工作树\n..&#x2F;test_demo2 就是我们新创建的工作树的目录。由于我们是在仓库的根目录下创建的工作树，因此会创建目录test_demo2与原始仓库目录平级\n\n\n\nother_feature 就是要在新工作树中checkout的分支\n\n运行完命令之后，将看到如下的目录结构：\n\n可以看到在test_demo2中没有.git文件夹，但是有一个.git文件，该文件就是指向原始的仓库，意味着你在test_demo2文件夹中所有的更改，同样的也会在test_demo中发生更改。\n如果不再需要other_feature工作树的话，可以进入到test_demo目录，通过下面的命令删除\ngit worktree remove ..&#x2F;test_demo2\n\n将会删除test_demo2整个目录，但不会影响test_feature这个分支，只是不再会checkout feature-test分支了。\n如果要删除的工作树中还有未提交的更改，git将会阻止你删除，但是你可以通过–force命令参数，强制进行删除。\n从新的分支中创建工作树\n第二种场景，假设你需要改一个着急的bug，但是你还没有有一个分支。git worktree命令有一个 -b 命令参数，可以用来创建一个新的分支关联到新的工作树中：\ngit worktree add ..&#x2F;test_demo2 origin&#x2F;main -b bug_fix\n\n通过远程origin&#x2F;main分支，创建了一个新的分支bug_fix，并在目录test_demo2进行了checkout操作，同样，也可以通过一下命令进行删除：\ngit worktree remove ..&#x2F;test_demo2\n\n小结不得不说git为代码的管理带来了不可估量的高效率，几乎每一种开发中遇到的代码管理问题都能在官方文档中找到解决方式。本文也是简单的记录下git worktree的基本使用，更多详细的使用方式，可参考Git 官方文档，如果英文阅读比较费劲的话，可参考Git 中文参考。\n","slug":"2022-06-24-git-worktree","date":"2023-05-13T11:29:06.795Z","categories_index":"开发知识","tags_index":"开发知识"},{"id":"5ea20968d8e7130fecf289d5412e680c","title":"《大道至简---软件工程实践者的思想》  读书笔记","content":"内容提要本书提出了审视软件工程的全新视角和软件工程的 体系模型(EHM，软件工程层状模型)。本书用非工 程的方式重新解析软件工程现象，全面、细致而深 刻地分析了工程中各个环节的由来、价值及其内在 关系，综合论述开发、工程二者的现状。全书语言 轻快，可读性强，薄且有味。\n本书作者周爱民(Aimingoo)，本书豆瓣评分7.3分，书中部分内容来自作者的个人博客，其中第10章，具体工程（讨论具体工程的思想和基本方法），取材自作者博客文章《杀不死的人狼》系列，作者博客中对本书创作背后的一些故事，也有阐述，感兴趣的同学可以作为背书阅读的课外阅读。\n编程的精义\n\n\n\n\n\n\n\n\n“虽我之死，有子存焉;子又生孙，孙又生子;子又有子，子又有孙。子子孙孙，无穷匮也。而山不加增，何苦而不平?”                   ——《愚公移山》，《列子·汤问篇》\n编程这件事于广大程序员的世界里，总有着一个高大上的梦：改变世界。但是仅仅编程来说，多多少少有点体力活的意思，近年来也多有“码农”的调侃称谓，但是细想也不乏形象，与实际还是有些关联的。\n两千年前的以为工程名家，他曾一人集项目组织者、团队经历、编程人员、技术分析师等等角色于一身，开创了一段美丽而有发人深省的佳话传奇，他就是愚公。\n愚公的寓言故事相信大家都耳熟能详了，那今天就看看愚公如何一步步实现看似不可能的原始需求的。\n愚公的原始需求：\n\n\n\n\n\n\n\n\n\n“惩山北之塞，出入之迂”\n此项目是谓巨大，但愚公并未退却，于是：\n\n\n\n\n\n\n\n\n\n“聚室而谋曰”\n然后，确定了该项目的具体目标：\n\n\n\n\n\n\n\n\n\n“毕力平险，指通豫南，达于汉阴”\n通过研讨，择定了一个可实现的技术方案：\n\n\n\n\n\n\n\n\n\n“扣石垦壤，箕畚运于渤海之尾”。\n有了这些，该找人来实现了，于是动用了三名技术人员和一名工程管理人员：\n\n\n\n\n\n\n\n\n\n“(愚公)率子孙荷担者三夫”\n另还获得了一个力量虽显薄弱，但是满腹工作激情的外协：\n\n\n\n\n\n\n\n\n\n“邻人京城氏之孀妻，有遗男，始龀，跳往助之”。\n有了目标、技术方案和参与人员，那整个工程的编程实现该怎么展开呢？“河曲智叟”与愚公的对话，阐述了整个工程的编程实现：\n\n“虽我之死，有子存焉”，这里描述了可能存在的分支结构，即“IF”条件判断;\n“子又生孙，孙又生子;……子子孙孙，无穷匮也”，这里描述了完成这个工程所必需的循环结构。\n\n这里循环往复会不会是个死循环，而导致整个项目无穷尽尔？其实不然，愚公论述了这个循环的可行性，即“山不加增”，所以条件“山平”是必然成立的，不会出现往复的轮回。\n从愚公的故事中我们看到了编程的根本：顺序、分支合循环。无论庞大还是微小的工程，都可通过这样的编程来实现。\n另外关于能不能学会写程序这件事，本人也被问到过多次，一直以来的回答便是，只要你想去写，都可以写。因为能问出这样问题的人，应该不是先天条件不足者。\n编写程序的第一要务想必大多数人都弄错了，并非上来直接coding，而是先把事情分析清楚，先后逻辑和依赖关系搞明白，必要时还需要画画逻辑关系图等辅助思考，然后再去写代码实现。因此代码实现的并不是程序本身，而是思想，包括使用算法描述逻辑实现，使用结构实现算法所依附的数据实体。\n最终程序本身，只有两部分组成程序 &#x3D; 算法 + 结构，\n程序的实现用什么语言，通常情况下我们不是在新创，而是在原来工程的基础上进行迭代等，语言的选择没有过多的选择性。但是就语言本身而言，没有好与坏、会与不会的问题，任何语言底层的相似性可能超出你的想象，因为所有的语言最终都依赖于操作系统。语言的差异主要表现在适用范围上，只有对当前项目而言，某种语言更加适合与否罢了。\n至此，可能已经大大提高你编写程序的欲望，但是这些都只是蛮荒时期，远古时代无工程思想下的必然产物，有了这些基础，善于钻研和思考的人们，开始造就方法，迈向更加高效文明。\n懒人造就了方法\n\n\n\n\n\n\n\n\n僰道有蜀王兵蘭，亦有神作大滩江中。其崖崭峻不可破，(冰)乃积薪烧之。”——《华阳国志》\n古有愚公凿山运石，再有李冰积薪烧之，那哪一种算是好的方法呢？仁者见仁智者见智，但这都是在特定条件下的使用方法而已。换个思路，愚公为何不采用积薪烧之，而是采用略显笨拙费力的凿山运石呢，可能原因是愚公太过勤快了，勤快到今天可以比昨天多凿一倍的石头，而无闲暇时间思考如何更加快速的方法，反观李冰，团队人数众多，他本身肯定是一个闲人，闲到没事去看或是否能够把石头烧爆，无论愚公还是李冰，都处在一个大工程里面，如果一个人闲到去看火烧石头，那他想必不是那么勤快，那不是懒是什么呢？\n人的精力总是有限的，提出新的“方法”，解决的将是影响做事成效的根本问题，愚公或许能够多吃饭，多加班，但是突破不了人的精力极限。\n\n\n\n\n\n\n\n\n\n番外：相传在两千年前的某一天，闲极无聊的李冰下厨给夫人炒了一个 小菜，他突然发现垒灶的鹅卵石被烧得爆裂开来，遇水尤甚。从此 《史记》上就记下了“蜀守冰，凿离堆”，而《华阳国志》上则记下 了他做这件事的方法:积薪烧之。\n打孔带是早期程序的载体，如果要让计算机去读其上的孔洞逻辑，必然需要连续性的读取，否则织机的运转将陷入走走停停的尴尬境地。\n早期的程序都比较小，几千行代码即可完成一个功能，且都存在于一个文件中，那个时期这样的写法司空见惯，也并不会引起什么不适。现代的软件都相对庞大，动辄上万行代码，如果此时还是单纯的写在一个文件中，可能你就要被痛骂或挑战了。为了解决此类问题，人们创造了单元文件，也随之出现了一个新的概念：模块。大模块细分小模块，小模块再细分为更小的模块，一个模块对应一个单元，于是便可以分工协作，团队作战了。此时结构化编程思维开始萌芽。\n\n\n\n\n\n\n\n\n\n番外：“为什么我学了一年的编程，却还是不知道怎么写程序呢?”“你桌上的书是乱的吗?”“比较整齐。”“你既然知道如何把书分类、整整齐齐地放在书桌上，那怎么没想过如何把所学的知识分类、归纳一下，整整齐齐地放在脑子里呢?”\n结构化编程的基本单位是**过程(Procedure)，而不是上面说到的单元(Unit)**。\n至此，程序 &#x3D; 算法 + 结构 可能并不直接适用了，它是面向过程时代的必然产物，随着面向对象时代的到来，有了事件驱动和模型驱动，所以有了“方法”的问题，有了方法的调配，程序更加的合理，此时程序 &#x3D; 算法 + 结构 + 方法。\n\n\n\n\n\n\n\n\n\n原文摘录所谓“面向过程开发”，其实是对“结构化程序设计”在代码阶段的一个 习惯性的说法。而我忽略了这个阶段的“方法”的根本原因，是即使 没有任何“方法”的存在，只需要“单元(Unit)”和“模块(Module)” 的概念，在面向过程时代，一样可以做出任意大型的程序。在那个 时代，“方法”问题并不会像鼻子一样凸显在每一个程序员的面前。在面向过程开发中，“过程(Procedure)”是由 CPU 提供的，“单元 (Unit)”则是编译器提供的(机制)。程序员无须(至少不是必须) 再创造什么“方法”，就可以进行愚公式的开发工作了。\n团队缺乏的不只是管理\n\n\n\n\n\n\n\n\n“言人三为众，虽难尽继，取其功尤高者一人继之，於名为众矣。”——《汉书·高惠高后文功臣表序》颜师古注\n我们常说“三人行，必有我师焉。” 那为何是三人行，而不是一人行，二人行呢？《汉书》中说“言人三为众”，是指三个人就算得上是“众”了。这里的“众”应该理解成一个群体，亦或者说是一个团队。\n团队至少是以三个人为规模的。这有其合理性。为什么呢？首先一个人算不得团队，那是个体。两个人则互相支撑，古文中“从”字是二人互立，就是这个意思。然而二人互立并不算团队，因为没有监督。三个人便可以构成团队，这样便有了团队的一些基本特性: 主从、监督和责任。\n\n\n\n\n\n\n\n\n\n片面地理解成“三人为众”是不对的。“三”在这里是虚词，指的是很多人的意思。然而，古人以“三”来泛 指很多人或者群体，则是很值得玩味的事。\n春秋时晋国最高司法长官李离，因为听信属下而判案失误，把一个 不该处死的人错判了死刑。随后“自拘于廷，请死于君”。晋文公打 算追究他属下的过错而免掉他的罪，而李离说:\n\n\n\n\n\n\n\n\n\n  “臣居官为长，不与吏让位;受禄为多，不与下分利。今过听杀 人，傅其罪下吏，非所闻也。”\n随后李离就拔剑自杀了。\n项目做不成就要掉脑袋，就好比枕着铡刀做程序；如果项目失败就要递交辞呈，那可能就从来不会有项目经理。但是从李离的故事中可以浅层次的发掘，管理者最基本的素质是承担责任。\n做项目并非死亡游戏，而是在尽可能的实现某个目标，项目成败往往由两个方面来评估：\n\n项目完成的质量\n项目完成的时间\n\n即项目的交付质量和工期，两者缺一不可。程序员的世界里，对于质量往往相对胸有成竹，多数不会出现大的问题，但是工期的预估却难倒了不知多少英雄汉。\n\n\n\n\n\n\n\n\n\n作者与一位讲师的对话摘录：“什么方法能保证预期的工期是正确的，或者说项目是可以按时完成的。”“经验丰富的工程师能尽可能接近地预估工期， 但没有办法保证(预估的)工期是绝对合理的。”\n即由于没有绝对合理的工期，所以项目的完成时间可能总是被进度变更所修正，所以项目也就总是不能“成功”。项目工期的问题不能解决，就不能保证项目成功。只有经验更加丰 富，才更有可能逼近“合理的工期”。\n汉朝的刘向在《新序•杂事二》中记录了一个故事，说是魏文侯出游，见路人把羊皮统子毛向内皮朝外地反穿着，还背着一篓喂牲口的草。 文侯奇怪地问他为什么。这个人答道:我爱惜这件皮衣，怕毛被磨掉了。文侯叹道:你难道不知道，如果皮被磨尽了，毛不也就掉光了吗?\n皮之不存，毛将焉附。没有确定的组织机构，又如何能指望做出来 的管理制度“合用”呢?\n制度的建立是为了解决体制中制的问题，无制不成体，没有制度，无惩戒劣质员工的依据，有了制度而没有惩戒，均属于管理者的过失。对于已经规范管理、体制健全的公司，对于员工的惩戒无可厚非，但是前提至少包括：\n\n员工已经接受过相关的培训，至少是员工规范和技术技能的学习;\n在该员工之前，相同或相关的错误没有被枉纵。\n\n即有人性化的体现，又是公平性的体现。规矩就是规矩，无特殊情况特殊处理，制度一旦被破坏，若要在做杀鸡儆猴状，那猴子是被吓着了，不平声、怨气也就随之而来了。\n因此最好的方法是修订制度，而不是不断的修理人。\n一般在项目开始时，我们会去确定一个人，附带角色定位。例如开发团队中的项目经理，技术负责人、开发人员等，这样一种三类角色构成的“三人”团队，即存在主从关系，也存在协作关系，但是要注意： 跟随蚂蚁。但不要栽进蚂蚁洞里。\n小的时候，我就喜欢观察蚂蚁。我喜欢看它们成群结队地搬着东西 穿过小路，或者水沟。我尝试用木棍导引它们改变行动的路线，然 而不久之后，它们就会翻过那根木棍，按照既定的路线行进。\n禀性难移，要改变一个人都难，何况是改变一个团队的既定习惯。\n团队真的需要管理吗？\n开发团队并不需要管理，或者说，在没有弄清楚状态前，不要去管它。\n如果有一群开发人员像蚂蚁一样辛勒地工作着，那么，请先不要打 扰他们。你应该跟随他们，看看他们是如何做的。发现规律，分析 这个规律的价值，最后再尝试改变他们(的一些负面价值的规律)。\n所以你要紧紧地跟随他们——除了一个地方。那地方是你去不得的，那就是蚂蚁洞。\n显然，你不是开发者，你是管理人员。所以尽管你也是团队中的角色，但千万记得离蚂蚁洞远点。你在洞外张望，可以发现问题;你在洞内，就只有做“循规蹈矩”的蚂蚁。 \n管理者是那个可以在洞外放木棍的人。\n流于形式的沟通\n\n\n\n\n\n\n\n\n“足下求速化之术，不于其人，乃以访愈，是所谓借听于聋，求道于盲。”——唐·韩愈《答陈生书》\n在韩愈的《答陈生书》中，他因自己不会“速化之术”，所以说陈生 是“求道于盲”。然而他用了一个不恰当的比喻:因为盲人并非不知 道路如何走，只是他不能像常人一样描述他所知道的路。因此“问道 于盲”是没有错误的，真正的错误是你睁着眼睛问。\n我们需要在正常人与盲人之间建立一种沟通的方式，既然盲人不能 睁开眼睛，那么你就闭上眼睛好了。\n大部分程序员回到老家，都可能会面临被问是做什么工作的？而当你回答写代码的、做程序员的等等一些自认为简单明了的回答时，对方却一脸懵，认为你答非所问。其实这样的沟通就是一种流于形式，看似有问有答，但是效果可想而知。就像C语言是程序员与计算机交流的语言，你不能希望客户也学习或精通C语言，这无疑是一种自杀式的行为，反之，客户希望某个项目的文档中“用户手册”让程序员来写，但是写完后，客户却觉得写的内容不契合或不正确等，程序员写了很多，但是却都是技术性的使用，而不是哪些非技术人员使用的内容一样。\n另一方面，沟通被复杂化。这个职场中还是能够见到的，某些会议中，开始可能会各种渲染，各种主题思想，但是重要的待沟通事项却最终早早了事，完全没有达到会议的目的，还占用着参会人员的时间。\n应该清楚的是，保障每一次沟通的有效性是最最重要的事。\n\n\n\n\n\n\n\n\n\n中国的“五千年文明史”实际上仅有三千年“有史可查”。因为我国古代编年史的上限，只能追溯到《史记•十二诸侯年表》中记载的西周共和元年，亦即公元前 841 年。在 司马迁在写史记时，他面临的许多文献材料就比较模糊，且相互间 不一致，只好弃之而不用。因而，这导致“(夏商周)三代”的年代 无法考证确实，司马迁也只能为其后可考证的年代写出“(十二诸侯 国)年表”。\n项目的中断和中止，与历史产生断层的内因是一致的，即无证可查。程序员的世界里，常见的是代码注释，但是代码注释并不是项目历史，而是便于代码阅读，后人理解代码意图等等，项目历史是为整个项目而记录的，例如需求背景、需求阶段的干系人、过程、结果，设计阶段的历史框架变化、结构变化等，开发阶段的技术选型、技术方案、评测以及影响等，有了此类较为完善的记录后，每一个不了解该项目的人看了，都不会无证可查，无据可依了。这也是一种沟通，让整个关于项目的沟通都切实有效，而非各种寻迹。\n其实沟通是具有目的性的，如果在没有目的的情况下进行沟通，将是浪费客户和自己的时间，这种目的，在项目中时了解项目的各种信息，挖掘潜在项目或问题，等等等等，最不济，是交流感情。\n然而大多数情况下，它仅仅被看成是交流感情。这便成了形式，且 往往是客户所讨厌的一种形式。沟通问题不仅仅存在于你跟客户的交流之中，还存在于项目的各个 角色之间。设计人员看不懂项目的分析报告，或者开发人员看不懂 设计人员的方案，又或者测试人员看不懂开发的结果，等等，都是 沟通问题。\n流于形式的沟通，可能是使你项目不断推翻和延迟的最直接原因。\n失败的过程也是过程\n\n\n\n\n\n\n\n\n “虚有其表耳。”——《明皇实录》\n软件工程的概念大概是20世纪60年代提出的，但是其成熟的标志是瀑布模型的提出。瀑布模型将软件开发的过程分为需求、分析、设计、开发和测试五个主要阶段，这个过程几乎主导了之后的所有的软件开发工作。在此过程中也演变出了例如RAD（Rapid Application Development, 快速应用开发）模型、螺旋模型和现在常备提及的RUP（Rational Unified Process, Rational统一开发过程）模型。\n所谓模型也就是“样子”，过程被描述为可重复的模型，但是实施的结果可能称为相当尴尬的局面。例如著名的秋千的需求陷阱即如此。\n\n秋千需求的陷阱是什么？同样是在执行者每一个开发阶段，但是最终的交付和最初的需求大相径庭，做完了过程中的每一个阶段，并不等于做完了工程，或者工程并不是这样就可以做成功的。\n因此无论采用什么模型来做工程，即使是亦步亦趋，也做不好工程。因此，做“过程”并不是做工程的精义，也不是目的。\n\n\n\n\n\n\n\n\n\n四川有句地方话叫“做过场”，也有说成“走过场”的。“过场”是舞台术 语，意思是角色从舞台一端出场，再走到另一端进场的一个过程。 过场角色一般没有唱腔或道白，即便是有，也是没有什么实质内容 的。\n秋千的例子就是一个典型的过场。\n究其根本，是忽略了真实的目的 — 实现。工程只是一种实现的途径，过程也好，方法也罢，无法实现也均是空谈。\n身边也有类似的案例，某个项目开始了，一群人勤勤恳恳，折腾了大半年，结果最后项目失败了。但是每个人都做完了工程的每一个过程，最终还是没有完成项目，或项目的每一个“实现目标”。\n\n\n\n\n\n\n\n\n\n“楚人有卖其珠于郑者，为木兰之柜，熏以桂椒，缀以珠玉，饰以 玫瑰，辑以羽翠。郑人买其椟而还其珠。”—- 《韩非子•外储说左上》\n在各种模型的驱使下，很多人很是崇拜模型，万事皆上模型。但是却忘记了模型也只是特定场景下的一种解决问题的方式，而非无它不可，若是一定要以模型来定义，瀑布模型可概括一切，哪些一而再、再而三的变体也只是在过程中不断探索和发现的瀑布模型的变体而已，因此决不能以模型定义过程，而是在过程中不断的完善模型，优化模型，制定适合当前项目的模型即可，但是记住模型也不是一蹴而就的。\n再着，工程并非是做出来的，就像面包馒头之类，有个模子，拿来照着操作就可以“做”出来。而工程几乎没有一模一样的，环境不同，工程的实施也不尽相同。工程的本质是组织，组织工程中的各个角色，大家分工明确，步调一致，共同完成项目。\n但是没有常胜，工程有成有败，失败的工程，也能够从其过程中得到很多。\n东汉时期，伏波将军马援在南征交趾期间写过一封著名的家书，是教导两个“喜讥议，而通轻侠客”的侄儿的，希望他们学习敦厚谨慎的龙伯高，不要仿效豪侠仗义的杜季良。\n龙伯高时任山都长，杜季良时任越骑司马，都是马援所“爱之重之” 的人。然而马援告诫两个侄儿说:\n\n\n\n\n\n\n\n\n\n“效伯高不得，犹为谨敕之士，所谓刻鹄不成尚类鹜者也。效季良不得，陷为天下轻薄子，所谓画虎不成反类狗者也。”\n于是，伯高、季良因马援家书而名留史册，“刻鹄类鹜”和“画虎类犬” 就此成为典故。这意思便是说，雕刻天鹅不成，总还可以像只鸭子 (鹜);若画虎不成反而像条狗，那就事与愿违，贻人笑柄了。\n同样在软件开发中，以得失而论，无论是什么模型应用的失败，都有其所得。例如瀑布模型和RUP模型之间，学习前者不成，可思过程的本质；学习后者而不成，可得文字的架子。\n往往越简单的东西，越接近本质。\n朱湘说:“画不成的老虎，真像狗;刻不成的鸿鹄，真像鹜吗?不然， 不然。成功了便是虎同鹄，不成功时便都是怪物。”\n马援说:“学龙伯高，即使达不到他的水平，总还能成为一个谨慎的 人;而学杜季良，如果学不到家，便会沦为轻薄浪子。”\n你到底是选择架子，还是骨子?\n从编程到工程\n\n\n\n\n\n\n\n\n“得其精而忘其粗，在其内而忘其外;见其所见，不见其所不见，视其所视，而遗其所不视。”——《列子·说符》\n\n猿之于为人，“学会制作和使用工具”是最重要的标志。编程语言之所以在软件工程中有着重要的作用，是因为语言是一个工具，学会使用语言、甚至制作语言，将各种项目需要实现，且高效率高质量，才使得语言这个工具变得有意义。\n\n每条纵向的细线用于定义一个关注点。EHM模型不描述工程元素之间的关系，甚至在试图割裂各个元素，以使得工程角色定位以及各自的视角更加清晰明确。\n\n在“程序”与“方法”层面，关注与“（具体的）实现”\n在“过程”和“工程”层面，首要考虑的是团队问题。\n\n从角色的角度上来说:开发经理思考项目的实施方案和管理具体的 开发行为，而项目经理则保障团队的稳定性和一致性。\n“程序&#x3D;算法+结构”是最内环，此部分虽然占比较小，但是在整个工程项目中却是最核心的部分，项目的成败也多取决于此。推进实现节点向前发展的是“方法”和“方法论”的出现，历史实践经验积累到一定程度，方法论也就应运而生了，任何人都能提出或总结出一些方法论，只不过时机不尽相同而已。\n\n\n\n\n\n\n\n\n\n有人在寺院扫了一辈子的落叶而得道，也有人因为一句话而得道。\n过程说的是很多的人(团队)如何组织在一起进行开发的问题。它 首先把工程中的环节分解出来。这样，有了环节，就有了角色;有 了角色，就有了沟通。\n因此过程中的问题，就是角色、沟通和环节的问题。\n哪些环节重要，哪些环节要紧，视具体的项目而定，但是相互协作和角色间的沟通可能是决定项目过程的步调一致。\n在工程中，站在“组织者” 这个角色上，你现在要考虑的内容可能会是:\n\n为项目的各个阶段建立计划，并逐渐地细化计划的内容，以及确立项目过 程中每一个环节、每一个计划阶段的优先级和复杂度;\n*确立项目或者产品阶段目标，成果的准确描述、定位，以及整个项目的质 量目标及其评核办法;\n对团队中的不同角色展开培训，以指导并协调角色间的工作，从而消除因 为工作习惯的差异带来的影响;\n为每一个人准备他所需要的资源，这不单单是把一套 Shareware 变成正式 版或者把 512MB 内存变成 2GB，还包括准确地评估他的工作量，以及决 定是否为他增加一个(能协同工作的)副手;\n决定在哪些环节上反复审核和回顾，而在哪些环节上采用较为宽松的方式 以加快进度;\n习惯于开会、组织更短而有效的会议，以及建立激励机制，当然也不要忘 记让每一个成员意识到这一项目的风险;\n不要乐观。\n\n现实中的软件工程\n\n\n\n\n\n\n\n\n “王不如远交而近攻，得寸，则王之寸;得尺，亦王之尺也。”  ——《战国策.秦策》\n大公司们在标准、理论、语言上的争来夺去，未必全然出于“软件实现”的考虑。对统一理论、统一工具、统一过程的企图，其最终目的是在整个软件工程体系中的全面胜出。\n因而，除了软件本质力量的推动之外，商业因素也推动着软件工程 体系的发展。大公司们的争夺战的最终结果，已经开始把软件工程， 从原始的“自身演进”状态，逐渐推进到“他激发展”的状态上了。\n这种他激发展可能会影响到软件工程发展的速度，而不会影响到各 个工程层面上的“关注点”。\n蚂蚁的团队总是被本能地组织得非常好。然而如果一个蚂蚁的群体 中有了流行疾病，蚂蚁在死去，而新生蚂蚁不能跟上其死亡的速度， 那么很快，这个团队就溃散了。\n这是因为蚂蚁用于维护团队运作的“资本”在流失。如果资本没有了， 就没了运作，团队的存在就没有了必要性和可能性。\n\nAOP、OOP等只是一种方法论，支撑着编程实现的思想，而C、C++等是语言，是编程思想的一个实现工具\nMDA(Model Driven Architecture)是驱动开发的统称，包括但不限于TDD（测试驱动开发）、BDD（领域驱动开发）等等，以什么驱动开发只是一个以哪个环节为中心或导向的问题。\n\n具体工程\n\n\n\n\n\n\n\n\n“齐人就赵学瑟，因之先调，胶柱而归。三年不成一曲，齐人怪之。”——邯郸淳《笑林·胶柱鼓瑟》\n\n脱离本质的答案可能不是正确的。\n现象之存在与是否被发现无关。\n本质是严谨的，而现象和答案千变万化。\n\n\n若无银弹，人狼或许杀不死。银弹可比各种工程思想，技术思维，方法论，工具等等；人狼好比庞大的工程，其有一定的复杂度、一致性、可变性和不可见性：\n\n要面对极端的复杂性。尽管我们可以用模件复用来缓解复杂性，但是软件 实体的扩展必须是不同元素实体的添加，这些元素“以非线性递增的方式交 互，因此整个软件的复杂度以更大的非线性级数增长”。 所以你创建一个新 软件就必然面临更多的(非线性级数增长的)旧软件中不能被复用的元素。 所以在复杂性方面，人狼是自疗系的:越做越复杂，不可能变简单。\n要背上不可丢弃的历史包袱。由于 Brooks 强调新的软件需要保证跟旧的 软件兼容(有点象 MS Vista 兼容 MS DOS)，你创生了一个软件也就创生 了下一个软件的需求，所有的创生活动产生了需求的自增集合，尽管这种 “变体不是必需的”，但它一个不可丢弃的历史包袱。所以在保证一致性这 一方面，人狼是自增长的。\n要接受需求的持续变更。软件要保证设计一致性才能成功，但从这个软件 被设计的那一刻开始，你就必须接受来自它人的、自身的、市场的、自然 及社会规律的，以及不同的文化和思想习惯的差异的需求(这意味着每个 人的想法都可能被作用在一个软件实体上)。需求是无度和不可控的，所 以人狼本身又是变形系的。\n不可见。你找不到足够的抽象方法描述软件的不同侧面，也就不能将它们 表达为抽象概念上的图形。如果你找到了这样的方法，那么这个“软件”本 身就不足够复杂，因此也就不是原本含义上的“根本任务”。所以，它是隐 形的，你如果看见了它，要么是看见了诸多复杂的方面中的一面，要么根 本就是看错了。\n\n而银弹可能有、没有，或者未来一定会有。\n不要去相信“它适合于所有的工程”，因为你可能在消耗你的资源(时间、人力与金钱)去适应一种方法。你:\n\n一方面要花销资源去组织、实践和推动这些工程方法\n另一方面工程的规模可能根本没有资源去推动它们\n\n所以你必然面临失败;如果你:\n\n增加资源去推动，那么成本可能大于项目利润\n你的老板会不乐意而直接中止这个项目\n\n你还是失败。\n所以问题出在你启动这个工程的最早阶段:你认清目标并决定用什 么方法来驱动这个工程。\n在广义工程与狭义工程(或言之具体工程)中，主要目标与次要目 标正好是倒置的。\n作者对“广义工程”的定义是: \n\n面向“软件活动的根本任务”;\n程序实现的过程无助于求解根本任务。\n\n而对“狭义工程”的定义是:\n\n面向“具体工程活动的需求”:实现;\n将“实现”作为一个过程或结果，则求解“根本任务”只是其探索活动或附加价 值。\n\n\n\n\n\n\n\n\n\n\n曾经，我们如同走在一片沙漠，我们看不到沙漠的边缘，也不知道 如何行走。Brooks 的伟大贡献，在于他用《人月神话》指出了一条 道路并教给我们基本的行走方法，让我们从中学会了辨识流沙，懂 得了沙暴的征兆;同时“没有银弹”的假设激发了我们的斗志，如同 有人在说“你要证明沙漠有边界，你就拿出一束青草来看看”。\n于是有了两种喋喋不休于“有没有青草”的人。一种是已经在灵魂上 上升到另一个层次，固而无需行走于沙漠。另一种则只是站在沙盘 边上，用长杆推动卒子，而鞋子上根本不会沾上一点点沙土。\n还有一种人则不时地宣传他们已经找到了青草。他们总能确保在你 付费的时候看到青草，转身时才会发现那里并不是沙漠的边缘。\n剩下的人一边喃喃着“沙漠边缘的青草”，一边在焦燥的沙海里缓步 前行。不同的是喃喃而不自觉者掉进了沙坑，心怀憧憬而盯紧脚步 的人走出了沙漠。\n走出来，你才会觉得:原来有没有青草，并不那么重要。\n思考还是思想\n\n\n\n\n\n\n\n\n “此郎亦管中窥豹，时见一斑。”——《晋书·王献之传》\n软件工程的三个要素：\n\n工具\n方法\n过程\n\n三者你中有我，我中有你，相辅相成，如能够每一个“管件”拼合起来，才能得到的是“豹”，而非一“斑”。\n而工程整体问题的本质，永远是“实现”。无论从那个角度来看，实现是保证一个工程推进，迭代，成功的关键，每个过程中，都有其工具、每个工具都有其方法、每个方法都有其实施过程等。\n软件项目的平衡三角：\n\n时间\n资源\n功能\n\n经典教材中总是关注：如何更快地完成项目，并减少资源占用，以及实现更多的功能。\n然而，及时平衡了这种关系，项目的结果仍可能产生一个天生的残障 — 质量。\n质量的保证是在过程中控制的，目标可能是在不断平衡三角中确立的。\n对于现代软件工程而言，整个软件工程的过程大多是非常灵活的，而非古诗词一定是“逐字论平仄”的，变化或变通，是常见的事。\n\n\n\n\n\n\n\n\n\n“古人做词的变格，势必依音律而为之，舍周邦彦、东坡、辛弃疾 此等人物，轻易变格，是为他人所笑话的。所以，词谱中所录变格既少，且俱为名家所创。”\n“未蕴而变，自欺也。知 律而变，智者之道也”，实为良言。变向不变求。不变者，万变之所 源，亦万变之所归。习诗词之法度，若蚕虫之结茧，若无结茧于前， 何有破茧于后?故，知律而变，智者之道也。\n“知律而变”中的“律”字，若解释作“规律”，那么便是可以用于软件工 程中的了。“道”是规律，如果明“道”，而可以变化无穷，这样做软件 工程才是活的。就如同今人难于填词一样，不明道，则不明智，不 明智则无所以为，因而在软件工程实施中不可避免的盲目与停滞。\n“知律”的另一层意思，是在于“知道原理”。明白“为什么要这样”或者 “为什么不是那样”。这在软件开发中是常见的问题，大多数人不知 究竟地使用着技巧和方法，而一旦出了问题，则归究于这些技巧和 方法的不好。而真正的问题在于，这些人(我们通常叫做 Copy&amp;Paster)并不知道这些技巧、技术和方法的原理，因而不知道 变通，也不知道回避错误。\n作者荐书\n软件工程Roger S.Pressman 著\n\n","slug":"2022-10-29-dadaozhijian","date":"2023-05-13T11:29:06.795Z","categories_index":"技术人生","tags_index":"读书笔记"},{"id":"c98e5d32ae2d193866c4e1eb0feb55b3","title":"基于MFCC的语音数据特征提取概述","content":"1. 概述语音是人类之间沟通交流的最直接也是最快捷方便的一种手段，而实现人类与计算机之间畅通无阻的语音交流，一直是人类追求的一个梦想。\n伴随着移动智能设备的普及，各家移动设备的厂家也开始在自家的设备上集成了语音识别系统，像Apple Siri、Microsoft Cortana、Google Now等语音助手的出现，使得人们在使用移动设备的同时，也能够进行语音交流，极大的方便了人们的生活。但是此类助手也存在一些尴尬的瞬间，例如在一些工作场合或者聚会的场合，某人的一句“Hey Siri”就可能唤醒多台苹果设备，使用者难免尴尬困惑。\n而此类予语音助手背后，均是一种被称作“闻声识人”的计算机技术，称为语音识别。语音识别技术属于生物认证技术，而其中的说话人识别（speaker recognize，SR）是其中的一种，该技术通常也被称为声纹识别技术，该技术是一项通过语音波形中反映说话人生理特征和行为特征的一组语音参数，自动识别说话人身份的技术。其核心是通过预先录入说话人的声音样本，提取出说话人独一无二的语音特征并存入数据库，应用的时候将待验证的语音进行特征提取并与数据库中的特征进行匹配，以确定说话人的身份。\n1.1 什么是声纹？声纹（voiceprint）是用电声学仪器显示的携带者言语信息的声波频谱，是由波长、频率以及强度等百余种特征维度组成的生物特征，具有稳定性、可测量性以及唯一性等特点。\n\n人类语言的产生是由人体语言中枢与发生器官之间进行的一个复杂的生物物理反应过程。发声器官如舌头、牙齿、喉咙、肺、鼻子在尺寸和形态上因人而异，所有任何两个人的声波图谱都有一定的差异性。\n每个人的语音声学特征既有相对稳定性，又有个体差异性。这种差异可能来自生理、病理、心理、模拟、伪装等，也可能会周围环境的干扰相关。\n由于每个人的发生器官都有其独特性，因此在一般情况下，人们仍然能区别不同的人的声音或者判断是否是同一个人的声音。\n\n声纹不像图像那样的直观，在实际的分析中，可以通过波形图和语谱图进行绘制展现，例如下图是一段从1到10的读数语音文件对应的波形图和语谱图（上部分为声音波形图，下部分为声音语谱图）：\n\nimport wave\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfw &#x3D; wave.open(&#39;test.wav&#39;,&#39;r&#39;)\nsoundInfo &#x3D; fw.readframes(-1)\nsoundInfo &#x3D; np.fromstring(soundInfo,np.int16)\nf &#x3D; fw.getframerate()\nfw.close()\n\nplt.subplot(211)\nplt.plot(soundInfo)\nplt.ylabel(&#39;Amplitude&#39;)\nplt.title(&#39;Wave from and spectrogram of test.wav&#39;)\n\nplt.subplot(212)\nplt.specgram(soundInfo,Fs &#x3D; f, scale_by_freq &#x3D; True, sides &#x3D; &#39;default&#39;)\nplt.ylabel(&#39;Frequency&#39;)\nplt.xlabel(&#39;time(seconds)&#39;)\nplt.show()\n\n\n语谱图更简单的绘制方法，可参考 scipy.signal.spectrogram。\n语谱图绘制的原理，可参考 Create audio spectrograms with Python。\n\n与其他的生物认证技术如指纹识别、人脸识别、虹膜识别等相同，声纹识别具有不会遗忘、无需记忆和使用方便等优点。在生物认证技术领域，说话人识别技术以其独特的方便性、经济性和准确性收到人们的广泛关注，并日益成为人们日常生活和工作中重要且普及的安全认证方式。\n但是，说话人识别有着其他生物认证技术所不具有的优势：\n\n用户接受度高：以声音作为识别特征，因其非接触性和自然醒，用户易接受。用户不用刻意的用手指触摸相应的传感器上，也不用将眼睛凑向摄像头，只需要简单的说一两句话即可完成识别认证。\n设备成本低：对输入设备如麦克风，摄像头等没有特别的要求，特征提取，模型训练和匹配只需要普通的计算机即可完成。\n其他生物认证特征技术各有其劣势：指纹识别需要特殊的传感器芯片，虹膜识别精确度较高，但是设备较为昂贵。\n在远程应用和移动互联网环境下优势明显：通过电话、移动设备进行身份认证，声音是最具优势的生物特征，语音控制也逐渐成为流行的交互形式，以声音为特征的身份鉴别技术也越发重要。\n\n1.2 声纹识别技术的历史声纹识别技术的研究始于20世纪30年代，早期的工作主要集中于人耳听辨实验和探讨听音识别的可能性方面。随着研究手段和计算机技术的发展，研究工作逐渐脱离了单纯的人耳听辨，使得通过机器自动识别人的声音称为可能。在这个过程中也出现了很多不同的计算机技术，从早期的模板匹配到最新的深度学习技术，均在不断的刷新着语音识别技术手段。整体来看，声纹识别技术的发展经历了七个技术演进之路，详见下图（下图来自speakin）：\n\n1.3 声纹识别的种类声纹识别根据实际应用的范畴可以分为 1:1识别 和 1:N识别两种：\n\n1:1识别：指确定待识别的一段语音是否来自其所声明的目标说话人，即确认目标说话人是目标说话人的过程。通常应用于电子支付、智能硬件、银行证券交易等。1:1识别有两个系统的性能评价参量，分别为\n\n错误接受率(False Acceptation Rate, FAR)：将非目标说话人判别为目标说话人造成的错误率\n错误拒绝率(False Rejection Rate, FRR)：将目标说话人误识成非目标说话人造成的错误率\n\n  对安全性要求越高，则设定阈值越高，此时接受目标说话人的条件越严格，即FRR越高，FAR越低；对用户体验要求越高，则设定阈值越低，此时接受目标说话人的条件越宽松，即FAR越高，FRR越低。在声纹系统中，可以通过设定不同的阈值来平衡FAR和FRR。\n\n1:N识别：指判定待识别语音属于目标说话人模型集合中的哪一个人，即在N个人中找到目标说话人的过程。通常应用于公安司法、军队国防等。\n\n\n2. 语音的特征提取方法概述语音是一种数字信号，其数字⾳频的采样率为44100Hz（根据乃奎斯特取样定理得出的结果，在模拟讯号数字化的过程中，如果保证取样频率大于模拟讯号最高频率的2倍，就能100%精确地再还原出原始的模拟讯息。音频的最高频率为20kHz，所以取样率至少应该大于40kHz，为了留一点安全系数，再考虑到工程上的习惯，最终选择了44.1kHz这个数值）。通常情况下使用傅里叶变换将信号在时域与频域之间进行转换，而频谱图可以显示傅里叶变换后的振幅与时间和频率的对应关系。\n2.1 特征提取方法对于语音识别系统而言，所提取的特征参数需要能够反映特定发信的信息，在说话人无关的系统中，更要求参数能够反映不同说话人相同发音的信息，要求说话人的特征参数要能够代表特定的说话人，能够区分不同说话人相同语音之间的差异，最好能够做到与具体的发音内容无关，也称为文本无关。\n在语音特征参数提取技术的发展历程中，线性预测编码（Linear Predictive Coding, LPC）被广泛应用于语音特征参数的提取，其中包括LPC系数、反射LPC系数、面积函数和LPC倒谱系数，能够很好的反映语音的声道特征，但是却对语音的其他特征无能为力。\n 不同于LPC等通过对人的发声机理进行研究而得到的声学特征，Mel倒谱系数MFCC是受人的听觉系统研究成果推出而导出的声学特征。根据人耳听觉机理的研究发现，人耳对不同频率的声波有不同的听觉灵敏度。从200Hz到5000Hz的语音信号对语音的清晰度影响最大。人们从低频到高频这一段频带内按临界带宽的大小由密到疏安排一组带通滤波器，对输入信号进行滤波。将每个带通滤波器输出的信号能量作为信号的基本特征，对此特征经过进一步处理后就可以作为语音的输入特征。由于这种特征不依赖于信号的性质，对输入信号不做任何的假设和限制，又利用了听觉模型的研究成果。因此，这种参数比基于声道模型的LPC相比具有更好的鲁棒性，更符合人耳的听觉特性，而且当信噪比降低时仍然具有较好的识别性能。\n MFCC（MeI-Freguency CeptraI Coefficients）是需要语音特征参数提取方法之一，因其独特的基于倒谱的提取方式，更加的符合人类的听觉原理，因而也是最为普遍、最有效的语音特征提取算法。MFCC是在Mel标度频率域提取出来的倒谱系数，Mel标度描述了人耳对频率感知的非线性特性。\n2.2 MFCC语音特征提取MFCC 语音特征的提取过程，如下图：\n\n需要对语音信号进行预加重、分帧、加窗等等处理，而这些处理的方式均是为了能够最大化语音信号的某些信息，以达到最好特征参数的提取。\n2.2.1 预加重预加重其实就是将语音信号通过一个高通滤波器，来增强语音信号中的高频部分，并保持在低频到高频的整个频段中，能够使用同样的信噪比求频谱。在本实验中，选取的高通滤波器传递函数为：\n\n式中a的值介于0.9-1.0之间，我们通常取0.97。同时，预加重也是为了消除发生过程中声带和嘴唇的效应，来补偿语音信号受到发音系统所抑制的高频部分，也为了突出高频的共振峰。\ndef pre_emphasis(signal, coefficient&#x3D;0.97):\n    &#39;&#39;&#39;对信号进行预加重&#39;&#39;&#39;\n    return numpy.append(signal[0], signal[1:] - coefficient * signal[:-1])\n\n2.2.2 分帧分帧是指在跟定的音频样本文件中，按照某一个固定的时间长度分割，分割后的每一片样本，称之为一帧，这里需要区分时域波形中的帧，分割后的一帧是分析提取MFCC的样本，而时域波形中的帧是时域尺度上对音频的采样而取到的样本。\n分帧是先将N个采样点集合成一个观测单位，也就是分割后的帧。通常情况下N的取值为512或256，涵盖的时间约为20-30ms。也可以根据特定的需要进行N值和窗口间隔的调整。为了避免相邻两帧的变化过大，会让两相邻帧之间有一段重叠区域，此重叠区域包含了M个取样点，一般M的值约为N的1&#x2F;2或1&#x2F;3。\n语音识别中所采用的信号采样频率一般为8kHz或16kHz。以8kHz来说，若帧长度为256个采样点，则对应的时间长度是256&#x2F;8000×1000&#x3D;32ms。本次实验中所使用的采样率(Frames Per Second)16kHz，窗长25ms（400个采样点），窗间隔为10ms（160个采样点）。\ndef audio2frame(signal, frame_length, frame_step, winfunc&#x3D;lambda x: numpy.ones((x,))):\n    &#39;&#39;&#39;分帧&#39;&#39;&#39;\n    signal_length &#x3D; len(signal)\n    frame_length &#x3D; int(round(frame_length))\n    frame_step &#x3D; int(round(frame_step))\n    if signal_length &lt;&#x3D; frame_length:\n        frames_num &#x3D; 1\n    else:\n        frames_num &#x3D; 1 + int(math.ceil((1.0 * signal_length - frame_length) &#x2F; frame_step))\n    pad_length &#x3D; int((frames_num - 1) * frame_step + frame_length)\n    zeros &#x3D; numpy.zeros((pad_length - signal_length,))\n    pad_signal &#x3D; numpy.concatenate((signal, zeros))\n    indices &#x3D; numpy.tile(numpy.arange(0, frame_length), (frames_num, 1)) + numpy.tile(numpy.arange(0, frames_num * frame_step, frame_step),(frame_length, 1)).T\n    indices &#x3D; numpy.array(indices, dtype&#x3D;numpy.int32)\n    frames &#x3D; pad_signal[indices]\n    win &#x3D; numpy.tile(winfunc(frame_length), (frames_num, 1))\n    return frames * win\n\n2.2.3 加窗在对音频进行分帧之后，需要对每一帧进行加窗，以增加帧左端和右端的连续性，减少频谱泄漏。在提取MFCC的时候，比较常用的窗口函数为Hamming窗。\n假设分帧后的信号为 S(n),n&#x3D;0,1,2…,N-1，其中N为帧的大小，那么进行加窗的处理则为：\n\nW(n)的形式如下：\n\n不同的a值会产生不同的汉明窗，一般情况下a取值0.46。进行值替换后，W(n)则为：\n\n对应的汉明窗时域波形类似下图：\n\ndef deframesignal(frames, signal_length, frame_length, frame_step, winfunc&#x3D;lambda x: numpy.ones((x,))):\n    &#39;&#39;&#39;加窗&#39;&#39;&#39;\n    signal_length &#x3D; round(signal_length)\n    frame_length &#x3D; round(frame_length)\n    frames_num &#x3D; numpy.shape(frames)[0]\n    assert numpy.shape(frames)[1] &#x3D;&#x3D; frame_length, &#39;&quot;frames&quot;矩阵大小不正确，它的列数应该等于一帧长度&#39;\n    indices &#x3D; numpy.tile(numpy.arange(0, frame_length), (frames_num, 1)) + numpy.tile(numpy.arange(0, frames_num * frame_step, frame_step),(frame_length, 1)).T\n    indices &#x3D; numpy.array(indices, dtype&#x3D;numpy.int32)\n    pad_length &#x3D; (frames_num - 1) * frame_step + frame_length\n    if signal_length &lt;&#x3D; 0:\n        signal_length &#x3D; pad_length\n    recalc_signal &#x3D; numpy.zeros((pad_length,))\n    window_correction &#x3D; numpy.zeros((pad_length, 1))\n    win &#x3D; winfunc(frame_length)\n    for i in range(0, frames_num):\n        window_correction[indices[i, :]] &#x3D; window_correction[indices[i, :]] + win + 1e-15\n        recalc_signal[indices[i, :]] &#x3D; recalc_signal[indices[i, :]] + frames[i, :]\n    recalc_signal &#x3D; recalc_signal &#x2F; window_correction\n    return recalc_signal[0:signal_length]\n\n\n2.2.4 对信号进行离散傅立叶变换 (DFT)由于信号在时域上的变换通常很难看出信号的特性，所有通常将它转换为频域上的能量分布来观察，不同的能量分布，代表不同语音的特性。所以在进行了加窗处理后，还需要再经过离散傅里叶变换以得到频谱上的能量分布。对分帧加窗后的各帧信号进行快速傅里叶变换得到各帧的频谱。并对语音信号的频谱取模平方得到语音信号的功率谱。设语音信号的DFT为：\n\n能量的分布为：\n\n在本次实验中，采用DFT长度 N&#x3D;512，结果值保留前257个系数。\ndef spectrum_magnitude(frames, NFFT &#x3D; 512):\n    &#39;&#39;&#39;计算每一帧经过FFT变幻以后的频谱的幅度，若frames的大小为N*L,则返回矩阵的大小为N*NFFT&#39;&#39;&#39;\n    complex_spectrum &#x3D; numpy.fft.rfft(frames, NFFT)\n    return numpy.absolute(complex_spectrum)\n\ndef spectrum_power(frames, NFFT):\n    &#39;&#39;&#39;计算每一帧傅立叶变换以后的功率谱&#39;&#39;&#39;\n    return 1.0 &#x2F; NFFT * numpy.square(spectrum_magnitude(frames, NFFT))\n\n下图是有频谱到功率谱的转换结果示意图：\n\n2.2.5 应用梅尔滤波器 (Mel Filterbank)MFCC考虑到了人类的听觉特征，先将线性频谱映射到基于听觉感知的Mel非线性频谱中，然后转换到倒谱上。 在Mel频域内，人对音调的感知度为线性关系。举例来说，如果两段语音的Mel频率相差两倍，则人耳听起来两者的音调也相差两倍。Mel滤波器的本质其实是一个尺度规则，通常是将能量通过一组Mel尺度的三角形滤波器组，如定义有M个滤波器的滤波器组，采用的滤波器为三角滤波器，中心频率为 f(m),m&#x3D;1,2…M，M通常取22-26。f(m)之间的间隔随着m值的减小而缩小，随着m值的增大而增宽，如图所示：\n\n从频率到Mel频率的转换公式为： \n \n 其中 f 为语音信号的频率，单位赫兹（Hz）。\ndef hz2mel(hz):\n    &#39;&#39;&#39;把频率hz转化为梅尔频率&#39;&#39;&#39;\n    return 2595 * numpy.log10(1 + hz &#x2F; 700.0)\n\ndef mel2hz(mel):\n    &#39;&#39;&#39;把梅尔频率转化为hz&#39;&#39;&#39;\n    return 700 * (10 ** (mel &#x2F; 2595.0) - 1)\n\n假如有10个Mel滤波器（在实际应用中通常一组Mel滤波器组有26个滤波器。），首先要选择一个最高频率和最低频率，通常最高频率为8000Hz，最低频率为300Hz。使用从频率转换为Mel频率的公式将300Hz转换为401.25Mels，8000Hz转换为2834.99Mels，由于有10个滤波器，每个滤波器针对两个频率的样点，样点之间会进行重叠处理，因此需要12个点，意味着需要在401.25和2834.99之间再线性间隔出10个附加点，如：\nm(i) &#x3D; 401.25,622.50,843.75,1065.00,1286.25,1507.50, 1728.74,1949.99,2171.24,2392.49,2613.74,2834.99\n现在使用从Mel频率转换为频率的公式将它们转换回赫兹：\nh(i) &#x3D; 300,517.33,781.90,1103.97,1496.04,1973.32,2554.33, 3261.62,4122.63,5170.76,6446.70,8000\n将频率映射到最接近的DFT频率：\n\nf(i) &#x3D; 9,16,25,35,47,63,81,104,132,165,206,256\n于是，我们得到了一个由10个Mel滤波器构成的Mel滤波器组。\n\ndef get_filter_banks(filters_num&#x3D;20, NFFT&#x3D;512, samplerate&#x3D;16000, low_freq&#x3D;0, high_freq&#x3D;None):\n    &#39;&#39;&#39;计算梅尔三角间距滤波器，该滤波器在第一个频率和第三个频率处为0，在第二个频率处为1&#39;&#39;&#39;\n    low_mel &#x3D; hz2mel(low_freq)\n    high_mel &#x3D; hz2mel(high_freq)\n    mel_points &#x3D; numpy.linspace(low_mel, high_mel, filters_num + 2)\n    hz_points &#x3D; mel2hz(mel_points)\n    bin &#x3D; numpy.floor((NFFT + 1) * hz_points &#x2F; samplerate)\n    fbank &#x3D; numpy.zeros([filters_num, NFFT &#x2F; 2 + 1])\n    for j in xrange(0, filters_num):\n        for i in xrange(int(bin[j]), int(bin[j + 1])):\n            fbank[j, i] &#x3D; (i - bin[j]) &#x2F; (bin[j + 1] - bin[j])\n        for i in xrange(int(bin[j + 1]), int(bin[j + 2])):\n            fbank[j, i] &#x3D; (bin[j + 2] - i) &#x2F; (bin[j + 2] - bin[j + 1])\n    return fbank\n\n2.2.6 对频谱进行离散余弦变换 (DCT)在上一步的基础上使⽤离散余弦变换，即进⾏了⼀个傅⽴叶变换的逆变换，得到倒谱系数。\n\n由此可以得到26个倒谱系数。只取其[2:13]个系数，第1个用能量的对数替代，这13个值即为所需的13个MFCC倒谱系数。\ndef lifter(cepstra, L&#x3D;22):\n    &#39;&#39;&#39;升倒谱函数&#39;&#39;&#39;\n    if L &gt; 0:\n        nframes, ncoeff &#x3D; numpy.shape(cepstra)\n        n &#x3D; numpy.arange(ncoeff)\n        lift &#x3D; 1 + (L &#x2F; 2) * numpy.sin(numpy.pi * n &#x2F; L)\n        return lift * cepstra\n    else:\n        return cepstra\n\n2.2.7 动态差分参数的提取（包括一阶微分系数和加速系数）标准的倒谱参数MFCC只反映了语音参数的静态特性，语音的动态特性可以用这些静态特征的差分谱来描述。通常会把动、静态特征结合起来以有效提高系统的识别性能。差分参数的计算可以采用下面的公式：\n\n上式中，d(t)表示第t个一阶微分，c(t)表示第t个倒谱系数，Q表示倒谱系数的阶数，K表示一阶导数的时间差，可取1或2。将上式的结果再代入就可以得到加速系数。\n⾄此，我们计算到了了⾳频⽂件每⼀帧的39个Mel频率倒谱系数（13个MFCC+13个一阶微分系数+13个加速系数），这些即为一个语音文件的特征数据，这些特征数据可以运用在之后的分类中。\ndef derivate(feat, big_theta&#x3D;2, cep_num&#x3D;13):\n    &#39;&#39;&#39;计算一阶系数或者加速系数的一般变换公式&#39;&#39;&#39;\n    result &#x3D; numpy.zeros(feat.shape)\n    denominator &#x3D; 0\n    for theta in numpy.linspace(1, big_theta, big_theta):\n        denominator &#x3D; denominator + theta ** 2\n    denominator &#x3D; denominator * 2\n    for row in numpy.linspace(0, feat.shape[0] - 1, feat.shape[0]):\n        tmp &#x3D; numpy.zeros((cep_num,))\n        numerator &#x3D; numpy.zeros((cep_num,))\n        for t in numpy.linspace(1, cep_num, cep_num):\n            a &#x3D; 0\n            b &#x3D; 0\n            s &#x3D; 0\n            for theta in numpy.linspace(1, big_theta, big_theta):\n                if (t + theta) &gt; cep_num:\n                    a &#x3D; 0\n                else:\n                    a &#x3D; feat[row][t + theta - 1]\n                if (t - theta) &lt; 1:\n                    b &#x3D; 0\n                else:\n                    b &#x3D; feat[row][t - theta - 1]\n                s +&#x3D; theta * (a - b)\n            numerator[t - 1] &#x3D; s\n        tmp &#x3D; numerator * 1.0 &#x2F; denominator\n        result[row] &#x3D; tmp\n    return result\n\n3. 总结本文针对语音数据的特征提取方法—MFCC进行了简单的概述和实践，MFCC是音频特征处理中比较常用而且很有效的方法。当特征数据提取出来之后，就可以进一步的进行数据的归一化、标准化，然后应用于机器学习、神经网络等等模型训练算法中，以得到能够识别语音类别的模型。在实际的应用中，可能还需要考虑很多的其他因素，例如源语音数据的采集方法、采集时长、模型的构建方式、模型的部署方式等等因素，因此需要根据业务的具体场景，来进行平衡取舍，以达到识别的时效性、准确性等。\n目前关于语音识别相关的研究还在持续中，目标是能够最小化成本的在移动端部署语音识别相关的功能，提高SDK在人工智能方便的能力等。\n4. 参考资料\nMel-frequency cepstrum\nMel Frequency Cepstral Coefficient (MFCC) tutorial\n\nNotes on Music Information Retrieval\n机器学习中距离和相似性度量方法\n\n","slug":"2018-07-24-speech-recognation-mfcc","date":"2023-05-13T11:29:06.791Z","categories_index":"机器学习","tags_index":"机器学习 MFCC"},{"id":"4e8d84f448a6e8b441c0b97b84207797","title":"11条数据化运营不得不知的数据预处理经验（无码篇）","content":"数据预处理是数据化运营过程中重要的环节，直接影响着后期所有的数据工作质量和价值输出。从数据预处理的主要内容来看，包括数据清洗、转换、归约、聚合、抽样等。本文将摒弃理论和方法说教，直接介绍内容本身可能遇到的问题以及应对方法。\n3.1 数据清洗：缺失值、异常值和重复值的处理\n清洗：是对数据集进行丢弃、填充、替换、去重等操作，实现去除异常、纠正错误、补足缺失的目的，实现去除数据中的异常、纠正错误、补足缺失的目的。\n\n3.1.1 数据列缺失的4中处理方法数据缺失分为两种：\n\n行记录的缺失，此种情况又称数据记录丢失；\n数据列值缺失，即由于某种原因导致的数据记录中某些列的值空缺等。\n\n\n\n\n\n\n\n\n\n\n某些少数情况下，会使用空字符串来代替缺失值，但是空字符串绝对不同于缺失值，从对象实体来看，空字符串是有实体的，实体为字符串类型，而缺失值其实是没有实体的，即没有数据类型。\n丢失的行记录通常是无法找回的，而对于列值来说，通常有四种方法或者思路来处理：\n1. 丢弃\n即直接删除带有缺失值的记录（整行删除）或者列字段（整列删除），以减少缺失记录对总体数据的影响。但是丢弃也意味着消减数据特征，在以下的场景中，不宜使用：\n\n数据集总体中存在大量的数据记录不完整情况且比例较大，例如超过数据集总体的10%，删除这些带有缺失值的记录意味着损失过多的有用信息；\n带有缺失值的数据记录大量存在着明显的数据分布规律或特征，例如带有缺失值数据记录的目标标签主要集中在某一类或几类，如果删除这些数据记录将是对应分类的数据样本丢失大量的特征信息，导致模型过拟合或者分类不准确。\n\n2. 补全\n即通过一定的方式方法将缺失的数据补上，从而形成完整的数据记录，对于后续的数据处理、分析和建模至关重要。常用的补全方法有：\n\n统计法： 对于数值型的数据，通常使用均值、加权均值、中位数等方法补齐；对于分类型数据，使用类别众数最多的值补齐；\n模型法： 基于已有的其他数据，将缺失值作为目标变量进行预测，从而得到最有可能的补全值。如果带有缺失值的列是数值变量，则使用回归模型补齐，如果是分类变量，则使用分类模型补齐；\n专家法： 对于少数具有重要意义的数据记录，通过领域专家来对数据进行分析，从而进行缺失值补齐；\n其他方法： 例如随机法、特殊值法、多重填补法等。\n\n3. 真值转换法\n核心思路是承认缺失值的存在，并且把数据缺失也作为数据分布规律的一部分，但是缺失值往往无法在后续的数据处理和模型中进行计算，此时需要将缺失值进行真值转换。例如用户的性别，很多数据库中无法对人员的性别进行补齐，但是此性别数据又非常的重要，因此将男、女、未知从一个变量的多值分布状态转换到多个变量的真值分布状态：\n\n转换前：性别（男、女、未知）\n转换后：性别_男（值域1或0）、性别_女（值域1或0）、性别_未知（值域1或0）\n\n然后将这3列新的字段作为输入维度以替换原来的1个字段，参与后续的数据分析、建模计算等。\n4. 不处理\n即在数据预处理阶段，不对带有缺失值的数据记录进行任何处理。此种方式主要要看后续的数据分析和建模应用，对于缺失值的容忍度或灵活处理方式。常见的能够自动补齐缺失值的模型有：KNN、决策树、随机森林、神经网络、朴素贝叶斯和DBSCAN（基于密度的带有噪声的空间聚类模型）等，这些模型对于缺失值的处理思路是：\n\n忽略：即缺失值不参与计算（KNN）\n将缺失值作为分布的一种状态，并参与到建模过程（决策树及其变体）\n不基于距离做计算，因此基于值的距离做计算，本身的影响将消除（DBSCAN）\n\n\n\n\n\n\n\n\n\n\n有时候在数据采集时，采集端针对各个字段设置了一个默认值。假设原本数据采集时没有采集到数据，字段的值将以默认值赋值，此时虽然让数据集看起来非常正常，但是本质上还是确实的，需要留心此类数据。\n3.1.2 不要轻易抛弃异常数据异常数据是数据分布的常态，处于特定分布区域或范围之外的数据通常被定义为异常或“噪声”。从数据异常的状态来看，所谓的数据异常分为两种：\n\n伪异常： 由于业务的特定运营动作产生，是正常反应业务状态的数据，而不是数据本身的异常规律；\n真异常： 并非特定的运营动作产生，而是客观反映数据本身分布异常的个案。\n\n在实际进行数据处理的过程中，“异常数据”往往被当做噪声直接剔除，但是在以下几种情况中，无需对异常值做抛弃处理：\n1. 异常值正常反应了业务运营的结果：是特定业务动作导致的数据分布异常，如果抛弃将导致无法正确反应业务的结果；\n2. 异常检测模型：异常数据本身是目标数据，如果被处理掉，将损失关键性的信息；\n3. 包容异常值的数据建模：数据算法或建模方法对异常值不敏感，异常值对模型本身不会造成负面影响（决策树中，异常值本身可以作为一种分裂节点）。\n\n\n\n\n\n\n\n\n\n除了抛弃和保留，还有一种思路是对异常值使用其他的统计量、预测量进行替换，但是此类方法会将数据集中本身的关键分布特征消除，从而改变原始数据集的分布规律。\n3.1.3 数据重复就需要去重吗数据集中数据重复包含两种情况：\n\n数据值完全相同的多条数据记录；\n数据主体相同但匹配到的唯一属性值不同\n\n去重的主要目标是保留显示特征的唯一特征记录，但是当遇到以下几种情况的时候，不建议或者慎重执行数据去重：\n1. 重复的记录用于分析演变规律：例如商品类别的归属变化，不同时间段，可能同一个商品的归属有所变化，这样在数据库中可能就有一个 变化维度表。表格的维度在不断的发生变化，而对于维度的变化，有3中不同的处理方式：\n\n直接覆盖原有值（无法保留历史信息）\n添加新的维度行（统一ID的商品会有两条匹配记录）\n增加新的属性列（不会改变数据行记录）\n\n\n\n\n\n\n\n\n\n\n变化维度表： 是数据仓库中的概念。维度表类似匹配表，用来存储静态的维度、属性等数据，而这些数据一般都不会发生改变。但是变与不变是一个相对的概念，随着企业的不断发展，很多的维度也会发生变化，因此在某个时间内的维度是不改变的，而整体来看维度是变化的。\n2. 重复的记录用于样本不均衡处理\n样本的不均衡是影响分类模型效果的关键因素之一，解决的方法一般是对少数样本进行简单过采样，通过随机过采样采取简单复制样本的策略来增加少数类样本，而这样的处理会在数据记录中产生相同记录的多条数据，此时不能对其中的重复值执行去重操作。\n3. 重复的记录用于检测业务规则问题\n主要针对的是事务性的数据，重复数据可能意味着重大运营规则问题。此类重复的数据记录可能是由于数据采集、存储、验证和审核机制的不完善问题导致的，会直接影响到前台生产和运营系统。例如重复的订单、重复的充值、重复的预约等等。\n3.2 将分类数据和顺序数据转为标志变量3.2.1 分类数据和顺序数据是什么非数值型变量通常在数据建模过程中无法处理，例如KMeans算法用于计算距离的相似度，而字符串则无法直接计算距离。此类无法直接使用的数据可以分为两大类：\n\n分类数据：指只能归于某一类别的非数值型数据。分类数据中的值没有明显的高低、大小等包含等级、顺序、排序、好坏等逻辑划分，只能用来区分两个或多个具有相同或者相当价值的属性。是在相同衡量维度上的不同属性而已。\n\n性别 — 男、女\n颜色 — 红、黄、蓝\n\n\n顺序数据：指只能归于某一有序类别的非数值型数据。在顺序数据中，有明显的排序规律和逻辑层次的划分。\n\n用户价值等级 — 高、中、底\n学历 — 学士、研究生、博士\n\n\n\n3.2.2 运用标志方法处理分类和顺序数据分类数据和顺序数据要参与建模，通常会转化为数值型数据。最佳的方法是：\n将所有分类或者顺序变量的值域从一列多值的形态转换为多列只包含真值的形态，其中真值可以使用True、False或者1、0来表示。 此类转换也被称为 真值转换。例如下表格中，第一列和第二列是原始的数据格式，性别由‘男’和‘女’来表示，第三列和第四列是经过转换后的表示。（这里为了演示，并没有在转换后去除原始的“性别”一列，在实际应用中需要在转换后去除原始列）\n\n\n\n用户ID\n性别\n用户性别-男\n用户性别-女\n\n\n\n35666841\n男\n1\n0\n\n\n65456567\n女\n0\n1\n\n\n65498932\n女\n0\n1\n\n\n3.3 大数据时代的数据降维数据降维是降低数据的维度数量，是维度归约的一种重要课题。\n3.3.1 需要数据降维的情况数据降维的主要目的是降低模型的计算量并减少模型运行事件、减低噪声变量信息对于模型结果的影响，便于通过可视化的方式展示归约后的维度信息并减少数据存储空间。是否需要进行降维主要需要考虑如下几个方面：\n\n维度数量： 降维的基本前提是高维，如果只有几个维度，就不需要降维了，另外还需要衡量维度的重要性、共线性以及其他排除关系，而不是出于高维的考虑。\n建模输出是否必须保留原始维度： 当需要保留原始维度时，不能进行转换方式降维，只能选择特征筛选的方式降维。\n对模型的计算效率与建模时效性有要求： 高维数据建模时，模型的消耗将呈现几何倍数增长，造成运算效率低、耗时长。\n是否要保留完整数据特征： 当需要所有数据集的完整特征时，不需要进行降维。\n\n3.3.2  基于特征选择的降维基于特征选择的降维指的是根据一定规则和经验，直接选取原有维度的一部分参与到后续的计算和建模过程，用选择的维度代替所有维度，整个过程不产生新的维度。基于特征选择的降维方法有四种思路：\n\n经验法： 通过领域专家的经验、对业务的理解等对特征进行选择；\n测算法： 不断测试多种维度组合的结果，最终选择最佳特征组合；\n基于统计分析的方法： 对维度之间进行相关性分析，进行人工去除或者筛选；\n机器学习算法： 通过机器学习算法得到不同特征的特征值和权重，根据权重选择特征。（例如CART决策树等）\n\n3.3.3  基于维度转换的降维按照一定的数据变换方法，把给定的一组相关变量（维度）通过数学模型将高维空间的数据点映射到低维空间，然后利用映射变量的特征来表示原有变量的总体特质。此种方法会产生一种新的维度，而转换后的维度并不是原始维度的本体，是综合多个维度转换或者映射后的表达式。\n基于维度转换的降维方式，通常会使用主成分分析（PCA）来进行。而PCA主要的使用场景有：\n\n非监督式的数据集： PCA是一种非监督式的降维方法，因此适用于不带有标签的数据集，对于带有标签的数据集则可以使用 LDA；\n根据方差自主控制特征数量： 最大的主成分分析的数量会小于或者等于特征的数量，也就是说PCA也可以输出完全相同数据的特征，主要取决于选择特征中解释的方差比例；\n更少的正则化处理： 选择较多的主成分分析将导致较少的平滑性，因为需要保留更多的数据特征，需要减少正则化；\n数据量较大的数据集： 包括数据记录多和数据维度多两种情况；\n数据分布是位于相同平面（非曲面），数据中存在线性结构。\n\n3.4 解决样本类别分布不均衡的问题样本不均衡是指不同类别的样本量差异非常大。主要出现在分类问题上，从数据规模上可以分为：\n\n大数据分布不均衡：整体数据规模大，只是其中的小样本类的占比较少，但从每个特征的分布上看，小样本也覆盖了大部分或者全部的特征；\n小数据分布不均衡：整体数据规模小，并且占据少量样本比例的分类数量也少，这会导致特征分布的严重不平衡。\n\n3.4.1 哪些运营场景中容易出现样本不均衡\n异常检测场景：异常检测中，异常数据本身是少量的，例如恶意刷单、信用卡欺诈场景等；\n客户流失场景：流失客户一般相对于整体客户量而言是少量的，有其是在一些垄断行业里，例如石油、网络运营商等；\n罕见事件的分析：同样属于发生个案较少，但是不同点在于异常检测通常都有预先定义的规则和逻辑，而罕见事件则无法预判，并且通常会有明显的积极或者消极的影响；\n发生频率低的事件：属于能够预期或者计划性的时间，但是发生频率非常低，例如买彩票等。\n\n3.4.2 通过过抽样和欠抽样解决样本不均衡重新抽样是解决样本不均衡相对简单的方法。\n\n过采样：又称上采样（over-sampling），增加分类中少数类样本的数量来实现均衡，直接的方法是复制，高端点的方法通过少数类中加入随机造成、干扰数据或通过一定的规则产生新的合成样本，例如SMOTE算法；\n欠采样：又称下采样（under-sampling），减少分类中多数类样本的数量来实现均衡，直接的方法是随机剔除。\n\n3.4.3 通过正负样本的惩罚权重解决样本不均衡在算法实现的过程中，对于分类中不同样本数量的类别进行分别赋予不同的权重（一般思路分类中的小样本的类别权重较高），然后进行计算和建模。\n现在绝大部分的算法模型库中都带有类似的权重设置参数，你可以轻松的进行权重的设置等。例如scikit-learn中的SVM，通过在class_weight：&#123;dict, &#39;balanced&#39;&#125;中针对不同类别设置权重来进行均衡处理。SVM中进行自动均衡的计算公式为：\nn_samples  / (n_classes * np.bincount(y))\n3.4.4 通过组合&#x2F;集成方法解决样本不均衡在每次生成训练集时使用所有分类中的小样本量，同时从分类中的大样本量中随机抽取数据来与小样本量合并构成训练集，反复之后会得到很多训练集和训练模型，最后使用组合产生分类预测结果。\n3.4.5 通过特征选择解决样本不均衡一般情况下，样本不均衡也会导致特征分布不均衡，但是如果小类别样本量具有一定的规模，意味着其特征值的分布较为均衡，可通过选择具有显著性的特征配合参与解决样本不均衡问题，一定程度上能够提高模型的效果。\n3.5 如何解决运营数据源的冲突问题\n数据类型冲突：同一数据对象的数据格式不同，常见的有时间戳、日期等；\n数据结构冲突：同一数据主体的描述结构有冲突，典型的代表是关联主键ID值由不同的逻辑结构，导致后期多源数据匹配和关联变的复杂；\n记录粒度不同：对于订单记录的粒度可以存在以订单ID为基础的一条数据中，此时多个商品同时存在商品项目列中；\n数据值域的定义不同：以订单来看，销售系统中可能包括提交订单、审核中、已审核通过、审核不通过四种状态；而库存系统中对于订单状态可能包括提交订单、审核通过、商品分拣、商品包装、商品出库、商品配送、配送成功。这些状态还仅是正常情况下的正向订单状态，即从商家发货到客户手中。几乎每个企业也都存在负向订单，通常产生于退换货的场景下，此时从会员发货到商家手中，这类的订单状态会更多；\n数据值不同：数据值的不同是数据冲突最重要也是最关键的问题所在，不同的数据源通过ETL过程大多可以解决，但若出现数据值不同的问题却难以判断到底哪份数据是正确的。\n\n3.5.1 为什么会出现多数据源的冲突\n内部工具与第三方工具数据冲突：\n对比指标不同（广告媒体代理商与网站统计分析）\n测量的时机不同\n网络丢包的问题\n去重机制的问题\n用户中途退出问题\n页面跟踪加载问题\n动机导致的数据夸大\n其他因素\n\n\n内部同一个业务主体的同一类数据工具的数据测量冲突\n指标定义不同\n采集逻辑不同\n系统过滤规则不同\n更新时间不同\n监测位置不同\n\n\n内部同一个业务主体的不同数据工具的数据测量冲突\n订单来源差异\n特殊商品订单跟踪\n订单状态差异\n数据同步问题\n内部系统拆单问题\n\n\n\n3.5.2 如何应对多数据源的冲突问题\n消除冲突并形成一份唯一数据：全量数据的汇总统计工作等；\n不消除冲突也不作任何处理：使用细粒度的数据进行数据建模等；\n不消除冲突但是使用全部冲突数据： 进行流程性统计分析等。\n\n\n\n\n\n\n\n\n\n\n不消除冲突的情况下，也需要谨慎的对待这种情况，一般情况下，需要关注两方面内容：\n\n\n\n\n\n\n\n\n\n\n差异性： 对于相同实体在相同逻辑下的数据冲突（差异）应该在5%以内，条件允许时可放宽到10%，超过则需要严格对待冲突问题；\n稳定性： 当冲突无法消除时，需要确保多数据源数据的差异性相对稳定，不能出现差异变更甚至相反分布的情况。\n\n3.6 数据化运营要抽样还是全量数据抽样是从整体样本中通过一定的方法选择一部分样本，抽样是雏菊处理的基本步骤之一，也是科学实验、质量检测、社会调查等普遍使用的一种经济有效的工作方法。\n3.6.1 什么时候需要抽样\n数据计算资源不足\n数据采集限制\n时效性要求\n\n应该使用抽样的方法来解决具体问题的场景：\n\n通过抽样实现快速的概念验证\n通过抽样来解决样本不平衡问题\n无法实现对全部样本覆盖的数据化运营场景\n定性分析的工作需要\n\n3.6.2 如何进行抽样抽样从整体上分为 非概率抽样 和 概率抽样 两种。非概率抽样不是按照等概率的原则进行抽样，而是根据人类的主观经验和状态进行判断；概率抽样则是以数学概率论为基础，按照随机的原则进行抽样，一般概率抽样分为如下几种：\n\n简单随机抽样：适用于个体分布均匀的场景\n等距抽样：适用于个体分布均匀或呈现明显的均匀分布规律，无明显趋势或周期性规律的数据\n分层抽样：适用于带有分类逻辑的属性、标签等特征的数据\n整群抽样：适用于小群体集的特征差异较小，并且对划分小群体集有更高的要求\n\n3.6.3 抽样需要注意的几个问题1. 数据抽样要能反映运营背景\n数据能正确反映运营背景，但实际上此过程需要数据工作者对于运营环节和流程非常熟悉才可。\n以下是常见的抽样不能反映运营背景的情况：\n\n数据时效性问题：使用合适时间段的数据，而非历史久远的数据\n缺少关键因素数据：没有运营活动的关键性数据\n不具备业务随机性：抽样后的数据只能反映某一种特定的数据场景\n没有考虑业务增长性：企业在成长，数据也应该有所变化\n没有考虑数据来源的多样性：不能只选择某一个来源的数据\n业务数据可行性问题：根据运营实际情况调整数据工作\n\n2. 数据抽样要能满足数据分析和建模要求\n数据抽样要注意一下几个方面：\n\n抽样样本量的问题\n以时间为维度分布的，至少要包含一个能满足预测的完整业务周期；\n做预测（包含分类和回归）分析建模的，需要考虑特征数量和特征值域的分布，通常数据记录数要同时是特征数量和特征值域的100倍以上；\n做关联规则分析建模的，根据关联前后项的数量（每个前项和后项可包含多个要关联的主体），每个主体需要至少1000条数据；\n对于异常检测类分析建模的，无论是监督式还是无监督式建模，由于异常数据本来就是小概率分布的，因此异常数据记录一般越多越好。\n\n\n抽样样本在不同类别中的分布问题\n\n\n抽样样本能准确代表全部整体特性：\n\n非数值型的特征值域（例如各值频数相对比例、值域范围等）分布需要和总体一致；\n数值型特征的数据分布区间和各个统计值（如均值、方差、偏度等）需要与整体数据分布区间一致；\n缺失值、异常值、重复值等特殊数据的分布要与整体数据分布一致。\n\n\n异常检测类数据的处理：\n\n对于异常检测类的应用要包含全部异常样本；\n对于需要去除业务因素的数据异常，如果有类别特征需要跟类别特征分布一致；如果没有类别特征，属于无监督式学习，则需要和整体分布一致。\n\n\n\n3.7 解决运营数据的共线性问题所谓共线性（又称为多重共线性）问题是指输入的自变量之间存在较高的线性相关度。会导致回归模型的稳定性和准确性大大下降，过多共线性的维度参与计算会浪费计算资源和时间。\n常见的具有明显的共线性的维度或者变量包括：\n\n访问量和页面浏览量\n页面浏览量和访问时间\n订单量和销售额\n订单量和转化率\n促销费用和销售额\n网络展示广告费用和访客数\n\n导致出现变量之间共线性的原因包括：\n\n数据样本不够，可能导致共线性存在偶然性（数据不够）\n多个变量都基于时间有共同或者相反的演变趋势（双11的网络销售额比平时有上升趋势）\n多个变量间存在一定的推移关系，但是总体上变量间的趋势一致，只是发生在时间点不一致（广告曝光后才会出现销售额）\n多个变量间存在近似线性关系（访客数y，广告费x，关系可能是 y &#x3D; 2 * x + b）\n\n3.7.1 如何检测共线性共线性一般通过容忍度、方差膨胀因子、特征值这几个特征数据来做判断：\n\n容忍度（Tolerance）：是每个自变量作为因变量对其他自变量进行回归建模时得到的残差比例，大小用1减得到的决定系数来表示。容忍度的值介于0.1和1之间，越小说明这个自变量与其他自变量间越可能存在共线性问题；\n方差膨胀因子（Variance Inflation Factor, VIF）: VIF是容忍度的倒数，值越大则共线性问题越明显，通常以10作为判断边界。当VIF&lt;10，不存在多重共线性，当10≤VIF&lt;100，存在较强的多重共线性，VIF≥100，存在严重多重共线性；\n特征值（Eigenvalue）：对自变量进行主成分分析，如果多个维度的特征值等于0，则可能有比较严重的共线性。\n\n3.7.2 解决共线性的5中常用方法\n增大样本量（huge samples）：可以减低共线性问题，但是不一定会解决\n岭回归法（Ridge Regression）：放弃最小二乘法的无偏性，以损失部分信息、降低精度为代价来获得更实际和可靠性更强的回归系数\n逐步回归法（Stepwise Regression）：每次引入一个自变量并进行统计检验，然后逐步引入其他变量，同时对所有变量的回归系数进行检验。如果改变不在显著，则剔除\n主成分回归（Principal Components Regression）：通过PCA将参与建模的变量转换为少数几个主成分，每个成分是原来变量的线性组合，再进行回归分析\n人工去除：直接结合人工经验，对参与回归模型的变量进行剔除\n\n3.8 有关相关性分析的混沌相关性分析是指对多个具备相关关系的变量进行分析，从而衡量变量间的相关程度或者密切程度。相关性用 R（相关系数） 表示，取值范围 [-1, 1]。\n3.8.1 相关和因果是一回事吗相关性不等于因果，用 x1 和 x2 作为两个变量进行解释，相关意味着 x1 和 x2 是逻辑上的并列相关关系，而因果关系可解释为应为 x1 所以 x2的逻辑关系。相关性不是用来分析 “为什么”，而是知道 “是什么”。\n3.8.2 相关系数低就是不相关吗R 的趋势是可以为负数的，但是负数并不代表相关性低，而是代表两个变量的增长趋势是相反的，因此要看 R 的绝对值来判断相关性的强弱的。\n3.9 标准化，让运营数据落入相同的范围标准化是一个常用的数据预处理操作，目的是处理不同规模和量纲的数据，使其缩放到相同的数据区间和范围，以减少规模、特征、分布差异等对模型的影响。\n3.9.1 实现中心化和整正态分布的Z-ScoreZ-Score 标准化是基于原始数据的均值和标准差进行的标准化，假设原转换的数据为 x, 新数据为 x′，那么 x′ = （x - mean） / std，其中mean和std是x所在列的均值和标准差。Z-Score方法是一种中心化方法，会改变原有数据的分布结构，不适合用于对稀疏数据做处理。\n3.9.2 实现归一化的Max-MinMax-Min标准化是对原始数据进行线性变换，假设原转换的数据为 x, 新数据为 x′，那么 x′ = （x - min） / (max - min)，其中min和max为x所在列的最小值和最大值。Max-Min方法能够使数据归一化而落入一定区间内，同时还能较好保持原有数据的结构。\n3.9.3 用于稀疏数据的MaxAbs最大值绝对值标准化即根据最大值的绝对值进行标准化，假设原转换的数据为 x, 新数据为 x′，那么 x′ = x / \\max\\，其中max为x所在列的最大值。MaxAbs的数据区间为[-1， 1]，不会破坏原有数据分布结构的特点，因此也可以用于稀疏数据、稀疏的CSR或CSC矩阵。\n\n\n\n\n\n\n\n\n\nCSR（Compressed Sparse Row, 行压缩）、CSC（Compressed Sparse Column，列压缩）\n3.9.4 针对离群点的RobustScaler某些情况下，假设数据集中有离群点，可以使用Z-Score进行标准化，但是标准化后的数据不理想，因为异常点的特征往往在标准化之后容易失去离群特点，此时可以使用RobustScaler针对离群点做标准化处理。\n3.10 离散化，对运营数据做逻辑分层所谓离散化，就是把无限空间中有限的个体映射到有限的空间中。大多数是对连续性数据进行，处理后的数据值域分布将从连续属性变为离散属性。离散化处理的必要性有：\n\n节约计算资源，提高计算效率\n算法模型（尤其是分类模型）的计算需要（例如决策树模型本身支持输入连续性数据，但是会将连续性数据转化为离散化数据）\n增强模型的稳定性和准确度（离散化后，异常数据会被划分为一个子集中的一部分，对模型的影响大大降低，尤其是基于距离计算的模型，K均值、协同过滤等）\n特定数据处理和分析的必要步骤，尤其在图像处理方面应用广泛（二值化也是离散化的一种）\n模型结果应用和部署的需要\n\n3.10.1 针对时间数据的离散化主要用于以时间为主要特征的数据集和粒度转换，离散化处理后将分散的时间特征转换为更高层次的时间特征。常见的针对时间数据的离散化操作分为两类：\n\n针对一天中的时间离散化：一般是将时间戳转换为时、分、秒或者上午、下午、晚上等\n针对日粒度以上数据的离散化：一般是将日期转换为周数、周几、月、工作日或者休息日、季度、年等\n\n针对时间数据的离散化可以将细粒度的时间序列数据离散化为粗粒度的三类数据：\n\n离散化为分类数据：例如上午、下午\n离散化为顺序数据：例如周一、周二、周三\n离散化为数值型数据：例如一年有52周，周数就是数值型的数据\n\n3.10.2 针对多值离散数据的离散化多值离散数据的离散化是指要进行离散化处理的数据本身不是数值型数据，而是分类或者顺序数据。\n例如用户活跃度变量的值，原来为高、中、低三个类别，但是由于业务的变化，新的用户活跃度变量需要高、中、低、负四个类别，此时就需要对不同类别的数据进行统一规则的离散化处理。\n3.10.3 针对连续数据的离散化此类离散化是主要的离散化应用，在分类或者关联分析中应用广泛，此类算法的结果是以类别或者属性标识为基础，而非数值型标记。连续数据的离散化结果可以分为两类：\n\n将连续数据划分为特定区间的集合\n将连续数据划分为特定类\n\n常用实现针对连续数据离散化的方法包括：\n\n分位数法：使用四分位、五分位、十分位等分位数进行离散化处理\n距离区间法：等距区间或者自定义区间进行离散化\n频率区间法：按照不同数据的频率分布进行排序，再按照等频率或者指定频率离散化（会改变原有数据的分布状态）\n聚类法：使用K均值将样本集分为多个离散化的簇\n卡方：基于卡方的离散化方法，找出数据的最佳临近区间并合并，形成较大的区间。\n\n3.10.4 针对连续数据的二值化二值化是指对每个数据点跟阈值进行比较，大于阈值设置为某一固定值，小于阈值设置为某一固定值，然后得到一个只拥有两个值域的二值化数据集。\n二值化应用的前提是数据集中所有的属性值所代表的含义相同或类似。\n3.11 数据处理应该考虑哪些运营业务因素数据处理工作不仅依赖于数据工作者的经验，也需要考虑实际的运营业务因素。数据处理时应该考虑的运营业务因素包括固定和突发运营周期、运营需求的有效性、交付时要贴合运营落地场景、专家经验、业务需求等变动因素。\n3.11.1 考虑固定和突发运营周期运营周期的属性主要表现在两个方面：\n\n有计划的周期性\n临时或突发周期\n\n运营业务的周期性对数据的影响：\n\n有计划的周期在数据的选取和分析过程中非常重要，尤其涉及对比时，选对具有相同属性的对比周期是形成结论的基础\n有计划的运营周期对于时间序列特征明显的建模影响较大，包括时间序列、时序关联、隐马尔可夫模型等\n不同周期下产生的数据可能有差异，尤其是对于高速发展的新型公司，不同周期下的数据可能带有明显的线性、指数、二项式以及其他变化特征，甚至可能带有业务因素导致的异常数据点\n运营过程中可能产生突发的数据工作需求\n数据工作的整个过程需要运营业务人员参与，而依赖于运营业务人员参与的时机以及对应的方式和切入点也很重要。\n\n3.11.2 考虑运营需求的有效性数据工作者可以对某些需求做拒绝或者延迟处理，主要原因如下：\n\n缺少数据\n需求不合理\n条件限制\n资源限制\n低价值需求\n\n3.11.3 考虑交付时要贴合运营落地场景数据处理工作虽然只是中间过程，并没有到达数据分析、建模、部署和应用的阶段，但是该阶段的很多工作会直接影响后期的交付和运营落地，典型因素如下：\n\n维持原有指标\n更容易理解的算法限制\n数据生产和应用环境\n\n3.11.4 不要忽视业务专家的经验业务专家经验在数据处理工作中的重要作用体现在一下两个方面：\n\n数据工作方向：专家经验会决定需要做什么、产出是什么、中间的过程应该向哪个方向考虑，侧重于“是什么”。直接影响着：\n数据项目工作目标和需求\n数据探索和摸底方向\n数据交付物的形式和规格\n\n\n数据工作逻辑：专家经验可以提出有价值的参考和工作建议，侧重于“怎么做”，直接影响着：\n总体数据周期、规则、条件等的选取\n数据抽样规则，有其涉及到分层、整群抽样\n多数据的整合、匹配和关联关系\n不同数据源和数据间的清洗、转换逻辑\n重复值、异常值和缺失值的处理逻辑\n数据离散化的方法选择和区间定义\n根据变量重要性进行数据变量的选取和降维\n数据算法和模型选择\n数据模型的调整、评估和优化\n\n\n\n3.11.5 考虑业务需求的变动因素为了最小程度的降低业务的变动给数据工作带来困惑，甚至失败，应该提前做好如下几个准备：\n\n充分、有效的沟通\n更完整、更原始的数据集\n可理解性强、规则清晰的算法和模型\n模块化工作方法\n建立数据工作流程和机制\n\n","slug":"2018-07-26-11-tips","date":"2023-05-13T11:29:06.791Z","categories_index":"数据科学","tags_index":"数据科学"},{"id":"5e9b9b13b72db5150ecf19d34ae2e64a","title":"异常点检测算法小结","content":"异常点检测，有时也叫离群点检测，英文一般叫做Novelty Detection或者Outlier Detection,是比较常见的一类非监督学习算法，这里就对异常点检测算法做一个总结。\n异常点检测算法使用场景什么时候我们需要异常点检测算法呢？常见的有三种情况。\n\n在做特征工程的时候需要对异常的数据做过滤，防止对归一化等处理的结果产生影响。\n对没有标记输出的特征数据做筛选，找出异常的数据。\n对有标记输出的特征数据做二分类时，由于某些类别的训练样本非常少，类别严重不平衡，此时也可以考虑用非监督的异常点检测算法来做。\n\n\n\n\n异常点检测算法常见类别异常点检测的目的是找出数据集中和大多数数据不同的数据，常用的异常点检测算法一般分为三类。\n第一类是基于统计学的方法来处理异常数据。这种方法一般会构建一个概率分布模型，并计算对象符合该模型的概率，把具有低概率的对象视为异常点。比如特征工程中的RobustScaler方法，在做数据特征值缩放的时候，它会利用数据特征的分位数分布，将数据根据分位数划分为多段，只取中间段来做缩放，比如只取25%分位数到75%分位数的数据做缩放。这样减小了异常数据的影响。\n第二类是基于聚类的方法来做异常点检测。这个很好理解，由于大部分聚类算法是基于数据特征的分布来做的，通常如果我们聚类后发现某些聚类簇的数据样本量比其他簇少很多，而且这个簇里数据的特征均值分布之类的值和其他簇也差异很大，这些簇里的样本点大部分时候都是异常点。比如我之前讲到的BIRCH聚类算法原理和DBSCAN密度聚类算法都可以在聚类的同时做异常点的检测。\n第三类是基于专门的异常点检测算法来做。这些算法不像聚类算法，检测异常点只是一个赠品，它们的目的就是专门检测异常点的，这类算法的代表是One Class SVM和Isolation Forest.\n下文主要会对One Class SVM和Isolation Forest做详细的讨论分析。\nOne Class SVM算法One Class SVM也是属于支持向量机大家族的，但是它和传统的基于监督学习的分类回归支持向量机不同，它是无监督学习的方法，也就是说，它不需要我们标记训练集的输出标签。\n那么没有类别标签，我们如何寻找划分的超平面以及寻找支持向量呢？One Class SVM这个问题的解决思路有很多。这里只讲解一种特别的思路SVDD, 对于SVDD来说，我们期望所有不是异常的样本都是正类别，同时它采用一个超球体而不是一个超平面来做划分，该算法在特征空间中获得数据周围的球形边界，期望最小化这个超球体的体积，从而最小化异常点数据的影响。\n假设产生的超球体参数为中心o和对应的超球体半径r&gt;0，超球体体积V(r) 被最小化，中心o是支持向量的线性组合；跟传统SVM方法相似，可以要求所有训练数据点xi到中心的距离严格小于r，但同时构造一个惩罚系数为 C 的松弛变量ξi，优化问题如下所示：\n\n在采用拉格朗日对偶求解之后，可以判断新的数据点 z 是否在类内，如果z到中心的距离小于或者等于半径r,则不是异常点，如果在超球体以外，则是异常点。\n在sklearn中，我们可以用svm包里面的OneClassSVM来做异常点检测。OneClassSVM也支持核函数，所以普通SVM里面的调参思路在这里也适用。\nIsolation Forest算法Isolation Forest(以下简称IForest)是周志华老师的学生提出来的，主要是利用集成学习的思路来做异常点检测，目前几乎成为异常点检测算法的首选项，我之前在Bagging与随机森林算法原理小结第4.3节中也简略讲解了IForest的思路，它是随机森林大家族的一员。\n算法本身并不复杂，主要包括第一步训练构建随机森林对应的多颗决策树，这些决策树一般叫iTree，第二步计算需要检测的数据点x最终落在任意第t颗iTree的层数ht(x)。然后我们可以得出x在每棵树的高度平均值h(x)。第三步根据h(x)判断x是否是异常点。\n对于第一步构建决策树的过程，方法和普通的随机森林不同。\n首先采样决策树的训练样本时，普通的随机森林要采样的样本个数等于训练集个数。但是iForest不需要采样这么多，一般来说，采样个数要远远小于训练集个数。原因是我们的目的是异常点检测，只需要部分的样本我们一般就可以将异常点区别出来了。\n另外就是在做决策树分裂决策时，由于我们没有标记输出，所以没法计算基尼系数或者和方差之类的划分标准。这里我们使用的是随机选择划分特征，然后在基于这个特征再随机选择划分阈值，进行决策树的分裂。直到树的深度达到限定阈值或者样本数只剩一个。\n第二步计算要检测的样本点在每棵树的高度平均值h(x)。首先需要遍历每一颗iTree，得到检测的数据点x最终落在任意第t颗iTree的数层数ht(x)。这个ht(x)代表的是树的深度，也就是离根节点越近，则ht(x)越小，越靠近底层，则ht(x)越大，根节点的高度为0.\n第三步是据h(x)判断x是否是异常点。我们一般用下面的公式计算x的异常概率分值：\n\n, s(x,m)的取值范围是[0,1],取值越接近于1，则是异常点的概率也越大。其中，m为样本个数。的表达式为：\n\n从s(x,m)表示式可以看出，如果高度h(x)→0, 则s(x,m)→1，即是异常点的概率是100%，如果高度h(x)→m−1, 则s(x,m)→0,即不可能是异常点。如果高度h(x)→c(m), 则s(x,m)→0.5，即是异常点的概率是50%，一般我们可以设置$s(x,m)的一个阈值然后去调参，这样大于阈值的才认为是异常点。\n在sklearn中，我们可以用ensemble包里面的IsolationForest来做异常点检测。\n异常点检测算法小结IForest目前是异常点检测最常用的算法之一，它的优点非常突出，它具有线性时间复杂度。因为是随机森林的方法，所以可以用在含有海量数据的数据集上面。通常树的数量越多，算法越稳定。由于每棵树都是互相独立生成的，因此可以部署在大规模分布式系统上来加速运算。对于目前大数据分析的趋势来说，它的好用是有原因的。\n但是IForest也有一些缺点，比如不适用于特别高维的数据。由于每次切数据空间都是随机选取一个维度和该维度的随机一个特征，建完树后仍然有大量的维度没有被使用，导致算法可靠性降低。此时推荐降维后使用，或者考虑使用One Class SVM。\n另外iForest仅对即全局稀疏点敏感，不擅长处理局部的相对稀疏点 ，这样在某些局部的异常点较多的时候检测可能不是很准。\n而One Class SVM对于中小型的数据分析，尤其是训练样本不是特别海量的时候用起来经常会比iForest顺手，因此比较适合做原型分析。\n","slug":"2018-08-02-novelty-detection","date":"2023-05-13T11:29:06.791Z","categories_index":"机器学习","tags_index":"机器学习"},{"id":"454e17e3669649f8307f998e0bce1204","title":"机器学习问题的通用方法","content":"一位数据科学家平均每天处理大量数据，有人说，超过60-70％的时间花在了数据采集、数据清理、数据整理上，使得机器学习模型可以应用于这些数据。本文重点介绍第二部分，即应用机器学习模型，包括预处理步骤。这篇文章中讨论的流水线是我参与过的一百多次机器学习竞赛的结果。必须指出，这里的讨论虽然普通，但非常有用，也存在非常复杂的方法，可供专业人员练习。\n我们将在这里使用python！\n数据在应用机器学习模型之前，必须将数据转换为表格形式。整个过程是最耗时且最困难的过程，如下图所示。\n\n然后是机器学习模型应用于表格数据，表格数据是在机器学习或数据挖掘中表示数据的最常用方式。我们有一个数据表，包含不同数据样本（或X和标签y）的行。标签可以是单列或多列，具体取决于问题的类型。我们将用X表示数据，用y表示标签。\n标签的类型标签定义了问题，可以是不同的类型，如：\n\n单列，二元值（分类问题，一个样本只属于一个类，只有两个类）\n单列，实数值（回归问题，仅预测一个值）\n多列，二元值（分类问题，一个样本属于一个类，但有两个以上的类）\n多列，实数值（回归问题，多值预测）\n多标签（分类问题，一个样本可以属于几个类）\n\n评估指标对于任何类型的机器学习问题，我们必须确定将如何评估我们的结果，要评估的指标或目标是什么？例如，如果存在倾斜的二分类问题，我们通常选择受试者工作特征曲线下的面积（ROCAUC或简称AUC）。在多标签或多分类问题的情况下，我们通常选择分类交叉熵或多分类对数损失，在回归问题的情况下选择均方误差。\n我不会详细讨论不同的评估指标，我们可以有许多不同的类型，具体取决于问题本身。\n机器学习库要开始使用机器学习库，首先安装基本的和最重要的库，例如numpy和scipy。\n查看和执行数据操作：pandas（http://pandas.pydata.org/）对于各种机器学习模型：scikit-learn（http://scikit-learn.org/stable/）最好的梯度提升库：xgboost（https://github.com/dmlc/xgboost）对于神经网络：keras（http://keras.io/）可视化数据：matplotlib（http://matplotlib.org/）监视进度：tqdm（https://pypi.python.org/pypi/tqdm）\n机器学习框架2015年，我提出了一个自动机器学习框架，该框架目前仍在开发中，将于近期发布。在这篇文章中，相同的（基础）框架如下图所示：\n\n本图来自：A.Thakur和A.Krohn-Grimberghe，AutoCompete：机器学习竞赛框架，AutoMLWorkshop，2015年机器学习国际会议\n在上面显示的框架中，粉红色的线代表最常用的路径。在我们提取并将数据缩减为表格格式后，我们可以继续构建机器学习模型。\n第一步是确定问题，这可以通过查看标签来完成。必须知道问题是二分类、多分类、多标签分类还是回归问题。在我们确定问题后，我们将数据分成两个不同的部分，一个训练集和一个验证集，如下图所示。\n\n数据分解为训练集和验证集“必须”考虑标签类型。如果出现任何类型的分类问题，请使用分层分割。在python中，你可以很容易地使用scikit-learn。\n\n在回归任务的情况下，简单的K-Fold分割就足够了。然而，有些复杂的方法往往需要训练集和验证集保持相同的标签分布，这个问题将留给读者作为练习。\n\n上述示例中我已经选择全部数据的10％作为eval_size或验证集的大小，此值可以根据它们所具有的数据大小进行选择。\n数据拆分完成后，请保留此数据不要动它。必须保存在训练集上应用的任何操作，然后将其应用于验证集。在任何情况下，验证集都不应该与培训集一起使用，这样做会产生非常好的评估分数并让用户感到满意，但是会构建一个严重过拟合的无用模型。\n下一步是识别数据中的不同变量。我们处理的变量通常有三种类型，即数字变量、分类变量和包含文本的变量。让我们以流行的泰坦尼克号数据集（https://www.kaggle.com/c/titanic/data）为例。\n\n在这里，survival就是标签，我们已经将标签从前一步中的训练数据中分离出来了。变量pclass、sex、embarke具有不同的级别，因此它们是分类变量。像age、sibsp、parch等变量是数值变量。name是一个包含文本数据的变量，但我不认为它是预测生存的有用变量。\n首先对于数值变量，这些变量不需要任何类型的处理，因此我们可以直接对这些变量应用规范化和机器学习模型。\n有两种方法可以处理分类数据：\n\n将分类数据转换为标签\n\n\n\n将标签转换为二元变量（one-hot编码）\n\n\n请记住先使用LabelEncoder将类别转换为数字，然后再应用OneHotEncoder。\n因为泰坦尼克号的数据没有文本变量的好例子，所以让我们制定处理文本变量的一般规则。我们可以将所有文本变量合并为一个，然后使用一些对文本数据起作用的算法并将其转换为数字。\n文本变量可以如下连接在一起：\n\n我们可以在变量上使用CountVectorizer或TfidfVectorizer：\n\n或\n\nTfidfVectorizer大多数时候比CountVectorizer性能都要好， TfidfVectorizer使用以下参数在很多情况下都有效。\n\n如果您只在训练集上应用这些vectorizer，请确保将其转储到磁盘中，以便稍后在验证集上使用它。\n\n接下来，我们来到stacker模块，stacker模块不是模型堆垛器，而是特征堆垛器。上述处理步骤之后的不同特征可以使用堆叠器模块进行组合。\n\n在通过使用numpy hstack或sparsehstack 进行进一步处理之前，您可以水平堆叠所有特征，具体取决于您是否拥有稠密或稀疏的特征。\n\n如果还有其他处理步骤如PCA或特征选择（我们将在本文的稍后部分讲解分解和特征选择），也可以通过FeatureUnion模块实现。\n\n一旦将这些特征堆叠在一起，我们可以开始应用机器学习模型。在这个阶段，你应该选择的模型应该集成基于树的模型。这些模型包括：\n\nRandomForestClassifier\nRandomForestRegressor\nExtraTreesClassifier\nExtraTreesRegressor\nXGBClassifier\nXGBRegressor\n\n我们不能将线性模型应用于上述特征，因为它们没有归一化。要使用线性模型，可以使用scikit-learn中的Normalizer或StandardScaler。\n这些归一化方法仅适用于稠密特征，如果应用于稀疏特征则不会给出非常好的结果。但可以在不使用均值的情况下在稀疏矩阵上应用StandardScaler（参数：with_mean&#x3D; False）。\n如果上述步骤给出了一个“好”的模型，我们可以去优化超参数，如果没有，我们需要继续下面的步骤并改进我们的模型。\n\n为了简单起见，我们将忽略LDA和QDA转换。对于高维数据，通常使用PCA来分解数据。对于图片以10-15个component开始，并且只要结果质量显着提高，就增加此数量。对于其他类型的数据，我们最初选择了50-60个component（只要我们能够处理得了数值数据，我们就倾向于避免PCA）。\n\n对于文本数据，在将文本转换为稀疏矩阵后，进行奇异值分解（SVD）。可以在scikit-learn中找到称为TruncatedSVD的SVD变体。\n\n通常用于TF-IDF或计数的SVD component的数量在120-200之间。以上任何数字都可能会提高性能，但不会实质性降低计算能力。\n在进一步评估模型的性能之后，我们转向数据集的缩放，以便我们也可以评估线性模型。特征被归一化或缩放后可以被发送到机器学习模型或特征选择模块。\n\n有多种方法可以实现特征选择。最常见的方式之一是贪婪特征选择（向前或向后）。在贪婪特征选择中，我们选择一个特征，训练一个模型并根据固定评估指标评估模型的性能，我们一个接一个不断添加和删除特征，并在每一步记录模型的性能，最后我们选择评估得分最高的特征。以AUC作为评估指标的贪婪特征选择的一个实现可以在这里找到：https：&#x2F;&#x2F;github.com&#x2F;abhishekkrthakur&#x2F;greedyFeatureSelection。必须指出的是，这种实现并不完美，必须根据要求进行修改。\n其他更快的特征选择方法包括从模型中选择最佳特征。我们既可以查看logit模型的系数，也可以训练一个随机森林来选择最佳特征，然后在其他机器学习模型中使用这些特征。\n\n请记住，要保持较少的estimator和最少的超参数优化，以免过拟合。\n使用梯度提升(GradientBoosting )也可以实现特征选择。我们在scikit-learn中推荐使用xgboost而不是GBM的实现，因为xgboost更快更灵活。\n\n我们也可以使用RandomForestClassifier &#x2F; RandomForestRegressor和xgboost来进行稀疏数据集的特征选择。\n从正稀疏数据集中选择特征的另一种流行方法是基于chi-2的特征选择，我们在scikit-learn中实现了这一功能。\n\n在这里，我们使用chi2和SelectKBest从数据中选择20个特征。这是我们想要优化以提高机器学习模型结果的超参数。\n不要忘记导出在所有步骤中使用的任何种类的transformer，它们将被用于在验证集上的评估性能。\n下一个（或中间）的主要步骤是模型选择+超参数优化。\n\n我们通常在选择机器学习模型的过程中使用以下算法：\n\n分类\n\nRandom Forest\nGBM\nLogistic Regression\nNaive Bayes\nSupport Vector Machines\nk-Nearest Neighbors\n\n\n回归\n\nRandom Forest\nGBM\nLinear Regression\nRidge\nLasso\nSVR\n\n\n\n我们应该优化哪些参数？如何选择趋近最佳的参数？这些是大多数人想到得到的几个问题。如果没有大量数据集上不同模型+参数的经验，就无法得到这些问题的答案，可能也有有经验的人不愿意分享他们的秘密。幸运的是，我也有相当多的经验，同时我愿意分享一些东西。\n让我们分解超参数，使模型更智能：\n\nRS* &#x3D;不能说完全适当的值，随机搜索这些超参数。\n严格地说我的观点是，上述模型将超越其他模型，我们不需要评估任何其他模型。\n再次记住保存transformer：\n\n并将它们分别应用于验证集：\n\n上述规则和框架在我处理的大多数数据集中都表现得非常好。当然，对于非常复杂的任务也可能是失败的。没有什么是完美的，我们继续改进我们学到的东西，就像机器学习一样。\n","slug":"2018-08-03-ml-normal-methods","date":"2023-05-13T11:29:06.791Z","categories_index":"机器学习","tags_index":"机器学习"},{"id":"abd2edbd638b8074672349cf6622a4a2","title":"Core ML vs ML Kit：哪一个移动端机器学习框架更适合你？","content":"截止2018年举行的Apple全球开发者大会（WWDC2018），Apple公司的用于iOS设备的机器学习框架CoreML走过了一年的更新迭代，迎来了首次较大规模的版本更新。在同一时期，Google也发布了其一款面向iOS和安卓设备的跨平台人工智能开发框架。这两类工具的目的均是为了优化大型人工智能模型和数据集开发的负担，使得开发者能够以轻量化的实现方式，增加移动应用程序的智能化等。但是值得思考的一点是，为什么在这个时期，Google和Apple会相继推出自家的移动端机器学习框架呢？\n\n\n移动端机器学习的重要性机器学习无疑是一项非常实用的数据科学技术，其应用的程度正在以指数速度在增长，我们几乎每天都会看到一些发展，但是假如普通大众无法获得机器学习带来的有点，无法改善人类的生活方式，那么发展再好的技术也是不会持续下去的。面对这一情况，结合移动设备的空前普及，在移动设备端使用机器学习是最快速让机器学习应用普惠大众的方式。但是机器学习本身是一项复杂而且专业性很高的任务，普通的开发者可能难以快速的理解和应用，为了使在移动设备上进行机器学习的复杂任务变的简单，并且允许没有机器学习经验的应用开发人员实现机器学习的功能，简便而且符合开发人员编程语言习惯的异动单机器学习开发工具势的必出。\nCore ML\nApple在2017年WWDC上发布了Core ML，并于今年更新为Core ML 2.0。Core ML使开发人员能够将机器学习模型集成到iOS或MacOS应用程序中，这是该领域的第一次重大尝试，最初，开发人员真的很喜欢它，原因有很多。 Core ML针对移动硬件性能进行了优化，可最大限度地减少内存占用和功耗。严格地在设备上运行还可确保用户数据安全，即使没有网络连接，应用程序也会运行。\nCore ML最大的有点就是使用起来非常简单，开发人员只需要几行代码就可以集成完整的机器学习模型。自Core ML发布以来，已经有大量的移动应用程序使用了。但是这里要说的是，Core ML并不是万能的，要使用它做什么是有限制的，Core ML智能帮助开发者将训练好的机器学习模型集成到应用程序中，也就意味着在你的应用程序中只能用来进行预测推理，是不可能进行模型的训练学习的。\n虽然如此，Core ML也是被证明对开发人员来说，非常有意义的。Core ML 2.0的发布，更是更进了一步，Apple表示Core ML 2.0的速度快了30%，这要归功于批量处理预测机制，而且它可以将模型的大小缩小到75%。\n\nCreate ML\nApple还在今年的WWDC上还发布了Create ML套件。 Create ML允许开发人员使用Swift和MacOS Playgrounds在Xcode中训练机器学习模型。并且号称没有ML经验的开发人员可以培训模型，而不必依赖其他开发人员。\n\n通过形成一个完整的工具包，Create ML增强了Core ML的实用性。目前，Create ML支持三种数据类型：图像，文本和表格数据。有许多训练和测试算法，如随机森林分类器和支持向量机。创建ML还减少了训练的ML模型的大小，并提供了使用Create ML UI训练模型的方法。\n\nML Kit\nFirebase在Google I&#x2F;O 2018大会上发布了ML Kit框架。ML Kit使开发人员能够以两种方式在移动应用中使用机器学习：开发人员既可以通过API在云中运行模型推理，也可以在设备上严格运行，就像使用Core ML一样。\nML Kit提供六种基本的API，可供开发人员使用，已提供的模型有：图像标注、文本识别（OCR）、地标检测、人脸检测、条形码扫描和智能回复。如果这些API不包括您的用例，那么您还可以上传TensorFlow Lite模型，ML Kit负责托管并为您的应用提供模型。\n\n与云版本相比，ML Kit的设备版本提供的精度较低，但同时它为用户数据提供了更高的安全性。 ML Kit提供的基本API涵盖了移动平台上机器学习的所有常规用例，并且使用自定义训练模型的选项使ML Kit成为移动平台的完整机器学习解决方案。开发人员也可以选择将机器学习模型与应用程序分离，并在运行时为它们提供服务，从而减少应用安装规模的大小，确保模型始终保持最新。\n\n比较Core ML和ML Kit都使开发人员能够在他们的应用程序中利用机器学习的强大功能，从而最终使大众可以使用机器学习的功能。\n与Core ML相比，ML Kit具有一些优势。 ML Kit的主要优点是它支持iOS和Android，并且可以在两个平台上使用相同的API。 ML Kit有六个基本API，易于实现，不需要任何ML专业知识。如果您使用ML Kit提供的基本API，那么由于已经存在预训练模型，使用起来更加的方便。\nML Kit的另一个优点是它提供了设备上和基于云的API。 ML Kit中的设备上API可以快速工作，即使在没有互联网连接的情况下也能提供结果。基于云的API利用Google Cloud ML平台提供更高的准确性。 ML Kit的缺点是您可能需要根据使用情况将Firebase计划升级为付费计划。\n如果您只对iOS开发感兴趣，那么与Create ML配对的Core ML可能会更有用。 Apple的工具允许您使用更少的代码行在您的应用程序中训练和实现ML模型。使用Create ML的训练模型比使用TensorFlow更容易，但TensorFlow能够提供更高级的训练算法。\nCore ML和ML Kit都是很棒的工具，但每个都有局限性。了解您的确切用例以及您将支持的平台可以帮助您确定哪个选项最佳。\n参考资料\nCore ML官方文档\nML Kit官方文档\n\n","slug":"2018-08-28-coreml-vs-mlkit","date":"2023-05-13T11:29:06.791Z","categories_index":"机器学习","tags_index":"机器学习"},{"id":"103385dd62332f9ae264b41726da9a1d","title":"金融领域的机器学习：为什么、是什么、怎么做","content":"现如今，机器学习的发展可谓如火如荼，尤其是在金融领域，机器学习似乎具有了某种魔法，应用可谓非常广泛。尽管如此，机器学习项目的成功更多地取决于构建高效的基础架构，收集合适的数据以及应用正确的算法几个方面。\n可以看到的是，机器学习正在金融服务行业取得重大的进展。那么为什么金融类企业应该关心机器学习乃至深度学习，以及可以通过AI和机器学习实现哪些细分领域的解决方案和如何应用这项技术。\n定义我们可以将机器学习定义为数据科学的一个子集，它使用统计模型来绘制具有一定洞察力的模式并进行预测推理。下图解释了人工智能、数据科学和机器学习之间的相互关系。为了简单起见，这篇文章中仅关注机器学习部分。\n机器学习解决方案的奇妙之处在于，它们可以从经验中学习而无明确的编码指向，简而言之，你只需要选择合适的模型并将数据提供给它们，然后，模型会自动调整其参数以改善模型结果。\n数据科学家使用现有的数据集训练机器学习模型，然后将训练有素的模型应用于现实应用中。模型会在后台进程运行，并根据其训练的方式自动提供结果。数据科学家可以根据需要重新训练模型，以保证模型的最新和有效。例如Mercanto会每天重新训练机器学习模型。\n通常情况下，你提供的数据越多，机器学习模型的结果就越准确。巧合的是，庞大的数据集在金融服务行业非常普遍，例如交易数据、客户数据、账单数据、资金流水数据等有数PB的数据量，而这恰恰非常适合机器学习。\n伴随着技术的发展和一些优质算法的开源，很难想象没有机器学习的金融服务的未来会是怎样的。\n也就是说，大多数的金融服务企业仍然没有准备好从这项技术中提取真正的价值，可能的原因如下：\n\n企业往往对机器学习及其组织的价值抱有完全不切实际的期望。\n人工智能和机器学习研究和开发成本很高。\n数据科学家&#x2F;机器学习工程师的短缺是另一个主要问题。下图显示了人工智能和机器学习技能需求的爆炸性增长：\n在更新数据基础架构方面，金融老牌企业不够灵活和积极。\n\n\n我们将在本文稍后讨论如何克服这些问题。首先，让我们看看为什么金融服务公司不能忽视机器学习。\n金融领域，为什么要考虑机器学习？尽管面临各种挑战，但许多金融公司已经利用了这项技术。下图显示金融服务的高管非常重视机器学习，并且出于以下原因：\n\n\n由于过程自动化，降低了运营成本。\n通过提高生产力和增强用户体验，增加收入。\n更好地遵守和加强安全性。\n\n有各种各样的开源机器学习算法和工具，可以很好地适应财务数据。此外，成熟的金融服务公司拥有大量资金，他们可以负担得起在最先进的计算硬件上的花费。\n金融领域的机器学习用例是什么？让我们来看看金融领域一些有前景的机器学习应用程序。\n\n过程自动化过程自动化是机器学习在金融领域最常见的应用之一。该技术可以替代手动工作，自动执行重复性任务并提高生产率。\n因此，机器学习使公司能够优化成本，改善客户体验并扩展服务。以下是金融机器学习的自动化用例：\n\n会话机器人\n呼叫中心自动化\n文书工作自动化\n员工培训的游戏化等等。\n\n以下是银行业务流程自动化的一些示例：\nJPMorgan Chase推出了一个合约智能（COiN）平台，该平台利用自然语言处理技术，这是一种机器学习技术。该解决方案处理法律文件并从中提取重要数据。对12,000份年度商业信贷协议进行人工审查通常需要约360,000个工时。然而，机器学习允许在短短几个小时内审查相同数量的合同。\nBNY Mello 将流程自动化集成到他们的银行生态系统中。这项创新每年可节省30万美元，并带来了广泛的运营改进。\nWells Fargo 通过Facebook Messenger平台使用AI驱动的聊天机器人与用户进行通信，并提供密码和帐户的帮助。\nPrivatbank 是一家乌克兰银行，通过其移动和网络平台实施聊天机器人助理。 Chatbots加快了一般客户查询的解决速度，并允许减少人工助理的数量。\n安全性随着交易，用户和第三方集成的数量不断增加，财务中的安全威胁也在不断增加。机器学习算法非常适合检测欺诈行为。\n例如，银行可以使用该技术实时监控每个账户的数千个交易参数。该算法检查持卡人采取的每个动作，并评估尝试的活动是否是该特定用户的特征。这种模型具有高精度的欺诈行为。\n如果系统识别可疑帐户行为，则可以请求用户提供额外的标识以验证交易。如果至少有95％的可能性是欺诈行为，甚至可以完全阻止交易。机器学习算法只需几秒钟来评估交易。速度有助于实时防止欺诈，而不仅仅是在犯罪发生后发现它们。\n财务监控 是金融机器学习的另一个安全用例。数据科学家可以训练系统检测大量小额支付，并将这种洗钱技术标记为smurfing。\n机器学习算法也可以显著增强网络安全性。数据科学家训练系统发现和隔离网络威胁，因为机器学习在分析数千个参数和实时时是首屈一指的。这项技术有可能在最近的将来为最先进的网络安全网络提供支持。\nAdyen，Payoneer，Paypal，Stripe和Skrill是一些值得注意的金融科技公司，他们在安全机器学习方面投入巨资。\n\n承保和信用评分机器学习算法完全适合金融和保险中常见的承保任务。 \n数据科学家在数千个客户档案中训练模型，为每个客户提供数百个数据条目。然后，训练有素的系统可以在现实环境中执行相同的承保和信用评分任务。这种评分引擎可以帮助人员更快，更准确地工作。\n银行和保险公司拥有大量历史消费者数据，因此他们可以使用这些条目来培训机器学习模型。或者，他们可以利用大型电信或公用事业公司生成的数据集。 \n例如，BBVA Bancomer正与另一个信用评分平台Destacame合作。该银行旨在为拉丁美洲信用记录薄的客户增加信贷准入。 Destacame通过开放API访问公用事业公司的账单支付信息。使用账单支付行为，Destacame为客户生成信用评分并将结果发送给银行。\n算法交易在算法交易中，机器学习有助于做出更好的交易决策。数学模型实时监控新闻和交易结果，并检测可能迫使股价上涨或下跌的模式。然后，它可以根据其预测主动出售，持有或购买股票。 \n机器学习算法可以同时分析数千个数据源，这是人类交易者无法实现的。 \n机器学习算法可以帮助人类交易者在市场平均水平上占据一席之地。而且，鉴于大量的交易操作，这种小优势通常会转化为巨额利润。\n机器人顾问机器人顾问现在在金融领域司空见惯。目前，在咨询领域中有两种主要的机器学习应用：\n投资组合管理 是一种在线财富管理服务，它使用算法和统计数据来分配，管理和优化客户的资产。用户输入他们目前的金融资产和目标，例如，在50岁时节省一百万美元。机器人顾问然后根据风险偏好和期望目标在投资机会中分配当前资产。 \n金融产品推荐 许多在线保险服务使用机器人顾问向特定用户推荐个性化保险计划。由于费用较低，客户选择机器人顾问而不是个人理财顾问，以及个性化和校准的推荐。\n\n金融领域如何使用机器学习？尽管人工智能和机器学习具有所有优势，但即使是拥有雄厚财力的公司也很难从这项技术中获取真正的价值。金融服务公司希望利用机器学习的独特机会，但实际上，他们对数据科学如何运作以及如何使用它有一个模糊的概念。 他们一次又遇到类似的挑战，例如缺乏业务KPI。反过来，这会导致不切实际的估计并导致预算耗尽。拥有合适的软件基础设施是不够的（尽管这将是一个良好的开端）。它需要一个清晰的愿景，扎实的技术人才，以及提供有价值的机器学习开发项目的决心。 \n一旦您充分了解此技术将如何帮助实现业务目标，请继续进行构思验证。这是数据科学家的任务。他们调查这个想法，帮助您制定可行的KPI并做出切合实际的估算。 请注意，此时您需要收集所有数据。否则，您需要数据工程师来收集和清理这些数据。 根据具体的使用案例和业务条件，金融公司可以采用不同的途径来采用机器学习。我们来看看吧。\n放弃机器学习，转而专注于大数据工程通常，金融公司开始他们的机器学习项目只是为了意识到他们只需要适当的数据工程。 N-iX的高级数据科学家Max Nechepurenko评论道：\n\n\n\n\n\n\n\n\n\n在开发[数据科学]解决方案时，我建议使用Occam的剃刀原理，这意味着不会过度复杂。大多数以机器学习为目标的公司实际上需要关注可靠的数据工程，将统计数据应用于聚合数据以及对数据进行可视化。\n仅仅将统计模型应用于处理过的和结构良好的数据就足以让银行隔离其运营中的各种瓶颈和低效率。\n这种瓶颈有哪些例子？这可能是特定分支的队列，可以消除的重复性任务，低效的人力资源活动，移动银行应用程序的缺陷等等。 \n更重要的是，任何数据科学项目中最重要的部分都归结为构建一个协调的平台生态系统，从数百个来源（如CRM，报告软件，电子表格等）收集孤立的数据。 \n在应用任何算法之前，您需要对数据进行适当的结构化和清理。只有这样，您才能进一步将这些数据转化为洞察力。事实上，ETL（提取，转换和加载）和进一步清理数据占机器学习项目时间的80％左右。\n\n使用第三方机器学习解决方案即使您的公司决定在即将开展的项目中使用机器学习，您也不一定需要开发新的算法和模型。 \n大多数机器学习项目都处理已经解决的问题。谷歌，微软，亚马逊和IBM等科技巨头将机器学习软件作为一种服务出售。 \n这些开箱即用的解决方案已经过培训，可以解决各种业务任务。如果您的项目涉及相同的用例，您是否认为您的团队可以通过庞大的研发中心超越这些技术巨头的算法？ 一个很好的例子是Google的多种即插即用推荐解决方案。该软件适用于各种域，检查它们是否适合您的业务案例是合乎逻辑的。 \n机器学习工程师可以实施专注于您的特定数据和业务领域的系统。专家需要从不同来源提取数据，将其转换为适合此特定系统，接收结果并可视化结果。 \n权衡取舍是缺乏对第三方系统的控制和有限的解决方案灵活性。此外，机器学习算法并不适合每个用例。 N-iX高级数据科学家Ihar Rubanau评论道：\n\n\n\n\n\n\n\n\n\n尚不存在通用机器学习算法。数据科学家需要在将算法应用于不同领域的不同业务案例之前对其进行调整和微调。\n因此，如果Google的现有解决方案解决了您特定域中的特定任务，您应该使用它。如果没有，请致力于定制开发和集成。\n创新与整合从头开始开发机器学习解决方案是风险最大，成本最高且耗时的选择之一。尽管如此，这可能是将ML技术应用于某些商业案例的唯一方法。 \n机器学习研究和开发针对特定利基市场的独特需求，并要求进行深入调查。如果没有为解决这些特定问题而开发的现成解决方案，则第三方机器学习软件可能会产生不准确的结果。\n\n不过，您可能需要严重依赖Google等开源机器学习库。当前的机器学习项目主要是将现有的最先进的库应用于特定的域和用例。\n在N-iX，我们确定了机器学习中成功的企业研发项目的七个共同特征。他们是：\n\n一个明确的目标。在收集数据之前，您至少需要对通过AI和机器学习实现的结果有一些大致的了解。在项目的早期阶段，数据科学家将帮助您将这一想法转化为实际的KPI。 \n机器学习解决方案的强大架构设计。您需要经验丰富的软件架构师来执行此任务。 \n适当的大数据工程生态系统是必不可少的（基于Apache Hadoop或Spark）。它允许从金融服务公司的众多孤立数据源中收集，集成，存储和处理大量数据。大数据架构师和大数据工程师负责构建生态系统。 \n在新创建的生态系统上运行ETL过程（提取，转换和加载）。大数据架构师或机器学习工程师执行此任务。 \n最后的数据准备。除数据转换和技术清理外，数据科学家可能还需要进一步优化数据，使其适用于特定的业务案例。 \n应用适当的算法，基于这些算法创建模型，微调模型以及使用新数据重新训练模型。数据科学家和机器学习工程师执行这些任务。 \n清晰可见的洞察力。商业智能专家对此负责。此外，您可能需要前端开发人员创建具有易于使用的UI的仪表板。\n\n小型项目可能需要更少的工作量和更小的团队。例如，一些研发项目涉及小型数据集，因此他们可能不需要复杂的大数据工程。在其他情况下，根本不需要复杂的仪表板或任何数据可视化。\n关键要点\n金融老牌企业最常使用机器学习来实现流程自动化和安全性。 \n在收集数据之前，您需要清楚地了解数据科学所期望的结果。\n在项目开始之前，需要设置可行的KPI并做出切合实际的估算。 \n许多金融服务公司需要数据工程，统计和数据可视化，而不是数据科学和机器学习。 \n训练数据集越大越清洁，机器学习解决方案产生的结果就越准确。 您可以根据需要随时重新训练模型，而无需停止机器学习算法。 \n没有通用的机器学习解决方案适用于不同的业务案例。 \n具有机器学习功能的财务软件的开发成本很高。 \n像谷歌这样的科技巨头创造了机器学习解决方案。如果您的项目涉及此类用例，那么您不能指望其优于Google，Amazon或IBM的算法。\n\n\n\n\n\n\n\n\n\n\n原文地址：https://www.n-ix.com/machine-learning-in-finance-why-what-how/\n","slug":"2018-09-18-ML_in_finance","date":"2023-05-13T11:29:06.791Z","categories_index":"机器学习","tags_index":"机器学习"},{"id":"2ddef7366c507d2b0030ac2779f34302","title":"机器学习基础介绍","content":"机器学习是一门从数据中提取知识的技术。 它是统计学、人工智能和计算机科学的交叉研究领域，被常被称为预测分析、统计学习。机器学习方法的应用近年来在日常生活中无处不在。从自动推荐看哪部电影、点什么食物或买什么东西，到个性化的在线收音机、智能化在线教育，再到从照片中找到你的朋友等等需要现代网站和设备的核心都是机器学习算法。当你查看例如Facebook、Amazon、Netflix、Weibo、Twitter等复杂网站时，很可能网站的每个部分都包含了多个机器学习模型。\n除了商业应用之外，机器学习已经对数据驱动的研究方式产生了巨大的影响。机器学习相关的技术、工具已经应用于各种科学问题，例如理解恒星、发现遥远的行星、发现新的粒子、分析DNA序列以及提供个性化的癌症治疗等。\n但是，为了从机器学习中获益，你的应用程序可能并不需要大规模。在本部分，将解释为什么机器学习变的如此的流行，并讨论使用机器学习可以解决哪些问题。然后，将展示如何构建你的第一个机器学习模型等。\n为什么是机器学习？较早期的“智能”应用程序，许多的系统使用“if”和“else”硬编码规则来处理数据或者根据用户的输入进行调整。想象一个垃圾邮件过滤器，其工作是适当的移动电子邮件到垃圾邮件文件夹。你可以构造一个垃圾邮件词库黑名单，并返回垃圾邮件标记 1。这是一个使用专家设计的规则来实现“智能”应用程序的例子。手工创建决策规则对于一些应用程序是可行的，特别是那些人类对建模过程有很好理解的应用程序，然而，使用手工编码的规则进行决策有两点主要缺点：\n\n做出决策所需的规则逻辑是针对特定的单个域和任务的，一些业务改变，整个系统可能都需要重写；\n设计规则需要深刻理解人类专家应该如何做出决定。\n\n\n\n\n这种编码方法失败的一个典型例子是检测图像中的人脸。如今，每个智能手机都能在图像中检测出人脸，然而，这项技术直到2001年，面部检测才有了进展。这项技术之前面临的主要问题是，像素被计算机“感知”的方式与人类感知面部的方式非常不同，这种表现上的差异使得人类基本不可能想出一套好的规则来描述数字图像中人脸的构成。\n然而，使用机器学习，仅仅呈现具有大量面部图像的程序就足以让算法确定识别面部需要什么特征。\n机器学习能解决的问题最成功的机器学习算法是那些通过从已知例子中归纳出来使决策过程自动化的算法。在称为监督学习的设定中，用户向算法提供一对输入和期望的输出，算法会自动找到一种方法，在给定输入的情况下产生期望的输出。特别地，这种算法能够在没有人帮助的情况下为它以前从未遇见的输入创建输出。例如上述垃圾邮件分类的示例，使用机器学习，用户向算法提供大量历史电子邮件（输入），以及关于这些电子邮件中是否有垃圾邮件的信息（期望的输出），算法变回找到一种分别是否为垃圾邮件的方法，当给定一个新的电子邮件，该算法将产生一个关于新邮件是否是垃圾邮件的预测输出。\n从输入&#x2F;输出对中学习的机器学习算法被称为监督学习算法，因为“教师”以他们学习的每个示例的期望输出向算法提供监督。虽然创建输入和输出的数据集常常是费时费力的手工过程，但是对于受监督的学习算法来说，却是易于理解的，并且它们的性能易于测量。如果你的应用程序可以被描述为受监督的学习问题，并且你能够创建包含所需结果的数据集，则机器学习可能能够解决你的问题。\n有监督的机器学习任务示例包括但不限于如下几种：\n\n从信封上手写的数字中识别邮政编码\n\n这里的输入是手写数字的扫描，所需的输出时邮政编码中的实际数字。要创建用于构建机器学习模型的数据集，需要收集需要的信封。然后可以自己读取邮政编码，并将数字存储为你想要的结果。\n\n基于医学图像判断肿瘤是否良性\n\n这的输入是图像，输出时肿瘤是否良性。要创建用于构建模型的数据集，需要一个医学图像数据库，还需要专家的意见，所以需要查看所有的图像，并决定哪些肿瘤是良性的，哪些不是，甚至可能需要做出超出图像内容的附加诊断，以确定图像中的肿瘤是否是癌性的。\n\n信用卡交易中欺诈行为的侦测\n\n这里的输入是信用卡交易的记录，输出是该交易是否可能欺诈。假设你是分发信用卡的金融机构，收集数据意味着需要存储所有的交易事务，并且如果出现欺诈的事务，需要进行记录。\n以上示例需要注意的一件有趣的事情是，尽管输入和输出看起来都非常简单，易于理解，但是这三个任务的数据收集过程却大不相同。虽然阅读信封是费力的，但是却是容易和廉价的；另一方面，获得医学成像和诊断不仅需要昂贵的机器，而且需要稀有和昂贵的专家知识，更不用说伦理问题和隐私问题了；在检测信用卡欺诈的例子中，数据收集简单的多，你的客户会提供给你想要的输出，因为他们会报告欺诈行为，你必须要做的是获得欺诈性和非欺诈性的输入&#x2F;输出对。\n无监督算法 是另一种机器学习算法。在无监督学习中，只有输入数据是已知的，并且没有已知的输出数据被赋予算法。虽然这些方法有很多成功的应用，但他们通常难以理解和评估。\n无监督学习的例子包括：\n\n在一组博客文章中识别主题\n\n如果你用大量的文本数据集合，你可能需要总结它们并找到其中的流行主题，你可能实现并不知道这些主题是什么，或者可能有多少主题，因此，没有已知的输出。\n\n将客户细分为具有相似偏好的群体\n\n给定一组客户记录，你可能希望识别哪些客户是相似的，以及是否具有相似的偏好。例如一个购物网站，客户可能是“父母”、“书虫”、“玩家”等，因为你事先不知道这些群体可能是什么，甚至不知道有多少群体，所以你没有已知的输出。\n\n检测网站的异常访问模式\n\n为了识别滥用和错误，找到与规范不同的访问模式通常对于网站来说是有益的。每个异常模式可能是非常不同的，并且你可能没有任何异常行为的记录实例，因为在这个例子中，你只能观察流量，并且你不知道什么构成了正常和异常的行为，所以这是一个无监督的问题。\n对于有监督和无监督的学习任务，计算机能够理解的输入数据的表示是至关重要的，通常把数据看做表格是有帮助的。你想要推理的每个数据点（每个电子邮件、每个客户、每个事务）都是一行，描述该数据点（例如，客户的年龄或者事务的数量或者位置）的每个属性都是一列，你可以根据用户的年龄、性别、创建账号时间以及从网上购买的频率来描述用户，你可以通过每个像素的灰度值来描述肿瘤的图像，或者可以使用肿瘤的大小、形状和颜色等。\n这里的每个实体或者行都称之为机器学习中的示例或数据点，而列（描述这些实体的属性）称之为特征。\n了解你的任务，认识你的数据在机器学习过程中最重要的部分是理解你正在处理的数据以及这些数据与你想要解决的任务之间的关系。随机选择一个算法并把数据丢给算法通常是无效的，在开始构建模型之前，必须了解数据集中发生的事情。每个算法在什么样的数据和什么样的问题设置下的表现是不同的，当你正在构建一个机器学习解决方案时，首先你必须回答一下几个问题或者至少要记住一下几个问题：\n\n我想要解决什么样的问题？所收集的数据能回答这个问题吗？\n将我的问题作为机器学习问题的最佳方式是什么？\n我收集了足够的数据来表示我想解决的问题吗？\n我提取了数据的哪些特征，这些特征会是正确的预测成为可能吗？\n我如何衡量机器学习在我的应用程序中是成功的？\n机器学习解决方案将如何与我的研究或商业产品的其他部分交互？\n\n在较大的场景中，机器学习中的算法和方法只是解决特定问题的的一小部分，并且始终要牢记全局。很多人花费大量的时间构建复杂的机器学习解决方案，结果却发现他们没有解决正确的问题。\n当深入研究机器学习的技术时，很容易忽略最终的目标，虽然我们在这里不会详述这些问题，但是仍然鼓励在开始构建机器学习模型时，记住可能正在显示或者隐式做出的所有假设。\n为什么选择Python？Python语言已经成为了一种通用语言，能够处理很多应用的科学数据。它结合了通用编程语言的优势和易于在特定领域使用的特定脚本语言，如MATLAB或R。Python具有用于数据加载、可视化、统计、自然语言处理、图像处理等库，这个庞大的工具库为数据科学提供了大量的通用和专用的功能，使用python的主要优点之一是能够直接与代码进行交互，使用终端或者其他工具，例如Jupyter Notebook。机器学习和数据分析都是不断的迭代过程，也被称为数据驱动分析，因此对于这样的过程来说，有必要有一些快速迭代和易于交互的工具。\n作为一种通用编程语言，Python还允许创建复杂的用户图形界面（GUI）和Web服务，以及集成到现有的系统中等。\nscikit-learnscikit-learn 是一个开放的源码项目，这意味着它可以自由使用和开发，任何人都可以轻松获得其源代码，以及了解内部的核心。scikit-learn 项目在不断地被开发和改进，并且它有一个非常活跃的用户社区，包含许多先进的机器学习算法，以及关于每个算法的综合文档。scikit-learn 是一个非常流行的工具，也是最著名的机器学习Python库，被广泛应用于工业和学术界，网路上有大量的教程和代码片段，scikit-learn 可以与其他Python工具一起工作。\n在阅读本书时，建议你浏览scikit-learn 的用户指南和API文档，了解关于每个算法的更多细节和更多选项。在线文档非常全面，本书将为你提供机器学习中的所有先决条件，以详细了解它。\n安装 scikit-learnscikit-learn 依赖两个其他的Python库， NumPy 和 SciPy。为了绘图和交互开发，你还应该安装 matplotlib、IPython 和 Jupyter Notebook。这里建议你使用以下某一种Python环境管理工具：\nAnaconda\nPython能够用于大规模数据处理、预测分析和科学计算，Anaconda 可与 NumPy、SciPy、matplotlib、Pandas、IPython 、Jupyter Notebook、scikit-learn一起工作，可以在Mac OS、Windows和Linux上安装，它是一个非常方便的集成解决方案，是我们没有进行科学安装Python经验的人的建议解决方案。\nEnthought Canopy\n另一种用于科学计算的集成Python管理工具，可与NumPy、SciPy、matplotlib、Pandas、IPython 一起工作，但是其免费版本不能与scikit-learn一起工作，如果需要使用scikit-learn则需要付费或者申请学术许可证，便可获得其免费访问付费订阅版本的Enthought Canopy，Enthought Canopy目前仅支持Python2.7.x，能够工作在Mac OS、Windows、Linux上。\nPython(x,y)\n一个免费的Python管理工具，用于科学计算，特别是Windows上。Python（X，Y） 可与  NumPy、SciPy、matplotlib、Pandas、IPython 、Jupyter Notebook、scikit-learn一起工作。\n如果你已经安装好了Python，也可以使用pip安装所有需要的包：\npip install numpy scipy matplotlib ipython scikit-learn pandas\n\n基本库和工具了解了什么是 scikit-learn 以及如何使用它很重要，但是还有一些其他的类库可以提高使用体验。scikit-learn 是建立在 NumPy 和 SciPy 之上的，除了NumPy 和 SciPy ，我们还将使用 Pandas、matplotlib 以及 Jupyter Notebook，Jupyter Notebook 是一个基于浏览器的交互式编程环境，简言之，以下这些工具是应该了解的内容，以便能够在scikit-learn 的使用中获得更多的益处。\nJupyter NotebookJupyter Notebook 是一个基于浏览器的交互式编程环境。它是进行探索性数据分析的一个很好的工具，被数据科学家广泛的使用。虽然 Jupyter Notebook 支持需要的编程语言，但是我们只需要Python支持即可。Jupyter Notebook 使得合并代码、文本和图像变的很容易，而且这本书实际上是在 Jupyter Notebook 中编写的。\nNumPyNumPy 是Python中科学计算的基本包之一，它包含多维数组的功能、高级数学函数，如线性代数和傅里叶变换，以及随机数发生器等等。\n在 scikit-learn 中，NumPy 数组是基本的额数据结构，scikit-learn 以 NumPy 数组的形式获取数据，你所使用的任何数据都必须转换为 NumPy 数组。NumPy 的核心功能是 ndarray 类，一个多维数组结构，数组中的所有元素必须是相同类型的，一个NumPy数组看起来是如下样子的：\nimport numpy as np\n\nx &#x3D; np.array([[1, 2, 3], [4, 5, 6]])\nprint(&quot;x:\\n&#123;&#125;&quot;.format(x))\n\nx:\n[[1 2 3]\n [4 5 6]]\n\n在本书中，将多次使用NumPy，我们将把NumPy 的 ndarray 类的对象称为 “NumPy 数组” 或仅仅是 “数组”。\nSciPySciPy 是Python中的科学计算功能的集合，它提供了高级线性代数程序、数学函数优化、信号处理、特殊数学函数和统计分析功能等，scikit-learn 从 SciPy 的功能集合中提取用于实现其算法的功能。SciPy 对于我们来说最重要的部分是 scipy.sparse，它提供了稀疏矩阵的运算，这是scikit-learn中用于数据的另一种表示，每当我们想要存储一个包含零点的二维数组时，便于使用稀疏矩阵，如下：\nfrom scipy import sparse\n\n# 创建一个具有对角线的2D NumPy数组，并且在其他任何地方创建零点\neye &#x3D; np.eye(4)\nprint(&quot;NumPy array: \\n&#123;&#125;&quot;.format(eye))\n\nNumPy array: \n[[1. 0. 0. 0.]\n [0. 1. 0. 0.]\n [0. 0. 1. 0.]\n [0. 0. 0. 1.]]\n\n# 将NUMPY数组转换成CSR格式中的一个SISPY稀疏矩阵。\n# 仅存储非零项\n\nsparse_matrix &#x3D; sparse.csr_matrix(eye)\nprint(&quot;\\nSciPy sparse CSR matrix:\\n&#123;&#125;&quot;.format(sparse_matrix))\n\nSciPy sparse CSR matrix:\n  (0, 0)\t1.0\n  (1, 1)\t1.0\n  (2, 2)\t1.0\n  (3, 3)\t1.0\n\n通常不可能创建稀疏数据的密集表示（因为它们不适合于内存），所以我们需要直接创建稀疏表示。下面是使用COO格式创建与以前一样的稀疏矩阵的方法：\ndata &#x3D; np.ones(4)\nprint(&quot;data: \\n&#123;&#125;&quot;.format(data))\nrow_indices &#x3D; np.arange(4)\nprint(&quot;row_indices: \\n&#123;&#125;&quot;.format(row_indices))\ncol_indices &#x3D; np.arange(4)\nprint(&quot;col_indices: \\n&#123;&#125;&quot;.format(col_indices))\neye_coo &#x3D; sparse.coo_matrix((data, (row_indices, col_indices)))\nprint(&quot;eye_coo: \\n&#123;&#125;&quot;.format(eye_coo))\n\ndata: \n[1. 1. 1. 1.]\nrow_indices: \n[0 1 2 3]\ncol_indices: \n[0 1 2 3]\neye_coo: \n  (0, 0)\t1.0\n  (1, 1)\t1.0\n  (2, 2)\t1.0\n  (3, 3)\t1.0\n\nSciPy 稀疏矩阵的更多细节可以在SciPy讲义中找到。\nmatplotlibmatplotlib 是Python的主要科学绘图库，它提供了用于制作高质量可视化的功能，如线形图、直方图、散点图等。可视化数据和分析的不同在于可视化可以给你提供更加直观的数据理解。我们使用matplotlib 进行所有的可视化，在 Jupyter Notebook 中工作时，可以使用 %matplotlib notebook 和 %matplotlib inline 在浏览器中直接使用可视化。\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\n# Generate a sequence of numbers from -10 to 10 with 100 steps in between\nx &#x3D; np.linspace(-10, 10, 100)\n# Create a second array using sine\ny &#x3D; np.sin(x)\n# The plot function makes a line chart of one array against another\nplt.plot(x, y, marker &#x3D; &#39;x&#39;)\n\n\n\n\n[&lt;matplotlib.lines.Line2D at 0x111be57b8&gt;]\n\n\npandaspandas 是一个用于数据处理和分析的Python库，它围绕了一个叫做DataFrame的数据结构进行构建。简单的说，pandas 数据文件是一个表，类似于Excel电子表格，pandas 提供了大量的方法来修改和操作这个表，特别是，pandas 允许类似SQL的查询和连接。与 NumPy 不同，要求数组中的所有条目都具有相同的类型，pandas 允许每个列具有单独的类型（例如整数、日期、浮点数和字符串）。pandas 提供的另一个有价值的工具是它能够从各种文件格式和数据库中获取信息，如SQL、Excel文件和逗号分隔值（CSV）文件等。详细介绍pandas 的功能不再本书的范围之内，然而Wes McKinney (O’Reilly, 2012)的Python数据分析提供了一个很好的指南。下面是使用字典数据创建数据文件的一个例子：\nimport pandas as pd\n\n# create a simple dataset of people\ndata &#x3D; &#123;&#39;Name&#39;:[&#39;John&#39;, &#39;Anna&#39;, &#39;Peter&#39;, &#39;Linda&#39;],\n       &#39;Location&#39;:[&#39;New York&#39;, &#39;Paris&#39;, &#39;Berlin&#39;, &#39;London&#39;],\n       &#39;Age&#39;:[24, 14, 53, 33]&#125;\n\ndata_pandas &#x3D; pd.DataFrame(data)\n# IPython.display allows &quot;pretty printing&quot; of dataframes \n# in the Jupyter notebook\ndisplay(data_pandas)\n\n\n\n\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n\n\n\n  \n    \n      \n      Name\n      Location\n      Age\n    \n  \n  \n    \n      0\n      John\n      New York\n      24\n    \n    \n      1\n      Anna\n      Paris\n      14\n    \n    \n      2\n      Peter\n      Berlin\n      53\n    \n    \n      3\n      Linda\n      London\n      33\n    \n  \n\n\n\n\n查询此表有几种可能的方式。例如：\n# Select all rows that have an age column greater than 30\ndisplay(data_pandas[data_pandas.Age &gt; 30])\n# Select all rows that have an age column equal 53\ndisplay(data_pandas[data_pandas[&#39;Age&#39;] &#x3D;&#x3D; 53])\n\n\n\n\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n\n\n\n  \n    \n      \n      Name\n      Location\n      Age\n    \n  \n  \n    \n      2\n      Peter\n      Berlin\n      53\n    \n    \n      3\n      Linda\n      London\n      33\n    \n  \n\n\n\n\n\n\n\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n\n\n\n  \n    \n      \n      Name\n      Location\n      Age\n    \n  \n  \n    \n      2\n      Peter\n      Berlin\n      53\n    \n  \n\n\n\n\n本书所用类库的版本本书使用了如下一些类库，各个类库的版本信息如下：\nimport sys\nprint(&#39;Python version: &#123;&#125;&#39;.format(sys.version))\n\nimport pandas as pd\nprint(&#39;pandas version: &#123;&#125;&#39;.format(pd.__version__))\n\nimport matplotlib\nprint(&#39;matplotlib version: &#123;&#125;&#39;.format(matplotlib.__version__))\n\nimport numpy as np\nprint(&#39;numpy version: &#123;&#125;&#39;.format(np.__version__))\n\nimport scipy as sp\nprint(&#39;scipy version: &#123;&#125;&#39;.format(sp.__version__))\n\nimport IPython\nprint(&#39;IPython version: &#123;&#125;&#39;.format(IPython.__version__))\n\nimport sklearn\nprint(&#39;sklearn version: &#123;&#125;&#39;.format(sklearn.__version__))\n\nPython version: 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) \n[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\npandas version: 0.23.3\nmatplotlib version: 2.2.2\nnumpy version: 1.14.5\nscipy version: 1.1.0\nIPython version: 6.4.0\nsklearn version: 0.19.1\n\n虽然使用精确匹配的版本并不重要，但是需要注意的是尽量保持你的scikit-learn版本最新。\n既然我们已经设置好了开发环境，让我们深入研究及其学习的第一个应用吧。\n第一个机器学习应用：鸢尾花分类在本部分，我们将实现一个简单的机器学习应用以及构建机器学习模型。在这个过程中，我们将介绍一些核心的概念和术语等。\n假设一个植物爱好者有兴趣区分他所发现的一些鸢尾花的种类，他收集了一些与每个鸢尾花相关的测量数据：花瓣的长度和宽度、萼片的长度和宽度，均已厘米为单位。\n\n收集到的数据经过植物专家的鉴定属于刚毛鸢尾、云彩鸢尾或维珍鸢尾。对于这些测量，他可以确定每个鸢尾属属于哪种。\n我们的目标是建立一个机器学习模型，可以这些鸢尾花已知物种的测量数据，最终能够预测新的鸢尾花的物种。\n因为我们有测量了的鸢尾花所属的种类，这是一个有监督的学习问题。在这个问题中，我们要预测几种选择中的一个（具体所属的种类），这是一个分类问题的例子，可能的输出（不同种类的鸢尾）被称为类，由于数据集中每个鸢尾都可能属于三个种类中的一个，因此这是一个三分类的问题。\n单个数据点的期望输出时这种花的种类，对于一个特定的数据点，它所属的五种种类被称为它的标签。\n遇见数据在这个例子中我们将使用iris数据集，机器学习和数据统计中经典的数据集，该数据集包含在了scikit-learn中，我们可以直接使用 load_iris 函数加载它：\nfrom sklearn.datasets import load_iris\niris_dataset &#x3D; load_iris()\n\n由函数 load_iris 加载的数据集返回的iris对象是一个堆对象，比较类似于字典。它包含的键和值如下：\nprint(&quot;Keys of iris_dataset: \\n&#123;&#125;&quot;.format(iris_dataset.keys()))\n\nKeys of iris_dataset: \ndict_keys([&#39;data&#39;, &#39;target&#39;, &#39;target_names&#39;, &#39;DESCR&#39;, &#39;feature_names&#39;])\n\n其中 DESCR 字段是对数据集的简要描述，我们可以简要的查看一下其描述内容（这里仅仅查看部分内容，你可以查看全部内容）：\nprint(iris_dataset[&#39;DESCR&#39;][:470] + &#39;\\n...&#39;)\n\nIris Plants Database\n====================\n\nNotes\n-----\nData Set Characteristics:\n    :Number of Instances: 150 (50 in each of three classes)\n    :Number of Attributes: 4 numeric, predictive attributes and the class\n    :Attribute Information:\n        - sepal length in cm\n        - sepal width in cm\n        - petal length in cm\n        - petal width in cm\n        - class:\n                - Iris-Setosa\n                - Iris-Versicolour\n                - Iris-Virginic\n...\n\ntarget_names 的值是一个字符串数组，包含了我们想要预测的花的种类：\nprint(&quot;Target names: &#123;&#125;&quot;.format(iris_dataset[&#39;target_names&#39;]))\n\nTarget names: [&#39;setosa&#39; &#39;versicolor&#39; &#39;virginica&#39;]\n\nfeature_names 是一个字符串列表，给出了每个特征的描述：\nprint(&quot;Feature names: \\n&#123;&#125;&quot;.format(iris_dataset[&#39;feature_names&#39;]))\n\nFeature names: \n[&#39;sepal length (cm)&#39;, &#39;sepal width (cm)&#39;, &#39;petal length (cm)&#39;, &#39;petal width (cm)&#39;]\n\n数据集本身包含了目标和数据，数据包含了萼片长度、萼片宽度、花瓣长度、花瓣宽度的测量数字，保存在一个 NumPy 数组中：\nprint(&#39;Type of data: &#123;&#125;&#39;.format(type(iris_dataset[&#39;data&#39;])))\n\nType of data: &lt;class &#39;numpy.ndarray&#39;&gt;\n\n数据阵列中的行对应着花的种类，而列表示针对每个花采取的四个度量：\nprint(&#39;Shape of data: &#123;&#125;&#39;.format(iris_dataset[&#39;data&#39;].shape))\n\nShape of data: (150, 4)\n\n我们看到阵列包含150种不同花的测量，在机器学习中也被称为样本，他们的属性称为特征。数据阵列的形状是样本的数量乘以特征的数量，这是Scikit-learn中的一个约定，你的数据将始终假定为该形状。以下是前5个样本的特征值：\nprint(&#39;First five columns of data: \\n&#123;&#125;&#39;.format(iris_dataset[&#39;data&#39;][:5]))\n\nFirst five columns of data: \n[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]]\n\n从这些数据中，我们可以看出，所有前五朵花的花瓣宽度都是0.2厘米，而第一朵花的萼片最长，为5.1厘米。\n目标数据阵列中包含被测量的每一朵花所属的种类，也是一个NumPy数组：\nprint(&#39;Type of target: &#123;&#125;&#39;.format(type(iris_dataset[&#39;target&#39;])))\n\nType of target: &lt;class &#39;numpy.ndarray&#39;&gt;\n\n目标（target）是一个关于每一朵花所属种类的一维的数组：\nprint(&#39;Shape of target: &#123;&#125;&#39;.format(iris_dataset[&#39;target&#39;].shape))\n\nShape of target: (150,)\n\n该目标数据被编码为从0到2的整数：\nprint(&#39;Target:\\n&#123;&#125;&#39;.format(iris_dataset[&#39;target&#39;]))\n\nTarget:\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]\n\n该目标值与target_names值所对应：0表示setosa、1表示versicolor、2表示virginica。\n衡量成功：训练集与测试集我们希望建立一个机器学习模型，使用这个数据集，可以预测鸢尾花的种类。但是在将模型应用在新的预测之前，我们需要知道模型是否真的有效，也就是说，我们是否应该相信模型的预测。\n不好的是，我们不能直接使用我们的数据集来构建模型并评估模型，因为我们的模型总是可以简单的记住整个数据集，并且总是会正确的预测训练数据集中任何数据点的正确标签。这种“记忆”并不表明我们的模型能够很好的泛化（也就是说，模型是否也会在新数据上同样表现良好。）。\n为了评估模型的性能，我们展示了我们有标签的新数据（以前没有见过的数据），通常情况下会分裂我们收集的标记数据（在这里，就是150个花的测量）分为两个部分，一部分用于构建我们的机器学习模型，被称为训练数据或者训练集，其余的数据将用来评估模型的工作如何，被称为测试数据或测试集。\nscikit-learn 中包含一个函数，它可以将数据集拆分为训练集和测试集：train_test_split 函数。该函数会将数据集中的75%行作为训练集，并连同这些数据所对应的标签一起提取，剩下的25%的数据，连同剩下的标签，被声明为测试集。当然你也可以自定义训练集和测试集所占比例，但是25%的测试集比例是一个很好的经验法则。\n在scikit-learn 中，数据通常使用大写字母X表示，而标签测用小写字母y表示。这其实是受到标准公式 f(x) &#x3D; y 的启发，其中x是函数的输入，y是函数的输出，遵循数学中的更多约定，我们使用大写字母X，因为数据是二维数组（矩阵），小写字母y是因为目标是一维数组（向量）。\n让我们在数据上调用 train_test_split，并使用上述命名规则：\nfrom sklearn.model_selection import train_test_split\n\nX &#x3D; iris_dataset[&#39;data&#39;]\ny &#x3D; iris_dataset[&#39;target&#39;]\nX_train, X_test, y_train, y_test &#x3D; train_test_split(X, y, random_state&#x3D;0)\n\n在实际进行数据集拆分之前，train_test_split 函数内部会使用伪随机数发生器对数据进行洗牌操作。如果我们仅仅只是使用数据集中的后25%作为测试集，那么所有的数据将只具有标签2，因为数据点是按照标签来排序的。使用只包含三个类之一的测试集，并不能评估出我们的模型泛化能力，因此对数据进行洗牌操作，以确保测试数据集包含来自所有类的数据。\n为了确保如果多次运行相同的函数，我们将获得相同的输出，这里使用random_state参数为伪随机数发生器提供一个固定的种子，这会使得输出确定。\ntrain_test_split函数的输出是 X_train, X_test, y_train, y_test，均为NumPy数组，X_train包含数据集的75%行，X_test包含剩下的25%行：\nprint(&#39;X_train shape: &#123;&#125;&#39;.format(X_train.shape))\nprint(&quot;y_train shape: &#123;&#125;&quot;.format(y_train.shape))\n\nX_train shape: (112, 4)\ny_train shape: (112,)\n\nprint(&quot;X_test shape: &#123;&#125;&quot;.format(X_test.shape)) \nprint(&quot;y_test shape: &#123;&#125;&quot;.format(y_test.shape))\n\nX_test shape: (38, 4)\ny_test shape: (38,)\n\n第一件事：看看你的数据在建立机器学习模型之前通常的一个好的思路是检查数据，看看所面临的问题是否不使用机器学习可以解决，或者查看期望的输出信息是否可能不包含在数据中等。\n除此之外，检查数据是发现数据异常和数据某些特殊性等的一个很好的方法，也许在你的鸢尾花数据集中有一些数据是以英寸为单位而不是厘米为单位的。在现实世界中，数据的不一致和意外的测量都是非常普遍的。\n检查数据最好的方式之一就是可视化数据，其中一种可视化方法就是使用散点图。数据的散点图沿着x轴放置一个特征，另一个沿y轴放置一个特征，并为每个数据点画一个点，但是不好的是，计算机屏幕只有两个维度，这使得我们一次只能绘制两个或三个特征，如果要绘制超过三个特征的数据集是困难的。解决这个问题的一个方法是绘制一对图，它查看所有可能的特征对，如果你有一小部分特征，比如我们这里的四个，这是相当合理的。但是，您应该记住，配对图不会同时显示所有特性的交互，因此以这种方式可视化数据时，可能不会显示数据的一些有趣方面。\n下图是数据集中特征的对图，数据点根据鸢尾花所属的种类进行着色，为了创建该图，首先将NumPy数据转换为Pandas数据文件，Pandas有一个功能，创建配对图称为散射矩阵。该矩阵的对角线填充有每个特征的直方图：\nimport mglearn\nimport seaborn as sns\nsns.set()\n\n# create dataframe from data in X_train\n# label the columns using the strings in iris_dataset.feature_names\niris_dataframe &#x3D; pd.DataFrame(X_train, columns&#x3D;iris_dataset.feature_names)\n# create a scatter matrix from the dataframe, color by y_train \npd.plotting.scatter_matrix(iris_dataframe, c&#x3D;y_train, figsize&#x3D;(15, 15), marker&#x3D;&#39;o&#39;,\n                           hist_kwds&#x3D;&#123;&#39;bins&#39;: 20&#125;, s&#x3D;60, alpha&#x3D;.8, cmap&#x3D;mglearn.cm3)\n\n\n\n\narray([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x1c160d2550&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x1c160f8e80&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x1c16127940&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x1c16153400&gt;],\n       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x1c1617ae80&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x1c1617aeb8&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x1c161d5400&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x1c161fce80&gt;],\n       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x1c16229940&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x1c16258400&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x1c1627ee80&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x1c162ad940&gt;],\n       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x1c162dc400&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x1c16301e80&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x1c1632f940&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x1c16361400&gt;]],\n      dtype=object)\n\n\n对角线部分： 每个特征的直方图。体现每个特征的密度分布情况。\n非对角线部分： 两个变量之间分布的关联散点图。将任意两个变量进行配对，以其中一个为横坐标，另一个为纵坐标，将所有的数据点绘制在图上，用来衡量两个变量的关联度（Correlation）。\n从图中我们可以看到，通过萼片和花瓣的测量数据似乎可以很好的区分鸢尾花的种类，这意味着机器学习模型能够学会如何分类它们。\n为了能够更加直观的解释为什么通过该图可以确定机器学习模型能够分类它们，让我们通过创建一个散布矩阵中花瓣的长度（Petal Length）和花瓣宽度（Petal Width）的散点图来展开这一扩展。\ndf &#x3D; pd.DataFrame(iris_dataset.data, columns&#x3D;iris_dataset.feature_names) \ndf[&#39;Target&#39;] &#x3D; pd.DataFrame(iris_dataset.target) \n\n\nplt.clf()\nplt.figure(figsize &#x3D; (10, 6))\nnames &#x3D; iris_dataset.target_names\ncolors &#x3D; [&#39;b&#39;,&#39;r&#39;,&#39;g&#39;]\nlabel &#x3D; (iris_dataset.target).astype(np.int)\nplt.title(&#39;Petal Width vs Petal Length&#39;)\nplt.xlabel(iris_dataset.feature_names[2])\nplt.ylabel(iris_dataset.feature_names[3])\nfor i in range(len(names)):\n bucket &#x3D; df[df[&#39;Target&#39;] &#x3D;&#x3D; i]\n bucket &#x3D; bucket.iloc[:,[2,3]].values\n plt.scatter(bucket[:, 0], bucket[:, 1], label&#x3D;names[i]) \nplt.legend()\nplt.show()\n\n\n&lt;Figure size 432x288 with 0 Axes&gt;\n\n\n乍一看，我们可以看到蓝色的点(Setosa类)可以很容易地通过画一条线来分隔，并将其与其他类隔离开来。但是其他两个类呢?\n让我们检查另一种更确定的方法。\n计算几何学\n在这种方法中，我们将使用凸包（Convex Hull）来检查一个特定的类是否是线性可分的。简而言之，凸包代表了一组数据点(类)的外边界，这就是为什么有时它被称为凸包。\n当测试线性可分性时使用凸包的逻辑是相当直接的，可以这样说:\n\n\n\n\n\n\n\n\n\n如果X和Y的凸包的交点是空的，那么两个类X和Y是线性可分的。\n一种快速的方法来查看它是如何工作的，就是将每个类的凸包的数据点可视化。我们将绘制凸包边界，以直观地检查交点。我们将使用Scipy库来帮助我们计算凸包。更多信息请参阅下方Scipy文档地址。\n\n地址：https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.ConvexHull.html\n\nfrom scipy.spatial import ConvexHull\n \nplt.clf()\nplt.figure(figsize &#x3D; (10, 6))\nnames &#x3D; iris_dataset.target_names\nlabel &#x3D; (iris_dataset.target).astype(np.int)\ncolors &#x3D; [&#39;b&#39;,&#39;r&#39;,&#39;g&#39;]\nplt.title(&#39;Petal Width vs Petal Length&#39;)\nplt.xlabel(iris_dataset.feature_names[2])\nplt.ylabel(iris_dataset.feature_names[3])\nfor i in range(len(names)):\n bucket &#x3D; df[df[&#39;Target&#39;] &#x3D;&#x3D; i]\n bucket &#x3D; bucket.iloc[:,[2,3]].values\n hull &#x3D; ConvexHull(bucket)\n plt.scatter(bucket[:, 0], bucket[:, 1], label&#x3D;names[i]) \n for j in hull.simplices:\n     plt.plot(bucket[j,0], bucket[j,1], colors[i])\nplt.legend()\nplt.show()\n\n\n&lt;Figure size 432x288 with 0 Axes&gt;\n\n\n至少从直观上看，Setosa是一个线性可分的类。换句话说，我们可以很容易地画出一条直线，将Setosa类与非Setosa类分开。Versicolor类和Versicolor类都不是线性可分的，因为我们可以看到它们两个之间确实有一个交集。\n构建你的第一个模型：K-最近邻模型（k-Nearest Neighbors，kNN）了解了数据之后，我们现在开始构建一个实际的机器学习模型。在scikit-learn中有很多的分类算法可以使用，这里我们使用易于理解的 k-Nearest Neighbors 分类器。该分类器仅需要存储的训练集，为了能够对新的数据点进行预测，该算法在训练集中找到距离新数据点最接近的点，然后，将这个训练点的标签分配给新的数据点。\nkNN 中的 k 表示在训练中我们可以考虑多少固定数目的数据点（例如最近的3个或者5个），而不是仅仅使用距离新数据点最新的点，然后，我们可以使用这些距离较近的数据点指点的多数进行最终的标签分配，为了简单起见，这里我们仅仅使用一个距离最近的点。\nscikit-learn 中的所有机器学习模型都在自己的类中实现的，通常被称为 估计器类。kNN 分类算法是在 neighbors 模块的 KNeighborsClassifier 类中实现的。在我们实现模型之前，需要将类实例化为一个对象，当我们设置模型参数的额时候，会将 KNeighborsClassifier 分类器最终的参数邻居数设置为1（即 k&#x3D;1）：\nfrom sklearn.neighbors import KNeighborsClassifier\nknn &#x3D; KNeighborsClassifier(n_neighbors&#x3D;1)\n\nknn 对象封装了用于根据训练数据集建立机器学习模型的算法，以及用于对新数据进行预测的算法，它还保存了算法从训练数据中提取的信息。\n为了在训练集上建立模型，我们只需要调用 knn 的 fit 函数，该函数包含训练数据的 NumPy 数组 X_train 和对应的训练标签 NumPy 数组 y_train 数组作为参数：\nknn.fit(X_train, y_train)\n\n\n\n\nKNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,\n           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n           weights=&#39;uniform&#39;)\n\nfit 函数返回 knn 对象本身（其内部已经根据设定进行修改），因为我们得到了我们的分类器的字符串表示，表明我们在创建模型的时候使用了哪些参数。几乎所有的这些都是默认值，但是你也能够找到 n_neighbors&#x3D;1，这是我们设定的参数。scikit-learn 中的大多数模型都需要很多的参数，但是大多数都是速度优化或者用于非常特殊的用例，不必担心在该表示中显示的其他参数。\n进行预测有了模型之后，我们就可以使用该模型对新的数据进行预测了。假设我们有一个新的鸢尾花的测量数据：萼片长度5cm、萼片宽度2.9cm、花瓣长度1cm、花瓣宽度0.2cm。该鸢尾花属于哪个类呢？我们可以将这些数据放在 NumPy 数组中，并计算数组形状 – 数组形状应该为样本数 1，特征数 4：\nX_new &#x3D; np.array([[5, 2.9, 1, 0.2]])\nprint(&#39;X_new.shaple: &#123;&#125;&#39;.format(X_new.shape))\n\nX_new.shaple: (1, 4)\n\n你可能注意到了，在构建 NumPy 数组的时候，我们使用的是二维的形式，这是因为在 scikit-learn 中的数据总是希望具有二维性。\n为了进行预测，我们只需要调用 knn 对象的 predict 函数即可：\nprediction &#x3D; knn.predict(X_new)\nprint(&#39;Prediction: &#123;&#125;&#39;.format(prediction))\nprint(&#39;Predicted target name: &#123;&#125;&#39;.format(iris_dataset.target_names[prediction]))\n\nPrediction: [0]\nPredicted target name: [&#39;setosa&#39;]\n\n如果你需要查看属于各个分类的概率，可以调用 knn 对象的 predict_proba 函数：\nprediction_prob &#x3D; knn.predict_proba(X_new)\nprint(&#39;Prediction prob: &#123;&#125;&#39;.format(prediction_prob))\n\nPrediction prob: [[1. 0. 0.]]\n\n可以看到概率的输出和标签的输出是一致的。\n评估模型在之前我们进行了数据集的拆分，分为了训练集和测试集，训练集我们用来训练模型，而测试集的作用便是评估模型了。在测试集中我们已经知道了每个鸢尾花的种类，因此我们可以对测试集数据调用预测函数，并将预测结果和实际的结果进行比较，已确定模型的性能。可以通过计算模型预测的精确度来测量模型的工作情况，精确度是预测正确种类的花朵的比例：\ny_pred &#x3D; knn.predict(X_test)\nprint(&#39;Test set predictions: \\n&#123;&#125;&#39;.format(y_pred))\n\nTest set predictions: \n[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n 2]\n\nprint(&#39;Test set score: &#123;:.2f&#125;&#39;.format(np.mean(y_pred &#x3D;&#x3D; y_test)))\n\nTest set score: 0.97\n\n上述方法是计算模型预测的精确度，统计所有预测正确的数目进行去均值计算。你也可以直接调用 knn 对象的 score 函数进行计算：\nprint(&#39;Test set score: &#123;:.2f&#125;&#39;.format(knn.score(X_test, y_test)))\n\nTest set score: 0.97\n\n对于这个模型，测试集的精确度为 0.97，这意味着我们对测试机中的 97% 的鸢尾花进行了正确的预测，在一些数据假设下，意味着我们可以预期我们的鸢尾花分类模型对新的鸢尾花的识别精确度为 97%。对于一个植物爱好者来说，这种高精度意味着我们的模型具有很高的可信赖度。\n总结与回归让我们总结一下我们在这章学到的内容。首先我们介绍了机器学习及其应用，然后讨论了监督学习和无监督学习的区别，并给出了我们将在本书中使用的工具的概述，之后，我们通过对鸢尾花的物理测定，确定了一种预测鸢尾花所属种类的预测任务。我们使用了一个带有正确标签的鸢尾花数据集建立了一个分类模型。\n鸢尾花数据集由两个 NumPy 数组组成，一个包含数据，在 scikit-learn 中称为 X，另一个包含正确或期望额输出，称为 y，数组 y 是一个一维数组，仅包含一个类标签，每个示例的证书范围是0到2。\n我们将数据集拆分为训练集和测试集，训练集用于构建我们的模型，测试集用于评估我们的模型。\n我们选择了 k-最近邻 分类算法，该算法通过考虑训练集中的最近邻来对新的数据点进行预测，该算法在类 KNeighborsClassifier 中实现，该类包含构建模型的算法和使用模型进行预测的算法，使用前需要先实例化类并设置参数。然后通过调用拟合函数 fit 进行模型的构建，将训练数据 X_train 和训练标签 y_train 作为参数传递。我们使用评分法对模型进行评估，计算模型的准确性。我们使用测试集和测试标签进行模型的评估，发现我们的模型准确率在97%左右，意味着在测试集上有97%的数据是预测正确的。这给了我们将模型应用到新的数据上的信心，并且相信模型在大约97%的事件内都是正确的。\n下面是整个代码实现：\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\niris_dataset &#x3D; load_iris()\nX &#x3D; iris_dataset.data\ny &#x3D; iris_dataset.target\n\nX_train, X_test, y_train, y_test &#x3D; train_test_split(X, y, random_state&#x3D;0)\n\nknn &#x3D; KNeighborsClassifier(n_neighbors&#x3D;1)\nknn.fit(X_train, y_train)\n\nprint(&#39;\\n&#123;&#125;&#39;.format(knn))\n\ny_pred &#x3D; knn.predict(X_test)\nprint(&#39;Test set score: &#123;:.2f&#125;&#39;.format(np.mean(y_pred &#x3D;&#x3D; y_test)))\n\nKNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,\n           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n           weights=&#39;uniform&#39;)\nTest set score: 0.97\n\n","slug":"2018-09-20-Introduction_Of_Machine_Learning","date":"2023-05-13T11:29:06.791Z","categories_index":"机器学习","tags_index":"机器学习"},{"id":"b1badcef23656fe021b375990b5cfa48","title":"8大场景数据清洗Python代码","content":"数据清洗是进行数据分析和使用数据训练模型的必经之路，也是最为耗费数据科学家、程序员的地方。\n在数据清洗的过程中，绝大多数的场景下，所进行的清洗工作都是相似甚至是重复的，因此有必要将数据清洗工作的场景进行总结并给出对应的清洗代码，以便形成可适用于多数工程项目的工具箱。\n\n涵盖8大场景的数据清洗代码以下数据清洗代码，涵盖了8个数据清洗工作中常见的场景，分别是：\n\n删除多列\n转换数据类型\n将分类变量转换为数字变量\n检查缺失数据\n删除列中的字符串\n删除列中的空格\n用字符串连接两列（带条件）\n转换时间戳（从字符串到日期时间格式）\n\n1. 删除多列在进行数据分析时，可能并非所有的列都有用，此时可以使用df.drop方便地删除指定的列：\ndef drop_multiple_col(col_name_list, df):\n\tdf.drop(col_name_list, axis&#x3D;1, inplace&#x3D;True)\n\treturn df\n\n2. 转换数据类型当数据集变大时，可能需要转换数据类型来节省内存空间：\ndef change_dtypes(col_int, col_float, df):\n\tdf[col_int] &#x3D; df[col_int].astype(&#39;int32&#39;)\n\tdf[col_float] &#x3D; df[col_float].astype(&#39;float32&#39;)\n\n3. 将分类变量转换为数字变量在一些机器学习模型中，会要求变量采用数值格式。此时便需要将分类变量转换为数字变量，同时，也可以保留分类变量，以便进行数据可视化等：\ndef convert_cat_2num(df):\n\tnum_encode &#x3D; &#123;&#39;col_1&#39; : &#123;&#39;YES&#39;:1, &#39;NO&#39;:0&#125;,\n\t\t\t\t  &#39;col_2&#39; : &#123;&#39;WON&#39;:1, &#39;LOSE&#39;:0, &#39;DRAW&#39;:0&#125;&#125;\n\tdf.replace(num_encode, inplace&#x3D;True)\n\n4. 检查缺失数据如果要检查每列缺失数据的数量，可使用下面的代码，目前来看应该是最快的方法。可以更好地了解哪些列缺失的数据更多，从而确定怎么进行下一步的数据清洗和分析操作：\ndef check_missing_data(df):\n\treturn df.isnull().sum().sort_values(ascending&#x3D;False)\n\n5. 删除列中的字符串有时，会有新的字符或者其他不需要的符号出现在字符串中，此时可以使用df[&#39;col_1&#39;].replace将它们处理掉：\ndef remove_col_str(df):\n\tdf[&#39;col_1&#39;].replace(&#39;\\n&#39;, &#39;&#39;, regex&#x3D;True, inplace&#x3D;True)\n\tdf[&#39;col_1&#39;].replace(&#39; &amp;#.*&#39;, &#39;&#39;, regex&#x3D;True, inplace&#x3D;True)\n\n6. 删除列中的空格当数据混乱的时候，什么情况都有可能发生。字符串开头有时会有一些空格，在删除列中字符串开头的空格时，可使用下面的代码：\ndef remove_col_white_space(col, df):\n\tdf[col] &#x3D; df[col].str.lstrip()\n\n7. 用字符串连接两列（带条件）当你想要有条件地用字符串将两列连接在一起时，这段代码很有帮助。比如，你可以在第一列结尾处设定某些字母，然后用它们与第二列连接在一起。\n根据需要，结尾处的字母也可以在连接完成后删除。\ndef concat_col_str_condition(df):\n    mask &#x3D; df[&#39;col_1&#39;].str.endswith(&#39;pil&#39;, na&#x3D;False)\n    col_new &#x3D; df[mask][&#39;col_1&#39;] + df[mask][&#39;col_2&#39;]\n    col_new.replace(&#39;pil&#39;, &#39; &#39;, regex&#x3D;True, inplace&#x3D;True)  # replace the &#39;pil&#39; with emtpy space\n\n8. 转换时间戳（从字符串到日期时间格式）在处理时间序列数据时，我们很可能会遇到字符串格式的时间戳列。\n这意味着要将字符串格式转换为日期时间格式(或者其他根据我们的需求指定的格式) ，以便对数据进行有意义的分析。\ndef convert_str_datetime(df): \n    df.insert(loc&#x3D;2, column&#x3D;&#39;timestamp&#39;, value&#x3D;pd.to_datetime(df.transdate, format&#x3D;&#39;%Y-%m-%d %H:%M:%S.%f&#39;)) \n\n以上便是针对8个常见场景的数据清洗代码，在部分场景下，你可能需要简单修改代码才可使用。在面对各种不同且复杂的数据时，可能需要先了解你的数据，然后再决定使用那个或者那些方法进行数据的清洗工作，使得数据能够更好的进入下一步的分析建模过程等。\n","slug":"2019-01-22-data_cleaning","date":"2023-05-13T11:29:06.791Z","categories_index":"机器学习","tags_index":"机器学习 Python"},{"id":"ea3e901619c09b0b5da7b4018126c113","title":"iOS中Log同步获取与重定向","content":"在iOS开发的过程中，经常会使用NSLog作为调试和查看相关数据的输出口，该方法连接Xcode构建项目时能够实时输出开发者在代码线中打印的日志。但是在断开Xcode并使用真机测试的时候，经常会无法查看真机的实时日志，导致一些问题难以追查和确定，导致问题的定位与解决花费较长的时间，一定程度上影响了产品开发的进度和优化。面对诸如此类的问题，我们可以通过Log信息的重定向等技术，让相关的Log信息转存到一个我们能够提取的地方，方便开发人员在出现问题的时候，得到详细的Log信息，快速的识别出问题的原因并修复和优化等。\nNSLog的输出到底在哪里？在iOS的系统API中，专门提供了一个上层函数NSLog以供开发者调用并打印相关的信息，NSLog本质上是一个C函数，它的声明如下：\nFOUNDATION_EXPORT void NSLog(NSString *format, ...)\n\n系统对该函数的说明是：Logs an error message to the Apple System Log facility。简单的说就是用来输出信息到标准的Error控制台上，其内部其实是使用Apple System Log（asl）的API，至少iOS 10以前是这样。在调试阶段，日志会输出到Xcode中，而在真机上，会输出到系统的/var/log/syslog文件中。\nApple System Logger我们可以通过官方文档了解到，OC中最常见的NSLog操作会同时将标准的Error输出到控制台和系统日志(syslog)中(C语言的printf系列函数并不会，swift的printf为了保证性能也只会在模拟器环境中输出)。其内部是使用Apple System Logger(简称ASL)去实现的，ASL是苹果自己实现的用于输出日志到系统日志库的一套API接口，有点类似于SQL操作。在iOS真机设备上，使用ASL记录的log被缓存在沙盒文件中，直到设备被重启。\n既然日志被写入系统的syslog中，那我们可以直接读取这些日志。从ASL读取日志的核心代码如下：\n#import &lt;asl.h&gt;\n&#x2F;&#x2F; 从日志的对象aslmsg中获取我们需要的数据\n+(instancetype)logMessageFromASLMessage:(aslmsg)aslMessage&#123;\n    SystemLogMessage *logMessage &#x3D; [[SystemLogMessage alloc] init];\n    const char *timestamp &#x3D; asl_get(aslMessage, ASL_KEY_TIME);\n    if (timestamp) &#123;\n        NSTimeInterval timeInterval &#x3D; [@(timestamp) integerValue];\n        const char *nanoseconds &#x3D; asl_get(aslMessage, ASL_KEY_TIME_NSEC);\n        if (nanoseconds) &#123;\n            timeInterval +&#x3D; [@(nanoseconds) doubleValue] &#x2F; NSEC_PER_SEC;\n        &#125;\n        logMessage.timeInterval &#x3D; timeInterval;\n        logMessage.date &#x3D; [NSDate dateWithTimeIntervalSince1970:timeInterval];\n    &#125;\n    const char *sender &#x3D; asl_get(aslMessage, ASL_KEY_SENDER);\n    if (sender) &#123;\n        logMessage.sender &#x3D; @(sender);\n    &#125;\n    const char *messageText &#x3D; asl_get(aslMessage, ASL_KEY_MSG);\n    if (messageText) &#123;\n        logMessage.messageText &#x3D; @(messageText);&#x2F;&#x2F;NSLog写入的文本内容\n    &#125;\n    const char *messageID &#x3D; asl_get(aslMessage, ASL_KEY_MSG_ID);\n    if (messageID) &#123;\n        logMessage.messageID &#x3D; [@(messageID) longLongValue];\n    &#125;\n    return logMessage;\n&#125;\n\n+ (NSMutableArray&lt;SystemLogMessage *&gt; *)allLogMessagesForCurrentProcess&#123;\n    asl_object_t query &#x3D; asl_new(ASL_TYPE_QUERY);\n    &#x2F;&#x2F; Filter for messages from the current process. \n    &#x2F;&#x2F; Note that this appears to happen by default on device, \n    &#x2F;&#x2F; but is required in the simulator.\n    NSString *pidString &#x3D; [NSString stringWithFormat:@&quot;%d&quot;, [[NSProcessInfo processInfo] processIdentifier]];\n    asl_set_query(query, ASL_KEY_PID, [pidString UTF8String], ASL_QUERY_OP_EQUAL);\n\n    aslresponse response &#x3D; asl_search(NULL, query);\n    aslmsg aslMessage &#x3D; NULL;\n\n    NSMutableArray *logMessages &#x3D; [NSMutableArray array];\n    while ((aslMessage &#x3D; asl_next(response))) &#123;\n        [logMessages addObject:[SystemLogMessage logMessageFromASLMessage:aslMessage]];\n    &#125;\n    asl_release(response);\n\n    return logMessages;\n&#125;\n\n使用以上方法的好处是不会影响Xcode控制台的输出，可以用非侵入性的方式来读取日志。\nASL在iOS10后被弃用但是Apple从iOS 10开始，为了减弱ASL对于日志系统的侵入性，直接废弃掉了ASLlink，导致在iOS 10之后的系统版本中无法使用ASL相关的API。因此为了能够在iOS 10之后的版本中同样获取日志数据，我们寻找一种版本兼容的解决方案。\nNSLog重定向NSLog能输出到文件syslog中，靠的是文件IO的API的调用，那么在这些IO操作中，一定存在文件句柄。在C语言中，存在默认的三个文件句柄：\n#define stdin __stdinp \n#define stdout __stdoutp \n#define stderr __stderrp\n\n其对应的三个iOS版本的文件句柄是(定义在unistd.h文件中):\n#define\t STDIN_FILENO\t0\t&#x2F;* standard input file descriptor *&#x2F;\n#define\tSTDOUT_FILENO\t1\t&#x2F;* standard output file descriptor *&#x2F;\n#define\tSTDERR_FILENO\t2\t&#x2F;* standard error file descriptor *&#x2F;\n\n在使用重定向之后，NSLog就不会写到系统的syslog中了。\ndup2重定向通过重定向，可以直接截取stdout,stderr等标准输出的信息，然后保存在想要存储的位置，上传到服务器或者显示到View上。要做到重定向，需要通过NSPipe创建一个管道，pipe有读端和写端，然后通过dup2将标准输入重定向到pipe的写端。再通过NSFileHandle监听pipe的读端，最后再处理读出的信息。之后通过printf或者NSLog写数据，都会写到pipe的写端，同时pipe会将这些数据直接传送到读端，最后通过NSFileHandle的监控函数取出这些数据。核心代码如下：\n- (void)redirectStandardOutput&#123;\n    &#x2F;&#x2F;记录标准输出及错误流原始文件描述符\n    self.outFd &#x3D; dup(STDOUT_FILENO);\n    self.errFd &#x3D; dup(STDERR_FILENO);\n#if BETA_BUILD\n    stdout-&gt;_flags &#x3D; 10;\n    NSPipe *outPipe &#x3D; [NSPipe pipe];\n    NSFileHandle *pipeOutHandle &#x3D; [outPipe fileHandleForReading];\n    dup2([[outPipe fileHandleForWriting] fileDescriptor], STDOUT_FILENO);\n    [pipeOutHandle readInBackgroundAndNotify];\n\n    stderr-&gt;_flags &#x3D; 10;\n    NSPipe *errPipe &#x3D; [NSPipe pipe];\n    NSFileHandle *pipeErrHandle &#x3D; [errPipe fileHandleForReading];\n    dup2([[errPipe fileHandleForWriting] fileDescriptor], STDERR_FILENO);\n    [pipeErrHandle readInBackgroundAndNotify];\n    [[NSNotificationCenter defaultCenter] addObserver:self \n                                            selector:@selector(redirectOutNotificationHandle:) \n                                            name:NSFileHandleReadCompletionNotification \n                                            object:pipeOutHandle];\n\n    [[NSNotificationCenter defaultCenter] addObserver:self \n                                            selector:@selector(redirectErrNotificationHandle:) \n                                            name:NSFileHandleReadCompletionNotification \n                                            object:pipeErrHandle];\n#endif\n&#125;\n\n-(void)recoverStandardOutput&#123;\n#if BETA_BUILD\n    dup2(self.outFd, STDOUT_FILENO);\n    dup2(self.errFd, STDERR_FILENO);\n    [[NSNotificationCenter defaultCenter] removeObserver:self];\n#endif\n&#125;\n\n&#x2F;&#x2F; 重定向之后的NSLog输出\n- (void)redirectOutNotificationHandle:(NSNotification *)nf&#123;\n#if BETA_BUILD\n    NSData *data &#x3D; [[nf userInfo] objectForKey:NSFileHandleNotificationDataItem];\n    NSString *str &#x3D; [[NSString alloc] initWithData:data encoding:NSUTF8StringEncoding];\n    &#x2F;&#x2F; YOUR CODE HERE...  保存日志并上传或展示\n#endif\n    [[nf object] readInBackgroundAndNotify];\n&#125;\n\n&#x2F;&#x2F; 重定向之后的错误输出\n- (void)redirectErrNotificationHandle:(NSNotification *)nf&#123;\n#if BETA_BUILD\n    NSData *data &#x3D; [[nf userInfo] objectForKey:NSFileHandleNotificationDataItem];\n    NSString *str &#x3D; [[NSString alloc] initWithData:data encoding:NSUTF8StringEncoding];\n    &#x2F;&#x2F; YOUR CODE HERE...  保存日志并上传或展示\n#endif\n    [[nf object] readInBackgroundAndNotify];\n&#125;\n\n\n\n\n\n\n\n\n\n\ndup函数可以为我们复制一个文件描述符，传给该函数一个既有的描述符，它就会返回一个新的描述符，这个新的描述符是传给它的描述符的拷贝。这意味着，这两个描述符共享同一个数据结构。而dup2函数跟dup函数相似，但dup2函数允许调用者规定一个有效描述符和目标描述符的id。dup2函数成功返回时，目标描述符（dup2函数的第二个参数）将变成源描述符（dup2函数的第一个参数）的复制品，换句话说，两个文件描述符现在都指向同一个文件，并且是函数第一个参数指向的文件。\n文件重定向另一种重定向的方式是利用c语言的freopen函数进行重定向，将写往stderr的内容重定向到我们制定的文件中去，一旦执行了上述代码那么在这个之后的NSLog将不会在控制台显示了，会直接输出在指定的文件中。在模拟器中，我们可以使用终端的tail命令(tail -f xxx.log)对这个文件进行实时查看，就如同我们在Xcode的输出窗口中看到的那样，你还可以结合grep命令进行实时过滤查看，非常方便在大量的日志信息中迅速定位到我们要的日志信息。\nFILE * freopen ( const char * filename, const char * mode, FILE * stream );\n\n核心代码如下：\nNSArray *paths &#x3D; NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, YES);\nNSString *documentsPath &#x3D; [paths objectAtIndex:0];\nNSString *loggingPath &#x3D; [documentsPath stringByAppendingPathComponent:@&quot;&#x2F;xxx.log&quot;];\n&#x2F;&#x2F;redirect NSLog\nfreopen([loggingPath cStringUsingEncoding:NSASCIIStringEncoding], &quot;a+&quot;, stderr);\n\n这样我们就可以把可获取的日志文件发送给服务端或者通过itunes共享出来。但是由于iOS严格的沙盒机制，我们无法知道stderr原来的文件路径，也无法直接使用沙盒外的文件，所以freopen无法重定向回去，只能使用第1点所述的dup和dup2来实现。\n&#x2F;&#x2F; 重定向\nint origin1 &#x3D; dup(STDERR_FILENO);\nFILE * myFile &#x3D; freopen([loggingPath cStringUsingEncoding:NSASCIIStringEncoding], &quot;a+&quot;, stderr);\n&#x2F;&#x2F; 恢复重定向\ndup2(origin1, STDERR_FILENO);\n\n使用GCD的dispatch Source重定向方式具体代码如下：\n- (dispatch_source_t)_startCapturingWritingToFD:(int)fd  &#123;\n    int fildes[2];\n    pipe(fildes);  &#x2F;&#x2F; [0] is read end of pipe while [1] is write end\n    dup2(fildes[1], fd);  &#x2F;&#x2F; Duplicate write end of pipe &quot;onto&quot; fd (this closes fd)\n    close(fildes[1]);  &#x2F;&#x2F; Close original write end of pipe\n    fd &#x3D; fildes[0];  &#x2F;&#x2F; We can now monitor the read end of the pipe\n    char* buffer &#x3D; malloc(1024);\n    NSMutableData* data &#x3D; [[NSMutableData alloc] init];\n    fcntl(fd, F_SETFL, O_NONBLOCK);\n    dispatch_source_t source &#x3D; dispatch_source_create(\n        DISPATCH_SOURCE_TYPE_READ, fd, 0, dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_HIGH, 0));\n    dispatch_source_set_cancel_handler(source, ^&#123;\n        free(buffer);\n    &#125;);\n    dispatch_source_set_event_handler(source, ^&#123;\n        @autoreleasepool &#123;\n\n            while (1) &#123;\n                ssize_t size &#x3D; read(fd, buffer, 1024);\n                if (size &lt;&#x3D; 0) &#123;\n                    break;\n                &#125;\n                [data appendBytes:buffer length:size];\n                if (size &lt; 1024) &#123;\n                    break;\n                &#125;\n            &#125;\n            NSString *aString &#x3D; [[NSString alloc] initWithData:data encoding:NSUTF8StringEncoding];\n            &#x2F;&#x2F;printf(&quot;aString &#x3D; %s&quot;,[aString UTF8String]);\n            &#x2F;&#x2F;NSLog(@&quot;aString &#x3D; %@&quot;,aString);\n            &#x2F;&#x2F; Do something\n        &#125;\n    &#125;);\n    dispatch_resume(source);\n    return source;\n&#125;\n\n总结虽然上述的几个重定向的方法都能够获取到Log数据，但是弊端是当使用Log重定向之后，连接Xcode进行调试应用程序时，Xcode的Console中将不会打印任何Log信息，Log信息已经被重定向到了我们指定的文件中了。这些方法有一定的局限性，在具体使用的时候，需要视情况而定。当然还有其他的方式能够即重定向Log数据到指定文件，还能够在Xcode的Console中输出日志（pipe、dup2与GCD的相互协作），这样能够避免调试阶段无法实时查看日志的缺陷，进一步的提高开发调试和优化的效率。\n另外也可以开发一个在桌面或者网页端实时展示Log信息的应用，实时从重定向的位置读取Log信息，达到实时查看信息的目的等。\n","slug":"2019-01-22-iOS_NSLog","date":"2023-05-13T11:29:06.791Z","categories_index":"开发知识","tags_index":"开发知识 iOS"},{"id":"11480c51ae26bed2fd1029069074ca32","title":"iOS虚拟内存管理","content":"虚拟内存是一种允许操作系统避开物理RAM限制的内存管理机制。虚拟内存管理器为每个进程创建一个逻辑地址空间或者虚拟内存地址空间，并且将它分配为相同大小的内存块，可称为页。处理器与内存管理单元MMU维持一个页表来映射程序逻辑地址空间到计算机RAM的硬件地址。当程序的代码访问内存中的一个地址时，MMU利用页表将指定的逻辑地址转换为真实的硬件内存地址，这种转换自动发生并且对于运行的应用是透明的。\n虚拟内存概述就程序而言，在它逻辑地址空间的地址永远可用。然而，当应用访问一个当前并没有在物理RAM中的内存页的地址时，就会发生页错误。当这种情况发生时，虚拟内存系统调用一个专用的页错误处理器来立即响应错误。页错误处理器停止当前执行的代码，定位到物理内存的一个空闲页，从磁盘加载包含必要数据的页，更新页表，之后返回对程序代码的控制，程序代码就可以正常访问内存地址了。这个过程被称为分页。\n如果在物理内存中没有空闲页，页错误处理器必须首先释放一个已经存在的页从而为新页提供空间。由系统平台决定系统如何释放页。在OS X，虚拟内存系统常常将页写入备份存储。备份存储是一个基于磁盘的仓库,包含了给定进程内存页的拷贝。将数据从物理内存移到备份存储被称为页面换出；将数据从备份存储移到物理内存被称为页面换入。在iOS，没有备份存储，所以页面永远不会换出到磁盘，但是只读页仍可以根据需要从磁盘换入。\n在OS X and iOS中，页大小为4kb。因此，每次页错误发生时，系统会从磁盘读取4kb。当系统花费过度的时间处理页错误并且读写页，而并不是执行代码时，会发生磁盘震荡（disk thrashing）。\n无论页换出／换入，磁盘震荡会降低性能。因为它强迫系统花费大量时间进行磁盘的读写。从备份存储读取页花费相当长的时间，并且比直接从RAM读取要慢很多。如果系统从磁盘读取另一个页之前，不得不将一个页写入磁盘时，性能影响会更糟。\n\n\n\n虚拟内存的限制在iOS开发的过程中，难免手动去申请内存，目前大多数的移动设备都是ARM64的设备，即使用的是64位寻址空间，而且在iOS上通过malloc申请的内存只是虚拟内存，不是真正的物理内存，那么在iOS设备上为什么会出现申请了2-3G就会出现申请失败呢？\nvoid *buffer &#x3D; malloc(2000 * 1024 * 1024);\n\nmalloc: *** mach_vm_map(size&#x3D;2097152000) failed (error code&#x3D;3)\n*** error: can&#39;t allocate region\n\n当申请分配一个超大的内存时，iOS系统会按照nano_zone和scalable_zone的设计理念进行内存的申请，申请原理如下：\nvoid *    szone_malloc_should_clear(szone_t *szone, size_t size, boolean_t cleared_requested)\n&#123;\n    void *ptr;\n    msize_t msize;\n\n    if (size &lt;&#x3D; SMALL_THRESHOLD) &#123;\n        &#x2F;&#x2F; tiny size: &lt;1024 bytes (64-bit), &lt;512 bytes (32-bit)\n        &#x2F;&#x2F; think tiny\n        msize &#x3D; TINY_MSIZE_FOR_BYTES(size + TINY_QUANTUM - 1);\n        if (!msize) &#123;\n            msize &#x3D; 1;\n        &#125;\n        ptr &#x3D; tiny_malloc_should_clear(szone, msize, cleared_requested);\n    &#125; else if (size &lt;&#x3D; szone-&gt;large_threshold) &#123;\n        &#x2F;&#x2F; small size: &lt;15k (&lt;1GB machines), &lt;127k (&gt;1GB machines)\n        &#x2F;&#x2F; think small\n        msize &#x3D; SMALL_MSIZE_FOR_BYTES(size + SMALL_QUANTUM - 1);\n        if (!msize) &#123;\n            msize &#x3D; 1;\n        &#125;\n        ptr &#x3D; small_malloc_should_clear(szone, msize, cleared_requested);\n    &#125; else &#123;\n        &#x2F;&#x2F; large: all other allocations\n        size_t num_kernel_pages &#x3D; round_page_quanta(size) &gt;&gt; vm_page_quanta_shift;\n        if (num_kernel_pages &#x3D;&#x3D; 0) &#123; &#x2F;* Overflowed *&#x2F;\n            ptr &#x3D; 0;\n        &#125; else &#123;\n            ptr &#x3D; large_malloc(szone, num_kernel_pages, 0, cleared_requested);\n        &#125;\n    &#125;\n#if DEBUG_MALLOC\n    if (LOG(szone, ptr)) &#123;\n        malloc_printf(&quot;szone_malloc returned %p\\n&quot;, ptr);\n    &#125;\n#endif\n    &#x2F;*\n     * If requested, scribble on allocated memory.\n     *&#x2F;\n    if ((szone-&gt;debug_flags &amp; MALLOC_DO_SCRIBBLE) &amp;&amp; ptr &amp;&amp; !cleared_requested &amp;&amp; size) &#123;\n        memset(ptr, SCRIBBLE_BYTE, szone_size(szone, ptr));\n    &#125;\n\n    return ptr;\n&#125;\n\n\n小于1k的走 tiny_malloc\n小于15k或者127k的走 small_malloc （视具体不同的设备内存上限不同）\n剩下的走 large_malloc\n\n由于我们分配的非常大，我们可以确定我们的逻辑是落入large_malloc中。需要特别注意的是： large_malloc分配内存的基本单位是一页大小，而对于其他的几种分配方式，则不是必须按照页大小进行分配。\n由于 large_malloc 这个函数本身并没有特殊需要注意的地方，我们直接关注其真正分配内存的地方，即 allocate_pages ，如下所示：\nvm_addr &#x3D; vm_page_quanta_size;\nkr &#x3D; mach_vm_map(mach_task_self(), &amp;vm_addr, allocation_size, allocation_mask, alloc_flags, MEMORY_OBJECT_NULL, 0, FALSE,\n            VM_PROT_DEFAULT, VM_PROT_ALL, VM_INHERIT_DEFAULT);\nif (kr) &#123;\n    szone_error(szone, 0, &quot;can&#39;t allocate region&quot;, NULL, &quot;*** mach_vm_map(size&#x3D;%lu) failed (error code&#x3D;%d)\\n&quot;, size, kr);\n    return NULL;\n&#125;\naddr &#x3D; (uintptr_t)vm_addr;\n\n从上不难看出，如果分配失败，就是提示报错。而 mach_vm_map 则是整个内存的分配核心。\n\n概括来说，vm_map 代表就是一个进程运行时候涉及的虚拟内存， pmap 代表的就是和具体硬件架构相关的物理内存。（这里我们暂时先不考虑 submap 这种情况）。\nvm_map本身是进程（或者从Mach内核的角度看是task的地址分布图）。这个地址分布图维护着一个 双向列表 ，列表的每一项都是 vm_entry_t ，代表着虚拟地址上连续的一个范围。而 pmap 这个结构体代表了个硬件相关的内存转换：即利用 pmap 这个结构体来描述抽象的物理地址访问和使用。\n进程（任务）的创建对于在iOS上的进程创建和加载执行Mach-O过程，有必要进行一个简单的介绍，在类UNIX系统本质上是不会无缘无故创建出一个进程的，基本上必须通过fork的形式来创建。无论是用户态调用posix相关的API还是别的API，最终落入内核是均是通过函数fork_create_child来创建属于Mach内核的任务。实现如下：\nthread_t\nfork_create_child(task_t parent_task, proc_t child, int inherit_memory, int is64bit)\n&#123;\n\tthread_t\tchild_thread &#x3D; NULL;\n\ttask_t\t\tchild_task;\n\tkern_return_t\tresult;\n\n\t&#x2F;* Create a new task for the child process *&#x2F;\n\tresult &#x3D; task_create_internal(parent_task,\n\t\t\t\t\tinherit_memory,\n\t\t\t\t\tis64bit,\n\t\t\t\t\t&amp;child_task);\n\tif (result !&#x3D; KERN_SUCCESS) &#123;\n\t\tprintf(&quot;execve: task_create_internal failed.  Code: %d\\n&quot;, result);\n\t\tgoto bad;\n\t&#125;\n\n\t&#x2F;* Set the child task to the new task *&#x2F;\n\tchild-&gt;task &#x3D; child_task;\n\n\t&#x2F;* Set child task proc to child proc *&#x2F;\n\tset_bsdtask_info(child_task, child);\n\n\t&#x2F;* Propagate CPU limit timer from parent *&#x2F;\n\tif (timerisset(&amp;child-&gt;p_rlim_cpu))\n\t\ttask_vtimer_set(child_task, TASK_VTIMER_RLIM);\n\n\t&#x2F;* Set&#x2F;clear 64 bit vm_map flag *&#x2F;\n\tif (is64bit)\n\t\tvm_map_set_64bit(get_task_map(child_task));\n\telse\n\t\tvm_map_set_32bit(get_task_map(child_task));\n\n#if CONFIG_MACF\n\t&#x2F;* Update task for MAC framework *&#x2F;\n\t&#x2F;* valid to use p_ucred as child is still not running ... *&#x2F;\n\tmac_task_label_update_cred(child-&gt;p_ucred, child_task);\n#endif\n\n\t&#x2F;* Set child scheduler priority if nice value inherited from parent *&#x2F;\n\tif (child-&gt;p_nice !&#x3D; 0)\n\t\tresetpriority(child);\n\n\t&#x2F;* Create a new thread for the child process *&#x2F;\n\tresult &#x3D; thread_create(child_task, &amp;child_thread);\n\tif (result !&#x3D; KERN_SUCCESS) &#123;\n\t\tprintf(&quot;execve: thread_create failed. Code: %d\\n&quot;, result);\n\t\ttask_deallocate(child_task);\n\t\tchild_task &#x3D; NULL;\n\t&#125;\nbad:\n\tthread_yield_internal(1);\n\n\treturn(child_thread);\n&#125;\n\n\n要注意的就是Mach内核里面没有进程的概念，只有任务，进程是属于BSD之上的抽象。它们之间的联系就是通过指针建立， child_proc-&gt;task = child_task。\n\nfork出来的进程像是一个空壳，需要利用这个进程壳去执行科执行文件编程有意义的程序进程。从XNU上看，可执行文件的类型有如下分类：\n&#123; exec_mach_imgact,        &quot;Mach-o Binary&quot; &#125;,\n&#123; exec_fat_imgact,        &quot;Fat Binary&quot; &#125;,\n&#123; exec_shell_imgact,    &quot;Interpreter Script&quot; &#125;\n\n常用的通常是Mach-o文件：\nexec_mach_imgact(struct image_params *imgp)\n&#123;\n    ... 省略无数\n\n    if ((mach_header-&gt;magic &#x3D;&#x3D; MH_CIGAM) ||\n        (mach_header-&gt;magic &#x3D;&#x3D; MH_CIGAM_64)) &#123;\n        error &#x3D; EBADARCH;\n        goto bad;\n    &#125;\n\n    if ((mach_header-&gt;magic !&#x3D; MH_MAGIC) &amp;&amp;\n        (mach_header-&gt;magic !&#x3D; MH_MAGIC_64)) &#123;\n        error &#x3D; -1;\n        goto bad;\n    &#125;\n\n    if (mach_header-&gt;filetype !&#x3D; MH_EXECUTE) &#123;\n        error &#x3D; -1;\n        goto bad;\n    &#125;\n\n    if (imgp-&gt;ip_origcputype !&#x3D; 0) &#123;\n        &#x2F;* Fat header previously had an idea about this thin file *&#x2F;\n        if (imgp-&gt;ip_origcputype !&#x3D; mach_header-&gt;cputype ||\n            imgp-&gt;ip_origcpusubtype !&#x3D; mach_header-&gt;cpusubtype) &#123;\n            error &#x3D; EBADARCH;\n            goto bad;\n        &#125;\n    &#125; else &#123;\n        imgp-&gt;ip_origcputype &#x3D; mach_header-&gt;cputype;\n        imgp-&gt;ip_origcpusubtype &#x3D; mach_header-&gt;cpusubtype;\n    &#125;\n\n    task &#x3D; current_task();\n    thread &#x3D; current_thread();\n    uthread &#x3D; get_bsdthread_info(thread);\n\n    if ((mach_header-&gt;cputype &amp; CPU_ARCH_ABI64) &#x3D;&#x3D; CPU_ARCH_ABI64)\n        imgp-&gt;ip_flags |&#x3D; IMGPF_IS_64BIT;\n\n    &#x2F;* If posix_spawn binprefs exist, respect those prefs. *&#x2F;\n    psa &#x3D; (struct _posix_spawnattr *) imgp-&gt;ip_px_sa;\n    if (psa !&#x3D; NULL &amp;&amp; psa-&gt;psa_binprefs[0] !&#x3D; 0) &#123;\n        int pr &#x3D; 0;\n        for (pr &#x3D; 0; pr &lt; NBINPREFS; pr++) &#123;\n            cpu_type_t pref &#x3D; psa-&gt;psa_binprefs[pr];\n            if (pref &#x3D;&#x3D; 0) &#123;\n                &#x2F;* No suitable arch in the pref list *&#x2F;\n                error &#x3D; EBADARCH;\n                goto bad;\n            &#125;\n\n            if (pref &#x3D;&#x3D; CPU_TYPE_ANY) &#123;\n                &#x2F;* Jump to regular grading *&#x2F;\n                goto grade;\n            &#125;\n\n            if (pref &#x3D;&#x3D; imgp-&gt;ip_origcputype) &#123;\n                &#x2F;* We have a match! *&#x2F;\n                goto grade;\n            &#125;\n        &#125;\n        error &#x3D; EBADARCH;\n        goto bad;\n    &#125;\ngrade:\n    if (!grade_binary(imgp-&gt;ip_origcputype, imgp-&gt;ip_origcpusubtype &amp; ~CPU_SUBTYPE_MASK)) &#123;\n        error &#x3D; EBADARCH;\n        goto bad;\n    &#125;\n\n    &#x2F;* Copy in arguments&#x2F;environment from the old process *&#x2F;\n    error &#x3D; exec_extract_strings(imgp);\n    if (error)\n        goto bad;\n\n    AUDIT_ARG(argv, imgp-&gt;ip_startargv, imgp-&gt;ip_argc, \n        imgp-&gt;ip_endargv - imgp-&gt;ip_startargv);\n    AUDIT_ARG(envv, imgp-&gt;ip_endargv, imgp-&gt;ip_envc,\n        imgp-&gt;ip_endenvv - imgp-&gt;ip_endargv);\n\n    &#x2F;* reset local idea of thread, uthread, task *&#x2F;\n    thread &#x3D; imgp-&gt;ip_new_thread;\n    uthread &#x3D; get_bsdthread_info(thread);\n    task &#x3D; new_task &#x3D; get_threadtask(thread);\n\n    &#x2F;&#x2F; 注意点：\n    lret &#x3D; load_machfile(imgp, mach_header, thread, &amp;map, &amp;load_result);\n\n    ... 省略无数\n\n上面的代码基本上都是在对文件进行各种检查，然后分配一个预使用的进程壳，之后使用load_machfile加载真正的二进制文件。\nload_return_t\nload_machfile(\n    struct image_params    *imgp,\n    struct mach_header    *header,\n    thread_t         thread,\n    vm_map_t         *mapp,\n    load_result_t        *result\n)\n&#123;\n    ... 省略一大堆\n\n    if (macho_size &gt; file_size) &#123;\n        return(LOAD_BADMACHO);\n    &#125;\n\n    result-&gt;is64bit &#x3D; ((imgp-&gt;ip_flags &amp; IMGPF_IS_64BIT) &#x3D;&#x3D; IMGPF_IS_64BIT);\n\n    task_t ledger_task;\n    if (imgp-&gt;ip_new_thread) &#123;\n        ledger_task &#x3D; get_threadtask(imgp-&gt;ip_new_thread);\n    &#125; else &#123;\n        ledger_task &#x3D; task;\n    &#125;\n\n    &#x2F;&#x2F; 注意点1\n    pmap &#x3D; pmap_create(get_task_ledger(ledger_task),\n               (vm_map_size_t) 0,\n               result-&gt;is64bit);\n\n    &#x2F;&#x2F; 注意点2\n    map &#x3D; vm_map_create(pmap,\n,\n            vm_compute_max_offset(result-&gt;is64bit),\n            TRUE);\n\n#if defined(__arm64__)\n    &#x2F;&#x2F; 注意点三\n    if (result-&gt;is64bit) &#123;\n        &#x2F;* enforce 16KB alignment of VM map entries *&#x2F;\n        vm_map_set_page_shift(map, SIXTEENK_PAGE_SHIFT);\n    &#125; else &#123;\n        vm_map_set_page_shift(map, page_shift_user32);\n    &#125;\n\n\n利用 pmap_create 创建硬件相关的物理内存抽象。\n利用 vmap_create 创建虚拟内存的地址图。\nARM64下的页是16k一个虚拟页对应一个物理页。\n\n这里需要重点关注 vm_map_create 0 和 vm_compute_max_offset(result-&gt;is64bit)，代表着当前任务分配的虚拟内存地址的上下限， vm_compute_max_offset函数实现如下：\nvm_map_offset_t\nvm_compute_max_offset(boolean_t is64)\n&#123;\n#if defined(__arm__) || defined(__arm64__)\n    return (pmap_max_offset(is64, ARM_PMAP_MAX_OFFSET_DEVICE));\n#else\n    return (is64 ? (vm_map_offset_t)MACH_VM_MAX_ADDRESS : (vm_map_offset_t)VM_MAX_ADDRESS);\n#endif\n&#125;\n\npmap_max_offset函数实现如下：\nvm_map_offset_t pmap_max_offset(\n    boolean_t    is64 __unused,\n    unsigned int    option)\n&#123;\n    vm_map_offset_t    max_offset_ret &#x3D; 0;\n\n#if defined(__arm64__)\n    assert (is64);\n    vm_map_offset_t min_max_offset &#x3D; SHARED_REGION_BASE_ARM64 + SHARED_REGION_SIZE_ARM64 + 0x20000000; &#x2F;&#x2F; end of shared region + 512MB for various purposes\n    if (option &#x3D;&#x3D; ARM_PMAP_MAX_OFFSET_DEFAULT) &#123;\n        max_offset_ret &#x3D; arm64_pmap_max_offset_default;\n    &#125; else if (option &#x3D;&#x3D; ARM_PMAP_MAX_OFFSET_MIN) &#123;\n        max_offset_ret &#x3D; min_max_offset;\n    &#125; else if (option &#x3D;&#x3D; ARM_PMAP_MAX_OFFSET_MAX) &#123;\n        max_offset_ret &#x3D; MACH_VM_MAX_ADDRESS;\n    &#125; else if (option &#x3D;&#x3D; ARM_PMAP_MAX_OFFSET_DEVICE) &#123;\n        if (arm64_pmap_max_offset_default) &#123;\n            max_offset_ret &#x3D; arm64_pmap_max_offset_default;\n        &#125; else if (max_mem &gt; 0xC0000000) &#123;\n            max_offset_ret &#x3D; 0x0000000318000000ULL;     &#x2F;&#x2F; Max offset is 12.375GB for devices with &gt; 3GB of memory\n        &#125; else if (max_mem &gt; 0x40000000) &#123;\n            max_offset_ret &#x3D; 0x0000000218000000ULL;     &#x2F;&#x2F; Max offset is 8.375GB for devices with &gt; 1GB and &lt;&#x3D; 3GB of memory\n        &#125; else &#123;\n            max_offset_ret &#x3D; min_max_offset;\n        &#125;\n    &#125; else if (option &#x3D;&#x3D; ARM_PMAP_MAX_OFFSET_JUMBO) &#123;\n        max_offset_ret &#x3D; 0x0000000518000000ULL;     &#x2F;&#x2F; Max offset is 20.375GB for pmaps with special &quot;jumbo&quot; blessing\n    &#125; else &#123;\n        panic(&quot;pmap_max_offset illegal option 0x%x\\n&quot;, option);\n    &#125;\n\n    assert(max_offset_ret &gt;&#x3D; min_max_offset);\n    return max_offset_ret;\n\n这里的关键点代码是：\nif (max_mem &gt; 0xC0000000) &#123;\n    max_offset_ret &#x3D; 0x0000000318000000ULL;     &#x2F;&#x2F; Max offset is 12.375GB for devices with &gt; 3GB of memory\n&#125; else if (max_mem &gt; 0x40000000) &#123;\n    max_offset_ret &#x3D; 0x0000000218000000ULL;     &#x2F;&#x2F; Max offset is 8.375GB for devices with &gt; 1GB and &lt;&#x3D; 3GB of memory\n&#125; else &#123;\n    max_offset_ret &#x3D; min_max_offset;\n&#125;\n\nmax_offset_ret 这个值就代表了我们任务对应的 vm_map_t 的最大地址范围，比如说这里是8.375GB。\n虚拟内存分配的限制之前提到了 large_malloc 会走入到最后的 vm_map_enter ，那么我们来看看 vm_map_enter 的实现：\nvm_map_enter(\n    vm_map_t        map,\n    vm_map_offset_t        *address,    &#x2F;* IN&#x2F;OUT *&#x2F;\n    vm_map_size_t        size,\n    vm_map_offset_t        mask,\n    int            flags,\n    vm_map_kernel_flags_t    vmk_flags,\n    vm_tag_t        alias,\n    vm_object_t        object,\n    vm_object_offset_t    offset,\n    boolean_t        needs_copy,\n    vm_prot_t        cur_protection,\n    vm_prot_t        max_protection,\n    vm_inherit_t        inheritance)\n&#123;\n\n#if CONFIG_EMBEDDED\n    &#x2F;&#x2F; 注意点1:检查页的权限\n    if (cur_protection &amp; VM_PROT_WRITE)&#123;\n        if ((cur_protection &amp; VM_PROT_EXECUTE) &amp;&amp; !entry_for_jit)&#123;\n            printf(&quot;EMBEDDED: %s: curprot cannot be write+execute. &quot;\n                   &quot;turning off execute\\n&quot;,\n                   __FUNCTION__);\n            cur_protection &amp;&#x3D; ~VM_PROT_EXECUTE;\n        &#125;\n    &#125;\n#endif &#x2F;* CONFIG_EMBEDDED *&#x2F;\n\n    if (resilient_codesign || resilient_media) &#123;\n        if ((cur_protection &amp; (VM_PROT_WRITE | VM_PROT_EXECUTE)) ||\n            (max_protection &amp; (VM_PROT_WRITE | VM_PROT_EXECUTE))) &#123;\n            return KERN_PROTECTION_FAILURE;\n        &#125;\n    &#125;\n\n    &#x2F;&#x2F; 1. 获取任务的可用的地址最小值和最大值\n    effective_min_offset &#x3D; map-&gt;min_offset;\n    effective_max_offset &#x3D; map-&gt;max_offset;\n\n    if (map-&gt;pmap &#x3D;&#x3D; kernel_pmap) &#123;\n        user_alias &#x3D; VM_KERN_MEMORY_NONE;\n    &#125; else &#123;\n        user_alias &#x3D; alias;\n    &#125;\n\n#define    RETURN(value)    &#123; result &#x3D; value; goto BailOut; &#125;\n\n    assert(page_aligned(*address));\n    assert(page_aligned(size));\n\n    if (!VM_MAP_PAGE_ALIGNED(size, VM_MAP_PAGE_MASK(map))) &#123;\n        clear_map_aligned &#x3D; TRUE;\n    &#125;\n\nStartAgain: ;\n\n    start &#x3D; *address;\n\n    if (anywhere) &#123;\n        vm_map_lock(map);\n        map_locked &#x3D; TRUE;\n\n        if (start &lt; effective_min_offset)\n            start &#x3D; effective_min_offset;\n        if (start &gt; effective_max_offset)\n            RETURN(KERN_NO_SPACE);\n\n\n        if( FALSE ) &#123;\n\n        &#125; else &#123;\n\n            if (map-&gt;holelistenabled) &#123;\n                hole_entry &#x3D; (vm_map_entry_t)map-&gt;holes_list;\n\n                if (hole_entry &#x3D;&#x3D; NULL) &#123;\n                    &#x2F;*\n                     * No more space in the map?\n                     *&#x2F;\n                    result &#x3D; KERN_NO_SPACE;\n                    goto BailOut;\n                &#125; else &#123;\n\n                    boolean_t found_hole &#x3D; FALSE;\n\n                    do &#123;\n                        if (hole_entry-&gt;vme_start &gt;&#x3D; start) &#123;\n                            start &#x3D; hole_entry-&gt;vme_start;\n                            found_hole &#x3D; TRUE;\n                            break;\n                        &#125;\n\n                        if (hole_entry-&gt;vme_end &gt; start) &#123;\n                            found_hole &#x3D; TRUE;\n                            break;\n                        &#125;\n                        hole_entry &#x3D; hole_entry-&gt;vme_next;\n\n                    &#125; while (hole_entry !&#x3D; (vm_map_entry_t) map-&gt;holes_list);\n\n                    if (found_hole &#x3D;&#x3D; FALSE) &#123;\n                        result &#x3D; KERN_NO_SPACE;\n                        goto BailOut;\n                    &#125;\n\n                    entry &#x3D; hole_entry;\n\n                    if (start &#x3D;&#x3D; 0)\n                        start +&#x3D; PAGE_SIZE_64;\n                &#125;\n            &#125;\n        &#125;\n\n        while (TRUE) &#123;\n            vm_map_entry_t    next;\n\n            end &#x3D; ((start + mask) &amp; ~mask);\n            end &#x3D; vm_map_round_page(end,\n                        VM_MAP_PAGE_MASK(map));\n\n            if (end &lt; start)\n                RETURN(KERN_NO_SPACE);\n\n            start &#x3D; end;\n            end +&#x3D; size;\n\n            if ((end &gt; effective_max_offset) || (end &lt; start)) &#123;\n                RETURN(KERN_NO_SPACE);\n            &#125;\n\n            next &#x3D; entry-&gt;vme_next;\n\n            if (map-&gt;holelistenabled) &#123;\n                if (entry-&gt;vme_end &gt;&#x3D; end)\n                    break;\n            &#125; else &#123;\n\n                if (next &#x3D;&#x3D; vm_map_to_entry(map))\n                    break;\n\n                if (next-&gt;vme_start &gt;&#x3D; end)\n                    break;\n            &#125;\n\n            entry &#x3D; next;\n\n            if (map-&gt;holelistenabled) &#123;\n                if (entry &#x3D;&#x3D; (vm_map_entry_t) map-&gt;holes_list) &#123;\n                    result &#x3D; KERN_NO_SPACE;\n                    goto BailOut;\n                &#125;\n                start &#x3D; entry-&gt;vme_start;\n            &#125; else &#123;\n                start &#x3D; entry-&gt;vme_end;\n            &#125;\n\n            start &#x3D; vm_map_round_page(start,\n                          VM_MAP_PAGE_MASK(map));\n        &#125;\n\n        if (map-&gt;holelistenabled) &#123;\n            if (vm_map_lookup_entry(map, entry-&gt;vme_start, &amp;entry)) &#123;\n                panic(&quot;Found an existing entry (%p) instead of potential hole at address: 0x%llx.\\n&quot;, entry, (unsigned long long)entry-&gt;vme_start);\n            &#125;\n        &#125;\n\n        *address &#x3D; start;\n    &#125; \n\n\n注意点1：基本上就是检查页的权限等，iOS上不允许可写和可执行并存。\n剩下的就是作各种前置检查。\n\n如果上述代码不够清晰明了，如下这段代码可以更加的简洁：\nentry &#x3D; map-&gt;first_free;\n\nif (entry &#x3D;&#x3D; vm_map_to_entry(map)) &#123;\n    entry &#x3D; NULL;\n&#125; else &#123;\n       if (entry-&gt;vme_next &#x3D;&#x3D; vm_map_to_entry(map))&#123;\n            entry &#x3D; NULL;\n       &#125; else &#123;\n            if (start &lt; (entry-&gt;vme_next)-&gt;vme_start ) &#123;\n                start &#x3D; entry-&gt;vme_end;\n                start &#x3D; vm_map_round_page(start,\n                              VM_MAP_PAGE_MASK(map));\n            &#125; else &#123;\n                entry &#x3D; NULL;\n            &#125;\n       &#125;\n&#125;\n\nif (entry &#x3D;&#x3D; NULL) &#123;\n    vm_map_entry_t    tmp_entry;\n    if (vm_map_lookup_entry(map, start, &amp;tmp_entry)) &#123;\n        assert(!entry_for_jit);\n        start &#x3D; tmp_entry-&gt;vme_end;\n        start &#x3D; vm_map_round_page(start,\n                      VM_MAP_PAGE_MASK(map));\n    &#125;\n    entry &#x3D; tmp_entry;\n&#125;\n\n\n整个这段代码的意思是，就是要我们要找个一个比我们这个 start 地址大的 vm_entry_t 。最终的目的是为了在两个已经存在 vm_entry_t 之间尝试插入一个能包含从 start 到 start + size 的新的 vm_entry_t。\n如果没找到的话，就尝试利用 vm_map_lookup_entry 找一个 preceding 我们地址的的 vm_entry_t 。\n\n当找到了一个满足 start 地址条件的 vm_entry_t 后，剩下就是要满足分配大小 size 的需求了。\nwhile (TRUE) &#123;\n    register vm_map_entry_t    next;\n\n    end &#x3D; ((start + mask) &amp; ~mask);\n    end &#x3D; vm_map_round_page(end,\n                VM_MAP_PAGE_MASK(map));\n    if (end &lt; start)\n        RETURN(KERN_NO_SPACE);\n\n    start &#x3D; end;\n    end +&#x3D; size;\n\n    if ((end &gt; effective_max_offset) || (end &lt; start)) &#123;\n        RETURN(KERN_NO_SPACE);\n    &#125;\n\n    next &#x3D; entry-&gt;vme_next;\n\n    &#x2F;&#x2F; 如果是空的头\n    if (next &#x3D;&#x3D; vm_map_to_entry(map))\n        break;\n\n    &#x2F;&#x2F; 如果下一个的start \n    if (next-&gt;vme_start &gt;&#x3D; end)\n        break;\n\n    entry &#x3D; next;\n    start &#x3D; entry-&gt;vme_end;\n    start &#x3D; vm_map_round_page(start,\n                  VM_MAP_PAGE_MASK(map));\n&#125;\n*address &#x3D; start;\nassert(VM_MAP_PAGE_ALIGNED(*address,\n               VM_MAP_PAGE_MASK(map)));\n\n\n判断 start + size 是不是可以正好插入在 vm_entry_t 代表的地址范围的空隙内，如果一直遍历到最后的任务地址上限都找不到，那就说明不存在我们需求的连续的虚拟内存空间用于作分配了。\n\n总结除了本文说明的虚拟内存分配的连续性限制以外，虚拟内存作为堆内存分配的一种，在布局范围上也有限制。更多详细的信息可参考如下链接。\n\nXNU\nMemory management\niOS内存管理\n理解 iOS 的内存管理\n\n","slug":"2019-01-22-iOS_VMManage","date":"2023-05-13T11:29:06.791Z","categories_index":"开发知识","tags_index":"开发知识 iOS"},{"id":"4e4a7be388e7ca1f326d22f43bf851ec","title":"从Keras开始构建iOS平台手写数字实时识别","content":"本文将介绍如何构建和训练一个深度学习网络来识别手写数字，以及如何将训练所得的深度网络模型转换为iOS平台的机器学习框架CoreML格式，并集成进iOS应用程序中以实时识别数字等。\n10步之内完成模型的构建、训练和发布使用TLDR；\n本文中暂时不会介绍卷积神经网络的细节内容，例如如何使用卷积层、池化层训练深度学习网络，以及如何使用预训练模型识别目标等，相关卷积神经网络细节的内容将会放在本文内容之后，进行详细的介绍。本文旨在介绍如何一步一步的从数据的获取、整理、模型的构建、训练以及后面的格式转换、使用等介绍Keras框架的基本使用和如何使用CoreML体系在一个实实在在的应用程序中使用模型等。\n下图是最终结果的预览：\n\n接下来，开始一步步的实现相关的过程等。\n1. 如何开始To have a fully working example I thought we’d start with a toy dataset like the MNIST set of handwritten letters and train a deep learning network to recognize those. Once it’s working nicely on our PC, we will port it to an iPhone X using the CoreML standard.\n在计算机程序设计学习的过程中，几乎都是以一个经典的“Hello World”程序开始的。而在机器学习领域，同样具有类似“Hello World”的一个经典入门级数据集——MNIST，该数据集是一系列手写数字0到9的图片文件，这里的目的是使用这个数据集训练一个深度学习网络来识别它们。在开始之前，你或许对iOS平台的CoreML以及keras还很陌生，你可以先了解一下它们的体系和设计：\n\nCoreML：\n\nCore ML | Apple Developer Documentation\n\nKeras：\n\nKeras 中文文档\n2. 获取数据在大多数的Python机器学习类库中，都有内置的数据集访问接口，以方便使用者的使用，在Keras中也不例外，可以很方便的使用其内置的数据集访问接口获取数据集，具体的接口定义在keras.datasets中，具体的使用如下：\n# 使用Keras内置数据集访问接口导入数据集并对数据集进行转换\n    from keras.datasets import mnist\n    from keras.utils import np_utils\n    from keras import backend as K\n    \n    def mnist_data():\n        # 定义输入图像的维度\n        img_rows, img_cols &#x3D; 28, 28\n        # 加载数据集\n        (X_train, Y_train), (X_test, Y_test) &#x3D; mnist.load_data()\n    \n        if K.image_data_format() &#x3D;&#x3D; &#39;channels_first&#39;:\n            X_train &#x3D; X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n            X_test &#x3D; X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n            input_shape &#x3D; (1, img_rows, img_cols)\n        else:\n            X_train &#x3D; X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n            X_test &#x3D; X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n            input_shape &#x3D; (img_rows, img_cols, 1)\n    \n        # 数据缩放，将原来的 [0, 255] 缩放至 [0, 1]\n        X_train &#x3D; X_train.astype(&#39;float32&#39;)&#x2F;255\n        X_test &#x3D; X_test.astype(&#39;float32&#39;)&#x2F;255\n    \n        # 对原始数据中的目标值进行One-Hot Encoding，使得目标数据更加的稀疏\n        Y_train &#x3D; np_utils.to_categorical(Y_train, 10)\n        Y_test &#x3D; np_utils.to_categorical(Y_test, 10)\n    \n        # 返回结果\n        return (X_train, Y_train), (X_test, Y_test), input_shape\n    \n    (X_train, Y_train), (X_test, Y_test), input_shape &#x3D; mnist_data()\n\n3. 正确地编码当处理图片数据的时候，必须要区分想要的编码方式。Keras是一个可以处理多个“后端”的高级库，例如Tensorflow, Theano 和 CNTK，首先我们要了解我们所使用的后端是如何编码数据的。在Keras默认使用的TensorFlow后端中，针对图像的处理通常是以“通道优先”或“通道末尾”的方式进行编码的，因此在我们的使用TensorFlow作为后端的时候，编码结果其实是一个张量，其形状为(batch_size, rows, cols, channels)。意味着首先是输入的batch_size，然后输入28行28列的图像维度，最后输入1作为通道数，因为我们使用的是灰度图像数据。\n我们可以看看前6张图像具体是什么样子，可以使用如下代码查看：\n# 可视化数据集中前6张图像\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    import matplotlib.cm as cm\n    import numpy as np\n    \n    (X_train, y_train), (X_test, y_test) &#x3D; mnist.load_data()\n    \n    fig &#x3D; plt.figure(figsize&#x3D;(20,20))\n    for i in range(6):\n        ax &#x3D; fig.add_subplot(1, 6, i+1, xticks&#x3D;[], yticks&#x3D;[])\n        ax.imshow(X_train[i], cmap&#x3D;&#39;gray&#39;)\n        ax.set_title(str(y_train[i]))\n    plt.show()\n\n\n4. 规范化数据可以看到，在黑色背景中显示了白色数字，每一张图像中的数字都是居中的，而且分辨率都很低——在这个例子中我们使用的是28x28像素。\n你可能已经注意到，在上述获取数据的部分，我们对每一张图片除以255来缩放了图像像素，这导致像素值在0和1之间，这对于任何类型的训练都非常有用。每个图像像素值在转换之前都是这样的：\n# 使用像素值可视化一个数字\ndef visualize_input(img, ax):\n    ax.imshow(img, cmap&#x3D;&#39;gray&#39;)\n    width, height &#x3D; img.shape\n    thresh &#x3D; img.max()&#x2F;2.5\n    for x in range(width):\n        for y in range(height):\n            ax.annotate(str(round(img[x][y], 2)),\n                        xy&#x3D;(y, x),\n                        horizontalalignment&#x3D;&#39;center&#39;,\n                        verticalalignment&#x3D;&#39;center&#39;,\n                        color&#x3D;&#39;white&#39; if img[x][y] &lt; thresh else &#39;black&#39;)\n\nfig &#x3D; plt.figure(figsize&#x3D;(12, 12))\nax &#x3D; fig.add_subplot(111)\nvisualize_input(X_train[0], ax)\nplt.show()\n\n\n可以看到图像中的每个灰度像素都是介于0到255之间的，并且当像素为255时，背景色为白色，像素为0时，背景色为黑色。在这里使用的是mnist.load_data()加载的数据集，此时并没有对图像进行像素缩放，而在我们自定义的数据集加载方法mnist_data()方法中，我们进行了像素的缩放，X_train = X_train.astype(&#39;float32&#39;)/255 。\n5. One-Hot 编码最初，数据以Y-Vector包含X Vector（像素数据）包含的数值的方式编码。例如，如果图像看起来像7，那么Y-Vector中必定包含数字7。但是这种方式不利于我们在网络结构中直接使用，我们需要进行这种转换，希望将数据的输出映射到网络中的10个输出神经元，此时当相应的数字被识别时，相应的神经元就会触发，从而达到有效的识别。\n\n6. 网络模型化了解了数据集的基本情况以及进行合理的数据转换后，该是定义卷积神经网络的时候了。这里讲直接使用卷积神经网络中的卷积层和池化层来定义网络，具体实现如下：\n# 定义网络模型\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.optimizers import Adadelta\n\ndef network():\n    model &#x3D; Sequential()\n    input_shape &#x3D; (28, 28, 1)\n    num_classes &#x3D; 10\n\n    model.add(Conv2D(filters&#x3D;32, kernel_size&#x3D;(3, 3), padding&#x3D;&#39;same&#39;, activation&#x3D;&#39;relu&#39;, input_shape&#x3D;input_shape))\n    model.add(MaxPooling2D(pool_size&#x3D;2))\n\n    model.add(Conv2D(filters&#x3D;32, kernel_size&#x3D;2, padding&#x3D;&#39;same&#39;, activation&#x3D;&#39;relu&#39;))\n    model.add(MaxPooling2D(pool_size&#x3D;(2, 2)))\n\n    model.add(Conv2D(filters&#x3D;32, kernel_size&#x3D;2, padding&#x3D;&#39;same&#39;, activation&#x3D;&#39;relu&#39;))\n    model.add(MaxPooling2D(pool_size&#x3D;(2, 2)))\n\n    model.add(Dropout(0.3))\n    model.add(Flatten())\n    model.add(Dense(500, activation&#x3D;&#39;relu&#39;))\n\n    model.add(Dropout(0.4))\n\n    model.add(Dense(num_classes, activation&#x3D;&#39;softmax&#39;))\n\n    # 模型概述\n    print(model.summary())\n    return model\n\n在模型的定义中，我们以内核大小为3的卷积，这也意味着窗口为3x3像素，输入形状的大小为28x28像素。紧跟着使用了一个池化大小为2的池化层，这里的池化大小为2，意味着将会对每一个输入缩减为原来的一般，因此在下一个卷积层中，输入大小为14x14像素。按照此方式重复两次后，最终的卷积输入大小转换为3x3像素。接下来，使用了Dropout层，将30%的输入单元随机设置为0，以防止训练的过拟合。最后，展平输入层（此例子中为3x3x32&#x3D;288），并将它们连接到一个具有500个输入的密度层。在这些步骤之后，添加了另一个Dropout层，之后连接到最后的密度层，该密度层中包含10个输出单元，这些输出单元对应着我们的目标类别，0到9之间的数字。\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 14, 14, 32)        4128      \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 7, 7, 32)          4128      \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 3, 3, 32)          0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 3, 3, 32)          0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 288)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 500)               144500    \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 500)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                5010      \n=================================================================\nTotal params: 158,086\nTrainable params: 158,086\nNon-trainable params: 0\n_________________________________________________________________\n\n7. 训练模型# 训练模型\nmodel &#x3D; network()\n# 编译模型\nmodel.compile(loss&#x3D;&#39;categorical_crossentropy&#39;, optimizer&#x3D;Adadelta(), metrics&#x3D;[&#39;accuracy&#39;])\n# 使用训练数据拟合模型\nmodel.fit(X_train, Y_train, batch_size&#x3D;512, epochs&#x3D;6, verbose&#x3D;1, validation_data&#x3D;(X_test, Y_test))\n# 模型评估分数\nscore &#x3D; model.evaluate(X_test, Y_test, verbose&#x3D;0)\n\nprint(&#39;Test loss:&#39;, score[0])\nprint(&#39;Test accuracy:&#39;, score[1])\n\n这里使用了categorical_crossentropy作为损失函数，因为我们的目标类别有多个（0至9），Keras库提供了多种优化器，你可以选择任意一个进行模型训练，并最终找到一个最好的。经过尝试之后，这里选择AdaDelta作为优化器进行模型训练，当然你也可以尝试AdaDelta的高级版AdaGrad。\n\n可以看到，经过训练，所得到的模型识别准确率达到了98%，考虑到这里仅仅使用了简单的网络结构，达到这样的准确率已经是非常出色了。在上述截图中，每次迭代的准确性都是在提高，可以说明这里使用的简单结构是合理的，训练得到的模型可以很好地预测输入28x28像素所表示的数字。\n8. 保存模型由于我们想要在iOS设备上使用该模型，因此需要将该模型转换为iOS系统能够理解的格式。实际上，微软、Facebook以及亚马逊等企业已经研发出了一套能够在所有深度学习网络格式见转换的协议，以便能够在任何设备上使用的可交换的开放式神经网络交换格式——ONNX。\n但是，截止目前，Apple设备上仅仅能够使用的是CoreML格式。为了能够将Keras模型转换为CoreML格式，Apple特意推出来一个非常方便的帮助类库——coremltools，这里我们就可以使用该类库来完成工作。该类库能够将scikit-learn、Keras、XGBoost等机器学习类库训练的模型转换为CoreML支持的格式，从而使得模型能够直接在Apple设备上使用。如果你还未安装coremltools类库，可以使用pip install coremltools进行安装，然后再使用。\ncoreml_model &#x3D; coremltools.converters.keras.convert(model,\n                                                        input_names&#x3D;&quot;image&quot;,\n                                                        image_input_names&#x3D;&#39;image&#39;,\n                                                        class_labels&#x3D;[&#39;0&#39;, &#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;, &#39;6&#39;, &#39;7&#39;, &#39;8&#39;, &#39;9&#39;]\n                                                        )\n\n在进行模型转换的时候，最重要的参数是class_labels，它定义了模型尝试预测的类数，以及input_names或者image_input_names。通过将它们设置为图像，Xcode会自动识别该模型是关于接收图像并从中预测某些内容，也就是说这些参数是告诉Xcode，该模型是关于那方面的任务。根据应用程序和模型的特定功能，需要研究官方文档进一步的了解这些参数的可选值等。\n另外还有一些可以定义模型元信息的参数，这些参数可以给模型一个简要的说明，甚至作者、license等，可以让使用者能够方便的查阅模型所针对的特定任务等。\n# 编辑模型元信息\ncoreml_model.author &#x3D; &#39;Robin&#39;\ncoreml_model.license &#x3D; &#39;MIT&#39;\ncoreml_model.short_description &#x3D; &#39;MNIST handwriting recognition with a 3 layer network&#39;\ncoreml_model.input_description[&#39;image&#39;] &#x3D; &#39;28x28 grayscaled pixel values between 0-1&#39;\ncoreml_model.save(&#39;SimpleMnist.mlmodel&#39;)\n\nprint(coreml_model)\n\n9. 使用模型预测在将模型保存为CoreML格式之后，我们可以尝试使用转换后的模型进行一个预测，来确定模型是否工作正常。在这里我们将从MNIST数据集中选择一张图像进行预测验证。\n # 使用CoreML模型预测验证\n from PIL import Image  \n import numpy as np\n model &#x3D;  coremltools.models.MLModel(&#39;SimpleMnist.mlmodel&#39;)\n im &#x3D; Image.fromarray((np.reshape(mnist_data()[0][0][12]*255, (28, 28))).astype(np.uint8),&quot;L&quot;)\n plt.imshow(im)\n predictions &#x3D; model.predict(&#123;&#39;image&#39;: im&#125;)\n print(predictions)\n\n输出结果：\n&#123;u&#39;classLabel&#39;: u&#39;3&#39;, \nu&#39;output1&#39;: &#123;u&#39;1&#39;: 0.0, \n                        u&#39;0&#39;: 0.0, \n                        u&#39;3&#39;: 1.0, \n                        u&#39;2&#39;: 0.0, \n                        u&#39;5&#39;: 0.0, \n                        u&#39;4&#39;: 0.0, \n                        u&#39;7&#39;: 0.0, \n                        u&#39;6&#39;: 0.0, \n                        u&#39;9&#39;: 0.0, \n                        u&#39;8&#39;: 0.0\n                        &#125;\n&#125;\n\n\n可以看到，预测过程和结果均符合预期。接下来是时候在Xcode项目中使用该模型了。\n10步完成模型在Xcode项目中的应用为了能够让几乎所有人了解机器学习模型文件是如何一步一步在Xcode项目中使用的，这里将会从最为基础的Xcode安装、项目创建等说起，如果你是iOS开发的老鸟，部分内容请自行略过。\n1. 安装Xcode对于iOS体系来说，Xcode是开发iOS应用程序必须的工具之一，因此如果你还未安装Xcode，需要安装Xcode，最为简单的方式是在Mac App Store中搜索并安装。如果你已经安装了Xcode，需要确保Xcode的版本至少在9.0或以上。\n2. 创建项目安装好Xcode之后，开启Xcode，选择iOS平台下的单视图应用，命名项目，这里命名为“MNIST-Demo”，选择一个保存项目文件的位置，创建项目即可。\n\n3. 添加CoreML模型文件现在，你可以将通过coremltools转换得到的CoreML模型加入到项目中了。最简单的方式是直接拖拽模型文件到项目目录中，如果为了之后更新模型而不用去删掉重新添加，你可以在弹出的选项框中选择“add as Reference”。\n\n4. 删除不需要的视图或者故事版因为我们仅仅使用相机并显示标签，因此这里会删除掉项目中默认的一些用户界面，也就是项目中的视图控制器和故事面板。当然你也可以选择不删除，直接使用现有的视图和故事面板进行开发，不论选择哪种方式都能达到目的。这里要注意的是，如果选择编码的方式构建应用，再删除了主故事面板文件后，需要在项目的TARGETS中同步删除”Main Interface”的默认设置。\n\n5. 程序化创建根视图控制器接下来我们将使用代码的方式，重新制定应用程序的根视图。具体如下：\n&#x2F;&#x2F; 通过编码的方式指定根视图控制器\nfunc application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplicationLaunchOptionsKey: Any]?) -&gt; Bool &#123;\n     &#x2F;&#x2F; 创建窗口\n     window &#x3D; UIWindow()\n     window?.makeKeyAndVisible()\n        \n     &#x2F;&#x2F; 指定根视图控制器\n     let vc &#x3D; ViewController()\n     window?.rootViewController &#x3D; vc\n        \n     return true\n&#125;\n\n6. 构建视图控制器细节接下来就是构建视图控制器的详细内容细节了。我们需要以下可交互的元素组件，例如按钮，也需要作为展示结果或者状态的标签等，另外重要的是，由于需要使用相机，因此AVFoundation类库是必须要添加的，该库用来访问和控制iOS设备上的相机，还需要Vision库，该库是iOS推出的用于计算机视觉相关任务的工具库，能够很好的和CoreML模型之间进行交互等。\n具体的代码细节，这里不再累述，完成之后的代码如下：\n&#x2F;&#x2F; 定义视图控制器\nimport UIKit\nimport AVFoundation\nimport Vision\n\n&#x2F;&#x2F; 由于要使用到相机设备进行视频流的输入，因此这里要继承AVCaptureVideoDataOutputSampleBufferDelegate协议\nclass ViewController: UIViewController, AVCaptureVideoDataOutputSampleBufferDelegate &#123;\n    &#x2F;&#x2F; 创建一个文本标签用来显示识别结果\n    let label: UILabel &#x3D; &#123;\n        let label &#x3D; UILabel()\n        label.textColor &#x3D; .white\n        label.translatesAutoresizingMaskIntoConstraints &#x3D; false\n        label.text &#x3D; &quot;Label&quot;\n        label.font &#x3D; label.font.withSize(40)\n        return label\n    &#125;()\n\n    override func viewDidLoad() &#123;\n        &#x2F;&#x2F; 调用相机设备设置方法、文本标签设置方法\n        super.viewDidLoad()       \n        setupCaptureSession()\n        view.addSubview(label)\n        setupLabel()\n    &#125;\n\n        &#x2F;&#x2F; 设置相机设备session\n    func setupCaptureSession() &#123;\n        &#x2F;&#x2F; 创建一个新的捕获session\n        let captureSession &#x3D; AVCaptureSession()\n\n        &#x2F;&#x2F; 查找可用的相机设备\n        let availableDevices &#x3D; AVCaptureDevice.DiscoverySession(deviceTypes: [.builtInWideAngleCamera], mediaType: AVMediaType.video, position: .back).devices\n\n        do &#123;\n            &#x2F;&#x2F; 选择首个设备并设置为输入源\n            if let captureDevice &#x3D; availableDevices.first &#123;\n                captureSession.addInput(try AVCaptureDeviceInput(device: captureDevice))\n            &#125;\n        &#125; catch &#123;\n            &#x2F;&#x2F; 如果未找到相机设备，则打印错误信息\n            print(error.localizedDescription)\n        &#125;\n\n        &#x2F;&#x2F; 将视频输出设置到屏幕并将输出添加到我们的捕获会话\n        let captureOutput &#x3D; AVCaptureVideoDataOutput()\n        captureSession.addOutput(captureOutput)\n        let previewLayer &#x3D; AVCaptureVideoPreviewLayer(session: captureSession)\n        previewLayer.frame &#x3D; view.frame\n        view.layer.addSublayer(previewLayer)\n\n        &#x2F;&#x2F; 缓冲视频并启动捕获会话\n        captureOutput.setSampleBufferDelegate(self, queue: DispatchQueue(label: &quot;videoQueue&quot;))\n        captureSession.startRunning()\n    &#125;\n\n    func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) &#123;\n        &#x2F;&#x2F; 加载Core ML 模型\n        guard let model &#x3D; try? VNCoreMLModel(for: SimpleMnist().model) else &#123; return &#125;\n\n        &#x2F;&#x2F; 使用Core ML运行推理\n        let request &#x3D; VNCoreMLRequest(model: model) &#123; (finishedRequest, error) in\n\n            &#x2F;&#x2F; 捕获推理结果\n            guard let results &#x3D; finishedRequest.results as? [VNClassificationObservation] else &#123; return &#125;\n\n            &#x2F;&#x2F; 捕获得分最高的推理结果\n            guard let Observation &#x3D; results.first else &#123; return &#125;\n\n            &#x2F;&#x2F; 构建最终显示的文本格式\n            let predclass &#x3D; &quot;\\(Observation.identifier)&quot;\n\n            &#x2F;&#x2F; 显示在文本标签内\n            DispatchQueue.main.async(execute: &#123;\n                self.label.text &#x3D; &quot;\\(predclass) &quot;\n            &#125;)\n        &#125;\n\n          &#x2F;&#x2F; 创建一个核心视频像素缓冲区，它是一个图像缓冲区，用于保存主存储器中的像素生成帧，\n                &#x2F;&#x2F; 压缩或解压缩视频或使用核心图像的应用程序都可以使用核心视频像素缓冲区\n        guard let pixelBuffer: CVPixelBuffer &#x3D; CMSampleBufferGetImageBuffer(sampleBuffer) else &#123; return &#125;\n\n        &#x2F;&#x2F; 执行请求\n        try? VNImageRequestHandler(cvPixelBuffer: pixelBuffer, options: [:]).perform([request])\n    &#125;\n\n    func setupLabel() &#123;\n        label.centerXAnchor.constraint(equalTo: view.centerXAnchor).isActive &#x3D; true\n        label.bottomAnchor.constraint(equalTo: view.bottomAnchor, constant: -50).isActive &#x3D; true\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\n如果你直接使用上述代码，请记得修改模型的名称。\n\n6. 添加隐私说明信息由于我们要使用相机设备进行视频数据流的获取，因此需要在Xcode工程项目中的info.plist文件中添加相应的权限申请说明“Privacy - Camera Usage Description”，并附带相应的说明性文字：\n\n7. 加入苹果开发者计划为了能够让该应用程序运行在你的手机设备上，你可能需要注册苹果的开发者计划。当然如果你不想为了运行项目而花费金钱，你也可以按照此教程注册免费的账户。\n8. 在iPhone设备上发布应用一切准备好之后，你就可以将该应用程序发布到你的手机设备上了。你可以按照如下图所示的方式发布项目，也可以直接在Xcode中选定目标设备，然后使用快捷键CMD+R的方式构建：\n\n9. 使用应用程序经过上述各种设置和编码之后，终于可以在设备上运行我们的应用程序了。如果一切正常，首次应用程序启动的时候，会询问你是否允许应用程序访问设备的相机，这里需要允许，否则我们的应用程序则无法正常工作。\n另外，我们这里所训练的模型以及制作的应用程序，没有进行详细的设计和优化，在识别的过程中，可能会遇到识别不出来以及识别错误的情况，如果需要将此功能应用在你的产品中，需要严格重新审查你所拥有的数据，以及模型的训练，app的使用等，以免出现不可预知的错误等问题。\n\n总结通过这篇文章，希望能够让你了解如何使用Keras训练所需要的模型，以及如何将其应用在iOS平台下的应用程序中，虽然介绍的不够深入，但是希望能够带给你继续深入理解Keras、了解Core ML的欲望，早日在你的应用程序中实现AI的能力，为你的应用程序增添色彩。\n","slug":"2019-01-22-keras_mnist_for_iOS","date":"2023-05-13T11:29:06.791Z","categories_index":"机器学习","tags_index":"机器学习 Keras MNIST"},{"id":"db6fdca23b371a06d21cf5b1b5c1c533","title":"《禅与摩托车维修艺术》之良质","content":"美国作家罗伯特·波西格（Robert M Pirsig）的《禅与摩托车维修艺术》，是一部奇特而有趣的哲学读物，作者进行了大量科学技术哲学以及其他哲学方面的讨论，见解独特而又机智。又是一部心灵自传，在与西方两千年来哲学传统的深入理解与争辩中，作者一度精神上不堪重负，但最终寻找到了生命的意义并完成了自我拯救。正是作者这种洒脱通达的人生观，让整本书亲切而又富有乐趣。\n\n作者：罗伯特·M.波西格（1928-2017，Robert M. Pirsig）大学时主修生物化学，后来对哲学产生兴趣，1950年前往印度学习东方哲学。回国后，在当地大学担任写作课教师。1961年，他被诊断为偏执型精神分裂症和临床忧郁症，被多次送进精神病院，接受过28次电击疗法。\n1968年出院后，他带着10岁的儿子克里斯，进行了一次长途摩托车旅行。他把旅行的感受和思考，写成了一本书《禅与摩托车维修艺术》（Zen and the Art of Motorcycle Maintenance）。\n简介\n该书一半是游记，讲述一对父子的一次摩托车旅行，从明尼苏达州一直到加州，耗时17天；另一半是哲学讨论，作者剖析自己的思想，寻求心灵的答案。两种文体交织在一起，维基百科称它为”哲学小说”。\n由于连续被121家出版社拒绝，直到1974年，这本书才出版。但是出版后，销售量惊人，超过500万册，成为70年代美国十大畅销书之一，目前累计销售量已经超过1000万册。《吉尼斯世界纪录》称它是”世界上被拒稿次数最多的畅销书”。\n此书在国内有两个中文版：《父子的世界》（中国友谊出版公司，黄欣译，1999）和《万里任禅游》（重庆出版社，张国辰译，2006）。后面一个版本，2011年9月已经再版了，并且终于将书名改成原名了。\n\n禅与摩托车\n这两个词都是象征。”禅”象征一个人内心的心灵探索，是主观哲学思考；”摩托车”象征科学技术，是客观的外部存在。作者把它们放在一起，就是暗示这本书讲的是，如何将主观和客观统一起来，正确地认识自我和外部世界，达到一种和谐存在的境界。\n\n禅与良质关于“良质”的定义，作者没有明确地讲，也拒绝下定义。”不可说”，这也是书名为什么要冠名以“禅”，因为禅，不可说，一说就错。\n良质即是卓越。这里卓越不是指成功，卓越是对自己的要求，拿自己跟自己比。卓越是一种进取心，同时卓越也是一种态度，用心投入所做事情的态度。\n\n\n\n\n\n\n\n\n\n比如，你做一个锤子，每一道工序你都用心雕琢，材料选择恰到好处，锤子做出来坚固耐用。这个做锤子的过程便是良质。与此同时你也为这把锤子注入了良质，这把锤子不仅仅是一把普通的锤子，而是一把被你用心投注态度的好用耐用的锤子。\n所以，在良质面前，没有二元论，没有关于唯物和唯心的辩证法。心与物都被良质融于一体。一切都可以用良质的和不是良质来划分。\n\n\n\n\n\n\n\n\n\n你在宜家买了一个39块的拉克桌，轻巧耐用，物美价廉，这就是良质，其背后设计师的设计也是一种良质。\n换一种说法，可以说良质是一种用心工作的态度。稻盛和夫在《活法》里就讲到了类似的精神，即工作中有神灵。用心工作，神灵是能够看见的。而这种专注于工作，专注于眼前事情的态度，便是良质。\n生活中处处都可以看到良质，比如一把非常好写字的笔，一个手感舒服且耐用的键盘，一把坚固且舒适的椅子，干干净净的地面和整整齐齐的衣柜。生活中的用心之处无一不见良质。\n在代码的世界里，良质是正确的，稳定的，简单优雅的代码。\n重复的代码不是良质，因为它带来了重复的代码，不够简单，可能会是bug滋生的温床。低效率的代码也不是良质，因为它带来了低效和浪费，代表了没有对问题进行深入的思考。\n根据《程序员修炼之道》和《重构》的说法，不是良质的代码总有一股“坏味道”。而一个有良质精神的程序员总能嗅到这股“坏味道”，然后将其改成好的代码，这个过程就是重构。\n作者有个美好的期盼，就是通过个人的良质，逐步传播开来，形成一个充满了良质的社会。\n我也有个美好的期盼，就是程序员们都能拥有良质，这样bug会减少，代码将更加简单易读，世界也将更美好。\n摘录\n当你做某件事的时候，一旦想要求快，就表示你再也不关心它，而想去做别的事。（慢慢来，不要急于求成和仓促行事）\n我猜想拥有更深刻的了解就会对螺丝有新的评价。如果你把注意力集中在这上面很长一段时间，那么你可能会发现，螺丝并不只是属于某一类物体，它更有自己独特的个性。如果你再深入研究，就会发现螺丝并不单单只是螺丝，它代表一组功能。于是你原先被卡住的现象就会逐渐消失，同时也消除了传统理性的模式。（不要因为螺丝小而忽略它，而要理解它的功能和它背后带来的影响。）\n我们对别人指责最严苛之处，就是我们最害怕自己的地方。\n如果你有正确的态度就不难，难的是有正确的态度。\n\n\n\n良质的陷阱\n外在环境迫使放弃了良质（挫折）\n\n内在因素迫使放弃了良质（忧虑）\n\n对于挫折的应对策略：\n\n将难题分解，写下每一个小的步骤\n重新审视问题。静下心来，不要急，急则容易出错\n问题解决后需要进行复查和总结，以确定问题真的被解决和从中的经验教训\n\n\n内在因素：\n\n价值一旦僵化，遇到问题时，就不会转变思路或者接受其他做法。\n如果自视甚高，则容易犯错。\n焦虑会导致拖延，拖延又会导致焦虑，这是一种恶性循环。  想要打破这种恶性循环，就应该把自己的焦虑写下来，然后告诉自己，没有哪一个人是不犯错的，然后勇敢去做。\n觉得厌倦的时候，放下工作，去放松，去休息，去尝试冥想（打坐，什么也不去想，放空）。\n\n\n\n\n\n","slug":"2019-03-07-zen","date":"2023-05-13T11:29:06.791Z","categories_index":"读书小记","tags_index":"读书小记"},{"id":"2d699b2c1e0ab59b8228bca658a563da","title":"iOS开发隐藏技能如何开启","content":"在iOS的开发过程中，我们经常会遇到一些需要关心但是无法直接得到的信息，本文记录了一些能够开启IDE隐藏功能的方法，帮助开发者了解更多的信息等。\n1. 在 Xcode 中追踪构建时间在使用Xcode进行项目的编译和打包的时候，总是耗时的，而这个时间Xcode本身是具有统计功能的。如果需要查看此时间，需要开启Xcode的ShowBuildOperationDuration选项，打开命令行工具，直接输入如下命令即可。\ndefaults write com.apple.dt.Xcode ShowBuildOperationDuration -bool YES\n\n开启后，Xcode的构建完成后，会在Xcode的状态栏显示本次构建的耗时。\n\n\n\n\n2. 改善 Swift 项目构建时间在 Xcode 9.2 的发布说明中提到了一个可以改进Swift项目构建时间的实验性功能，可以通过开启BuildSystemScheduleInherentlyParallelCommandsExclusively来实现提速。\n\n开启方式也是通过命令行工具，输入如下命令开启：\ndefaults write com.apple.dt.Xcode BuildSystemScheduleInherentlyParallelCommandsExclusively -bool NO\n\n如果要关闭此功能，输入如下命令即可：\ndefaults delete com.apple.dt.Xcode BuildSystemScheduleInherentlyParallelCommandsExclusively\n\n\n\n\n\n\n\n\n\n\n！！！重要：根据发布说明，这是一个实验性功能，会在项目构建期间增加内存使用量。\n3. 在全屏模式下同时使用Xcode和模拟器在Xcode全屏的情况下，如果需要同时使用模拟器在Xcode 9以前是很难实现的，但是在Xcode 9 以上，我们可以做到这样。我们只需要在命令行中输入如下的命令来开启这个功能即可：\ndefaults write com.apple.iphonesimulator AllowFullscreenMode -bool YES\n\n完成后，如果我们在全屏模式下使用Xcode + 模拟器就很轻松了。如下：\n\n如果你想在模拟器中使用更多的Apple为公开的隐藏功能，你需要启用Apple隐藏的内部菜单。为此，您需要在根目录中创建一个名称为“AppleInternal”的空文件夹（详解）。只需在下面运行此命令并重新启动模拟器：\nsudo mkdir &#x2F;AppleInternal\n\n如果上述命令输入后，出现权限问题。可参考下图中的步骤：\n\n最终你可以在模拟器菜单中发现一些新的功能特性（下图仅为部分功能）：\n\n更多关于sdsds的介绍可参考：一条命令让您的 macOS 用 Touch ID 授权 sudo！\n4. 捕获iOS模拟器视频如果需要针对模拟器视图进行截图或者录视频，你可以使用xcrun command-line工具，其命令格式如下：\nxcrun simctl io booted recordVideo &lt;filename&gt;.&lt;file extension&gt;.\n\n例如，如果要录视频，对应的命令如下：\nxcrun simctl io booted recordVideo appvideo.mov\n\n在录制的过程中，你可以按下Control + c 来停止录制，文件保存的位置就在当前的目录中。\n5. 从Finder将文件共享到Simulator从 Xcode 9 开始，所有的模拟器便具有了Finder的扩展功能，可以让你从Mac的Finder直接共享文件到模拟器，对应的菜单在文件上右键 -&gt; 分享 中：\n\n当然，还有一种更为简单的共享方式，直接拖拽文件到模拟器即可完成共享。另外也可以使用下面的simctl命令对图像&#x2F;视频文件做类似的操作：\nxcrun simctl addmedia booted &lt;PATH TO IMAGE&#x2F;VIDEO&gt;\n\n6. 使用指纹授权sudo本方式仅针对具有Touch Bar的Macbook Pro。如果你想使用你的指纹来授权sudo，可以在命令行中输入如下命令：\nsudo sed -i &quot;.bak&quot; &#39;2s&#x2F;^&#x2F;auth       sufficient     pam_tid.so\\&#39;$&#39;\\n&#x2F;g&#39; &#x2F;etc&#x2F;pam.d&#x2F;sudo\n\n然后输入管理员密码，回车即可。现在可以使用你的指纹进行sudo了，想象都激动。\n7. 使用声音通知调试AutoLayout约束在调试AutoLayout约束的时候，你可以通过声音通知的方式来提醒AutoLayout约束是否合规。使用此项功能，只需要在Xcode项目中增加UIConstraintBasedLayoutPlaySoundOnUnsatisfiable参数即可，增加后，如果AutoLayout约束出现异常或者冲突，会有提示声音：\n-_UIConstraintBasedLayoutPlaySoundOnUnsatisfiable YES\n\n\n8. 从Xcode中移除不可用的模拟器这个命令将从Xcode中删除所有不可用的模拟器。这里的“不可用”表示模拟器和Xcode的xcode-select版本不相符导致的模拟器不可用：\nxcrun simctl delete unavailable\n\n\n","slug":"2019-03-08-iOS_Tips","date":"2023-05-13T11:29:06.791Z","categories_index":"开发知识","tags_index":"开发知识 iOS"},{"id":"09ad77e68bf4944e7f633c8fdb014fd1","title":"什么是决策树","content":"决策树(Decision Tree）是在已知各种情况发生概率的基础上，通过构成决策树来求取净现值的期望值大于等于零的概率，评价项目风险，判断其可行性的决策分析方法，是直观运用概率分析的一种图解法。由于这种决策分支画成图形很像一棵树的枝干，故称决策树。在机器学习中，决策树是一个预测模型，他代表的是对象属性与对象值之间的一种映射关系。Entropy &#x3D; 系统的凌乱程度，使用算法ID3, C4.5和C5.0生成树算法使用熵。这一度量是基于信息学理论中熵的概念。决策树是一种树形结构，其中每个内部节点表示一个属性上的测试，每个分支代表一个测试输出，每个叶节点代表一种类别。分类树（决策树）是一种十分常用的分类方法。他是一种监管学习，所谓监管学习就是给定一堆样本，每个样本都有一组属性和一个类别，这些类别是事先确定的，那么通过学习得到一个分类器，这个分类器能够对新出现的对象给出正确的分类。这样的机器学习就被称之为监督学习。\n什么是决策树？有的人可能听过一个词：CART，这个代表的意思是Classification And Regression Tree。它是一个分类和回归的决策树。它被分为两类，一类是分类决策树(Classification Trees)，另一个类是回归决策树(Regression Trees)。也就是我们要用这个决策树解决两类问题，一个分类问题一个回归问题。\n\n对于分类决策树，一般来说用于一些分类离散的数据，比如说人的性别是男或者女，水果的种类有苹果梨子等等都是离散的。反之回归决策树，那么对应的场景就是连续的数据，比如人的年龄或者室外的温度。当我们进行分类问题时，分类的组之间是无序的。这里首先介绍下什么是有序，可以举个例子比如年龄，又年龄大或者年龄小。那么对于性别问题，男或女，它是没有顺序的。本文要讲的是分类问题在决策树上的应用。\n来看个例子，在一个二维平面上有两个颜色分组的数据，我们要用决策树算法来构建分类器。这里的决策树算法要做的事情就是不断用水平和竖直的线不断对平面进行分隔，直到某一个区域类只有红类或者绿类。如图所示，我们画出几条线对平面进行分隔。\n\n这样图中的红组和蓝组的数据点就被这些数据分隔开来了，但这组数据是为了方便展示而特地画成这个样子的，实际情况并不一定会出现这种比较清晰的分割线。那我们先看看第一条分割线，将其分割成了上下两块区域，虽然两边都是既有红色又有蓝色，但我们可以说分类的结果还是比较纯的。用复杂点的数学语言来说就是，我们正在寻找一条分隔线，可以是水平的也可以是竖直的，我们想要做一个优化的问题，需要最小化分隔后的基尼不纯度。什么叫纯，指的是分隔后的一边如果只有红点或者绿点，那么可以说这个分隔的结果是非常纯的，那么如果两边既有红也有蓝，那么就是不纯的。我们希望当我们添加一条分割线后，想要将两边的纯度和最小化。那么每一条的分割线的寻找实际上就是在做一个优化的问题，那么优化的对象可以是基尼不纯度，也可以是信息学中的熵。这里不做过多解释，只是展示下决策树是如果运作的。\n画出第一条分隔线后如图可以得到两组分类结果，一个是x2小于或者不小于60，再然后我们画出第二条分割线，看出x1&lt;50是绿组，否则就是红组，接着再画出第三条分割线，x1&lt;70都是红组，再对x1&gt;70分隔，得出红组和绿组数据。\n\n如图其实就是上述所说的工作流程，我们得到的每一片叶子都是比较纯的结果，如果在实际实际生活中，数据可能非常复杂，那么我们的树可能就非常非常大，枝节非常非常多。那么有的时候，有的枝节不一定非要到最后知道yes or no，也许可能在前面某个枝节就停止了。比如对于x2&lt;20这里不再继续分割，假设有个新的数据点落在了这个区域，它落在绿色的区域的概率比落在红色的概率要大，那么我们就可以把这一部分都划分到绿色组中，也就是说可以剪掉多余的枝节，也许它对于训练集是有意义的，但对于更多其他的数据来说，它可能就是个噪音，我们不需要知道这么详细的信息。那最终就没有这两片叶子，到前面一步就结束了。\n决策树算法是个很经典的机器学习算法，很多年以前是比较流行的。但到了20世纪初已经逐渐被其他算法所取代。直到最近又发现这个算法中一些新的精妙的东西，比如说随机森林，就是以决策树为根本来展开的。还有提升梯度(Gradient Boosting)等等都是在决策树算法之上我们加上了一些新的元素。\n代码实现由于这次决策树算法，我们没有使用欧式距离，也就是说可以不用进行特征缩放。但最终画图像时之前模版中定义的步距可能就过大或者过小，所以这里就妥协一下保留特征缩放的代码。分类器改成决策树算法的DecisionTreeClassifier。这个方法的参数criterion指的就是标准，默认gini，即基尼指数或者说基尼不纯度。它和熵都是表示分类时划分质量的好坏。这里我们使用熵。其他的参数暂时用不到,random_state依然只是用来大家如果想得到相同的结果时就设置为相同的值即可。\nfrom sklearn.tree import DecisionTreeClassifier\nclassifier &#x3D; DecisionTreeClassifier(criterion&#x3D;&#39;entropy&#39;,random_state&#x3D;)\nclassifier.fit(X_train, y_train)\n\n随机森林在开始讲随机森林之前我们先讲一个更为广义的概念: Ensemble Learning，集成学习。它的意思是我们使用多个分类器对我们的结果进行预测，最后再对分类结果进行一个组合，以达到最终的结果。这个组合的方式有很多种，比如平均，加权平均或者投票等等。这个集成学习的作用就是，我们觉得任何一个单独的分类器去分类结果回感觉有误差，这时可以用成百上千个分类器都进行预测，然后再对结果进行一个组合，可以减少预测结果的浮动率。下面来看看随机森林算法的步骤。\n首先，随机采用训练集合中的数据，相当于装袋的过程，构建自己新的训练集；然后用这些数据训练决策树分类器；再然后实际上就是重复第一第二步，但每一次得到的结果是不同的，因为在第一步中我们取得的数据都是随机的。对于一个新的数据点，我们用已经训练好的多个训练器分别对这个新数据的分类进行预测，最后进行一个投票，拥有最大投票数量的分类结果胜出就使用这个分类结果。\n\n前文讲述了如何构建一棵决策树，现在拥有成百上千棵决策树来帮助我们解决分类问题。这个分类算法还有不少数学上的一些细节问题，比如Boosting(提升)，还有当我们有高维度的情况时，我们每次选取数据时可能只选取部分维度，这样可以避免个别维度比其他维度大的多情况。\n代码实现这里依然开始先套用分类的模版，然后换成随机森林分类器，这里的参数n_estimators指的是决策树的数量,这里暂时设置成10 criterion依然设置为entropy。\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier &#x3D; RandomForestClassifier(n_estimators&#x3D;10, criterion&#x3D;&#39;entropy&#39;, random_state&#x3D;0)\nclassifier.fit(X_train, y_train)\n\n通过结果观察，这里使用随机森林分类器是会出现过拟合的情况。对比这几篇文章中的分类器，实际上最适合的是核svm和朴素贝叶斯，线性分类器准确度不够，随机森林分类器会出现过拟合，而这两者它们保证了拟合的准确率，并且也不会出现过拟合的问题。\n","slug":"2019-03-14-cart","date":"2023-05-13T11:29:06.791Z","categories_index":"机器学习","tags_index":"机器学习"},{"id":"f1227f6f63d3c96fb5fd23a95f0b0cbd","title":"软技能 --- 代码之外的生存之道","content":"本文是《软技能：代码之外的生存指南》一书的读书笔记，内容大部分都是原文的摘录，因为个人觉得原文中的一些语言更能够体现其本质，一旦泛化了，可能就不是那么的贴切了。这本书在我的书架上已经躺了很久了，与其说没有时间去读，其实也是关于技能提升的书籍几乎琳琅满目，暂时无暇顾及而已，最近一口气通读了本书，也是受益匪浅，对于以往不重视或者不在考虑范围之内的一些事情也有了一点感悟。\n图书简介这是一本真正从“人”（而非技术也非管理）的角度关注软件开发人员自身发展的书。书中论述的内容既涉及生活习惯，又包括思维方式，凸显技术中“人”的因素，全面讲解软件行业从业人员所需知道的所有“软技能”。本书聚焦于软件开发人员生活的方方面面，从揭秘面试的流程到精耕细作出一份杀手级简历，从创建大受欢迎的博客到打造你，从提高自己工作效率到与如何与“拖延症”做斗争，甚至包括如何投资不动产，如何关注自己的健康。本书共分为职业篇、自我营销篇、学习篇、生产力篇、理财篇、健身篇、精神篇等七篇，概括了软件行业从业人员所需的“软技能”。通过阅读本书，软件工程人员、编程人员和其他技术人员能够积极思考自己的职业生涯，丰富自己的生活，让自己更接近成功。\n\n\n    标题：《软技能：代码之外的生存指南》\n    作者：John Sonmez \n    译者：王小刚 \n    评分：8.1\n\n\n    \n\n第一章 职业你犯的最大的错误就是相信自己为别人工作，工作是属于公司的，但是职业生涯是属于你自己的。\n第二章 从非同凡响开 始：绝不要做他人都在做的事开发人员最大的错误，就是没有把自己的软件开发事业当做一桩生意来看待，其实进入代码世界的时候和中世纪的木匠没啥区别，时代变了而已。大多数人为公司工作，但是我们的技能和生意都还是自己的，我们随时都能换个地方另起炉灶。\n拥有商业心态？\n尽管你在职业生涯的某个阶段里，你可能确实在某家公司打工，但是千万不要那个特定的角色固化了你和你的整个职业生涯。 把雇主当成你的软件开发企业的一个客户。\n如何像企业一样思考？\n大多数企业都都需要以下几样东西： 产品，服务。 一般软件开发人员卖的就是软件开发的服务（创建软件）。你需要做到：\n\n专注于你正在提供怎样的服务，以及如何营销这项服务\n\n想方设法提升你的服务\n\n思考你可以专注为哪一特定类型的客户或行业提供特定的服务\n\n集中精力成为一位专家，专门为某一特定类型的客户提供专业整体服务（记住，作为一个软件开发人员，你只有真正专注于一类客户，才能找到非常好的工作）\n\n\n大多数成功的公司都会开发出让客户主动上门购买的产品或服务，它们才不会一个接 一个地追逐客户。\n第三章 思考未来，你的目标是什么现在你已经把你的软件开发职业当做是一个商业活动，那么，是时候着手定义你的业务目标了。\n如果没有确定自己的目的地，你永远都不会取得实质性的进展。一旦明确了目的地，你就会向着目标全力以赴。\n如何设定目标？\n起步阶段最简单的就是在心中树立一个大目标，然后再建立能帮你达成这个大目标的小目标。\n想一想你的职业生涯的终极目标：\n\n想成为一家公司的经理或主管？\n\n想在某一天走出去开拓自己的软件开发业务？\n\n想成为一名企业家创建自己的产品并将其推向市场？\n\n\n追踪你的目标？\n你应该定期追踪并更新自己设定的目标，必要时还要调整。定期核对自己的目标。这有助于在必要时进行调整，让你对自己负责。你可能愿意在每周末为下一周设定目标之前先检查上周设定的目标。这同样适用于每月、每季和每年。\n第四章 人际交往能力：远比你想象的重要别管我，我只想一个人安静的写代码？\n我曾经对软件开发人员的工作的印象就是写代码。事实是，在软件开发领域，我们大多数时候是与人而非与计算机打交道，甚至我们所写的代码首先是供人使用的，其次才是让计算机可以理解的。\n如果你还是觉得自己的工作就是写写代码，那你最好要三思。作为一个软件开发人员，你的工作就是与人打交道（其实几乎所有的职业都是这样）。\n学会如何与人打交道？\n\n每个人都希望感到自己很重要\n\n永远不要批评\n\n换位思考\n\n避免争吵\n\n\n第五章 破解面试之道通过面试的最快捷的方式？\n通过面试的最快捷的方式是让面试官对你有好感。达成该目标有很多方法，其中大多数可以在面试之前完成。\n突破陈规，建立融洽关系？\n大量工作岗位来自“个人推荐”。\n但是，如果你在申请的公司里谁都不认识，怎么办？你可以找这家公司工作的开发人员的博客，并与他们建立了联系。于是当有新工作岗位时，获得他们的推荐也就轻而易举。\n真正的面试会怎么样的？\n如果顺利的话，在你走进面试间的时候，面试官已经知道你是谁了，接下来要关注的事情就是自信地展现自己的能力——知道要获得这份工作需要做什么，做就是了。\n你还必须要证明：在技术上你确实胜任工作。\n当下你能做什么？\n\n保持技术能力，阅读技术书籍，博客文章\n\n扩展自己的社交网络\n\n实战，实战，实战\n\n\n第六章 就业选择：列出你的选择选择1. 雇员\n\n选择2. 独立咨询师\n\n选择三，创业者\n定义：软件开发创业者使用自己的软件技能开发自己的产品、拓展自己的业务。\n\n到底选择哪一个？\n职业生涯的起步阶段“雇员”是一个明智的选择，选择什么完全取决于你自己，你也可以随时切换路径。\n第七章 你是哪类软件开发人员专业化是非常重要\n身为“专才”后，潜在雇主和客户群都变小了，但是实际上你对他们更具吸引力了。只要你专业能够雄厚，市场没有过渡饱和，与那些自称为“软件开发人员”的人相比，你能更轻松地找到工作或者赢得客户。\n在一个专业方向上拥有专长\n\n\n\n\n\n\n\n\n\n注意：专业化的规则是：专业化程度越深，潜在的机会就越少，但获得这些机会的可能性越大。\n开发人员的专业类型\n\nWeb开发\n\n嵌入式系统\n\n特定的操作系统\n\n移动开发\n\n框架\n\n软件系统\n\n\n选择你的专业？\n\n在你现在或以前的公司里，有哪些主要的痛点？你能成为一名专门解决这些疼点的专家吗？\n\n有没有一种特定的工作是无人能做，或者缺乏经验丰富的人？成为这个领域的专家，你会得到大量的业务\n\n在各种会议上或者用户组中那些话题最长出现？\n\n哪类问题你回复的最多，无论是同事还是答问上？\n\n\n精通多种语言的程序员该怎么办？\n团队里有一个全能的开发人员是件好事，但是很少有公司或客户会去寻找这样的人才。\n第八章 公司与公司是不一样的在接收一份工作之前考虑是很重要，从薪资和福利的角度评价一个潜在的工作机会很容易的，但是长期发展和工作环境的角度评价可能对你更为重要。\n公司分类：\n\n小公司或创业公司：职责多，工作内容不稳定，自己工作成就对公司影响很大（好，坏），第一批员工可能得到更大的回报（股票，提升等）\n\n中等公司：角色很明确，你也会很稳定。缓慢而稳健的做事风格通常能占的先机，大多数中等公司讨厌风险。\n\n大公司：大量的规范和流程，成长机会，培训机会，提供各种软件产品使用，技术创新，你可能负责很少的一部分代码或者模块，办公室政治\n\n\n\n\n\n\n\n\n\n\n\n注意：我不建议为了“中彩票”而选择去创业公司。如你喜欢快速节奏，兴奋的工作环境，也希望构建伟大的产品并见证它的成长，那你可以试试。\n软件开发公司&amp;&amp;非软件开发公司\n建议：我们尽量选择软件开发公司，可以得到尊重，发展空间，最近技术。\n第九章 攀登普升阶段承担责任\n在任何公司里能让你脱颖而出的最重要法宝就是承担更多的责任。金钱总是跟随着责任。有任何机会去承担更多责任时，承担起来！\n如何能让自己承担更多的责任？\n\n有一个不受重视的项目，你能去负责它吗？\n\n你能帮助团队里的新人快速成长吗？\n\n你能负责文档制作流程，并保证及时更新这些文档吗？\n\n那些工作是没有人愿意去做，你愿意承担起来，并将其简化或者自动化吗？\n\n\n引入注目\n\n每天都记录自己的活动日志–把这个日志以及周报的形式发送给领导。\n\n提供演讲或培训–选择一个对你的团队有用的话题\n\n发表意见–只要在会议上就这么做，或者只要你能得到的机会就这么做。\n\n保证”曝光度“–定期与老板会面，确保你经常被注意到。\n\n\n自学\n\n不断的学习，这样你的价值不断的提升。如考证书等\n\n不要只学软件开发，你还得学领导力，管理和商科的有关知识。\n\n分享自己学到的东西。\n\n\n成为问题的解决着\n要成为那个永远能为各种问题找到解决方案的人。要成为勇敢执行这些解决方案以获得成果的人。\n如果你解决”别人无法解决或不愿意解决的问题“，无论你在哪一家公司都会得到重视。\n如果如果:没有这样的机会咋办？答案：辞职换工作。\n关于办公室政治\n应该对所在的组织的政治气候保持警觉。尽管不能完全避开，但至少应该知道会发生什么，那些人需要避开，那些人永远不要交集。\n第十章 成为专业人士成为专业人士是一种心态。\n成为专业人士的全部在于：引入注目，恪尽职守，以及不屈服于挫折。需要你克服自身的缺点，静下来创作出尽可能最好的作品。专业将是你最大的财富，学会像专业人士那样做事和思考。\n什么是专业人士?\n专业人士会严肃的对待自己的责任和事业，愿意做出艰难的选择去做自己认为是正确的事情–往往还要自己承担责任。\n\n成为专业人士（养成良好习惯）\n一切都开始习惯，改变人生，从习惯开始。想成为专业人士，你需要养成自己的专业习惯。\n时间管理：专业人士的强大的习惯。\n坚守正道\n技术和道德两方面的挑战。你必须两种情况下做出正确的选择。\n专业人士有着不可逾越的底线。\n专业人士必须工作的优先级做出艰难的选择。专业人士会评估需要完成的工作，判定优先级后再\n开始工作，并学会“不”。\n\n\n\n\n\n\n\n\n\n如果如果：如果不能说“不”时，就同意吧，然后赚点钱离开找下一家公司吧。\n追求品质，完善自我\n专业人士–必须不断的改善和提高自己的工作品质。不要随便降低标准。。\n不断的努力，学习来培养，维持自己的专业能力。改善自己的弱点，并极大的发挥自己的优点。最好了解自身的强项是什么并且充分发挥自己的优势。\n第十一章 懂得自由：如何辞职明智的处理方式\n辞职–希望你银行有些储存。因为一旦辞职了，只能靠自己了。就几个月的储存，缺乏坚实的情况下辞职是一种冒险行为。\n明智的方式：开始做自己的副业务，并让他足够成功，这样薪水大幅度减少，也可以完成自己的转型。在考虑辞掉工作之前，你需要有一个切实可行的计划，推荐业余时间启动你想创建的业务，等这个业务产生足够维持生存的收入时，你再转为全职。\n\n\n\n\n\n\n\n\n\n如果如果：已经辞职了，但是没有储存，怎么办？\n答案：努力工作，养成高效的习惯，给自己最好的成功机会。节省资源，有线电视等费用都砍掉。同时想想自己还能维持多久？自己能做些什么来维持更久。\n准备好为自己工作\n为自己工作比想象中难得多。正式辞职前的副业务非常重要，副业务为自己当老板做好准备。\n你真正工作的时间到底有多长\n为别人打工时，我么每天努力的工作时间不到一半（4个小时左右）。\n辞职工作之前，你对自己实际承担的工作量有一个符合实际的预期。并训练自己提前处理更高强度的工作负荷。\n切断脐带\n缩小开销，节约。\n计划好，打算那一天离职，在日历上做好标记。并做好准备，准备好了就可以提出辞职\n\n\n\n\n\n\n\n\n\n提醒：辞职必须注意劳动合同，不同的公司对辞职的要求不一样。”业余时间开发的软件是否属于公司“这个必须要注意。\n第十二章 成为自由职业者：开启自己的一片天地开启自己的一片天地开始自己的业务可以通过成为自由职业者或独立咨询师来实现。\n开始\n推荐，在全职从事新业务之前先做一段时间的兼职副业。随着时间流逝不断增强业务能力。\n问问你认识的人\n如何开始？问问你认识的人，发下邮件，社交等方式，毕竟刚开始时相信你的就是认识你的那些人\n获得客户的最佳路径\n\n怎么收费\n自由工作收费 &#x3D;（平时工作 ×２倍）\n说服客户：给客户带来的价值高，值这个价钱。\n第十三章 创建你的第一个产品软件开发人员能开发软件，还能开发博客，视频，书等信息产品。\n找到受众\n没有解决问题的产品毫无意义，所以不要找到客户前创建产品。否则你只是冒险为一个不存在的问题创造了一个解决方案。\n你想开发出一款产品，第一步应该是筛选出一组特定的受众，他们也是你的解决方案的目标用户。\n如果你想让自己的产品也同样成功（虽然也许在规模上达不到），首先打造一个成功的博客，使用播客、演讲、视频和其他媒体来发展自己的受众。\n测试市场\n发个准备要做的产品列表发给受众（预付费折扣等来吸引），用户数达到想要的数目就开始做，不然就退款，道歉。。。\n从小处着手\n从小出着手，你不可能第一次就开发出一个完美，强大的，而且市场特别好的产品。\n如果你想尽可能缩短自己的学习曲线，你就需要尽量缩短开始行动到看到成果之间的周期。\n如何开始，行动？\n尝试，你必须去做自己认为正确的，失败了时找出为什么它不管用，然后再去尝试不同的东西。大多数创造出成功产品的创业者也是这样做的。\n第十四章 你打算开始创业吗如果你已经有一个好点子，有了让自己坚持到底的激情和干劲，你会发现冒着风险白手起家还是值得的。\n创业的基础\n创业公司：投资性创业公司，自力更生创业公司\n不做大，就回家\n公司到达一定规模时，被收购或者上市。创业失败，可能两手空空回家。\n创业典型的周期\n单独创始人，还是合作，一般投资性至少一个合作人。\n创业加速器\n加入加速器计划，得到资金，短时间内快速发展，当然风险也很大。\n获得投资\n第一笔资金：种子资金，VC投资：A轮投资，最后上市，或者被收购来获得最大的回报。\n\n\n\n\n\n\n\n\n\n注意：股权时公司的命脉，必须考虑清楚，不然以后公司上市后，得到回报的人是别人。那样两手有空空了。\n第十五章 远程工作的生存策略做“隐士”面临的条件\n\n时间管理\n\n我们面临的最明显挑战就是时间管理。在家办公遇到各种各样的干扰。\n需要计划－－坚持时间管理来执行计划。日程表越有规律、越是规划得当越好。\n\n自我激励\n\n无法做到自律和自控，那就重新考虑是否在家办公了。\n日程表和常规是非常重要的依靠。当激情不再时，习惯就帮上你。\n推荐：最下来１５分钟集中注意力工作，然后就自然的继续下去了（设置闹钟）\n\n孤独感\n\n长时间一个人工作，容易产生孤独感，需要出去走走，参加会议，健身等。\n\n\n\n\n\n\n\n\n\n如果如果：找不到远程工作咋办？\n\n\n\n\n\n\n\n\n\n\n试试目前的工作是否远程做。\n\n\n\n\n\n\n\n\n\n\n\n找找远程的工作。\n\n第十六章 假装自己能成功有些人面对困难的时候挑战，因为他么有共同点“假装自己能成功”。\n“假装自己能成功”的真正含义\n暗示自己”我能成功“，\n\n你仿佛已经具备了成功完成任务的技能和天分。\n\n你仿佛已经成为自己想成为的那类人。\n\n你仿佛战斗已经结束，而你大获全胜，因为你深知如果自己坚持不赖，胜利就是眼前。\n\n你仿佛已经对即将踏上的未知道路驾轻就熟。\n\n\n“假装自己能成功”就是这样起作用的。你说服自己的身体和内心去努力，使梦想成为现实\n付诸实践\n如果你假装能成功，那你必须有勇气。\n使用场合：面试，不要假装懂，你要证明”你以前克服过这类困难“的心态，姿势。证明”你可以“。\n第十七章 单调乏味的简历——如何修改如你的简历和大多数开发人员的简历差不多，那就你得花一点工夫。\n你不是专业的“简历写手”\n“你的CEO不会写软件”，就这样思考，那你为什么花点钱找一个写手帮你写呢。\n雇一个简历写手\n雇个写手（你一定要确保准备好了发所需要的所有信息，记住：进来的垃圾，出来的也是垃圾）：\n\n熟悉行业\n\n可以给你展示简历样本\n\n\n比别人多做一点\n对软件开发人员来说，简历不一定要花哨好看，但一份专业的简历非常重要。\n不想雇专业的简历写手该怎么办\n\n把简历放到网上\n\n简历有创意\n\n使用“行动–结果”的描述\n\n校对\n\n\n第十八章 请勿陷入对技术的狂热之中如果你能让自己不成为某种技术的信徒，你会在职业生涯之路上走的更远。\n我们都是技术的信徒\n我们大多数人崇拜某种技术，因为我们熟悉这种技术。很自然的会相信自己选择是最好的。我们不可能充分了解现存的所有技术， 没必要选择最好的而贬低其他的。\n天生一物必有用\n在少在历史的某个时间点，每项技术都被看作是那个时代里“好的”甚至“伟大的”。\n发生在我身上的转变\n世界上没有最好的语言，就是特定的问题，需求，环境来选择某一种语言。\n不拘一格\n没有理由去强烈坚持自己的技术就是最好的，而轻视甚至无视其他技术。如你保持开放的心态，你可能得到更多的机会。\n","slug":"2019-03-14-soft-skills-notes","date":"2023-05-13T11:29:06.791Z","categories_index":"技术人生","tags_index":"技术人生 读书计划"},{"id":"196b905e85a618a55bf6a09a3e889f53","title":"如何高效读懂一本书","content":"“书中自有黄金屋，书中自有颜如玉。” 读书这件事从历史上就已经是人们获取知识，扩展视界，完成人生大转身的一个道路。但是在如今的飞速发展的互联网时代，人们已经不能够专注地去读书了，以及如今的图书出版也没有那么的繁杂和耗时了，每日都会有非常多的图书出版，面对着琳琅满目的图书，人们选择图书的范围大了，但是如何选择适合自己并且精品图书也变的苦难了。\n《如何高效读懂一本书》是一本帮助你建立系统化思考的框架，该工作时工作，该玩耍时玩耍，用碎片化的时间，每年可以读100本书的高效读书指南。在没有读次本书之前，大多数人总是觉得读书没时间，经常坚持不下来，没有一个有效的方法，不够专注，以及不懂得如何分享最终导致感受很糟，枯燥乏味等。而读完这本书之后，对于那些无法继续读书或者不能有效读书的事情其实都是借口。这本书从各个方面总结并且给出了能够有效并且高效读书的实践方案，让每个人都能够轻松读书且从读书中真正的汲取营养。\nξ·读书的若干误区在没有读这本书之前，总是感觉没有定力读完某一本很喜欢的书，或者读完了一本书但却没有深刻的体会，读了就读了，没有自己的东西。当读完这本书的时候，才明白，对于读书其实有很多的误区。\n\n没有时间\n\n在如今快节奏的生活方式中，每个人都视时间为声明，快速的使用着生活中的每时每刻，每天眼睛时刻盯着手机、电脑等等，却没有能够静下心来好好的读读书。而针对这样的问题，人们总是想着不是我不想读书，是实在没有时间呀。但是请仔细想想，你是真的没有时间吗？在每日的生活中，多少事情是可以不用做的，哪些事情是在浪费时间呢？加入利用这样的时间去读读书，会怎么样呢？\n\n逐行阅读\n\n好读书的人都知道，不是每本书都需要一字一句，逐行去阅读的。但是大多数读书的人，拿到一本数之后，就一头扎了进去，也并不是这种方式不好，但是会不会有另一种读书的方式，能够更加的高效呢？其实每本书、每类书都有其自己的逻辑，我们去阅读的时候也不是每本书都用同样的方式，找到阅读某类书的好方式。\n\n阅读不广\n\n大多数人喜欢的图书基本上都是自己所擅长的，虽然读自己所擅长或者喜欢的那类图书没有错，但是久而久之，对于读者来说，可能会造成阅读面变窄，导致其他类型的信息无法获得等。在不同的成长过程中，应该有所侧重的去选择阶段所适合的图书去阅读，这样才能够在阅读的过程中，增长自己的知识和技能，提升自己的阶段性提升等。\n\n逢书精读\n\n图书种类非常之多，很多人逢书就精读，其实也并不尽然，并不是每本书都需要精读的，对于好书，例如一些经典的图书或者对自己技术能力提升有很大帮助的数，一定要精读，而且可能还需要多遍精读，才能够消化其中的知识信息等，但是对于一些兴趣点图书，我们大可不必话长时间去精读，可以略读、速读等，了解其中的主要内容即可。\n\n开卷有益\n\n很多人在读完一本书之后，总觉得收益很少。例如某本书甲用一个月的时间读完，收益是80%，乙用三个月读完，收益同样是80%，虽然甲乙都读完了书，而且收益是相同的，但是明显甲所花费的时间远远少于乙，这就是用最少的时间成本获取知识。在飞速发展的现代社会，不管是技术的革新，还是观念的提升，都可能一朝一夕，因此用最少的成本获取知识更符合当下社会的现实。\n\n碎片阅读\n\n碎片化阅读是目前可能比较火的一个词，但是个人来说，不太认同碎片化阅读能够带来的收益。碎片化阅读更加符合新闻、消息、短信息等类型的阅读，但是对于读书这件事来说，碎片化虽然能够读完书，但是可以肯定的是，每次碎片化阅读的时候，总是难以回想起之前所读内容的理解或者含义等，导致碎片化阅读的间隔时间内总是独立的，难以形成系统性的知识框架体系等。\nξ·读书的若干方法上述读书的若干误区中，相信大多数人都有，包括本人，在很长一段时间内，都在被如何快速阅读一本书来获取收益所打扰，总是碎片化的时间里，读了那么几行几句，并没有多大的收益。在《如何高效读懂一本书》读完之后，多少看到了一些提高读书技巧的方法，希望能够在以后的读书过程中有所应用实战，提高读书效率，以最小的成本获得知识信息等。\n\n通读法\n\n\n\n树读法\n\n\n\n图读法\n\n\n\n框读法\n\n\n\n炼读法\n\n\n\n逆读法\n\n\n\n抄读法\n\n\n\n仿读法\n\n\n\n诵读法\n\n\n","slug":"2019-03-18-how-to-read-books","date":"2023-05-13T11:29:06.791Z","categories_index":"技术人生","tags_index":"技术人生 读书计划"},{"id":"abc9ff5171e506cd1d10cfb92b486d4d","title":"如何完成技术跃迁","content":"前言：近期又到了毕业招聘季，我作为技术分享嘉宾，回到母校参加宣讲会，做了一个主题为《如何在毕业三年完成技术跃迁》的分享，本文由此次分享整理而成，并改名为《如何完成技术跃迁》，希望能够给刚进入职场的程序员，或者卡在瓶颈期的程序员，带来一些指导，在技术的道路上少走些弯路。请注意，本文源于我的经验思考，非教条或准则，仅供参考。另由于本人主要的项目经验来源于App端（主要是iOS、Android），Web前端及后端只是稍有涉猎，因此文中的例子大多也来自App端，其他端同学可能会觉得陌生，但应该不会影响理解。\n本文约1W字，阅读时长大概二十分钟，稍有啰嗦，请见谅。 \n1. 什么是技术跃迁首先，我们需要明确一个定义，什么是技术跃迁？在说技术跃迁之前，跟大家解释下跃迁这个词。\n”跃迁“，来源于量子力学，说的是微观状态发生跳跃式变化的过程，比如从低能态跳跃到高能态，需要注意的是：因为微观粒子的状态是分立的，也即是非连续性的，所以这个变化是跳跃性的。用这个词来说明技术的成长，个人认为是非常合适的。\n\n\n\n以个人的经验来看，程序员的技术成长曲线大抵是这样的：\n\n成长阶段说明：\n\n成长期：新手通过正常的学习工作积累，一般能够在一到两年成为熟手。\n稳定期：是程序员的舒适区，但并非停滞期，该期间，程序员会进入到比较长的学习积累期，为后续的跃迁做准备。\n跃迁：成长期和稳定期积累的知识点一般是离散的，点与点之间联结较少。在逐步的反思，慢慢有意识联结，一但联结成网构成了下一阶段所需具备的技术知识体系，即完成阶段的跃迁。\n\n成长路径说明：\n\n新手成长至熟手：从新手到熟手，只需要正常的经验积累成长即可。\n\n熟手稳定期：大多数程序员会在熟手阶段经历较漫长的稳定期。此期间的表现为，有一定的平台开发经验，能够负责大部分需求功能的开发工作，但看问题不够全面，无法负责复杂系统的设计开发工作。\n\n熟手跃迁至单领域专家：这是程序员的第一个跃迁，带来的变化是非常可观的。表现为，对所在领域&#x2F;平台有比较全面而深入的理解，能够负责复杂系统甚至全系统的设计开发工作。\n\n单领域专家稳定期：经过第一次跃迁之后，单领域专家会经历更漫长的稳定期，在此阶段会经常出现多方向的分化：\n\n\n\n管理方向：成为单领域专家之后，一般被认为具备了单领域&#x2F;平台技术负责人的能力，此时部分人员会成为技术负责人或经理，走上管理路线。\n困于舒适区：大部分程序员成为单领域专家之后，会困于舒适区。因为他的能力已经足够把控所在领域的开发工作，此时无论朝单领域深度发展，或是跨领域发展，除了个人主观能动之外，还需要有合适的平台和实战机会；另外，成为单领域专家的程序员大多开始步入成家立业的阶段，生活会对其精力造成一定的分散。\n多领域专家方向：少部分人会朝多领域专家方向前进，这是一条最艰难的道路，如果只是自己主观意愿的话，即使努力学习，没有合适的机会去实战锻炼的话，很可能只是学些皮毛，拓展下视野。当然，天纵奇才不在此之列。\n\n\n多领域专家&#x2F;宗师：成为单领域专家之后，要想成为多领域专家，甚至宗师，需要付出更多的努力。本人自认非多领域专家，更非宗师，所以这往上的阶段只是个人的臆想而已。\n\n成长曲线只是一个简化的抽象模型，让大家比较形象地理解技术成长，但实际上却是因人而异，现在也没有一个认证考试来证明你具备了某一层级的技术水平，希望大家不要直接往上去套。在技术的道路上，不排除存在某些人突然灵光乍现、醍醐灌顶而跃迁飞升；但大部分人不过是日积月累、日拱一卒，慢慢形成自己的技术知识体系。\n1.1 技术知识体系上文中经常提到的技术知识体系，是跃迁重要的标志。就如同本科生、研究生、博士生的知识体系一样，不同行业不同的层级也需要不同的知识体系。知识体系，这个词其实不难理解。本节用一个例子来说明，让大家有个直观的理解，什么是技术知识体系。\n假如现在你所在的项目组，需要实现一个移动端（App&#x2F;H5）的登录功能，如下图：\n\n你会如何开始你的表演？\n你可能会计划根据软件工程的规范，做下设计，画下流程图，然后再敲代码实现。这只是你的臆想，根据我的经验观察，80%的新手都会选择：”Talk is cheap, Let’s Code!“ 直接上手写代码，大部分人在动手之前，可能脑袋都是一团浆糊，但却盲目自信：边写代码，思维会越来越清晰。\n下面，来看一个具备移动App技术知识系统的程序员的常见做法：\n1.1.1 设计先行\n\n确定设计目标：第一要务，是要确定功能的设计目标是什么，我现在假设登录功能的优先目标是可靠性、健壮性和安全性，以保证用户能够稳定、安全地进行登录。\n\n架构设计：如果App已有成熟的架构，登录功能的架构设计会遵循App的架构设计；如果登录需要做特殊设计，应该会考虑优先采用比较成熟稳定的架构设计模式，以保证架构成熟、稳定、可靠及易于理解，满足设计目标。\n\n详细设计：假设此次登录功能采用MVC的架构设计模型，一般Model层是比较复杂的，所以我们着重Model的设计。\n\n\n\n业务逻辑层的设计：包括接口设计、重要业务逻辑设计。此处重要业务逻辑，举了个客户端登录中非常重要的，涉及切换用户导致用户上下文切换的例子。如已登录的A用户退出登录后，B用户登录，那么必须保证A用户与B用户的之间不会窜数据。有人可能认为这个非常简单，实际不然。设想下这样的场景：A用户发出了一个拉取个人收藏的请求，而然后退出了登录，并登录了B用户；由于网络关系，可能A用户的收藏请求是在B用户登录成功之后返回的，那么此时处理不好，就会导致窜数据的问题。\n存储层：存储层的设计，也需要根据登录的需求，保证高效、安全、隔离。后面两个比较好理解，高效？不是所有存储层都应该高效么？是这样没错，我们当然希望存储越高效越好，甚至其他特性也是越强大越好，但明显是不符合实际情况的，任何设计都需要考虑优先级。有些功能，比如活动列表，高效并非是第一优先级。而登录将高效放在第一优先级，主要是考虑到App启动之后，就需要进行登录态的判断，如果登录态的存储不够高效，势必影响启动速度。\n网络：网络要求安全性、健壮性，并且还需要考虑弱网情况的下异常处理。\n多线程：一般登录功能包含了多次加解密过程，为了登录功能的高效，我们可能希望将其放到一个独立的线程，或者多线程上去执行，这时候需要考虑多线程的设计，以及在此之上延伸出来的数据安全和锁的问题。\n\n\nToken设计：为了安全的考虑，客户端不可能存储用户的任何加密加签的密码，而是使用具有生命周期的Token来替代，所以需要跟后台一起设计Token的机制。\n\n1.1.2 实现思维完成设计之后，是否就可以直接Coding 了呢？理论上是可以的，但实现过程并非大家想象的一样可以无脑码代码。在具体编码前，还需要多种知识体系支撑的，已指导编码实现的思维，进而指导代码实现。如下图：\n\n\n设计模式：在动手Coding之前，我们一般会思考，是否有合适的设计模式可以使用。如一般的登录流程可能包含了多个步骤：密码验证、图形验证码、OTP验证码、Token交换等，我们可以考虑使用责任链的设计模式。\n\nOOP五大原则（SOLID）&#x2F;设计模式六大原则：在我们编写一个类、或者一个方法时，我们需要遵循SOLID原则，以保证代码模块的清晰、高效、松耦合和易于理解。\n\n重构：在编写详细的逻辑代码时，经常会增删类、接口、方法等，此时灵活使用《重构》里面的方法，保证代码逻辑的清晰，就显得特别重要。\n\n\n从上面的例子，大家应该能够很好地理解，如何运用自身技术知识体系，解构一个普通的登录功能。当然，这个例子并不全面，还有很多细节需要考虑，限于篇幅，我这边做了简化。\n\n\n2. 跃迁方法上一章节，大家了解了跃迁其实就是构建个人的技术知识体系。本章节，想跟大家聊聊个人总结的跃迁的方法：持续学习基础知识体系和平台知识体系，再通过不断地经验总结织网，完成技术知识体系的搭建。\n2.1 基础知识体系如果大学是计算机相关专业的程序员，那么大学学习的大部分课程，都是跃迁所需的基础知识体系。下表是列举的是一般软件开发工程师所需的基础知识，而目标列则是想要三年跃迁为单领域专家必要条件。\n\n\n\n知识点\n目标\n\n\n\n计算机基础&#x2F;操作系统\n了解计算机是怎么运作的\n\n\n网络\nHTTP1.1&#x2F;HTTP2.0&#x2F;HTTPS、TCP&#x2F;IP、TLS\n\n\n算法\n会计算时间&#x2F;空间复杂度\n\n\n数据结构\n掌握List、Set、Map、Stack、Tree\n\n\n存储\nFile、数据库等各项操作开销\n\n\n多线程\n线程开销、线程池、锁\n\n\n架构设计\n基础的架构设计模式\n\n\n编程\n掌握常用设计原则、设计模式和重构方法\n\n\n上表中，除了“架构设计”这一项不涵盖在大学课程里，其他几项基本都是大学课程知识。接下来，我会一一做简单分析，基础扎实的同学可以略过。\n\n计算机基础&#x2F;操作系统：在量子计算机真正面世应用之前，我们现在绝大部分计算机都是冯诺依曼结构。了解操作系统，了解计算机运行的机制，包括CPU（流水线、多线程、锁）、内存（虚存、物理地址、虚拟地址）、IO等等，能够让我们了解自己开发的程序运行的基本原理和机制，从而写出高效的代码，同时还能帮助快速定位问题。比如iOS开发工程师，了解iOS操作系统，对启动性能优化很有帮助。\n\n网络：在互联网时代，一个程序员不了解网络，跟厨子不懂火候、戏子不懂台词没什么区别。现在不连入网络的应用寥寥无几，每个接入网络的应用，为满足可靠性，都需要考虑网络延迟、安全等问题，所以网络基础知识是非常重要的。\n\n算法：AI的发展，让算法的应用更为广泛而流行起来。虽然现在硬件发展迅速，平台API封装的算法足够高效，需要我们实现特殊算法的状况越来越少，但基本的时间空间复杂度还是需要掌握的，不然很可能有合适的算法而不会用，导致程序执行效率低。\n\n数据结构：在一般的编程领域，数据结构的重要性比算法要高。一个很主要的原因是，数据结构在编码过程中无处不在。所以掌握常用的数据结构，知道每个数据结构的适用场景，以及在平台上的特性，如线程安全等，是非常重要的。\n\n存储：我们常用的存储（IO）系统包括了文件系统和数据库系统，当然数据库的最终落地也是以文件的形式存在的，但为简化模型，此处文件系统特指除数据库以外的文件系统。只要信息需要持久化，我们就需要用到存储系统，其重要性不言而喻。其中，重点是需要了解存储系统各种操作的开销。比如文件系统，如果要拷贝一个文件，软链接、硬链接的开销要比物理拷贝要小很多；比如数据库增加索引，会导致更新操作的额外开销等。\n\n多线程：多线程是编程中一个重要的知识点，也是很多程序员需要花比较长时间迈过去的一个坎。当然，现在各端流行框架基本上会把复杂性进行封装，包括多线程，所以在是使用框架进行开发时，不需要多线程的知识也能够完成开发任务。但我们想要的并非只是会用，想要跃迁，掌握线程的开销、线程池&#x2F;线程队列和锁是必须的。\n\n架构设计：架构设计是唯一不在大学课本上基础知识，因为没有实践，教了也没用。大部分程序员，初接触架构都是学习各端平台框架上最流行最简单的架构设计模型，如MVC、MVP、MVVM等；而后慢慢接触到分层架构模式、事件驱动架构模式、微服务架构模式等；最终才会系统地学习什么是架构，进行架构设计的方法论。我认为，一个合格的领域专家，也应该是这个领域合格的架构师。\n\n编程：编程，掌握几门不同类型编程语言（编译型、解释型、动态、静态等）是基础，在此基础上，还需掌握通用的编程技能。比如前面例子中说的SOLID设计原则、软件设计模式（GOF）以及常见的重构方法。上个例子中已经说明。\n\n\n2.2 平台知识体系前面说到，基础知识体系是大学时的课程，那么平台知识体系则大部分来源于工作中的项目实战。在讨论如何积累平台知识体系之前，大家须先理解，什么是平台知识体系；而要想理解平台知识体系，需要了先解什么是平台。\n2.2.1 平台定义在本文定义的平台，跟计算机中定义的系统平台比较类似。在计算机中，系统平台的定义是：指在计算机里让软件运行的系统环境，包括硬件环境和软件环境。而本文平台的定义稍微狭宽泛一点：是指支持特定软件运行的相关环境，包括开发环境、软件环境和硬件环境。\n假如你是一名Android开发工程师，对应的平台就是：\n\n开发环境：JAVA、Kotlin、Android Studio、Gradle、Git、LeakCanary等\n软件环境：Dalvik、Android Framework、Linux等\n硬件环境：屏幕（分辨率、DPI）、内存、不同手机的特性；\n\n理解了平台的定义之后，就不难理解平台知识体系了。\n2.2.2 平台知识体系思维图平台知识体系就是基于平台进行开发所需的知识的系统集合。\n以下是个人总结的平台知识体系的思维图。虽然每个平台自己的差异，但总结下来，平台知识体系大体可以按下图来划分。\n\n\n编程语言：即平台相关语言，如Android平台是Java、Kotlin；Java后端则是Java等等；\n\n平台库API：即平台提供的API，如Android平台有Android的相关库和API，H5前端HTML、CSS、Javascript等的Web API。\n\n架构模式&#x2F;框架：平台一般会提供开发框架或常用的架构模式，如Apple官方推荐的iOS开发的MVC架构、Java后端的Spring框架；\n\n系统内核：应用软件都需要运行在操作系统上，而学习系统内核运行机制，能够帮助我们更好地理解程序底层运行的机制。如上一章所说的，iOS开发工程师学习iOS的系统内核，能够更好的理解iOS App的启动运行原理。而这对于Android开发更常见，有时候一些系统Bug，需要对系统内核有深入的认识，才能规避或者解决。\n\n关联系统：所谓关联系统，即是与程序有交互的其他进程或系统，如App里面的Push系统，后端开发常见的Web服务器、容器、数据库等。\n\n开发工具：就是前面所说的开发环境，主要包括了IDE、VCS代码版本控制系统、包管理、调试工具等。\n\n性能：不同的平台有不同的性能要求，如App开发会比较多考虑内存、CPU、IO、网络等比较孤立的项，而后端开发会考虑负载均衡、TPS等比较具规模的项；\n\n安全：不同的平台，安全性和安全措施都不一样。后端主要须保护服务器，防止被入侵和攻击，常用的安全措施是防火墙、防止被注入等；而App端安全性要求相对来说没那么高，主要是需要保护本地逻辑和小部分敏感数据。\n\n构建及发布：开发完成的程序想要运行在平台上的必经步骤。\n\n\n这些知识类型，大家都应该很熟悉。你可以一一对应自我评估下，看看自己各方面的水平如何。\n2.2.3 如何构建平台知识体系对平台知识体系有了大体的认识之后，你可能会疑惑，那么多知识类型，我应该怎么来学习呢？这个问题不止困扰你，同时也困扰了无数的程序员们，所以这些踩过坑的前辈们就制定了许多的学习路线图，也就是Roadmap，帮助后面的同学，按照这个学习就行了。\n下面两张图分别是Web前端开发的Roadmap和iOS开发的Roadmap，供各位参考。\n\nWeb前端开发 Roadmap(图片来源于 The 2018 Web Developer Roadmap)\niOS开发 Roadmap (图片来源于The 2018 Web Developer Roadmap)\n那如何按照Roadmap来渐进式学习，以达到技术跃迁呢？总结有四点：\n\n选择合适的Roadmap，制定规划。网络上的信息是爆炸式的，每个人的学习路线也是不一样，所以导致，在不同端不同平台有非常多的Roadmap，哪个合适你呢？我的建议是，你可以向你的导师、Leader，或者团队内的牛人寻求帮助，让他帮你选择好Roadmap，并规划好学习的计划。这样有两个好处：一是他们的经验丰富，了解你的自身情况，更能帮助你选择合适的Roadmap；二是他们选择的Roadmap一般也是他们自己认可并赞成的，很可能跟他们的技术栈是比较契合的，能够给你更深入的指导。\n\n刻意进行系统性总结和思考。大家应该都听说过一万小时定律，其中很重要的点是，练习需要有目标、专注、有反馈及走出舒适区的刻意练习。Roadmap的学习也是类似的。由于Roadmap包含了很多知识点，所以新手可能会遇到学习不全面，不扎实等问题，这就需要你定期停下来进行系统性总结和思考，这些总结和思考最好能够形成博文、分享课程等，能及时收获反馈，增强学习的积极性。\n\n优先深度：很多人为了贪快或贪全，就好像是打卡一样，草草看了几篇技术文章之后，就觉得自己掌握了某项技术，这是很不可取的。知识点的学习，最重要的是深度。优先深度，不仅学习知识点比较扎实，最重要的是学习效率高，这可能违背了很多人的直觉。举个例子，假如你需要挖一个直径10米、深10米的大坑，你会怎么做？假如你是画一个十米的圆，然后在每个点均匀的往下挖，那么你每个点做功都是一样的；还有另外一个选择，先挖一个10米深的坑，然后在中间或底部开始往四周挖，你会发现挖一点就泥沙俱下，比每一个点均匀做功往下挖要省时省力。技术知识的学习也是一样的，因为知识点之间并非孤立的，而是连结的，比如网络的知识，又会连结安全、性能和关联系统等知识点。深入学习了一个知识点，学习其他知识点的时候，就能够与之前深入理解的知识点进行印证思考，并建立连结。说句题外话，假如面试过程中，应聘者对某些知识点有深入理解，是非常重要的亮点。\n\n织网：上一节已经说了，知识点并非孤立的，织网才能让你的平台知识体系更完整。随着你知识的增长，织网是非常自然而然的，但也是最难的一环。因为连结并非是一个简单的事情，就算你已经深入理解了两个知识点，但如果没有合适的实战和深入的思索，你可能永远不会发现他们之间的特殊的连结。\n\n\n2.3 沟通交流大家可能比较奇怪，技术跃迁跟沟通交流有什么关系？\n大家应该都接受过这样一个理念：沟通很重要。但实际上大部分人不太明白沟通的重要性在哪。可能工作了几年的同学感触会比较深，而如果是学生，基本不会有什么概念，因为在学校这样的关系纯粹的象牙塔里，沟通能产生的影响微乎极微。工作越长的同学越能深刻理解沟通在职场上的重要性。同一批大学生进入到同一个公司，负责同一个项目，假如大家的天分一样的话，沟通很可能是造成几年后分化的最重要因素。其实道理很简单，你的沟通能力越好，你获得的机会就会越多，也会越好，最终导致你成长越快，成就越大。 \n作为程序员，在职场上的沟通主要分以下几个方面：\n\n对上（直线Leader）沟通：很明显，对上沟通是最重要的。不仅仅是因为他是你的年终重要考核人，而且他一般还是团队内比较优秀的人，更重要的是他最了解团队目标（KPI）的人，也掌握着工作资源分配权力。因此，如果能够与上级形成非常良好的沟通，那么，你会知道团队的目标是什么，确定努力的正确方向，少走弯路；你还能够获得团队优秀人员（你的Leader）的指导，有了好的学习模范；并通过自己的主动和努力，去获得更多的资源支持；最后，你还能够通过沟通，增进与Leader的相互了解，Leader了解了你的贡献，你也了解了Leader对你的期望和满意程度，从而大大降低了年底考核与预期出入太大的概率。\n\n对内（程序员之间）沟通：团队内部，与程序员的沟通也是非常重要的。在我个人的技术成长道路上，跟同事或者其他程序员之间的沟通，让我受益良多。通过跟团队内其他程序员的交流、讨论，甚至争论，我发现了很多我不知道的知识点，这个越在初期越明显。慢慢的，我成为了一个有经验的，或者说有成见的程序员，这时每次与其他程序员讨论之后，我都会反思，自己的观点是否是错的，为什么他是这个观点看问题的，然后我会去尝试从对方的角度来思考问题，甚至去实际操作一遍，对比优劣，总结，然后提升。所以，与团队内其他程序员保持良好而有效的沟通，也许是你能够最容易获得的最长久有效的跃迁资源。\n\n对外（产品经理、项目经理、测试、设计等）沟通：当你成为一个熟手，你应该已经融入在项目里面，此时，你的工作也跳出了一个纯程序员做的事情——写代码，一般你会参与需求评审、设计评审、接口协议评审、测试用例评审、ShowCase等繁杂的流程，此时，建立一个良好的沟通渠道，能够达到事半功倍的效果，让项目高效运行。我们常说的敏捷的工作模式，其中提升沟通饱和度就是一个很重要的点。跟业务&#x2F;产品经理多沟通，可以培养你主人翁的意识，也就是说你是在切实关注业务产品的。而且有良好的沟通的话，能够形成良好的推动力，让你实现需求更加高效。如果一开始不理解需求，也不沟通或者沟通不充分，做出来的东西可能就会有错漏；但如果一开始就沟通充分，你出错的概率就大大降低；或者有持续沟通的机制，你的错误也能够及时的改正过来。跟测试沟通，你会了解你团队的质量状况，或者一些常见的bug，这样可以有效提升你的代码质量。跟项目管理沟通，让你了解项目的流程，帮助你做好工作规划等。\n\n\n上面说了沟通的重要性，那如何来做好沟通交流呢？由于本人在这方面并不太专业，无法系统讲解，只能给些个人的建议：\n\n主动最重要：沟通是相互的，总有一个人需要先主动，你是那个主动的人么？\n空杯心态：多倾听，多反思，不要只听得见你想听的。而且沟通的目标是找到问题的最优解，而不是为了说服对方；\n日常多交流：沟通其实是一个持续的过程，请重视与每个人日常关系处理，因为这很可能会影响到你们的下次沟通；\n有原则，懂妥协：在每一次沟通中，保持底线，让人知道你是个有原则的人，能够提升下次的沟通效率。而懂的妥协，则是为了双赢的目标而努力，也为下一次沟通奠定基础。\n\n沟通是重要的，但要成长也不是单一因素所能决定的；而且职场上，大部分人的情商和沟通技巧其实没有太大的差别，主动性反而变得比较重要。与各种角色建立良好的沟通关系，确实能够让你的跃迁道路上走得更快，但绝不是让你成为交际花，或者成为圆滑世故而没有原则的人。沟通很重要，但也不要妖魔化了。\n2.4 经验总结跃迁的道路，跟游戏升级没什么区别，也是需要经验积累的，然后再总结过往的经验，不断夯实自己的技术知识体系。很多熟手，难以跃迁成为一个技术专家，很重要的原因，就是缺少经验总结的环节，导致无法搭建完整的、有深度的知识体系。\n我们先来做个评测，请看以下情景：\n\n作为应聘者参加面试，对面试官的问题都能说上一部分，但问细问深就不知道怎么答了。\n看一些分享讲座，你觉得讲师说的大部分你都懂，但你做分享的时候却又不知从何说起。\n你掌握很多解决问题的方法，但一谈到根本原因、内在机制的时候，你却一头雾水。\n需要实现相似功能时候，你习惯复制代码，而不是思考如何提炼重构。\n\n如果上述情景，你符合两条或以上，那么你应该是很少总结，个人的技术知识体系是比较薄弱的。\n经验总结，分两部分，经验和总结。经验，大部分是从工作实践中来，所以需要我们比别人更加积极主动，去争取更多的机会，从而获得更快的成长。当然，能力与责任是相辅相成的，能力越大责任越大。反之，能力不够，也很难获得好的机会。但积极主动，至少比能力相同的其他人要更容易获得机会。实践经验很重要，是因为没有实践经验支持而学习的知识，很可能只是空中楼阁，很快就会被遗忘。假如实在没有合适的实践机会，可以考虑做一些个人业余项目，也是非常好的锻炼机会。\n而总结，则是在实践经验的基础上，进行织网，完善相关的技术知识。关于经验的总结，本人以个人成长经验，推荐我认为比较有效果的方式：\n\n成体系地学习：由于移动互联网大爆炸，导致我们的阅读学习越来越碎片化，从而导致我们的知识也是碎片的，难以形成体系的知识结构。相比于每天看公众号上散乱的知识点，我更推荐大家结合工作需要和工作中遇到的问题，成体系地学习某个知识点。比如学习网络知识，可以先看《图解HTTP》、《图解TCP&#x2F;IP》，然后进阶看《HTTP权威指南》、《Web性能权威指南》，还想在深入，可以看《TCP_IP详解》的三卷。这里列举的是通过阅读书本来系统学习，现在在线教育发展飞速，如“极客时间”、“GitChat”等在IT在线教育平台上，也有很多优秀的成体系的课程，而且这些课程普遍有较强的实践指导性，通过这些课程学习也是很好的方式。在学习过程中，我个人的方法是绘制思维脑图来提炼总结知识点，从而形成网络知识体系巩固下来。有成体系的书本来帮你构建个人的知识体系，会事半功倍。而平时碎片化的有时效性的阅读，则用来填充知识网里的空隙，以及拓展个人视野。\n\n写博客（公众号、专栏）：很多同学经常遇到的问题是，认为已经掌握了某个知识点，但很可能你掌握的只是其中一小点，甚至可能只是知其然而不知其所以然。比如感觉学了《计算机网络》，了解了网络七层模型，会Network API组包拆包，就觉得掌握了网络知识；但却连HTTP协议报文结构都说不明白，更不用说HTTP请求经历了哪些网络往返阶段。而写博客，则是一个很好的总结提炼知识点的方式。当你需要说明清楚一个知识点时，你必然想要去了解内在的逻辑是什么，然后你接触越多，你就会越发现你懂得越少。比如我曾经写了篇关于怎么写界面的博客，其中谈到界面的优化，为了说清楚这个知识点，去查了很多资料，包括UIView与CALayer的关系，Offscreen Render的机制等。从而形成较完整的界面优化知识。当然，现在看看还是有很多可改进的空间。\n\n做分享演讲：这个方法的成效与写博客比较类似，都是需要将知识再整理，形成一套个人的知识体系后，让更多的人能够理解。不同点在于博客通过平面文字图像，而分享演讲则是通过文字图像声音，并且能够与分享的对象进行实时的沟通反馈，更有利于知识的传播交流。\n\n\n上述的三个方法，是我自己认为比较有效的经验积累的方式。三个方法与工作相结合，可以形成良好的有机循环：\n\n工作实践中需要的解决的问题，或者需要的技术储备，可以通过成体系地学习，掌握比较完整的知识点；\n将这些知识点运用到工作中，解决实际问题，获得实战经验加成；\n将经验和知识点串联，形成博客，或者做分享演讲，这是一个知识加工的过程，可以让你掌握的知识更加系统。\n\n\n# 4. 跃迁规划 \n\n为更好的完成技术跃迁，本章节为刚毕业的同学准备了一份跃迁规划，仅供参考。主要点在于构建平台知识体系，粗略分三阶段：\n\n\n入门：入门大概需要半年的时间，该阶段主要需要完成心态上的转化：从一个学生角色转换成一位职员的角色。另外，还需要适应公司文化，学习团队开发过程中常用的系统、工具等。入门完成之后，应该可以完成基础功能的开发。\n\n熟练：熟练的阶段，也就是要锻炼成熟手的阶段，这个阶段大概需要两年。在这个阶段前期，主要学习编程语言初级特性、平台API、开发工具和关联系统，主要目的是为了能够高质高效地完成开发任务；而在熟练阶段后期，则需要学习所在平台的编程语言的高级特性，高级API，以及常用的架构模式和框架。熟练阶段不存在什么难度，只要保持积极主动、好学好问，勤于思考，基本能够达成。完成之后，应该可以独当一面，开发一个中型系统不在话下。\n\n进阶：进阶，也就是为最后的跃迁做准备的阶段。该阶段需要学习系统内核、平台性能和安全、以及构建发布等相关知识，拼上平台知识体系最后一块拼图。图上画的是半年，但实际情况因人而异，有些同学进展缓慢，主要的原因可能是受限于项目团队规模，无法获得良好的技术指导和实践经验，此时需要多发挥主观能动性，积极发掘项目中可改进和实践的点，或者启动个人项目，进行实践。\n\n\n而其余两点，构建基础知识体系和经验总结，则是一个持续学习、总结的过程，此处不展开讲。\n\n## 5. 结语\n\n非常感谢你耐着性子，阅读到了这里，相信你一定有所收获，而这也是我写下这篇文字最大的期许。曾经年少时，好为人师，跟没小几岁的后辈大谈人生道理，历数惨痛教训，以为他必鉴往知来，前程一片坦途；后面慢慢明白，所谓的良苦用心，还不如让他碰上几块墙壁，跌上几个跟头。等你明白了舍身取义，你自然会回来跟我唱这首歌的。\n当我们从婴儿，成长为少年、青年，我们一直都在蓬勃向上成长；慢慢的，我们的身体成长转而停滞，而此时知识、阅历还会继续不断成长壮大，建筑我们强大的内心。能感受成长，是一件很美好的事情。我相信，不管任何阶段，任何年龄，只要你坚持主动学习、思考，成长和跃迁是非常自然的事情。\n\n\n\n\n\n\n\n\n\n原作者：jaminzzhang\n原文链接：http://oncenote.com/2018/12/25/Transition/\n","slug":"2019-03-23-transition","date":"2023-05-13T11:29:06.791Z","categories_index":"技术人生","tags_index":"技术人生"},{"id":"30d6bb78003d1902f34a0b31bdcc29e2","title":"码农是怎么炼成的","content":"有人说，每个看起来与正常人无异的工程师，其实都是在学习程序开发的途中熬过、压抑过、而且创伤过的反社会人士(sociopaths)。\n在学习程序开发的过程中，常常看到网络上的「甘苦谈」，也听过身边前途一片光明的工程师朋友们分享过学习历程，总觉得不同的人、同样的故事却不断的重复，像是狼叫声般，从远处传来一声又一声的回响。\n最近读到Erik Trautman在Viking Code School部落格中的文章《Why Learning to Code is So Damn Hard》，文章里将学习写程序(Learn to Code)的过程分成了四个阶段，并解释了两个影响各阶段形成的关键因素「资料密度」以及「知识广度」，最后集合成这张图：\n\n这篇文章很有趣也十分符合我所听闻的那些「工程师辛酸史」，因此决定将这四个阶段介绍给大家，希望程序初学者们在进入这条不归路之前，眼睛要放亮、计划要周详，清楚明白在前方等你们的是什么，做好完全心理准备吧!\n接下来我将介绍从刚开始写程序到成为一名工程师，Erik Trautman所归类必经的四个阶段：\n想成为工程师，请做好准备迎接这段必经之路先假设你学写程序的终极目标是要靠这行吃饭––进入相关领域工作或是自行创业，你是否做好万全准备可以从你的信心(Confidence)跟能力(Capability)散佈图中看出：\n\n随着你具备的知识跟技能越来越多，你的自信心也会随之而增减，最后达到能力够信心足的「Job Ready」点。在Job Ready前则可以分成四个阶段：\n第一阶段：手牵手心连心蜜月期刚开始进入程序开发界的朋友们总是怀抱着远大的梦想跟抱负，这不能怪他们，毕竟一方面，大家小时候听多了「写程序很难」、「电脑科学很硬」这种传闻，从一开始就把不少人吓去念社会科学(没有冒犯社会科学专业人士的意思);另一方面，「全民写程序」这项运动实在太成功，坊间许多工具跟学习平台让程序开发变得超好理解、上手容易，像是Codecademy、Treehouse、跟Code School等线上平台，或是麻省理工的Scratch语言、Google的Blockly等程序语言工具，成功地营造了人人都能写程序而且靠这行吃饭的假象形象。\n突然间我们的问题不再是「困难度」，而是「比天高的期望」跟「比地大的梦想」。\n最重要的是，以上提到的这些工具跟平台实在太有用，带领毫无程序开发经验的初学者们一步步认识变数、条件语句、程序语法。当你一路过关斩将把程序语言基本逻辑跟语法学会的同时，你就会超有成就感、自信心大增，开始有「原来我也行嘛」、「写程序也不过就这样」的感觉，基本上觉得自己已经跟「工程师」相差不远了。\n\n这个阶段将充满喜悦与成就感，在各种线上工具、网络教学的帮助下，你享受着用指尖下指令、电脑就能准确执行的主导感，你赞叹着程序语言的神奇与强大之处，从Hello World到简单回圈，每完成一道练习题你的成就感又增加几分，很多人会在这个时候认为自己已经爱上了电脑科学(而且觉得电脑科学也爱他们)，正处于能力提升，自信心也大增的「蜜月期」，这时你可能会觉得世界真美好、人生大概就会从此飞黄腾达，但我得残酷的告诉你：\n这段旅程才刚开始而已。\n第二阶段：困惑之崖就跟大部份的情侣&#x2F;新婚夫妻一样，蜜月期会结束，你会慢慢发现「相爱没这么简单」。\n作业难度一增加(重点是程序码长度也会跟着增加)，程序错误警告就频频出现，开始不停的除错(Debug)。而且通常最大的挑战是––当错误出现时，你根本不知道错在哪里、该问什么问题。你的学习进度在这个阶段开始停滞不前，像路走到一半突然遇到悬崖而无路可走般，开始对之前的认知感到困惑，跟着信心大失。\n\n通常这个阶段会在你完成线上的基础教学后发生。以制作个人网站(Portfolio Website)为例好了，W3School平台提供了一系列HTML、CSS、JavaScript等网页制作相关的程序教学，让初学者一单元一单元的学习语法跟功能，每单元还有例子示范用法，看似好简单!全部跟着学一遍之后，你准备好动手打造自己的网站，打开文字编辑器，……，然后写没两行就卡关了。\n也许靠Google搜寻可以让你撑到完成网站基本架构，但当你想实现自己的创意、加上个人化的设计时，网络上的回答跟示范总是和你心里所想的不太一样，所以程序码不能全抄，然而左拼右凑出的程序码看似可行但实际上差得可远了!偏偏还不知从何debug起，可能投资了大半的时间程序码还「有减无增」，毫无进展可言。\n这是一个尤其挫折的必经阶段，想成为Programmer就必须经历这个关卡，勇敢跳下悬崖、逼自己展翅高飞(当然在这个阶段摔死的小雏鸟数量十分可观)。\n但即使你消灭了无数的bug，终于完成了几个小专桉后，你也别高兴得太早，未来的路还是非常长远而且挑战性更高!对于想进入这行吃饭的人来说，「困惑之崖」通常是你决定是否全心全意进入这一行的转捩点，而当你投资所有的时间心力在写程序上时，你将进入最让人心灰意冷的第三阶段。\n你可能会很好奇，到底为什么紧紧相连的第一阶段(蜜月期)跟第二阶段(困惑之崖)会差这么多?如果你也正在经历以上两个阶段，你要知道，造成阶段转换的原因跟你一点关係都没有，并不完全是因为你比别人笨或比别人不努力，而是因为「资源密度」改变的缘故。\n因素1：资源密度Resource Density\n\n在第一阶段中有提到，当零经验零基础的你开始学习写程序时，身边有着无数的资源跟工具等着你来运用。到Google搜寻打「Learn toCode」你会查到超多程序学习平台、教学文、教学影片、甚至经验谈，让你感到万分的亲切及温暖，其「手牵手心连心蜜月期」的称谓当之无愧。\n\n然而到了第二阶段时，这些教学资源的数量将大为骤减，任何一个刚脱离初学者的程序学习者都能够证实我此言不假。初学者一开始遇到的障碍都是「一般常见问题」，教学文、教科书里就会注明了;后期由于作业难度以及个人需求，问题才渐渐复杂起来，要从StackOverflow或是一些程序人的部落格中去找寻解题线索。一直到在你遇到的问题已经棘手到网络上根本找不太到线索的时候，你便进入了下一个阶段。\n第三阶段：绝望沙洲要了解进入第三阶段的关键，就要了解另一项影响着各阶段变化的重要因素：知识广度。\n因素2：知识广度Scope of Knowledge\n\n「知识广度」也就是度过每个阶段你所必备的知识领域范围。刚开始时你需要吸收的知识很集中，不管用哪种程序语言、不管功能是什么，首先都要学会变数型态、宣告语法、回圈及条件判断式等等，这时随便请一个工程师教你都是一样的，因为「重要须知」就是这几点而已。\n然而学完基本功后，你所需的知识领域会一下子扩展很多，像是开始学习物件导向或是着重演算法的效率，你会需要扎实的电脑科学背景来应付，而且每一个应用都可以牵扯出更多的变化…相信我，这不是几堂MOOC课程就能救得了你的。\n在这个时期，万能的Google也只会丢给你更多你不懂的东西，根本查不到相关的线索!最糟的是你根本不知道你什么不知道。(You don’t know what you don’t know.)。于是「学也学不完、越学越不懂」的无力感排山倒海而来，进入最最难熬的第三阶段––「绝望沙洲」。\n这个阶段顾名思义像是在横越沙漠般，是一段非常长且寂寞的旅程，让你有不知何年何月才能走出来的绝望感。在一望无际的沙漠里，根本搞不清楚东西南北，资料查了半天毫无斩获，还不时被海市蜃楼(错误资讯或看似可行的解决方桉)给误导，搞得灰头土脸、头昏眼花，在这个阶段晒死、渴死、绝望死的有为青年更是不计其数。\n\n但只要在绝望沙洲里熬下去，接下来就会自在许多了!累积足够的经验，程序的错误就会大量减少、达到一定知识水准，就能准确判断问题的方向切入核心，工作效率因而有所增进，知识广度也会慢慢聚焦。等你拖着一身的疲惫终于走出这荒漠时，就进入了最后的阶段。\n第四阶段：创伤后的恢复期踩着千万人的尸体成功横越了沙漠，你的自信心开始回升，Google功力也可以说是神人的等级。到了这个时候，Hacker News的新闻以及超硬的MOOC课程都不成问题，你也选定了某个程序语言跟框架来专研，而且有能力制作出可以正常运作的应用程序了。\n但你心里深处总有着隐隐的不安，觉得程序能「用」但其实代码凌乱无章，工程师的头衔下其实是误打误撞进这行的半调子，虽然你似乎具备了一切就职条件，却总害怕面试官发现你根基薄弱的电脑知识…你正在经历「创伤后的恢复期」。\n在飞越困惑之崖、横越绝望沙洲之后，你应该已经学会该学的、做了该做的，成为一个名符其实的工程师，却总觉得自已资质平庸根基不稳，虽然有成功打造出一个个专案而信心回升，但老是感叹自己与心目中「专业工程师」仍有一大段差距…，这些都是「冒牌者症候群」(Impostor Syndrome)在作祟!\n\n在这创伤后的恢复期中，你可能会经常自我怀疑，但只要顺着这波效率提升信心也回升的潮流继续努力，在能力与自信达到一个程度时…恭喜你：\nYou Are Job Ready!orI learned the value of hard work by working hard.\n原文：http://www.ijiandao.com/2b/baijia/64041.html\n","slug":"2019-04-17-data-mind","date":"2023-05-13T11:29:06.791Z","categories_index":"技术人生","tags_index":"技术人生"},{"id":"16be2042ed36bcbed3b5d7b4eb45f41f","title":"思维的火花 --- 大数据与数据思维","content":"在电子设备飞速发展的今天，互联网、移动互联网都已经非常成熟，物联网也在搭建的过程中。对于我们来说4G时代好像还刚开始，5G就即将来临了。每个人、每时每刻都在产生着数据，面对着庞大的数据体量，却只有相对少数的人能够使用正确的方式， 在合适的时机，创造出合适的产品等等。凭借着数据，也诞生了一些新兴的企业或者行业，有人调侃能够使用数据去了解当下，预知未来的视角是先知的视角，从普通的一个广告投放，到预测并影响美国总统大选，从企业门店选址，到智能化精准医疗，数据均是主角，数据为何能够如此的神奇，好像无所不能呢？在了解其本质之前，可能需要先了解一下什么是大数据？什么是大数据时代？\n一、数据与大数据数据关于什么是数据？维基百科是这样解释的：“数据（英语：data），是指未经过处理的原始记录。一般而言，数据缺乏组织及分类，无法明确的表达事物代表的意义，它可能是一堆的杂志、一大叠的报纸、数种的开会记录或是整本病人的病历纪录。数据描述事物的符号记录，是可定义为意义的实体，涉及事物的存在形式。是关于事件之一组离散且客观的事实描述，是构成消息和知识的原始材料。”\n而在计算机的世界里，数据并不是物理世界真实存在的客观事物，而是对客观事物的性质、状态以及相互关系进行记载的物理符号或者物理符号的组合，是可以进行鉴别的符号等。符号不仅指狭义上的数字，还可能是具有一定意义的文字、字符、数字符号的组合，以及图像、视频、音频等等，也可以是客观事物的属性、数量、位置及其相互关系的抽象表示。例如，“0、1、2…&#96;”、“阴、雨、下降、气温”“学生的档案记录、货物的运输情况”等都是数据。简而言之，凡是能够被电子化记录的都是数据。\n\n\n\n大数据与大数据时代有了上面对数据的认识，什么是大数据就明了了。大数据其实就是海量的数据或者巨量数据，这些数据来源于世界各地，每时每刻所产生的记录。那么什么又是大数据时代呢？其实大数据时代是人们对当前由于数据体量巨大，传统处理软件或者处理方式无法在可接受的时间内处理，而必须使用在数十、数百甚至数千台服务器上同时平行运行的软件（例如：计算机集群）的这种现象级事件（未来可能会有各种变数）以及处理方式的改变而起的一个应景的名称。高德纳公司（英语：Gartner，NYSE：IT），美国一家从事信息技术研究和顾问的公司分析员早在2001年指出大数据时代的挑战和机遇有三个方向：数据量（Volume）、数据输入输出的速度（Velocity）、多样性（Variety），合称为3V或者3Vs。在2012年高德纳公司修正了大数据的定义：“大数据是大量、高速、以及多变的信息资产，它需要新型的处理方式去促成更强的决策能力、洞察力与最优化处理。” \n同时有机构在原有3V的基础上定义了第四个V：真实性（Veracity）为第四特点。截止目前人们认可并了解的大数据时代的四个特征，分别为：数据量（Volume）、数据输入输出的速度（Velocity）、多样性（Variety）、真实性（Veracity），一般我们称之为4V。\n数据的价值数据的体量在越来越大，但是数据到底有什么价值？这么多的数据有什么用呢？我们每个人都在时刻产生着数据，对于个人来说，我们都希望数据能够帮助我们或者解决我们所遇到的问题；对于企业来说，希望数据能够提高企业在决策过程中的准确性，改善以往以人的主观意识来做决策的方式亦或提高企业的收入、降低支出或者规避风险等等。不论是个人还是企业，数据的价值核心便是通过对数据的分析研究，得到一个合适合理的结果，以解决某些业务的核心诉求。例如在广告投放领域，传统的方式是广泛撒网，想方设法的覆盖到每个平台、每个时间段，耗时耗力，看似人群覆盖大而广，应该会有很好的收入，但是往往投入产出比很低，而且整个过程耗时耗力，有了大数据的支持之后，研究人员可以通过对历史数据的分析研究，了解用户的各类喜好以及日常习惯，广告的投放就能够根据用户喜好或者场景在合适的时间进行投放，这样既能够实现广告的精准投放，也能够很快的实现转化等等。在这个例子中有一个关键的地方就是，对历史数据进行分析研究，往往比较传统的企业拥有大量的数据，但是却没办法去进行数据的分析研究或者没有想到去进行分析研究，从而错了数据中的价值。\n二、数据思维 — 利用数据解决问题什么是数据思维？数据思维的核心是利用数据解决问题，利用数据解决问题的核心是了解需求、了解业务，了解真正要解决什么样       的问题，解决问题背后的真实目的是什么。在解决问题的过程中通常使用数据的方法，可称为量化的方法。即解决问题的过程要可衡量、可评估，有非常明确的定义。车品觉老师《决战大数据》一书中提出的PIMA，非常好的概述了量化分析的维度，即：\n\n需要有明确的目的(P)\n在达到目的的过程中需要有清晰的定义(I)\n在解决问题的过程中所使用的手段是可量化的(M) 对问题、解决问题的全过程可评估(A)\n\n通过量化的数据解决问题，就是我们所谓的数据思维。数据思维可以套用统计学科一个专有名词—回归分析的思维方式，将业务        问题转化为数据可分析问题。那么什么样的问题可以被看做是数据可分析问题呢？通常需要找到两类业务相关的变量：\n\n因变量Y：即业务的核心诉求。影响业务本身的各种因素或多个因素的组合，均是业务核心诉求的影响因素，只有找到影响业务的因素，才能进一步的确定数据范围，明确核心诉求。\n自变量X：即能够对因变量Y进行解释说明的相关变量，也即影响了因变量Y变化的变量。自变量X更加的需要对业务的熟悉和理解。自变量X并不一定越多越好，而是要在众多变量中，找到影响程度较高或者直接影响因变量Y的变量，才是根本。\n\n数据思维中，难点就是确定因变量Y，即准确的定位业务的核心诉求，并找到影响核心诉求的相关因素，然后使用各种数据分析或       者人工智能的方式方法对数据进行分析研究建模等。\n例如金融类行业最核心的业务诉求是风险控制。如果是简单的存取款问题，可以说是没有风险的。但是如果是信贷问题，可能就存在着一定的风险，此时核心诉求是如何在贷款过程中降低风险，尽量减少贷款个体或企业不还款的风险。这个风险越低，银行的利润空间就越大。因为整个贷款利差并不高，可能只有几个点，最多也不会超过十个点，即便是现在的小贷，也不会超过十个点。但一般一个贷款人还不了款的话，银行利润就会被大打折扣。现在整个市场上的风险率或坏账率有时会高达百分之三、百分之五，即便比较低的时候可能在很多银行有百分之一点几、百分之二点几。所以如何有效的控制这个风险对银行很重要。\n因此需要了解贷款人的还款能力。而且还款能力从他贷款到还款过程中也在时时发生变化，有消费者在贷款瞬间是有还款能力的，但在还款之前的整个周期里他经历的状况其实在不断发生变化。企业更是这样子，每个企业在经营过程中的状态是瞬息万变的。所以对于银行来讲了解消费者或企业的整个经营状况、资产状况、风险状况是非常关键的，中间的每个环节都可能造成贷款人最后无法还款，银行需要评估这里面的每一个因素与最后能否发签证的关系。\n“ 其实我是有一点近视眼的，我看很远处的一个广告牌，上面的文字有时我看得不是很清楚，但我的大脑是能够猜出来文字大概是讲什么的。本质上是因为在我的大脑是拥有识别低分辨率的数据，同时再把它还原推测到高分辨率的那个能力。这种能力其实也是大数据公司里面非常核心的能力。”\n三、数据治理——别让数据成为累赘当具备了数据思维，定位到了核心业务诉求之后，就需要着手对数据进行一系列的处理操作，使得数据能够更好更快的进行分析和研究，以最快的速度实现业务诉求的达成。在数据处理阶段，最为核心的工作有两大类，数据治理和数据关联。先看看数据治理或称为数据清洗。\n在如今时代，每时每刻都会产生大量的数据，但如果这些数据没有办法整合到一起，没办法清洗、在线化，没办法让使用者方便取用，那即便数据量再大也不能说这个公司有大数据。所以清洗和整合数据是非常重要的。通常在技术领域有一个概念叫“ETL”，ETL其实只把数据抽取到一起，进行数据格式统一化，最后再加载到一个可应用的平台上，这是整个数据治理行业里面最核心的几个环节。但在大数据概念出来之后，跟传统ETL有一个挺大的区别在于数据格式跟以前相比更加复杂。通常我们所谓的大数据、我们处理的数据除了包括以前的结构化数据，还包括新的非结构化数据以及半结构化数据。\n非结构化数据是数据结构不规则或不完整，没有预定义的数据模型，不方便用数据库二维逻辑表来表现的数据。包括所有格式的办公文档、文本、图片、XML, HTML、各类报表、图像和音频&#x2F;视频信息等等。数据里每一条记录之间的格式并不统一，甚至很多数据都是无效或者无用的数据。另外还有一种半结构化数据，往往在数据产生的过程中，会有多个形式的数据，多种数据在汇聚到一起时，由于格式的不统一，直接带来存储、处理等方面的压力。而如何有效清洗数据，将多种格式的数据合理清洗、在线化，方便使用者取用是对未来数据应用的关键。\n “并不是所有的数据在系统里面都存在，比如说我跟我同事之间的关系，我跟我爱人之间的家庭关系，可能在公安系统里面并没有       完整的存储数据。但是很多数据可以非常快速的被发现出来。”\n四、数据关联——歌迷与犯罪分子前面我也提到了很多大数据客户不管是政府还是企业都有很多不同的数据，因为数据本身是需要关联起来，在数据真正联系到一起       之后，在数据内部我们可以发现很多数据和数据之间的关系，而这些关系真正的挖掘好了之后，它的实战价值是非常大的，可以起       到1+1远远大于2的作用。\n例如设备和人的关联，假设某人有多个智能设备，每个设备上使用了不同的账户，进行着日常不同的事务，其中一台设备是这个人       的主力设备，当我们采集到相关的信息之后，可以将多个设备之间进行关联，并与这个人的信息以及日常的行为信息进行关联，并       最终的到完整的活动信息。否则当我们只有一部设备的信息时，是无法得到完整的活动信息的，部分数据可能就成了一个孤立的数       据，而无法发挥数据的价值。\n近期，演唱会上抓犯罪分子的事件发生了不止一次。而如何准确定位到某人是否是犯罪分子，靠的就是大数据的支撑以及AI技术的        发展。在公安平台上，会有一个庞大的数据记录，存放着每个犯罪分子的各类特征数据，例如基础的身份证号、人的基本信息、居       住信息、指纹以及人脸特征等等数据，有了这些数据再加上AI技术的帮助，可以将一个人的信息与犯罪分子的信息进行了关联，从       而达到识别犯罪分子的目的。设想如果犯罪分子的备案信息和社会上活动的人之间无法建立连接，会怎样呢？\n五、总结我们现在生活在一个和数据息息相关的时代，时刻都产生着数据，也使用着数据，数据思维提升着人们对数据的整体认知，人们通过对数据进行挖掘，解决日常问题和业务问题，帮助业务成长，提升了数据的价值。在大数据时代，第一、我们要知道数据是如何获取的，了解数据产生、数据流动等问题；第二、要拥有数据思维，拥有数据思维最核心是要考虑一个事务从起因到结果的发展过程，所有数据其实是记录该过程的证据；第三、深入了解业务，尤其是核心的业务，挖掘业务背后的数据问题，将业务问题转变为数据问题。\n参考资料\n维基百科-数据\n《数据思维》\n《数据的本质》\n《决战大数据》\n演唱会上抓罪犯，是如何做到的呢？\n结构化数据 vs. 非结构化数据\n\n","slug":"2019-08-31-mind-flower","date":"2023-05-13T11:29:06.791Z","categories_index":"技术人生","tags_index":"技术人生"},{"id":"8324f2deff47aff54f6d1dc34d4c54d8","title":"技术债务，到底应该怎么还？","content":"几乎所有的技术团队，都会经历或多或少的技术债务，技术债务虽然是实现快速收益的一种捷径，但是为了修复哪些为了快速收益而不得不为之的技术问题，企业往往需要花费大量的金钱、人力等。那么如何有效地避免技术债务，使得开发人员更多的精力投入在有效的工作，从而产生额外价值，提高企业的产品竞争力呢？\n技术债务的产生有着很多的原因，但是其中更多的是由于匆忙的工作使得原来耗时较长的工作，在短时间内完成，导致部分业务逻辑没有完整的设计等，使得产品在短时间内有效，但是长远来看，却是一颗不稳定的炸弹，一旦触发，对产品、对企业都有可能造成无法挽回的损失。总而言之，技术债务会带来很多麻烦，有些甚至是“致命”的。\n\n\n\n\n\n\n\n\n\n本文以发布至：技术专栏丨技术债务，到底应该怎么还？\n什么是技术债务？\n\n\n\n\n\n\n\n\n\n技术负债（英语：Technical debt），又译技术债，也称为设计负债（design debt）、代码负债（code debt），是编程及软件工程中的一个比喻。指开发人员为了加速软件开发，在应该采用最佳方案时进行了妥协，改用了短期内能加速软件开发的方案，从而在未来给自己带来的额外开发负担。这种技术上的选择，就像一笔债务一样，虽然眼前看起来可以得到好处，但必须在未来偿还。软件工程师必须付出额外的时间和精力持续修复之前的妥协所造成的问题及副作用，或是进行重构，把架构改善为最佳实现方式。 \n摘自 维基百科\n很多人将技术债务类比于金融债务，但是和金融债务不同的是，技术债务可能不会承担利息。例如当需要快速验证产品的某个特点的时候，带有一定技术债务的产品可能是个好的选择，当验证之后，无需该特点的时候，可以直接移除等，此时可能不会承担债务利息。但是大多数情况下，此类情况较少，就算仅仅是为了验证产品，也不建议使用技术债务的方式去实施。类似这样方式的技术债务可称为有意的技术债务，另一种更加危险的技术债务称为无意的技术债务，无意的技术债务就像是前文说到的隐藏在代码中的炸弹。\n无论是那种技术债务，在未来的产品迭代过程中，都需要开发人员去界定债务边界，不能任由技术债务滋生，否则在迭代过程中，面临的困难越来越多，甚至需要被迫承担更多的技术债务。基本上，你承担的债务越多，项目的进度就越慢，项目的后续阶段就会更加困难。\n但是需要清楚的是，技术债务是无法消除的，你必须随时做好承担技术债务的准备。因为在一些项目场景中，一些具体问题的解决方案本身是可以解决问题的，但是该方案可能不是全局有效或最佳的，在系统的其他方面，就形成了一个不可避免而必须承担的技术债务问题。一个好的工程师团队应该是最小化技术债务影响，并对技术债务进行合理管理的团队。\n\n上文提到，技术债务分为有意的技术债务和无意的技术债务，两种形式的技术债务形成的原因和带来的结果也是不同的。在某些情况下，有意的技术债务相比无意的技术债务更好，有意的技术债务会让团队意识到问题，从而有意的去进行优化改进等，而无意的技术债务可能在项目中潜伏很长一段时间，可能导致严重的问题，然而，无意的技术债务在项目中是无法避免的，在工程师团队中可以强化编码规范、业务理解等来进行管理或者减弱技术债务出现的可能。\n另外还可以将技术债务分类为鲁莽型技术债务和谨慎型技术债务 。一些谨慎型的技术债务在项目的进度中是可取的，但是不论是那种技术债务，都需要每个人用于去承担，两者是共同工作的。理想的情况下，承担的债务应当是哪些有意的和谨慎的技术债务，而哪些无意的和鲁莽的技术债务应当不惜一切代价避免。\n为什么要关心技术债务？\n技术债务如何影响开发在开发阶段，开发人员不可避免会遇到技术债务，开发人员应当直面技术债务，并处理技术债务问题。虽然处理技术债务可能会使得开发周期变长，但从长远来看，开发人员及时处理技术债务是有益的，一方面处理技术债务是一个技术经验积累的过程，另一方面及时的处理在之后的迭代中也减少了技术债务产生的可能等。每一个开发员都应当有意的或者尽力地避免那些无意的技术债务和鲁莽的技术债务等。\n技术债务如何影响客户虽然乍看起来，技术债务和客户并无联系，客户也不太关心产品的代码质量等，客户只需要在成本没有增加的情况下，产品按时交付使用。然而，一个携带无意或者鲁莽的技术债务的产品在开发过程中，往往需要花费更多的时间、精力和资源，导致成本增加，但是收益却减少的情况等。\n\n技术债务如何影响用户即使是间接的，用户也会受到技术债务的影响。 他们可能不关心软件中的工作量或资金数量，但他们确实关心它的可靠运行，以及快速添加的新功能，这两者都可能受到大量技术债务的影响。 用户越快乐，客户越快乐，开发者越快乐。\n技术债务最佳实践\n解决科技债务的最大问题是，它无法真正量化。这使得开发团队很难跟踪并让管理层向客户展示为什么要投入更多的资源和时间。\n但是这里有一些你可以做的事情：\n保持最新状态不言而喻，工具，框架和库应该始终保持最新状态，可能你还未意识到这个问题所带来的影响，那只是你还没意识到而已。\n文档记录需要修复或更新的所有内容是确保实际修复和更新的最重要步骤。\n如果存在技术债务，最好了解它并确保团队或未来的开发人员也知道。 文档减少了定位和修复任何问题所需的工作量，如果债务记录良好，甚至可能在业务层面上可见，将可能导致客户承认并提供额外资源。\n代码评审另一个强大的工具是在sprint期间定期审查代码。 代码审查可以捕捉到可能导致问题的隐患，并找到解决方案。 代码评审确实需要一些时间，但在整个项目的背景下肯定是值得的。\n但是，代码审查也有其缺点。 开发人员往往太忙，无法深入挖掘他人的代码，因此他们只会发现明显的错误，而挑剔可能会导致团队内部紧张。 因此，它可以成为减少技术债务的有力工具，但应该谨慎应用。\n自动化测试自动化测试是一种非常强大的工具，但是经常被忽视。 自动化测试被忽略后，代码中的隐藏问题可能会无法察觉出，往往导致产品发布后需要投入不成比例的人力和时间来应对，是的成本变高甚至不可控。在开发阶段，有必要实施测试驱动开发，编写完善的测试用例，以清除代码中的许多不易察觉的问题等。\n敏捷架构敏捷架构具有很多优点，在构建软件的过程中对更改更加开放，基本上保证在任何项目上都会发生。 但是，它确实要求代码具有灵活性和可维护性，因此敏捷方法自然会使开发人员保持良好的代码，这有助于防止大量技术债务的积累。\n有效地复盘如果出现问题，应该用于面对，当问题解决后，需要进行有效地复盘。 但是要注意的是复盘是为了提高工作效率，绝不应该是找人责备。 复盘的重点应放在了解问题及其产生的原因上，以便团队可以采取必要措施防止同样的问题再次发生。 \n管理技术债务的最佳做法\n即使你做了以上所有事情，并尽可能避免堆积技术债务，你仍然需要处理一些问题。 这是无法避免的，因此您应该实施实践和流程以防止技术债务陷入困境。\n高息技术债务优先并非所有技术债务都是平等的，因此您应该优先考虑在特定时间解决的问题以及不解决的问题。 对于经常使用和更改的代码而言，比在几乎没有使用或更改过的部分的重要性要重要得多。\n高息债务往往是那些在项目中起重要做的核心部分，通常围绕它进行了很多工作并以此为基础。 如果此部分的技术债务保持不变，就会妨碍所有的工作，并可能迫使更多的技术债务被添加到代码的其他部分。 因此，如果有可能，首先应优先考虑这些问题，从长远来看，使一切变得更加顺畅。\n童子军规则“要始终保持营地比你发现它的时候更清洁”也是适用于软件开发的：“提交的代码比检出的要更好”。鼓励团队成员，以积极减少技术债务 ; 例如，当他们发现了一块为了功能增加或错误修复的代码时激励他们重构。\n当然，它不能没有边界，否则它可能是一直消耗。 但是，如果你在每个sprint中留出一定比例的时间专门用于修复开发人员可能发现的任何技术债务，那么它可以在很大程度上保持产品尽可能无债务。\n\n在履行有价值的客户工作时偿还债务在项目的整个冲刺阶段，用于修复技术债务不是一个好主意。 一方面，客户往往不喜欢延期，对他们来说，看起来你似乎花了他们的时间和金钱来解决你做错的事情。另一方面，它也表明你已经做了大量的技术债务工作，所以你可能已经支付了更高的债务利息。\n你最好指定在每个冲刺中偿还技术债务所花费的时间，并用它来解决高优先级或发生过的问题。 让客户满意，并使技术债务处于可控水平。\n忽略同样重要的是要注意技术债务不应该总是得到偿还。 当产品接近其使用寿命时，如果它是短期制造的，或者它是一次性原型，技术债务不是主要问题。 这些实例很少见，但是当它们出现时你可以节省一些时间和精力。\n结论技术债务是伴随着项目的，无法避免，但是如何保持其在可控范围之内，是我们应该思考的问题。技术债务的避免和消除都需要好的优秀的开发人员，人始终是软件开发中最重要的因素。作为一名普通的码农，不断地提升自己是非常必要的。\n参考资料\nTECHNICAL DEBT: EVERYTHING YOU NEED TO KNOW, AND HOW TO MANAGE IT\n技术负债\n技术债治理的四条原则\n解析技术债务\n\n","slug":"2019-08-31-technical-debt","date":"2023-05-13T11:29:06.791Z","categories_index":"技术人生","tags_index":"技术人生"},{"id":"04c112f33ade68949ca049cf167e7b66","title":"深入了解Core ML 3","content":"\n在之前的文章中，介绍过iOS 11中的机器学习，简单了解了伴随iOS 11发布的Core ML框架，以及简单的使用方式等，随后，Core ML 技术底层探秘也揭开了点Core ML背后的技术和数据结构，对Core ML相对有了一个认识。随着Core ML vs ML Kit：哪一个移动端机器学习框架更适合你？，简单比较了两者的差异之后，尝试了从Keras开始构建iOS平台手写数字实时识别的实现，以及学习了Apple开源机器学习框架 Turi Create 简介与实践，并使用Turi Create进行了人类行为识别任务的尝试，如何使用Turi Create进行人类行为识别，对Apple的机器学习架构有了基本的认识。经过两次大版本的迭代，目前Core ML 3 也随即推出，对比之前的版本，Core ML 3 可以说已经是一个完整的端测智能计算架构，其中也改变了很多实现方式和支持的协议类型等，这里将再次学习，以加深对Core ML的架构认识，并探索其端测智能计算体的使用和可能的业务等。\n\n通过WWDC 2019 Machine Learning and Vision的介绍可以了解到，全新的Core ML 3 为iOS侧的机器学习增加了很多特性，其中称得上杀手锏的是端测训练模型的特性，以及支持更多先进的模型结构，由于增加了非常多的新的层类型，是的曾经无法执行的模型结构在端测使用也称为了可能。\n\n这次的更新，是2017年Core ML推出以来最大的一次更新。新特性的Core ML配合Apple 的 A12 神经引擎芯片，Apple可谓在端测计算能力上提升了一大步，可想而知，未来苹果会在此方向在此提高和优化，构建完善的CoreML端测计算生态系统。\n这篇文章将在Core ML 技术底层探秘的基础上，学习mlmodel格式的改变和新增的层类型等，而不会直接涉及CoreML.framework的API（事实上，除了增加了训练模型的API外，其他并没有变化）。\n由于Core ML所使用的模型目前都是由其他机器学习框架训练后，进行转换后来使用的，因此如果能够详细的了解Core ML所支持的类型，那么对于设计自己的机器学习模型，并能够顺利投入到Core ML中使用，是有一定的帮助的。\n万变不离其宗 — proto文件如果仅仅是查阅CoreML.framework 的 API文档，并不能找到相关的模型格式细节说明等，事实真相是，细节内容并不在API的文档中，而是在Core ML的模型规格文档里。\n该规范是由许多包含protobuf消息定义的**.proto**文件组成。Protobuf是Core ML的mlmodel文件使用的序列化格式，该序列化技术是目前较为常用的，TensorFlow和ONNX也同样使用该格式。关于proto文件的具体内容，可以在Core ML的模型规格文档中找到，如果你习惯阅读源码，也可以直接查看coremltools repo，其中有目前支持的所有内容。\n在所有的proto文件中，主要的格式规格文件是Model.proto，该文件中定义了模型的种类，以及输入和输出的类型，另外还定义了已支持模型的不同类型等等。\n在该文件中，比较重要的属性还有Model类中的 specification version，该属性决定了模型的版本以及哪些函数在mlmodel文件中支持，那个操作系统能够运行模型等。\n\n\n\n\n\n\n\n\n\n\n目前官网还没有将specification version修改为最新的 4，上图是官网文件中的定义，可以预知到正式版推出后，specification version将是 4。\nCore ML的模型规格版本号为 4 的情况下，只能运行在iOS 13 和macOS 10.15（Catalina）或更新的版本上。如果你需要运行在iOS 12或者iOS 11，需要剔除掉最新的特性。\n\n\n\n\n\n\n\n\n\n当使用coremltools进行模型转换的时候，coremltools将选择最低的可能规格版本对模型格式进行兼容。v3版本的模型能够运行在iOS 12上，v2版本的模型能够运行在iOS 11.2上，v1版本能够在iOS 11上运行，当然，如果你的模型使用了任何最新的特性，就只能运行在iOS 13及以后的系统中。\n新的模型类型Core ML始终支持以下模型类型（spec v1）：\n\nIdentity（映射）： 仅用于测试，将输入数据传递到输出；\nGLM（广义线性）： 支持广义线性回归器和分类器；\nSVM（支持向量机）： 支持支持向量机回归和分类，底层使用的是libsvm；\nTree ensemble（决策树模型）： 支持回归和分类；\nNeural networks（神经网络）： 支持回归、分类，以及一般目标的神经网络；\nPipeline models（管道模型）： 连接多个模型，形成一个机器学习工作流；\nFeature engineering（特征工程）： 这里指的是支持特征工程的数学模型类型，例如One-Hot编码、缺失值处理、输入矢量化等，这些主要用于将scikit-learn模型转换为Core ML。该模型将变为一个管道，该管道连续具有多个这些特征工程模型。\n\nspec v2 仅仅是一个小小的更新，支持了16-bit浮点权重。开启之后，mlmodel文件将减小2倍，但是经过一些使用者反映，此优化并没有提高模型的运行耗时。\n在Core ML 2（spec v3）中，增加了如下的模型类型：\n\nBayesian probit regressor（贝叶斯概率回归）： 一种奇特的逻辑回归版本；\nNon-maximum suppression（非极大值抑制）： 对目标检测任务的后期处理有用，通常位于Pipeline的最后一层；\nVisionFeaturePrint（可视化特征描述）： 用于卷积神经网络，从图像中提取特征，输出规格是2048个元素的向量。也可用于图像的相似性检测等任务；\nCreate ML Support Models： 其他来自Create ML工具的模型类型，例如文本分类、词标注等；\nCustom models（自定义模型）： 有时候，你可能有一个CoreML还不支持的模型类型，但是仍然希望将该模型与其他模型放在一起使用。自定义模型的功能允许开发者将模型参数和数据放置在mlmodel文件中，同时将自定义的逻辑放在应用程序中。\n\nspec v3 还增加了以减小mlmodel文件大小的权重量化功能以及灵活的输入大小，API层面增加了批处理预测，并为顺序数据提供了更好的支持。\n在Core ML 3（spec v4）中，增加了如下的模型类型：\n\nk-Nearest Neighbors（k-NN，k近邻）： k-NN分类器；\nItemSimilarityRecommender（基于相似度的推荐器）： 可以使用该类型构建个性化推荐模型\nSoundAnalysisPreprocessing（声音分析预处理）： 支持Create ML的声音分类模型。输入音频信号样本，并会转换为mel频谱图，可以在Pipeline中用做音频特征模型的输入；\nGazetteer： 支持Create ML的MLGazetteer模型，使用自然语言处理框架中的NLTagger。一个gazetteer是一个用于单词和短语的花式查找表；\nWordEmbedding： 支持Create ML的新MLWordEmbedding模型，该模型是单词及其嵌入向量的字典。也用于自然语言框架；\nLinked models： 对应用程序包中另一个mlmodel文件（编译版本，mlmodelc）的引用。这使得可以跨多个分类器重用昂贵的特征提取器 - 如果两个不同的管道使用相同的链接模型，则只会加载一次。\n\n目前，Model对象的属性中增加了isUpdatable属性，当该属性是true时，代表模型可以在端测进行训练，目前仅支持神经网络和k-NN模型。\nk-NN模型是一个相对简单的机器学习模型，非常适合在端测进行训练，常见的方法是使用固定的神经网络，例如VisionFeaturePrint，从输入数据中提取特征，然后使用k-NN对这些特征向量进行分类。这样的模型在训练时很快，因为它只是记住了你输入的样本，并没有做任何实际的学习。\nk-NN模型的一个缺点是，当记忆了非常多的样本时，预测就会变得很慢，但是在Core ML中，使用了一个k-NN的变种**K-D树**。(下图是一个三维k-d树)\n\n神经网络的更新在Core ML 2的版本中，仅支持40中不同的神经网络层类型，Core ML 3中增加了超过100中层类型。但是并不是所有的都是新增，部分是对旧的层类型的改进，以支持或者更加适合处理柔性张量的处理等。\n在Core ML 2及之前的版本，流入神经网络的数据总是一个5等级的张量，也就是说每个张量都是由如下5个维度组成的：\n(sequence length, batch size, channels, height, width)\n\n当神经网络的输入是图像的话，这个数据结构非常适合，但是对于其他数据结构就不那么适合了。\n例如，在处理一维向量的神经网络中，应该使用channels来描述向量的大小，并将其他维度设置为1，在这种情况下，输入的张量形状是(1, batch size, number of elements, 1, 1)。虽然这样的方式也可以解决问题，但是对于开发者来说，无意义的参数设置就是浪费时间，因此在Core ML 3中新增了很多新层来支持任意等级和形状的张量，使Core ML对于处理图像之外的数据也更适合。\n\n\n\n\n\n\n\n\n\n上面部分的描述均来自proto文件中的描述和解释的理解，在其他的文档中并不会去解释和说明这些内容，因此有兴趣的话，可以详细阅读下proto文件的内容，以加深理解。\n在NeuralNetwork.proto文件中，接近6000行的内容，对Core ML中神经网络的内容进行了描述和定义。\n其中，主对象是NeuralNetwork，还有另外两个变种NeuralNetworkClassifier和NeuralNetworkRegressor，不同的是，普通的神经网络输出的是MultiArray对象或者image，分类器输出的是包含类别和对应预测概率的字典，回归器输出的是一个数值。除了输出和响应的解释不同，但是这三种模型的工作方式是相同的。\nNeuralNetwork对象含有一个层的列表，以及任何图像输入的预处理选项列表。Core ML 3 增加了一些描述的新特性：\n\n输入的MultiArray类型是如何转换为张量的。此时，开发者可以选择老的方式，创建一个秩为5的张量，或者使用新的方式。大多数情况下的输入类型都不是图像，因此这里将是常用的方法。\n输入的Image类型是如何转换为张量的。更换了老的秩为5的张量，开发者可以使用秩为4的张量，(batch size, channels, height, width)。这里去除了在图像处理中不需要的sequence length维度。\n训练模型的超参数。在NetworkUpdateParameters中描述。\n\n关于端测训练的能力，Core ML 3中也相应增加了一些支持的描述，具体如下：\n\nisUpdatable位于Model对象中，表示模型是否可以被训练或再训练；\n在任何希望进行训练的层中，isUpdatable必须设置为true。使用该参数，开发者可以控制某些层的训练与否。目前，端测训练仅支持卷积层和全链接层；\nWeightParams是训练时可学习的参数，只有在isUpdatable为true的时候会起效；\n在训练前，需要为模型定义一个训练输入，该输入将用于训练中损失函数的实际标签。\n\n另外，在NetworkUpdateParameters对象中，定义了模型训练的一些方法和参数等，具体描述如下：\n\nlossLayers：指定使用那种损失函数，目前支持分类交叉熵和MSE（均方误差）。在mlmodel文件中，损失函数是另外的一层，含有两个属性，模型输出层名称和对应目标类别的训练输入名称。对于交叉熵损失函数，输入必须连接softmax输出层；\noptimizer：目前支持SGD（随机梯度下降）和Adam（可替代SGD的一种一阶优化算法）；\nepochs：模型训练的迭代次数。\nshuffle：每次迭代时，数据是否需要随机重新排序；\nseed：随机种子参数。\n\nCore ML 2 中的神经网络层 对于神经网络来说，最有意思的还算各种神经网络层了，在Core ML第一个版本中，支持一下的神经网络层类型：\n\nConvolution（卷积层）：仅支持2维度，但是可以设置内核宽度和高度为1来使用1维。同时支持空洞卷积或扩张卷积、分组卷积和反卷积；\nPooling（池化层）：支持max、average、L2，以及全局Pooling；\nFully-connected（全链接层）：也被称为内积层或密集层；\nActivation functions（激活函数）：支持linear、ReLU、leaky ReLU、thresholded ReLU、PReLU、tanh、scaled tanh、sigmoid、hard sigmoid、ELU、softsign、softplus、parametric soft plus；\nBatch normalization（批量标准化层）：\nNormalization（标准化层）：mean &amp; variance, L2 norm, and local response normalization (LRN)；\nSoftmax：在NeuralNetworkClassifier中的最后一层使用；\nPadding（填充）：用于在图像张量的边缘周围添加额外的零填充。卷积和池化层已经可以自己处理填充，但是使用此层可以执行诸如反射或复制填充之类的操作；\nCropping（剪裁）：用于去除张量边缘周围的像素；\nUpsampling（上采样）：最近邻或双线性上采样整数比例因子；\nUnary operations（一元处理）：sqrt, 1&#x2F;sqrt, 1&#x2F;x, x^power, exp, log, abs, thresholding；\nTensors Element-wise operations（两个及以上张量元素操作）：add, multiply, average, maximum, minimum；\nTensor Element-wise operations（两单个张量元素操作）：乘以比例因子，增加偏差；\nReduction operations（降维）： sum, sum of natural logarithm, sum of squares, average, product, L1 norm, L2 norm, maximum, minimum, argmax；\nDot product（张量点积）：计算余弦相似度；\nReorganize（张量重组）： reshape, flatten, permute, space-to-depth, depth-to-space；\nConcat, split, and slice（张量联合、分割、切片）：张量合并或扩张；\nRecurrent neural network layers（递归神经网络层）：basic RNN, uni- and bi-directional LSTM, GRU (unidirectional only)；\nSequence repeat（序列复制）：多次复制给定的输入序列；\nEmbeddings\nLoad constant（负载常数）：可以用于向一些其他层提供数据，例如对象检测模型中的锚定区。\n\nApple在 Spec v2 中增加了对神经网络中自定义层的支持。这个补充，对更多模型的转换有了很大的帮助。\n在mlmodel文件中，自定义图层只是一个占位符，可能具有经过训练的权重和配置参数。在应用程序中，应该提供该层功能的Swift或Objective-C实现，并且可能还有一个Metal版本以及在GPU上运行它。 不幸的是，神经引擎目前不是自定义图层的选项，该功能也仅支持传统机器学习模型。\n例如，如果模型需要不在上面列表中的激活函数，则可以将其实现为自定义层。也可以通过巧妙地组合其他一些图层类型来完成此操作。例如，可以通过进行常规ReLU，然后将数据乘以-1，将阈值乘以-6，最后再乘以-1来制作ReLU6。这需要4个不同的层，但理论上，Core ML框架可以在运行时优化它。\n在Core ML 2（Spec v3）中，添加了以下图层类型：\n\nResize bilinear：与上采样层（仅接受整数比例因子）不同，这使您可以将双线性调整为任意图像大小；\nCrop-resize：用于从张量中提取感兴趣的区域。这可以用于实现掩模R-CNN中使用的RoI Align层。\n\n在Core ML 3（Spec v4）放宽了对这些现有层类型的要求，除了添加了一大堆新层之外，Core ML 3还使现有的图层类型更加灵活。\n新的神经网络层上文提到，此次更新，新增了100多个层，下面会一一查看都有哪些层，更加详细的内容可参考NeuralNetwork.proto描述文件。\nCore ML 3 为元素明确的一元操作添加以下层：\n\nClipLayer：夹在最大值和最小值；\nCeilLayer、FloorLayer：对张量进行ceil和floor运算；\nSignLayer：告知数字是正数，零数还是负数；\nRoundLayer：将张量的值四舍五入为整数；\nExp2Layer：对张量元素进行2^x运算；\nSinLayer, CosLayer, TanLayer, AsinLayer, AcosLayer, AtanLayer, SinhLayer, CoshLayer, TanhLayer, AsinhLayer, AcoshLayer, AtanhLayer：（双曲线）三角函数；\nErfLayer：计算高斯误差函数。\n\n这次和运算相关的增加，扩展了Core ML支持的数学原语的数量，与已有的数学函数不同，它们可以处理任何等级的张量。\n这里只有一个新的激活函数：\n\nGeluLayer：高斯误差线性单元激活函数，精确的或使用tanh或S形近似。\n\n当然，也可以使用任何一元函数作为激活函数，或通过组合不同的数学层来创建一个。\n另外还增加了用于比较张量的新的层类型：\n\nEqualLayer, NotEqualLayer, LessThanLayer, LessEqualLayer, GreaterThanLayer, GreaterEqualLayer\nLogicalOrLayer, LogicalXorLayer, LogicalNotLayer, LogicalAndLayer\n\n当条件为真时，这些函数输出一个新的张量，其值为1，反之为0。这些图层类型支持广播，因此您可以比较不同等级的张量。您还可以将张量与（硬编码）标量值进行比较。\n这些图层类型有用的一个地方是使用新的控制流操作（见下文），以便您可以根据比较的结果进行分支，或者创建一个循环，该循环一直重复直到某个条件变为false。\n以前，在两个或更多张量之间有一些用于元素操作的图层。Core ML 3添加了一些新类型，从名称可以看出这些新增的更加灵活，因为它们完全支持NumPy风格：\n\nAddBroadcastableLayer： 加法\nSubtractBroadcastableLayer：减法\nMultiplyBroadcastableLayer：乘法\nDivideBroadcastableLayer：除法\nFloorDivBroadcastableLayer：除法返回四舍五入的整数结果\nModBroadcastableLayer：除法余数\nPowBroadcastableLayer：幂运算\nMinBroadcastableLayer, MaxBroadcastableLayer：最大、最小\n\n在新的Core ML中，内置了大量的张量操作方法，而且不仅是图像，也可以通过一个或者多个维度的变换来进行张量缩小等。\n\nReduceSumLayer：计算指定维度的总和\nReduceSumSquareLayer：计算张量元素的平方和 \nReduceLogSumLayer：计算元素的自然对数之和\nReduceLogSumExpLayer：指定元素进行加和，再取自然对数\nReduceMeanLayer：计算元素的平均值\nReduceProdLayer：所有元素的乘积\nReduceL1Layer, ReduceL2Layer： L1、L2标准化\nReduceMaxLayer, ReduceMinLayer：寻找最大值、最小值\nArgMaxLayer, ArgMinLayer：最大值、最小值的索引\nTopKLayer：找到k个顶部（或底部）值及其索引。\n\n关于数学的计算，Core ML 3还增加了如下的类型：\n\nBatchedMatMulLayer：两个输入张量上的通用矩阵乘法，或单个输入张量和一组固定的权重（加上可选的偏差）。支持广播并可在进行乘法之前转置输入；\nLayerNormalizationLayerParams：一个简单的归一化层，它减去β（例如均值）并除以γ（例如标准偏差），两者都作为固定权重提供。这与现有的MeanVarianceNormalizeLayer不同，后者执行相同的公式但实际上在推理时计算张量的均值和方差。\n\n许多其他现有操作已经扩展到使用任意大小的张量，也称为秩-N张量或N维张量。您可以通过名称中的“ND”识别此类图层类型：\n\nSoftmaxNDLayer\nConcatNDLayer\nSplitNDLayer\nTransposeLayerParams\nEmbeddingNDLayer\nLoadConstantNDLayerParams\n\nCore ML 3为我们提供了两个新的切片层，支持在任何轴上切片：\n\nSliceStaticLayer\nSliceDynamicLayer\n\n静态基本上意味着“预先知道此操作的一切”，而动态意味着“此操作的参数可以在运行之间改变”。例如，图层的静态版本可能具有硬编码的outputShape属性，而动态版本每次都可以使用不同的输出形状。\n因为Core ML不再局限于基于静态图像的模型，而是现在还包含控制流和其他动态操作的方法，因此它必须能够以各种奇特的方式操纵张量。\n\nGetShapeLayer\nBroadcastToStaticLayer, BroadcastToLikeLayer，BroadcastToDynamicLayer\nRangeStaticLayer, RangeDynamicLayer\nFillStaticLayer, FillLikeLayer, FillDynamicLayer\n\n其中一些图层类型有三种不同的变体：Like，Static和Dynamic。\n\nStatic：该图层的所有属性都在mlmodel文件中进行了硬编码。\nLike：需要一个额外的输入张量并输出一个与输入具有相同形状的新张量。\nDynamic：它还需要一个额外的输入张量，但这次它不是那个重要的形状，而是它的内容。\n\nCore ML 3还允许您通过随机分布采样创建新的张量：\n\nRandomNormalStaticLayer, …LikeLayer, …DynamicLayer\nRandomUniformStaticLayer, …LikeLayer, …DynamicLayer\nRandomBernoulliStaticLayer, …LikeLayer, …DynamicLayer\nCategoricalDistributionLayer\n\n另外的一些变体层：\n\nSqueezeLayer：删除任何大小为1的维度\nExpandDimsLayer：和SqueezeLayer相反\nFlattenTo2DLayer：将输入张量展平为二维矩阵\nReshapeStaticLayer, ReshapeLikeLayer, ReshapeDynamicLayer\nRankPreservingReshapeLayer：类似NumPy中的reshape(…, -1)\n\n除了任意张量的连续和分割操作外，Core ML 3还增加了以下张量操作操作：\n\nTileLayer：重复张量一定次数\nStackLayer：沿着新轴连接张量\nReverseLayer：反转输入张量的一个或多个维度\nReverseSeqLayer：对于存储数据序列的张量，反转序列\nSlidingWindowsLayer：在输入数据上滑动一个窗口，并在每一步返回一个带有窗口内容的新张量\n\n同样支持聚集和缩放：\n\nGatherLayer, GatherNDLayer, GatherAlongAxisLayer：给定一组索引，只保留输入张量的那些索引\nScatterLayer, ScatterNDLayer, ScatterAlongAxisLayer：将一个张量的值复制到另一个张量中，但仅限于给定的索引。除了复制之外，还有其他累积模式：加，减，乘，除，最大和最小。\n\n除了能够选择层之外，还可以选择某些指定的层：\n\nWhereNonZeroLayer：创建一个只有非零元素的新张量。您可以将此与张量比较中的掩码张量一起使用，例如LessThanLayer。\nWhereBroadcastableLayer：采用三个输入张量，两个数据张量和一个包含（真）或零（假）的掩码。返回包含第一个数据张量或第二个数据张量元素的新张量，具体取决于掩码中的值是true还是false。\nUpperTriangularLayer, LowerTriangularLayer：将对角线下方或上方的元素归零\nMatrixBandPartLayer：将中心带外的元素归零\n\n目前，coremltools 3.0的Beta中还隐藏了一些新的图层类型：\n\nConstantPaddingLayer：在张量周围添加一定量的填充。与现有的填充图层不同，此图层适用于任何轴，而不仅仅是宽度和高度尺寸。\nNonMaximumSuppressionLayer：已经有一个单独的模型类型用于在边界框上进行NMS，您可以在对象检测检测模型之后将其放入管道中，但现在也可以直接在神经网络内部进行NMS。\n\n在Core ML 3中还增加了控制流层，这些层是激动人心的，极大的提高了神经网络的结构适配广度：\n\nBranchLayer\nLoopLayer\nLoopBreakLayer\nLoopContinueLayer\nCopyLayer\n\n这些控制流相关的层，coremltools给出了使用样例，详细使用方式可以参考Neural_network_control_flow_power_iteration.ipynb。\n至此，Core ML 3中的新的内容基本罗列出来了，可以看到，在新的升级更新中，大多数都是针对层张量的创建、整形和操作，还有很多的数学运算能力的提升，但是通过这些操作，开发者已经可以通过定制、组合等来支持新的层类型，然后实现不同的AI任务等。Apple在一步一步地强化着Core ML的体系，以增强端测AI的能力，\n参考资料\ncoremltools\nCore ML Documentation\nAn in-depth look at Core ML 3\n\n","slug":"2019-09-05-coreml-indepth-look","date":"2023-05-13T11:29:06.791Z","categories_index":"端测计算","tags_index":"端测计算 CoreML"},{"id":"cbe0c261ec14d11a436421cf64def38c","title":"机器学习与移动应用开发的未来","content":"移动开发者可以从设备上的机器学习（on-device machine learning）所能提供的革命性变化中获益匪浅。这是因为该技术能够支持移动应用程序，即允许通过利用强大的功能来实现更流畅的用户体验，例如提供准确的基于地理位置的建议或即时检测植物疾病等。\n移动机器学习（mobile machine learning）的这种快速发展已经成为是对经典机器学习（classical machine learning）所面临的许多常见问题的回应。事实上，这些问题即将发生。未来的移动应用将需要更快的处理速度和更低的延迟。\n你可能会疑问为什么人工智能优先的移动应用程序（AI-first mobile applications）不能简单地在云端中进行推理运算。首先，云技术依赖于中央节点（设想一个拥有大量存储空间和计算能力的大型数据中心）。而这种集中式的方式无法满足创建流畅的、基于机器学习驱动的移动用户体验所需的处理速度。因为数据必须在这个集中式数据中心进行处理，然后将结果发送回设备。这需要花费时间和金钱，并且很难保证数据的隐私。\n在概述了移动机器学习的这些核心优势之后，下面让我们更详细地探讨为什么作为移动应用开发者，你会希望继续关注即将到来的设备机器学习革命。\n\n\n\n降低延迟\n移动应用开发者都知道，高延迟将会是导致一个 App 失败的重要原因，无论其功能有多强大或者品牌声誉如何。Android 设备的许多视频类应用在过去曾存在延迟问题，导致观看时音频和视频不同步的体验。同样，一个高延迟的社交应用也会导致非常令人沮丧的糟糕用户体验。\n正是由于这些延迟问题，在移动设备上运用机器学习变得越来越重要。考虑到社交媒体图像过滤器和基于位置的用餐建议 —— 这些应用程序功能需要低延迟才能提供最高级别的结果。\n如前所述，云处理的时间可能会很慢，最终，开发者需要达到零延迟才能使机器学习功能在其移动应用中正常运行。设备上的机器学习通过其数据处理能力为接近零延迟铺平了道路。\n\n\n\n\n\n\n\n\n\n\n图为实时低延迟的示例：Heartbeat 应用中实时视频的样式转换结果。\n智能手机制造商和大型科技公司正在追赶这一目标。Apple 在这方面一直处于领先地位，它正在使用其仿生系统（Bionic system）开发更先进的智能手机芯片，该系统具有一个完整的神经引擎，可帮助神经网络直接在设备上运行，并具有令人难以置信的处理速度。\nApple 还在继续迭代更新 Core ML，这是一个面向移动开发者的机器学习平台；TensorFlow Lite 增加了对 GPU 的支持；Google 继续为其自己的机器学习平台 —— ML Kit 增加预加载特性。这些技术是移动开发者用于开发能够以闪电般的速度处理数据、消除延迟和减少错误的应用程序的技术之一。\n这种精确性和无缝衔接的用户体验的结合是移动开发者在创建由 ML 驱动的应用程序时需要考虑的首要因素。为了保证这一点，开发者需要拥抱并接受设备上的机器学习。\n增强安全性和隐私\n边缘计算（edge computing）的另一个不可低估的巨大优势是它如何提高其用户的安全性和隐私性。确保应用程序数据的受保护和隐私是移动开发者工作中不可或缺的一部分，特别是考虑到需要满足通用数据保护法规（General Data Protection Regulations，GDPR），这些新的隐私相关法律肯定将会影响移动开发实践。\n由于数据不需要发送到服务器或者云端进行处理，因此网络犯罪分子很少能有机会利用数据传输中的任何漏洞，从而保证了数据的不受侵犯。这使移动开发者可以更轻松地满足 GDPR 中关于数据安全的规定。\n设备上的机器学习解决方案也提供了去中心化，这与区块链的做法非常相似。换句话说，与针对集中式服务器的相同攻击相比，黑客更难通过 DDOS 攻击摧毁隐藏设备的网络连接。这项技术也可被证明对无人机和未来的执法工作有用。\n上述 Apple 智能手机芯片也有助于提高用户安全性和隐私性，例如这些芯片是 Face ID 的支柱。iPhone 的这一功能依赖于设备上的神经网络，它可以收集用户脸部所有不同维度的数据，作为更准确，更安全的识别方法。\n\nApple 介绍 iPhone X 上的 Face ID 视频链接：https://www.youtube.com/watch?v=z-t1h0Y8vuM\n\n这类以及未来的人工智能硬件将为用户提供更安全的智能手机体验铺平道路，并为移动开发者提供额外的加密层，以保护用户的数据。\n无需网络连接\n除了延迟问题之外，将数据发送到云端以进行推理计算还需要有效的 Internet 连接。通常，在世界上比较发达的地区，这种方式可以很容易实现。但是，在网络连接不发达的地区呢？通过设备上的机器学习，神经网络可以直接在手机上运行。这允许开发者在任何给定时间和在任何设备上使用该技术，而不用管网络连接性如何。此外，它可以使机器学习特性大众化，因为用户不需要 Internet 连接到他们的应用程序。\n医疗保健是一个可以从设备上的机器学习中受益匪浅的行业，因为应用开发者能够创建医疗工具来检查生命体征，甚至可以进行远程机器人手术，而无需任何 Internet 连接。该技术还可以帮助那些需要在没有网络连接的地方访问课堂材料的学生，例如在公共交通隧道中。\n设备上的机器学习最终将为移动开发者提供创建应用程序的工具，这些应用可以使世界各地的用户受益，无论他们的网络连接情况如何。即使没有互联网连接，但未来新的智能手机功能将非常强大，用户在离线环境中使用应用程序时也不会受到延迟问题的困扰。\n减少业务开销成本\n设备上的机器学习还可以为您节省一笔支出，因为您不必为实现或维护这些解决方案而向外部供应商付费。如前所述，您不需要云计算或互联网来提供此类解决方案。\nGPU 和人工智能专用芯片将是您可以购买的最昂贵的云服务。在设备上运行模型意味着您不需要为这些集群付费，这要归功于如今智能手机中日益复杂的神经处理单元（Neural Processing Units，NPU）。\n避免移动端和云端之间繁重的数据处理噩梦，对于选择设备上的机器学习解决方案的企业来说是一个巨大的成本节省。通过这种设备上的推断计算（on-device inference）也可以降低带宽需求，最终节省大量的成本。\n移动开发者还可以大大节省开发过程的开支，因为他们不必构建和维护额外的云基础设施。相反，他们可以通过一个较小的工程团队实现更多目标，从而使他们能够更有效地扩展他们的开发团队。\n结语毫无疑问，云计算在 2010 年代一直是数据和计算的福音，但科技行业正以指数级的速度发展，设备上的机器学习（on-device machine learning）可能很快将成为移动应用和物联网开发的标准。\n由于其更低的延迟，增强的安全性，离线功能和降低成本，毫无疑问，该行业的所有主要参与者都在大力关注这项技术，它将定义移动开发者如何推进应用程序的创建。\n如果你有兴趣了解移动机器学习的更多信息，它的工作原理，以及为什么它在整个移动开发领域中如此重要，这里有一些额外的资源可以帮助您入门：\n\nMatthijs Holleman 的博客《Machine, Think!》在 Apple 的移动机器学习框架 Core ML 方面有很多不错的教程和其他相关内容：https://machinethink.net/blog/\n\n边缘人工智能（Artificial Intelligence at the Edge）：https://youtu.be/6R5pjcqBq6Y\n\n此外，Heartbeat 在移动开发和机器学习的交叉领域也拥有越来越多的资源库：http://heartbeat.fritz.ai/\n\n\n\n\n\n\n\n\n\n\n\n本文转载自：KANGZUBIN\n原文作者: Karl Utermohlen\n原文: Machine Learning and the Future of Mobile App Development\n","slug":"2019-09-07-machine-learning-feature","date":"2023-05-13T11:29:06.791Z","categories_index":"机器学习","tags_index":"机器学习"},{"id":"7587d0e7690fa9850e8d9b7745fb8f05","title":"浅谈iOS架构模式","content":"每一个软件开发者在开始学习软件开发的时候，可能都不清楚软件的架构设计是什么样的，仅仅是依靠前人的方式进行代码开发的，至少本人是这样的。慢慢熟悉了软件开发后，对于软件代码如何更加合理的进行组织，以前的开发为什么是那样进行组织的便有了有些理解。其实这一切都是软件的架构模式。\n对于iOS开发者来说，几乎每个人都熟悉应用程序的测试、代码的重构和通过视图控制器对业务进行支持等，但是如何合理的选用对当前产品业务更加合理的软件架构，往往会被忽略。这里针对当前业界常见的五种架构模式，进行详细的分析和试用，了解每种架构模式。\n\n\n\n\n\n\n\n\n\n架构模式并不是所有问题都适用的解决方案，它们仅仅描述了移动应用程序代码的组织方式和方法，具体的实现细节往往会跟随业务的变化而变化。\n在本文中，将介绍以下五种iOS端的通用架构模式：\n\n传统MVC\n苹果的MVC\nMVP\nMVVM\nVIPER\n\n传统MVC在70年代后期，Model、View、Controller的模式在编程语言Smalltalk-80中出现，随着时间的推移，人们对MVC有了许多不同的理解，尽管最初的想法逐渐被人们遗忘，但是MVC带给软件开发行业的巨大变化是有目共睹的，有必要好好了解一下最初的MVC以及相关的原理等。MVC最初要解决的问题是：将组件的职责明确划分为模型、视图、控制器。\n模型： 一组封装特定主题领域数据及其验证算法的类。 在传统MVC中，模型还包含处理逻辑（“业务逻辑”）。 有两种类型的模型：主动模型和被动模型。 主动模型能够通知其状态的更改（通常是通过观察者模式）。 传统MVC实现被认为是主动模型，该模型对View和Controller一无所知，并且可以独立运行。 在测试中，此要求起着重要作用。\n视图： 负责（但不一定）显示数据的图形类。 在传统MVC中，仅在只读模式下，视图可以直接访问模型，视图不应直接更改模型的状态，状态的更改应该是控制器的职责。\n控制器： 直接和外部互动的组件，根据不同的外部行为，控制器会执行一些逻辑，包括但不限于改变模型的状态等，但是控制器不会直接对视图做出响应，也不会保持视图的状态，也就是说控制器并不是视图和模型的中间介质，也不负责将数据从模型输出到视图。\n\n传统MVC原理在70年代，MVC模式基本上都是在具有实体按键的设备上应用的。一些外部按键事件，该事件和控制器进行交互，控制器决定如何处理该事件。例如，控制器可以更改模型的状态（一般是调用模型的方法），但是绝不能更改视图的状态，仅仅只有模型会直接影响视图。\n如果模型的状态发生了更改，模型将通知视图进行相应的更改，并且视图应该读取新的模型数据，然后在必要时更新并重新绘制视图（视图观察者模型）。虽然MVC在控制台模式下成功完成了任务，但图形界面和鼠标或触摸变得越来越流行，用户现在可以直接与视图进行交互，并且视图会生成事件，从理论上讲，该事件应由Controller处理。 实际上传统的MVC已经发生了变化。\n在图像界面时代，界面上将要显示各种样式的图形组件，开发人员的大部分任务演变成了建立各个小组件的层级结构并将事件从组件上重定向到所需的类，因此在现代开发中，可以认为视图是由小部件的不同层级结构构成的。\n图形组件通常相对比较复杂。例如，UIKit库中的常用按钮（UIButton）可以为按钮的每种状态包含不同的文本（例如，“highlighted” –“处于突出显示状态”，以及“selected” –“处于选定状态”）。 您还可以设置每种状态的文本颜色，可以直接在可视编辑器中进行配置，也可以通过写代码的方式配置。\n因此，按钮本身具有设置功能，并且本身也响应外部事件。 实际上，它包含自己的模型（所谓的View Model）和自己的Controller。 因此，当前程序更像是View，Controllers和Model的复杂层次结构。\n传统MVC的缺点传统MVC的缺点之一是组件之间的强互连性，这使单元测试变得复杂。 在现代程序中，控制器，视图和视图模型的层次结构愈发复杂，它们被认为是基于MVC的应用程序，因此实际上无法进行单元测试。\n另一个问题是业务模型的“增厚”。 为什么会这样呢？ 视图可以具有复杂的状态。 例如，文本输入框的输入字段验证的逻辑及其取决于验证结果的文本颜色的设置，此时视图的状态不能直接保存在视图模型的字段中，也不能在IDE中进行设置。\n那么，在哪里“转移”这种状态呢？模型和控制器中可以吗？\n在传统的MVC中，控制器不应保存视图的状态，因此这些复杂的状态需要在Model中实现。 因此，除了域模型之外，该模型还包括部分文本输入ViewModel。\n苹果MVC为了适应传统MVC并解决其缺点，苹果重新构建了MVC架构，实际上是在传统的MVC的基础上构建了Cocoa和CocoaTouch框架。 在苹果的MVC下，模型与传统MVC中的模型相同，并且是主动模型（即在观察者的帮助下通知其状态的变化）。\n为此，在Cocoa和CocoaTouch框架中，可以方便地使用NSNotificationCenter和KVO，而不必了解其他组件。 视图也类似于来自MVC的视图（可以是组件的层次结构）。 为了减少类的互连性，View无法直接访问Model。\n\n用户在视图上进行也写操作，视图既能自行处理一部分视图逻辑，也能够将一部分事件转发到控制器，由控制器决定处理事务并在必要时更改模型的状态。如果模型的状态发生了更改，将通知控制器，并由控制器决定如何处理这些更改。控制器的职责还有从模型中读取数据，必要的时候会对数据进行一些转换（以便于视图使用），并对视图进行新值设定等。\n优于传统MVC的优势在Apple的MVC模式下，视图和模型之间不再存在直接的连接，视图的状态和数据表示的处理逻辑也在控制器中，在当前情况下，这种职责分工更为合适。\n这种模式的缺点是Controller包含View状态的一部分和几乎所有View逻辑，而且由于Controller还充当View和Model之间的中介者，因此它成为应用程序逻辑适应的一个非常着重的地方。 实际上，UIViweController类变得过于庞大。 通常，由于Controller和视图之间的紧密关系，它们被视为表示层的组成部分。\n\n\n\n\n\n\n\n\n\n\n查看逻辑 : 一种与小部件层次管理，从一个场景到另一个场景的动画过渡，显示对话等相关的逻辑。\n表示逻辑 : 与将域模型转换为可在View上显示的模型以及处理View中需要操纵域模型的事件相关的逻辑。 \n域逻辑 : 在具有模型对象的模型级别上运行的基本逻辑。 域逻辑因此可以在另一个应用程序中重用。\n应用程序逻辑 :特定应用程序中固有的逻辑。 这与域逻辑不同，它不能重复使用，因为它是特定于特定应用程序的并且是唯一的。\nMVPMVP（Model、View、Presenter）是MVC模式的进一步发展。 Controller由Presenter代替。 Presenter，与经典MVC中的Controller不同：\n\n保存视图的状态；\n更改视图的状态；\n处理视图的事件；\n将域模型转换为ViewModel。\n\nPresenter与经典MVC中的Controller也有类似之处：\n\n拥有模型；\n响应外部事件（通过调用适当的方法）更改模型的状态；\n可能包含应用逻辑。\n\nMVP诞生于上世纪90年代初期的IBM。 与MVC一样，由于对其模式的不同解释，因此出现了多个版本。 马丁·福勒（Martin Fowler）定义了MVP的以下变化：\n\n演示模型\n监督控制器\n被动视图\n\n它们都是相似的，但主要取决于View和Presenter之间的连接以及View的更新顺序。 小部件的层次结构通常扮演视图的角色。 MVP中的模型与MVC中的模型没有什么不同。\n监督控制器与MVC最接近的模式。 组件之间的相互作用如下图所示。\n\n监督控制器视图：\n\n实现视图逻辑；\n将事件转发给演示者；\n与经典MVC中一样，观察模型（在数据绑定的帮助下或实现观察者模式）；\n不会直接更改模型的状态；\n可能需要从Presenter请求数据或读取模型。\n\nPresenter处理View的事件并更改Model的状态（通过调用适当的方法）。 与经典MVC中的Controller不同，如果无法借助数据绑定或Observer在Model与View之间建立连接的话，Presenter会保持并更改View的状态。\n监督控制器的好处在于，视图状态现在位于Presenter中（而不是在Model中）。 Presenter处理演示逻辑，因此View和Model变得“更薄”。 缺点是View严重依赖Model和Presenter，这极大地使单元测试复杂化。\n展示模型移除了监督控制器缺点的MVP，该结构进一步开发了视图与模型之间的连接。 组件之间的交互方案是：\n\nView：\n\n负责视图逻辑；\n将所有事件重定向到Presenter；\n\n与经典的MVC和Supervision Controller不同，View无法直接访问模型。 \nPresenter：\n\n将视图的状态移动到单独的Presentation Model中，作为Presenter的一部分；\n交互并提供与域模型的接口（即，视图的外观）；\n观察模型状态的变化；\n提供一个公共接口，View可以使用该接口与Presenter进行交互。\n\n该方案的工作原理如下：视图中有一个事件，View可以尝试自行处理它，并向Presenter请求数据。 如果View无法处理该事件，它将把该事件委托给Presenter，Presenter决定如何处理该事件。 如有必要，Presenter可以更改模型的状态。 该模型将其状态更改反向通知给Presenter，Presenter读取模型的新值，如有必要，对它们执行附加逻辑并更新视图。\n该模型相对于Supervision Controller的优势在于，视图与模型没有任何关系，这有利于单元测试。 缺点包括需要创建其他接口（至少对于View和Presenter而言）以及在View中进行更新的逻辑，这并不能大大简化测试。\nHumble ViewHumble View和Presentation模型之间的区别在于视图及其状态如何更新。 视图变为被动，MVP的先前版本没有对View施加限制，它可能会向Presenter询​​问一些数据。 在这种情况下，被动视图受到限制，它不再向Presenter询问任何数据。\n视图状态的任何更改均由Presenter执行。 视图不知道Presenter或Model的存在。 View的无源性最多可以简化单元测试。 与每种架构模式一样，组件之间的关系也有很多问题。 最常见的：\n\n谁拥有MVP中的View和Presenter？\n\n视图通常具有对Presenter的强烈引用。 反过来，Presenter对模型有很强的引用，而对View则无能为力。 与经典MVC中一样，该模型对View和Presenter一无所知。\n\n谁创建View和Presenter？\n\n可以认为，视图是由Presenter创建的。 但是，Presenter需要一个模型，即创建Presenter的视图必须通过模型进行配置，并且在此之后，她知道模型的存在。 此顺序不适合我们，因为我们正在尝试使组件之间的连接性达到最小（以实现更轻松的测试和更大的灵活性）。\n因此，如果下一个View Presenter是由另一个Presenter创建的，或者是在单独的Router类中创建的，则更好（后者也可能参与下一个View的配置和创建）。 但是，没有明确的规则。\niOS MVP经过一些理论，我们可以进行实际的发展。 一个典型的iOS应用程序是围绕一个中央UIViewController类构建的，该类承担着许多责任，因此放置UI逻辑和应用程序逻辑的一部分是最有吸引力的地方。 但是，我们在上面提到，由于View和Controller之间的紧密结合（在iOS UIViewController和UIView的上下文中），将它们视为View很方便。\n\n例如，让我们考虑一个包含两个场景的简单应用程序。 它允许您使用REST服务 http://random.cat/meow 从Internet上加载猫的随机照片（“加载猫场景”） ，在猫的图片上应用内置照片滤镜，然后保存编辑后的照片（“编辑猫”现场）。\n您可以在此处下载示例应用程序： https : &#x2F;&#x2F;github.com&#x2F;thinkmobiles&#x2F;CatApp_MVP_Sample\n加载照片时，“加载猫场景视图”会显示活动指示器，实际加载的照片和图片的URL。 演示者将借助“最小”界面LoadCatViewProtocol与“加载猫场景视图”进行交互。\nprotocol LoadCatViewProtocol: View &#123;\n    \n    func updateLoadingState(_ loadingState: Bool)\n    func updateTitle(_ imageTitle: String?)\n    func updateImage(_ image: Data?)\n&#125;\n \nclass LoadCatPresenter: LoadCatPresenterProtocol &#123;\n    \n    weak var view: LoadCatViewProtocol!\n    private var isLoading: Bool\n    private var image: Data?\n    private var imageTitle: String?\n    \n    func installView(_ view: View) &#123;\n        self.view &#x3D; view as! LoadCatViewProtocol\n    &#125;\n \n    func updateUI() &#123;\n        view.updateLoadingState(isLoading)\n        view.updateTitle(imageTitle)\n        view.updateImage(image)\n    &#125;\n \n   func load() &#123;\n        \n        guard !isLoading else &#123; return &#125;\n        \n        isLoading &#x3D; true\n        image &#x3D; nil\n        imageTitle &#x3D; nil\n        \n        updateUI()\n        loadCat()\n    &#125;\n. . . \n&#125;\n\n加载猫场景允许您开始加载和取消它，还可以转到下一个场景进行图像编辑。 这些事件由用户启动，并且View只是将它们重定向到Presenter，调用其方法。 视图通过协议LoadCatPresenterProtocol与Presenter进行交互。\nprotocol LoadCatPresenterProtocol: Presenter &#123;\n    \n    func load()\n    func cancel()\n    func updateUI()\n    func edit()\n    \n    var catProvider: CatProvider! &#123; get set &#125;\n&#125;\n \nclass LoadCatViewController: UIViewController, LoadCatViewProtocol &#123;\n    \n    var presenter: LoadCatPresenterProtocol!\n \n    @IBAction func actLoad(_ sender: UIBarButtonItem) &#123;\n        presenter.load()\n    &#125;\n    \n    @IBAction func actCancel(_ sender: UIBarButtonItem) &#123;\n        presenter.cancel()\n    &#125;\n \n\tfunc setPresenter(_ presenter: Presenter) &#123;\n        self.presenter &#x3D; presenter as! LoadCatPresenterProtocol\n    &#125;\n. . . \n&#125;\n\n在我们的测试项目中，无需Router类即可过渡到下一个场景。\n\n要将负载猫场景切换到编辑猫场景，您需要按编辑。\nLoadCatViewController将此事件重定向到LoadCatPresenter。\nLoadCatViewController不知道此事件会启动转换。\nLoadCatPresenter创建EditCatPresenter并使用必要的模型对其进行配置。\n要显示下一个场景，LoadCatPresenter调用LoadCatViewController showEditScene的方法并在此处传递EditCatPresenter。\nLoadCatViewController创建下一个视图，将其与接收的Presenter连接并显示。\n\nprotocol LoadCatViewProtocol: View &#123;\n\n    func showEditScene(withPresenter presenter: Presenter)\n&#125;\n \nclass LoadCatViewController: UIViewController, LoadCatViewProtocol &#123;\n\t\n\t@IBAction func actEdit(_ sender: UIBarButtonItem) &#123;\n        loadButton.isEnabled &#x3D; false\n        editCat()\n    &#125;\n \n\tfunc showEditScene(withPresenter presenter: Presenter) &#123;\n        let nextViewController &#x3D; storyboard!.instantiateViewController(withIdentifier: Constants.editCatViewControllerStoryboardId) as! View\n        presenter.installView(nextViewController)\n        nextViewController.setPresenter(presenter)\n        present(nextViewController as! UIViewController, animated: true, completion: nil)\n    &#125;\n. . .\n&#125;\n如果是第一个场景，则可以按照Apple的所有原则在UIApplicationDelegate中执行此配置。\nclass AppDelegate: UIResponder, UIApplicationDelegate &#123;\n \n    func application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplicationLaunchOptionsKey: Any]?) -&gt; Bool &#123;\n \n        let view &#x3D; window?.rootViewController as! LoadCatViewProtocol\n        let presenter &#x3D; LoadCatPresenter()\n        presenter.catProvider &#x3D; catProvider\n        presenter.installView(view)\n        view.setPresenter(presenter)\n        \n        return true\n    &#125;    \n&#125;\n\nMVVM尽管MVP具有很多优点，但由于IDE开发和框架，它不适合自动化应用程序开发，需要“手动”工作。 下一个模式应该可以解决这些问题。 MVVM（Model、View、ViewModel）由Microsoft Ken Cooper和Ted Peters的工程师开发，并由John Gossman在2005年的博客中宣布。\n该模式的目的是将用户界面与开发以及业务逻辑开发分开，并使用WPF和Silverlight平台的主要功能来促进应用程序测试。 尽管专业化模式是针对Microsoft技术构想的，但可以在Cocoa &#x2F; CocoaTouch框架中使用。\n\nMVVM源自MVC模式，由以下3个组件组成：模型，视图，视图模型。 模型与MVP和MVC中的模型不同：\n\n它是一个领域模型；\n包括数据，业务逻辑和验证逻辑；\n不依赖于其他组件（ View 和 ViewModel ）。\n\nView：\n\n确定用户界面（如MVP，Apple MVC）的结构，位置和外观；\n具有View的逻辑：动画、View与子View的操作之间的过渡等；\n保持对ViewModel的强烈引用，但对Model一无所知；\n监视ViewModel并使用数据绑定或直接引用它进行通信。\n\n为了避免View与ViewModel之间的牢固关系，需要创建一个接口，View将通过该接口与ViewModel进行通信。 ViewModel是视图和模型之间的中介者，并负责表示逻辑的处理。\nViewModel：\n\n保持View的状态；\n了解模型并可以更改其状态（适当类的调用方法）；\n将模型中的数据转换为对视图更方便的格式；\n验证来自视图的数据；\n不了解View，只能通过数据绑定机制与View交互。\n\n在Cocoa中有其自己的数据绑定机制，但在CocoaTouch中则没有。 我们只能用KVO来做，但是这个东西不方便使用，只允许您实现单边绑定。 反过来，数据绑定使实现MVVM固有的全部潜力成为可能，并总体上促进了开发。 因此，应该使用一些提供与CocoaTouch的数据绑定或响应式编程的第三方库。\nMVVM和MVP中的UIViewController被视为View的一部分。\n\n从苹果的MVC到MVVM的过渡过程中出现了一个重要的问题：如何实现导航？ 如上所述，视图直接执行到其他视图的过渡。 因此，有两种方法可以进行过渡：\n\n最简单的一种是从View启动过渡时。 在这种情况下，当前场景的ViewModel会创建下一个场景的ViewModel（如果需要，可以通过模型对其进行配置）。 然后，View创建下一个场景的View，将新的ViewModel传递给它，然后执行过渡。 \n过渡从ViewModel启动。 由于ViewModel对View一无所知，因此无法进行过渡。 在这种情况下，需要一个特殊的组件-路由器-它知道视图的层次结构以及如何进行转换。 ViewModel可以将下一场景的ViewModel或模型传递给路由器。 路由器处理其他所有事务。\n\n因此，MVVM和MVP（低视角）在Presentation层（在MVP中由Presenter呈现，在MVVM中由ViewModel呈现）差异很大。 MVVM优于MVP（Humble View）的优点是Presentation层完全独立于View（意味着更容易测试）和DataBinding的使用。 总之，它成为在现代IDE中使用的更具吸引力的候选者，并减少了将View与ViewModel同步的代码量。\nMVVM的缺点主要在于数据绑定机制，因为在某些情况下，它可能需要大量的内存资源，并且也是内存泄漏出现的薄弱环节。 接下来，我们将考虑上一节中描述的应用程序示例，但使用MVVM模式。 您可以在此处下载示例应用程序： https : &#x2F;&#x2F;github.com&#x2F;thinkmobiles&#x2F;CatApp_MVVM_Sample\n应用程序和模型（Cat，CatProvider）的用户界面相同。 它们仅在表示逻辑上有所不同，这将是主要重点。 View组件由LoadCatViewController和EditCatViewController呈现。 LoadCatViewController通过以下接口与LoadCatViewModel进行交互：\nprotocol CatViewModelProtocol &#123;\n \n    var isLoading: Observable &#123; get &#125;\n    var isEditable: Observable &#123; get &#125;\n    var title: Observable&lt;String?&gt; &#123; get &#125;\n    var imageData: Observable&lt;Data?&gt; &#123; get &#125;\n \n    var editCatViewModel: EditCatViewModelProtocol? &#123; get &#125;\n \n    func loadNextCat()\n    func cancelCurrentDownloading()\n&#125;\n\nLoadCatViewModel包含一组用于定义LoadCatViewController的状态的功能，以及一组与用户可以执行的操作相对应的方法。 对于数据绑定机制，我们使用 Bond 。 由于Load Cat是初始场景，因此很明显，它的配置是在AppDelegate中执行的：\nfinal class AppDelegate: UIResponder, UIApplicationDelegate &#123;\n \n    var window: UIWindow?\n \n    lazy var catProvider &#x3D; CatProvider()\n \n    func application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplicationLaunchOptionsKey: Any]?) -&gt; Bool &#123;\n        let catViewModel &#x3D; CatViewModel(catProvider: catProvider)\n        (window?.rootViewController as? CatViewController)?.viewModel &#x3D; catViewModel\n        return true\n    &#125;\n&#125;\n\n与MVP一样，配置Edit Cat场景分别在View和ViewModel中进行。\noverride func prepare(for segue: UIStoryboardSegue, sender: Any?) &#123;\n        if let editCatViewController &#x3D; segue.destination as? EditCatViewController &#123;\n            editCatViewController.viewModel &#x3D; viewModel.editCatViewModel\n        &#125;\n    &#125;\n\n\n首先，使用Segue机制的LoadCatViewController创建EditCatViewController。\n然后，在prepareForSegue方法中，LoadCatViewController询问LoadCatViewModel下一个场景的已配置ViewModel，即包含当前Cat模型的EditCatViewModel。\n此外，我们将此EditCatViewModel传递给EditCatViewController。\n单元测试是ViewModel和Model中的应用程序测试。 在测试项目中，您将找到单元测试的示例。\n\nVIPER在上面描述的架构中，如果尝试将体系结构划分为多个层，则使用Presenter或View Model可能会遇到困难。 它们属于哪一层？ 这个问题没有明确的答案：您可以为Presenter引入一个单独的Presentation层，或者它可以属于Application Logic。 MVVM也一样。 这种歧义造成了另一个问题。\n将应用逻辑与域模型逻辑分开是非常困难的。 因此，通常没有分隔并且位于同一层。 此外，Presenter中存在应用程序逻辑有时会使很难测试不同的用例。 以前的体系结构中的另一个问题是组装和导航。 在数十个场景的大型项目中，很明显，这是由单独的模块路由器负责的。\n2012年 发表 了一篇非凡的文章 。 清洁建筑以及有关该主题的几篇演讲。 后来，在Mutual Mobile中，我们为iOS做了一些修改，并进入了VIPER的新模式。 它 是View，Interactor，Presenter，Entity，Router的缩写，它们是构成应用程序的基本组件。 在下面查看他们如何互动。\n\nView：\n与MVP（被动视图）一样，它是来自Presenter的数据的可视化。 View通过高于UI类级别的协议与Presenter通信。 演示者不知道构成视图层次结构的特定类。 要在View和Presenter之间共享数据，可以使用单独的结构（即，没有方法可以更改其状态的类）。 只有View和Presenter知道这些类。\nPresenter： 与MVP中的功能相同，不同之处在于它不应包含应用程序逻辑。 我们主要让Presenter参与数据转换。\nInteractor： 这些对象封装了应用程序的单独用例（我们将其称为应用逻辑）。 交互器与演示者和模型一起使用。 Interactor永远不会将属于模型层的对象类传递给Presenter。 因此，演示者不依赖于模型。 而且，他不知道该模型的存在。\nModel： 与以前的模式相同。 对于方向模型，只有交互器起作用。 该模型不知道其他组件的存在。 模型层可能包含各种管理器（用于创建或保留实体）和封装数据处理算法的对象。\nEntity： 实体是仅包含数据且不包含其处理方法的PONSO（普通的NSObject）对象（例如，其所有属性均为只读，并且NSManagerObject类的对象不能脱离模型层的边界）。\nRouting： 线框和演示者负责VIPER中的导航。\n演示者接收视图的事件并知道如何响应它们。 但是Presenter对View的层次结构一无所知，并且包含View Logic（场景之间的动画切换– View Logic示例），并且无法在场景之间切换。\n在这里，它将需要Wireframe（一个包含对UIWindow的引用的对象），可以创建View &#x2F; UIViewController并知道如何将它们放入View层次结构中。 同样，线框是诸如场景之间的自定义过渡之类的事务处理的理想位置。 例如，让我们考虑一个测试项目的VIPER版本，上面已针对MVP进行了描述。\n您可以在此处下载示例代码： https : &#x2F;&#x2F;github.com&#x2F;thinkmobiles&#x2F;CatApp_VIPER_Sample\n在项目的MVP和VIPER版本中比较LoadCatView的协议。\n\n\n\nMVP\nVIPER\n\n\nprotocol LoadCatViewProtocol: View {\n func updateLoadingState(_ loadingState: Bool)\n func updateTitle(_ imageTitle: String?)\n func updateImage(_ image: Data?)\n func showEditScene(withPresenter presenter: Presenter)\n func finishedEdit()\n}\nprotocol LoadCatViewProtocol: View {\n func updateLoadingState(_ loadingState: Bool)\n func updateTitle(_ title: String?)\n func updateImage(_ image: UIImage?)\n func finishEditing()\n}\n\n\n\n\n\n\n它们仅在方法上有所不同\nfunc showEditScene(withPresenter presenter: Presenter) \n\n因为就VIPER而言，新场景或对话显示是线框的职责。 因此，两个项目的LoadCatViewProtocol实现几乎相同。 比较MVP和VIPER项目的LoadCatPresenter。\n\n\n\nMVP\nVIPER\n\n\nprotocol LoadCatPresenterProtocol: Presenter {\n func load()\n func cancel()\n func updateUI()\n func edit()\n ar catProvider: CatProvider! { get set }\n}\nprotocol LoadCatPresenterProtocol: Presenter {\n func load()\n func cancel()\n func updateUI()\n func edit()\n var loadCatInteractor: LocadCatInteractor! { get set }\n}\n\n\n\n\n它们之间的区别不是很大。 该项目的MVP版本包含一个变量catProvider，该变量引用了Model层。 在项目的VIPER版本中，Presenter不必依赖于Model层。\n由于通过按下按钮加载图片是一个用例（或应用程序逻辑），因此要实现功能，需要一个Interactor（可变loadCatInteractor）。 通常，交互器具有输入（演示者可以通过其与之交互的接口）。\nprotocol LoadCatInteractorInput &#123; \n    func loadCat() \n    func cancelLoad() \n    &#125; \n\n和与演示者交互的输出\nprotocol LoadCatInteractorOutput &#123; \n    func didLoadCatURL(_ catURL: NSURL?, success: Bool, cancelled: Bool) \n    func didLoadCatImage(_ image: Data?, success: Bool, cancelled: Bool) \n&#125; \n\n因此，通过按下按钮加载猫图片处理如下所示\nclass LoadCatViewController: UIViewController, LoadCatViewProtocol &#123;\n    \n    var presenter: LoadCatPresenterProtocol!\n    \n    @IBAction func actLoad(_ sender: UIButton) &#123;\n        presenter.load()\n    &#125;\n. . . \n&#125;\n \nclass LoadCatPresenter: LoadCatPresenterProtocol, LoadCatInteractorOutput &#123;\n \n    var loadCatInteractor: LocadCatInteractor!\n     \n    public func load() &#123;\n        \n        &#x2F;&#x2F; Some code to prepare UI\n        loadCatInteractor.loadCat()\n    &#125;\n    \n    &#x2F;&#x2F;MARK: LoadCatInteractorOutput\n    \n    func didLoadCatURL(_ catURL: NSURL?, success: Bool, cancelled: Bool) &#123;\n        &#x2F;&#x2F; Show the URL\n    &#125;\n    \n    func didLoadCatImage(_ image: Data?, success: Bool, cancelled: Bool) &#123;\n        &#x2F;&#x2F; Show the image\n    &#125;\n    . . . \n&#125;\n\n交互器和模型层之间的交互。 模型层由CatProvider和Cat类表示。 由于它很原始，因此对于交互器和模型之间的数据交换，我们没有创建实体类。\n让我们考虑在场景之间切换。 正如我们上面提到的，在VIPER项目中，这是线框的责任。 如果下一个场景需要上一个场景的某些数据，则可以将它们传递到线框中。\nclass LoadCatPresenter: LoadCatPresenterProtocol, EditCatPresenterDelegate &#123;\n \n    func edit() &#123;\n        let image &#x3D; UIImage(data: self.image!)\n        let editCatPresenter &#x3D; EditCatPresenter()\n        editCatPresenter.delegate &#x3D; self\n        editCatPresenter.image &#x3D; image!\n        \n        view.showEditScene(withPresenter: editCatPresenter)\n    &#125;\n. . .\n&#125;\n\n因此，不再将Seguey机制用于场景之间的过渡是不方便的，但是也不是拒绝使用UIStoryboard这样的便捷机制处理场景的理由。 这里的场景将没有Seguey。\n一个普通的VIPER项目包含许多您需要配置的模块。 对于我们的简单示例，在应用程序启动时使用单独的Dependencies类就足够了。 但是，在复杂的项目中，更容易使用其他解决方案或库。\n测试: VIPER项目的测试与MVP相似，不同之处在于将应用逻辑交付到单独的类–交互器中。 一方面，您必须编写更多用于单元测试的代码，另一方面，还需要针对单个功能测试（用户案例）使用更简单的算法。 在我们的测试项目中，您将找到所有VIPER项目的单元测试示例。\n结论在本文中，我们研究了可用于开发iOS应用程序的体系结构模式的演变。 进化链中的每个模式都改进了前一个模式。 明确了组件之间的界限及其职责（如有必要，引入了新的层或组件），这有助于开发和支持。\n参考资料\niOS architecture patterns: A guide for developers\niOS 架构模式 - 简述 MVC, MVP, MVVM 和 VIPER\niOS的MVP设计模式\n\n","slug":"2019-09-29-ios-architecture-patterns","date":"2023-05-13T11:29:06.791Z","categories_index":"开发知识","tags_index":"开发知识 iOS"},{"id":"0eccc1a2eb6b2260157a3a0e333d43b7","title":"What is Event Modeling?","content":"Event Modeling is a way to design a blueprint for an Information System of any size or scale. It is done in a way that allows the clearest communication of the system’s workings to the largest possible cross-section of roles in an organization. The system can be checked for completeness by following the single thread of data propagation through it.\nMotivationMoore’s LawDigitized Information Systems are a relatively new concept. Humans have been working with information systems for thousands of years. Over centuries banks, insurance companies and many other large scale organizations have managed to succeed.\nWith the advent of the transistor, the speed and accuracy of processing information increased by orders of magnitude. What did not gain the same quantum leap is digital storage. This imbalance caused information systems to be optimized for a very small amount of online information. You can see this in the advent of RDBMS technology. What it mean is that the compromise was to throw information away.\nHuman MemoryStory telling is something that enables humans to pass knowledge on to subsequent generations and relies heavily on how we store memories - whether logical, visual, auditory or other. This is important because there is a parallel with how information systems were constructed. There is a “memory” of all your visits to the doctor. It’s the ledger of the forms that are filled in with each visit.\nSpecifications by example are a way to show how something is supposed to work. This can be seen in successful practices in software such as Behaviour Driven Development. This works well because we communicate by stories more effectively. It ties back to story telling as a way to keep information in society. Our brains are built for it more than they are built for flow-charts and other formats. \nLife After the Dawn of the Computer AgeIn recent decades, Moore’s Law from the side of online storage has caught up. This means that after the initial few decades of living with computer systems, our information systems that are now digitized can use the mechanics that made them effective throughout history.\nThis means we have enough storage to not throw away information. The ability to be able to keep a history of all that has happened allows systems to be more reliable by means of audit and specification by example that literally translates to how the system is implemented.\nWe also have enough storage to have a cache of different views into what has happened in the system. This is important as we now have made the task of trying to fit all our concerns into one model an unnecessary constraint. In 1956, an IBM harddrive that stored 10MB cost $1M and required $30K monthly budget.\nReality of Current ToolingSo we are now at a cross-roads where we have very mature tooling, but that tooling is made for solving a problem we no longer have - being efficient with storage constraints. The new tooling that we see on the rise is what information systems always had: a ledger of what happened - storage is not a major issue anymore. There are many benefits to keeping ledger. They represent the natural way we think about systems - digital or not.\nThe Model That Works\nTime is a concept that is now a core piece of describing a system. The components and classes that we saw in computing are not as important. We can show, by example, what a system is supposed to do from start to finish, on a time line and with no branching - again to make use of that memory aspect of our brains. This is the Event Model. It is used to follow all field values in the UI to the storage of those value to where they finally end up on a report or a screen. It’s generally done with sticky notes on a wall or whiteboard - or an online version of a whiteboard. We’ll see that simplicity is at the heart of the approach as we will only use 3 types of building blocks as well as traditional wireframes or mockups. Further to keep things simple, we will rely on only 4 patterns of how we structure the diagram.\nSimplicityWhen we want to adopt certain practices or processes to help one another understand and communicate, it is inversely proportional to the amount of learning individuals must do to be proficient in those methods. Put in another way, if an organization chooses to adopt a process called “X”, and X requires one book and a workshop that takes a week to go through, it nullifies the effectiveness of X, and here’s the worst part, no matter how good X is.\nWhen the book is a required reading by the people in an organization, everyone will say they have read it; only half will have actually read it; half of those will claim they understood it; and only half of those will have understood it; and half of those will be able to apply it.\nThis is why Event Modeling only uses 3 moving pieces and 4 patterns based on 2 ideas. It takes a few minutes to explain and the rest of the learning is done in practice, transparently where any deficiencies in the understanding of even those few core ideas are quickly corrected.\nThis is how you get to an understanding in an organization.\nEventsLet’s say we want to design a hotel website for a hotel chain for allowing our customers to book rooms online and for us to schedule cleaning and any other hotel concerns. We can show what events, or facts, are stored on a timeline of the year in that business. We can pretend we have the system already and ask ourselves what facts were stored as we move forward through time.\nWireframesTo bring in the visual part of story-telling we show wireframes or web page mockups across the top. These can be organized in swim-lanes to show different people (or sometimes systems) interacting with our system. We also show any automation here with a symbol like gears to illustrate that the system is doing something. This has an easy to understand set of mechanics of a todo list that a process goes and does and marks items as done. In our hotel example, this could be a payment system or notification system.\n\nAt this point we have enough to be able to design some systems with some UX&#x2F;UI people. But there are 2 very fundamental pieces that must be added to the blueprint which show 2 core features of any information system: Empowering the user and informing the user.\nCommandsMost information systems must give an ability for a user to affect state of the system. In our example, we must allow the booking of a room to change the system so that we don’t over-book and when that person arrives at that future date, they have a room ready for them.\nIntentions to change the system are encapsulated in a command. As opposed to simply saving form data to a table in a database, this allows us to have a non-technical way to show the intentions while allowing any implementation - although certain ones have advantages as we will see.\n\nFrom the UI and UX perspective this drives a “command based UI” which goes a long way into helping make composable UIs. With this pattern, it’s a lot clearer what the transactional boundaries are both from the technical and business perspectives. The hotel guest either registered successfully or not.\nWhen there are nuances to what the prerequisites are for having a command succeed, they are elaborated on “Given-When-Then” style specifications. This is, again, a way to tell a story of what success looks like. There may be a few of these stories to show how a command can and cannot succeed.\nAn example might be “Given: We have registered, and added a payment method, When: We try to book a room, Then: a room is booked.” This form of specification is also referred to as “Arrange, Act, Assert” and in the UX&#x2F;UI world “Situation, Motivation, Value”.\nViews (or Read Models)The second part of any information system is the ability to inform the user about the state of the system. Our hotel guest should know about what days are available for certain types of rooms they are interested in staying in. There are usually many of these and support the multi-model aspect of information systems.\n\nA view into the facts already in the system has been changing as these new events were being stored. In our hotel system, this calendar view was being updated as new events that affected inventory were happening. Other views may be for the cleaning staff to see which rooms are ready to be cleaned as events about guests checking out are being stored.\nSpecifying how a view behaves is very similar to the way we specify how we accept commands with one difference. The views are passive and cannot reject an event after it’s been stored in the system. We have “Given: hotel is set up with 12 ocean view rooms, ocean view room was booked from April 4th - 12th X 12, Then: the calendar should show all dates except April 4th - 12th for ocean view availability”.\nIntegrationWe just covered the first 2 patterns of the 4 that are needed to describe most systems. Systems can get information from other systems and send information to other systems. It would be tempting to force these 2 patterns to be an extension of the first 2 and share the same space. However, these interactions are harder to communicate as they don’t have that human-visible aspect to them and require some higher level patterns.\nTranslationWhen we have an external system that’s providing us with information, it’s helpful to translate that information into a form that is more familiar in our own system. In our hotel system, we may get events from guests’ GPS coordinates if they opted in to our highly reactive cleaning crew. We would not want to use longitude and latitude pairs as events to specify preconditions in our system. We would rather have events that mean something to us like “Guest left hotel”, “Guest returned to hotel room”.\n\nOften, translations are simple enough to represent as views that get their information from external events. If we don’t use them as any “Given” parts of tests, the values they store in that view model are simply represented in the command parameters in our state change tests.\nAutomationOur system is going to need to communicate with external services. When the guests in our hotel are paying for their stay when they check out, our system makes a call to a payment processor. We can make the concept of how this occurs with the idea of a “todo list” for some processor in our system. This todo list shows tasks we need to complete. Our processor goes through that list from time to time (could be milliseconds or days) and sends out a command to the external system to process the payment, as an example. The reply from the external system is then translated into an event that we store back in our system. This way we keep the building blocks that we use in our system as something that’s meaningful to us.\n\nWe show this by putting a processor in the top of our blueprint which has the wireframes. This shows that there are things not evident on the screen but are happening behind the scenes. A user may expect a spinning icon to indicate a delay due to background tasks needing to finish. The specification for this has the form of “Given: A view of the tasks to do, When This command is launched for each item, Then These events are expected back.”\nIn reality, these may be implemented in many different ways such as queues, reactive or real-time constructs. They may even actually be manual todo lists that our employees use. The goal here is to communicate how our system communicates with the outside world when it needs to affect it. \nWorkshop Format - The 7 StepsEvent Modeling is done in 7 steps. We explained the end-goal already. So let’s rewind to the beginning and show how to build up to the blueprint:\n1. Brain Storming\nWe have someone explain the goals of the project and other information. The participants then envision what system would look and behave like. They put down all the events that they can conceive of having happened. Here we gently introduce the concept that only state-changing events are to be specified. Often, people will name “guest viewed calendar for room availability”. We put those aside for now - they are not events.\n2. The Plot\nNow the task is to create a plausible story made of these events. So they are arranged in a line and everyone reviews this time line to understand that this makes sense as events that happen in order.\n3. The Story Board\nNext, the wireframes or mockups of the story are needed to address those that are visual learners. More importantly, each field must be represented so that the blueprint for the system has the source of and destination of the information represented from the user’s perspective.\n3.1 UX ConcurrencyThe wireframes are generally put at the top of the blueprint. They can be divided into separate swimlanes to show what each user sees if there is more than one. There are no screens that appear above one another as we need to capture each change in the system state as a separate vertical slice of the blueprint. The different ordering can be shown in the various specifications. If it is core to the system or very important to communicate, alternate workflows will need to be added to the blueprint. This is part of the last step that shows organization but can be done earlier if helpful.\n4. Identify Inputs\nFrom the earlier section we saw that we need to show how we enable the user to change the state of the system. This is usually the step in which we do this introduction of these blue boxes. Each time an event is stored due to a users action, we link that to the UI by a command that shows what we are getting from the screen or implicitly from client state if it’s a web application.\n5. Identify Outputs\nAgain looking back at our goals for the blueprint, we now have to link information accumulated by storing events back into the UI via views (aka read-models). These may be things like the calendar view in our hotel system that will show the availability of rooms when a user is looking to book a room. \n6. Apply Conway’s Law\nNow that we know how information gets in and out of our system, we can start to look at organizing the events themselves into swimlanes. We need to do this to allow the system to exist as a set of autonomous parts that separate teams can own. This allows specialization to happen to a level that we control instead of falling out of the composition of teams. See Conway’s Law by Mel Conway.\n7. Elaborate ScenariosEach workflow step is tied to either a command or a view&#x2F;read-model. The specifications were explained earlier on. How we make them is still collaboratively with all participants in the same space. A Give-When-Then or Given-Then can be constructed one after the other very rapidly while being reviewed by multiple role representatives. This allows what is traditionally done as user story writing by a dedicated product owner in isolation in a text format, to be done visually in a very small amount of time collaboratively. What’s very critical here, is that each specification is tied to exactly one command or view.\nCompleteness CheckAt this time the event model should have every field accounted for. All information has to have an origin and a destination. Events must facilitate this transition and hold the necessary fields to do so. This rigor is what is required to get the most benefits of the technique.\nA variation of this is where we don’t do this final check and rely on absorbing the rework costs. There are scenarios where this is desired.\nProject ManagementThe final output of the exercise if done to completion is a set of very small projects defined by all the scenarios for each workflow step. They are in a format that allows them to be directly translated to what developers will use to make their unit tests. They are also coupled to the adjacent workflow steps by only the contract.\n\nStrong ContractsMany project management, business and coordination issues are mitigated by the fact that we have made explicit contracts as to the shape of the information of when we start a particular step of the workflow and what is the shape of the data when it’s finished. These pre- and post-conditions are what allows the work to be completed in relative isolation and later snap together with the adjoining steps as designed.\nFlat Cost CurveThe biggest impact of using Event Modeling is the flat cost curve of the average feature cost. This is due to the fact that the effort of building each workflow step is not impacted by the development of other workflows. One important thing to understand, is that a workflow step is considered to be repeated on the event model if it uses the same command or view. \n\nThe impact of this is very far reaching because it is what changes software development back into an engineering practice. It’s what makes creating an information system work like the construction of a house. Features can be created in any order. Traditional development cannot rely on estimates because whether the feature gets developed early on versus later in the project impacts the amount of work required. Reprioritizing work makes any previous estimates unreliable.\nDone is Done Done RightWhen a workflow step is implemented, the act of implementing any other workflow step does not cause the need to revisit this already complete workflow step. It’s the reason that the constant feature cost curve can be realized.\nEstimates without EstimatingWith a constant cost curve, the effort for an organization to implement can simply be measured over many features over time. This is an impartial way to empirically determine the velocity of teams. These numbers are then used to scope, schedule and cost out future projects.\nTechnical Side-Note About Test Driven DevelopmentThis is the impact of the adoption of Agile practices in the industry to put band-aids over the core issue of lack of design. Because the scope of each set of requirements is now per workflow step, the refactoring step of TDD does not impact other workflow steps in the event model. When we don’t have an event model, refactoring goes unrestricted and previously completed pieces of work have to be adjusted. The more work is already completed, the more that has to be reviewed and adjusted with each new addition as we build the solution.\nSubcontractingThe constant cost curve gives the opportunity to do fixed-cost projects. Once there is a velocity established for a team, you have the cost of the software for your organization. With this number, you now can price out what you are willing to give contractors in pay for each workflow step they complete.\nGuaranteesSince each workflow step is protected from being affected by other workflow steps, any deficiencies are to be guaranteed by who is delivering them with non-billable work. So in the case of a subcontractor doing a bad job just to get more billable items done quickly, they will have to have the next hours of work dedicated to fixing deficiencies of work already done before. This evens out their effective rate of pay because they are not working on new delivarables.\nThis can be carried out over longer periods within an employee engagement by making these metrics available through different checkpoints for performance.\nDue to the effective pay self-adjusting to the capability of the individual, it is also a way to on-board new employees and pay them fairly while they are in the probation stage of the engagement. This contract-to-hire process removes the subjective and largely ineffective interview process for technical positions.\nPrioritizationMoving work on a schedule as to what steps are going to be implemented first is done without changing the estimated costs of each item. This ensures that prioritization of work has no impact in the total cost also. The constant cost curve is required to allow this “agility” of reprioritizing features.\nChange ManagementWhen the plans change, we simply adjust the event model. This is usually done by just copying the current one and adjusting. Now we can see where the differences are. If a new piece of information is added to one event, that constitutes a new version of the workflow that creates it. Same with the views. If these have not been implemented yet, they don’t change our estimate. If they are already implemented, they add another unit of work to our plan because it’s considered a replacement. There are a few more rules around this. The end result is a definitive guide for change management.\nSecurity\nWith an event model, the solution shows exactly where, and equally importantly, when sensitive data crosses boundaries. With traditional audits, the number of interviews with staff was time consuming and at risk of missing important areas. Security concerns are addressed most responsibly when the applications have an event model to reference.\nLegacy SystemsMost of the scenarios that real organizations face is where a system is already in place. The main way to deal with a system that is hard to manage because of complexity and lack of understanding is to either rewrite it or to refactor it while it runs. Both of these are very costly.\nA third, less risky option exists: Freeze the old system. With proper buy-in, the organization can agree to not alter the existing system. Instead, dealing with bugs and adding new functionality is done on the side as a side-car solution.\nEvents can be gathered from the database of the old system and make views of that state - employing the translate pattern described previously. Y-valve redirection of user action can add new functionality in the side solution. An example which fixes a bug (notice that we use the external integration pattern and extends the old system to add profile pictures is shown here:\n\nThis pattern allows an organization to stop putting energy into the sub-optimal existing system and get unblocked from delivering value via the patterns that enable the benefits of the Event Model.\nConclusion for NowEvent Modeling is changing how information systems are built. With simple repeatable patterns, information systems are as predicable as engineering efforts should be.\nIMPORTANTThis content reprinted from Event Modeling: What is it?\nThanks.\n","slug":"2019-10-23-what-is-event-modeling","date":"2023-05-13T11:29:06.791Z","categories_index":"技术人生","tags_index":"技术人生"},{"id":"065e711203c90529e076df9f2cdf951d","title":"关于iOS App启动时间的那些事","content":"在iOS应用程序的开发过程中，应用的启动时长可谓是影响应用程序用户体验的第一要素，过长的应用启动耗时，势必带来用户的长时间等待，直接让用户失去了对应用程序进一步体验的兴趣，影响应用程序在用户心中的印象。一般情况下，应用程序开发完成上线后，接下来就是针对架构、性能、业务进行进一步优化和调整的阶段，这个阶段也是检验一个iOS开发工程师内功的时候。\niOS应用启动方式iOS应用程序的启动整体分为冷启动和热启动两种方式，两种启动方式具有不同的启动触发条件，也是在不同的业务场景模式下，最终导致应用启动，进而延续业务的方式。\n\n冷启动：指的是当应用还没准备好运行时，必须从零开始加载和构建整个应用。包括设置屏幕底部的分栏菜单，确保用户是否被合适地登录，以及处理其他更多的事情。整个应用程序的入口是在*applicationDidFinishLaunching:withOptions:*方法中开始的。\n热启动：指的是应用已经运行但是在后台被挂起（比如用户点击了 home 健）。在这种情况下，应用通过 applicationWillEnterForeground: 接收到回到前台的事件，接着应用恢复。\n\n\n\n\n\n\n\n\n\n\n另一种理解是，冷启动时App的进行不存在，系统需要为App分配进程等资源，以供App正确启动，而热启动时，App进程是存在的，只是App处于被挂起状态，热启动可以认为是App恢复形式的启动。\n在应用启动时间的衡量和治理上，往往冷启动是重中之重，因为严格意义上，冷启动是包含热启动的（冷启动初始化应用程序并获取摘要，热启动仅获取摘要），另外，冷启动需要做的工作更多，其中包含了一些额外的初始化工作，也更加的耗时，因此，针对冷启动的治理更加有意义。\n冷启动的定义通常情况下，针对iOS的冷启动过程是从用户点击App图标开始到*applicationDidFinishLaunching:withOptions:*方法执行完毕为止，在这个过程中主要分为两个阶段：\n\nT1阶段：应用程序*main()函数执行之前，即操作系统加载App可执行文件到内存，然后执行一系列的加载和链接等工作，最后执行至App的main()*函数。\nT2阶段：*main()函数执行之后，即从main()函数开始，到applicationDidFinishLaunching:withOptions:*方法执行完毕。\n\n\n在T1阶段，通常也被称为pre-main阶段，在该阶段，主要的工作主角是操作系统，此时会执行如下几个工作：\n\n在pre-main阶段做进行的各个任务，其主要工作也不尽相同，操作系统采用分而治之的策略，并顺序执行（可能会有并行的情况）。\n\n\n\n阶段\n工作\n\n\n\nLoad dylibs\nDyld从主执行文件的header中获取到需要加载的所依赖动态库列表，然后找到动态库所对应的每个dylib，而应用所依赖的dylib文件还可能依赖其他的dylib，所以所需要加载的动态列表是一个递归依赖的集合。\n\n\nRebase\nRebase是在Image内部调整指针的指向。在历史OS中，会把动态库加载到指定的地址，所有指针和数据对应的代码都是正确的，而在随着OS的演进，指针和数据所对应的地址空间演变成了随机化的方式，所以需要在原来地址的基础上根据随机的地址偏移量进行指向修正。\n\n\nBind\nBind是把指针正确地指向Image外部的内容，这些指向外部的指针被符号（symbol）名称绑定，dyld需要去符号表里进行查找，找到symbol对应的实现。\n\n\nObjC Setup\n- 注册ObjC类（class registration）  - 把category的定义插入到方法列表（category registration） - 保证每个selector的唯一性（selector uniquing）\n\n\nInitializers\n- ObjC的+load()函数   - C++的构造函数属性函数等  - 非基本类型的C++静态全局变量的创建（通常是类或结构体）\n\n\npre-main阶段耗时统计对于pre-main阶段，Xcode提供了针对上述各个阶段耗时统计的功能，只需要开发者为项目添加特殊的环境变量即可。针对pre-main耗时统计的环境变量有两个，分贝是DYLD_PRINT_STATISTICS和DYLD_PRINT_STATISTICS_DETAILS，前者是各个阶段的整体耗时统计，后者会输出一些更加详细的参数。\nXcode环境变量的添加位置在 Product -&gt; Scheme -&gt; Edit Scheme -&gt; Environment Variables。\n\n\n\n\n\n\n\n\n\n\nDYLD_PRINT_STATISTICS和DYLD_PRINT_STATISTICS_DETAILS的值设置为1表示开启，0表示关闭，默认为0.\n设置之后，重启App，则会在Xcode的console中看到如下的统计输出：\nTotal pre-main time: 216.18 milliseconds (100.0%)\n         dylib loading time:  61.15 milliseconds (28.2%)\n        rebase&#x2F;binding time: 126687488.9 seconds (372410141.8%)\n            ObjC setup time:  25.85 milliseconds (11.9%)\n           initializer time: 174.40 milliseconds (80.6%)\n           slowest intializers :\n             libSystem.B.dylib :  13.24 milliseconds (6.1%)\n   libBacktraceRecording.dylib :   7.55 milliseconds (3.4%)\n    libMainThreadChecker.dylib : 144.91 milliseconds (67.0%)\n                              ...\n\n当然我们也可以获取更详细的时间，只需将环境变量 DYLD_PRINT_STATISTICS_DETAILS 设为 1 就可以得到更加详细的信息：\ntotal time: 966.57 milliseconds (100.0%)\n  total images loaded:  334 (327 from dyld shared cache)\n  total segments mapped: 21, into 370 pages\n  total images loading time: 710.13 milliseconds (73.4%)\n  total load time in ObjC:  20.68 milliseconds (2.1%)\n  total debugger pause time: 472.96 milliseconds (48.9%)\n  total dtrace DOF registration time:   0.15 milliseconds (0.0%)\n  total rebase fixups:  17,943\n  total rebase fixups time:   2.25 milliseconds (0.2%)\n  total binding fixups: 457,972\n  total binding fixups time: 188.15 milliseconds (19.4%)\n  total weak binding fixups time:   0.01 milliseconds (0.0%)\n  total redo shared cached bindings time: 201.78 milliseconds (20.8%)\n  total bindings lazily fixed up: 0 of 0\n  total time in initializers and ObjC +load:  45.17 milliseconds (4.6%)\n                         libSystem.B.dylib :   5.18 milliseconds (0.5%)\n               libBacktraceRecording.dylib :   5.59 milliseconds (0.5%)\n                            CoreFoundation :   1.99 milliseconds (0.2%)\n                libMainThreadChecker.dylib :  27.94 milliseconds (2.8%)\n                    libLLVMContainer.dylib :   1.89 milliseconds (0.1%)\ntotal symbol trie searches:    1109484\ntotal symbol table binary searches:    0\ntotal images defining weak symbols:  37\ntotal images using weak symbols:  92\n\n有了以上信息，就可以对pre-main阶段的时间消耗进行一个度量和优化了。那么除了上述两个环境变量外，Xcode还支持dyld的其他一些环境变量，如下：\n\n\n\n环境变量\n描述说明\n\n\n\nDYLD_PRINT_SEGMENTS\n日志段映射\n\n\nDYLD_PRINT_INITIALIZERS\n日志图像初始化要求\n\n\nDYLD_PRINT_BINDINGS\n日志符号绑定\n\n\nDYLD_PRINT_APIS\n日志dyld API调用(例如，dlopen)\n\n\nDYLD_PRINT_ENV\n打印启动环境变量\n\n\nDYLD_PRINT_OPTS\n打印启动时命令行参数\n\n\nDYLD_PRINT_LIBRARIES_POST_LAUNCH\n日志库加载，但仅在main运行之后\n\n\nDYLD_PRINT_LIBRARIES\n日志库加载\n\n\nDYLD_IMAGE_SUFFIX\n首先搜索带有这个后缀的库\n\n\npre-main阶段的优化策略从上可知，在pre-mian阶段，应用程序会执行dylib loading、rebase&#x2F;binding、ObjC setup、initializers四个步骤，从每个阶段的主要工作分析得知：\n\n\n\n阶段\n优化策略\n\n\n\nLoad dylibs\n1.尽量不使用内嵌（embedded）的dylib，加载内嵌dylib性能开销较大；2.合并已有的dylib和使用静态库（static archives），减少dylib的使用个数；3.懒加载dylib，但是要注意dlopen()可能造成一些问题，且实际上懒加载做的工作会更多\n\n\nRebase&amp;Bind\n1.减少ObjC类（class）、方法（selector）、分类（category）的数量；2.减少C++虚函数的的数量（创建虚函数表有开销）；3.使用Swift structs（内部做了优化，符号数量更少）\n\n\nObjC Setup\n减少 Objective-C Class、Selector、Category 的数量，可以合并或者删减一些OC类\n\n\nInitializers\n1.少在类的+load方法里做事情，尽量把这些事情推迟到+initiailize；2.减少构造器函数个数，在构造器函数里少做些事情；3.减少C++静态全局变量的个数）\n\n\n简单概括就是\n\n应用程序所依赖的动态库越多，启动越慢；\nObjC的类、方法越多，启动越慢；\nObjc的+load()越多，或+load()中有过多的逻辑，启动越慢；\nC的constructor函数越多，启动越慢；\nC++静态对象越多，启动越慢。\n\n以上是对iOS App启动（主要针对冷启动）耗时的一点总结性内容，在具体的项目开发过程中，开发人员应当追求更加简洁高效的代码实现，追求高内聚，低耦合的项目架构，并有意的进行代码优化，使得App的启动耗时控制在良好的范围内，只有高效的启动，才不会再App的第一关就被Pass掉，从而为后续的业务提供良好的开端。\n工具集在了解了如何进行pre-main阶段耗时治理的策略之后，你可以动手进行一系列的优化提升，这里不进行具体的代码展示，列出两个可使用的工具，有兴趣的小伙伴可以详细研读学习。\n\nobjc_cover：一款通过对Mach-O文件进行解读，从中找到方法列表后，根据是否有对方法进行引用判定方法是否有用，可以用来删除项目中无用的方法。\nDynamicLoader：一款项目自启动技术，实现了可插拔的函数的注册和启动等。\n\n参考资料\nApp Startup Time: Past, Present, and Future\n手淘iOS性能优化探索\n探秘 Mach-O 文件\n\n","slug":"2019-10-30-app-start-time-measure-and-improvement","date":"2023-05-13T11:29:06.791Z","categories_index":"开发知识","tags_index":"开发知识 iOS"},{"id":"3158244125ce6cdd857a3a3ca56bd557","title":"探索性数据分析入门","content":"在数据科学领域里，最具挑战的问题之一便是如何确定数据对特定问题带来价值。在使用机器学习或者深度学习之前，确定数据或者特征是否利于特定问题，是数据科学后续工作的重中之重。\n因此，在进行数据科学问题之前，通常会对数据进行分析，洞察数据中所涵盖的深层特性是否利于特定问题，以及是否适用于所选用的机器学习算法等，而这一步被称为探索性数据分析（Exploratory Data Analysis， EDA）。\n探索性数据分析（Exploratory Data Analysis，EDA） 是指对已有数据在尽量少的先验假设下通过作图、制表、方程拟合、计算特征量等手段探索数据的结构和规律的一种数据分析方法，该方法在上世纪70年代由美国统计学家J.K.Tukey提出。传统的统计分析方法常常先假设数据符合一种统计模型，然后依据数据样本来估计模型的一些参数及统计量，以此了解数据的特征，但实际中往往有很多数据并不符合假设的统计模型分布，这导致数据分析结果不理想。EDA则是一种更加贴合实际情况的分析方法，它强调让数据自身“说话”，通过EDA我们可以最真实、直接的观察到数据的结构及特征。\n\n\n\n\n\n\n\n\n\n探索性数据分析（EDA）是一种数据分析方法，它采用多种技术来最大化对数据集的洞察力。揭示底层结构；提取重要变量；检测异常值和异常；建立简约模型；并确定最佳因子设置。\n\n从实战中学习EDA实践是检验整理的唯一途径。 为了能够更好更快的理解EDA，这里将直接从**鸢尾花数据集(UCI Machine Learning Repository)**的探索性分析中学习EDA的方法。\n目标： 从给定4个维度特征的鸢尾花数据集中学习，已确定新的鸢尾花属于3个鸢尾花类别中的哪一个类别。\n\n\n\n\n\n\n\n\n\n在进行EDA的过程中，需要始终牢记最初确立的目标，否则EDA可能偏离目标！\n导入所需类库显而易见，进行Python语言相关的开发时，第一步基本上都是导入所需的类库（前提是类库已经被安装在当前坏境）。在进行EDA时，所需的类库可能并不是很多，满足需求即可，在这里，将导入像Pandas、Matplotlib、numpy等类库，对应类库的作用，可自行搜索学习。\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n下载数据并加载&#39;&#39;&#39;downlaod iris.csv from https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;uiuc-cse&#x2F;data-fa14&#x2F;gh-pages&#x2F;data&#x2F;iris.csv&#39;&#39;&#39;\n#Load Iris.csv into a pandas dataFrame.\niris &#x3D; pd.read_csv(&quot;.&#x2F;iris.csv&quot;)\niris.head()\n\n\n\n\n\n\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n\n\n\n  \n    \n      \n      sepal_length\n      sepal_width\n      petal_length\n      petal_width\n      species\n    \n  \n  \n    \n      0\n      5.1\n      3.5\n      1.4\n      0.2\n      setosa\n    \n    \n      1\n      4.9\n      3.0\n      1.4\n      0.2\n      setosa\n    \n    \n      2\n      4.7\n      3.2\n      1.3\n      0.2\n      setosa\n    \n    \n      3\n      4.6\n      3.1\n      1.5\n      0.2\n      setosa\n    \n    \n      4\n      5.0\n      3.6\n      1.4\n      0.2\n      setosa\n    \n  \n\n\n\n\n\n\n*.head()函数是Pandas中的标准函数，用于观察数据集的数据详情，默认情况下返回数据集的前5个样本点。同时，.tail()*函数返回数据集的后5个样本点。\n\n# Data-points and features\niris.shape\n\n\n\n\n(150, 5)\n\n.shape参数可以查看数据集的形状（行数、列数）。\n\n此处使用的鸢尾花数据集是一个150行和5列的数据集。\n\niris.info()\n\n&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nRangeIndex: 150 entries, 0 to 149\nData columns (total 5 columns):\nsepal_length    150 non-null float64\nsepal_width     150 non-null float64\npetal_length    150 non-null float64\npetal_width     150 non-null float64\nspecies         150 non-null object\ndtypes: float64(4), object(1)\nmemory usage: 6.0+ KB\n\n*.info()*函数用于展示数据集列数据的数据类型情况。\n\n此处，数据只有float类型和object类型两种值类型数据；\n无变量或列包含null值或者缺失值。\n\niris.columns\n\n\n\n\nIndex([&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;,\n       &#39;species&#39;],\n      dtype=&#39;object&#39;)\n\n\n.columns 用来查看数据集的列或特征的名称。\n\niris[&#39;species&#39;].value_counts()\n\n\n\n\nversicolor    50\nsetosa        50\nvirginica     50\nName: species, dtype: int64\n\n\n*.value_counts()*是对数据集上特定列进行降序后，获取该列的每个值的计数值；\n此处，每一个种类（Versicolor, Setosa, Virginica）各有50个观察对象，因此该数据集应该是均匀分布的。\n\niris.describe()\n\n\n\n\n\n\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n.dataframe tbody tr th &#123;\n    vertical-align: top;\n&#125;\n\n.dataframe thead th &#123;\n    text-align: right;\n&#125;\n\n\n\n  \n    \n      \n      sepal_length\n      sepal_width\n      petal_length\n      petal_width\n    \n  \n  \n    \n      count\n      150.000000\n      150.000000\n      150.000000\n      150.000000\n    \n    \n      mean\n      5.843333\n      3.054000\n      3.758667\n      1.198667\n    \n    \n      std\n      0.828066\n      0.433594\n      1.764420\n      0.763161\n    \n    \n      min\n      4.300000\n      2.000000\n      1.000000\n      0.100000\n    \n    \n      25%\n      5.100000\n      2.800000\n      1.600000\n      0.300000\n    \n    \n      50%\n      5.800000\n      3.000000\n      4.350000\n      1.300000\n    \n    \n      75%\n      6.400000\n      3.300000\n      5.100000\n      1.800000\n    \n    \n      max\n      7.900000\n      4.400000\n      6.900000\n      2.500000\n    \n  \n\n\n\n\n\n\n*.describe()*函数用于获取数据集的各种汇总统计信息。该函数返回计数值、均值、标准差、最小值和最大值、以及数据的分位数。\n\n至此，对数据集来说已经有了一个基础的了解，对于数据的探索性分析来说，这才刚刚开始，往往通过对数据的图形化描述能够更加详细的了解数据特征之间的关系等，包括单变量和多变量分析等。\n二维散点图散点图是一种将数据显示为点集合的图。点的位置取决于其二维值，每个值都是水平或者垂直维度上的位置。\n# 2-D Scatter plot with color-coding for each flower type&#x2F;class.\n# Here &#39;sns&#39; corresponds to seaborn\nsns.set_style(&#39;whitegrid&#39;)\nsns.FacetGrid(iris, hue&#x3D;&#39;species&#39;, height&#x3D;8) \\\n    .map(plt.scatter, &#39;sepal_length&#39;, &#39;sepal_width&#39;) \\\n    .add_legend()\nplt.show()\n\n\n\nSeaborn中的FacetGrid类有助于使用多个面板在数据集的子集中可视化一个变量的分布以及多个变量之间的关系。参数hue根据与每个参数相关的颜色将数据点分开。\n三个类别的数据点根据sepal_length分散。\n\n使用sepal_length和sepal_width特征，可以区分Setosa同其他类别（线性可分）；\n区分Versicolor和Virginica相对困难一点，因为它们之间有大量的重叠部分。\n\n对图对图有助于查看数据中单个变量的分布以及多个变量之间的关系。\n# pairwise scatter plot: Pair-Plot\n# Dis-advantages: Cannot visualize higher dimensional patterns in 3-D and 4-D.\n# Only possible to view 2D patterns.\nplt.close()\nsns.pairplot(iris, hue&#x3D;&#39;species&#39;, size&#x3D;3)\nplt.show()\n\n\n\n\npetal_length和petal_width是区分各种类型鸢尾花的重要特征；\nSetosa类型的鸢尾花很容易被识别（线性可分），Virginica和Versicolor的特征有一些重叠（接近于线性可分）；\n可以找到“分割线”或者“if-else”条件来建立一个简单的模型，对鸢尾花的类型进行分类。\n\n直方图和PDF（概率密度函数）sns.FacetGrid(iris, hue&#x3D;&#39;species&#39;, height&#x3D;8) \\\n    .map(sns.distplot, &#39;petal_length&#39;) \\\n    .add_legend()\nplt.show()\n\n\n\ndistplot() 函数绘制了各种鸢尾花类型的petal_length的分布。图中蓝色代表Setosa类型鸢尾花的petal_length的直方图，黄色、绿色类似。y轴代表x轴上一个小窗口或者一个间隔中存在的数据点的数量，意味着在x轴上给定一个点或者区域，该点或者区域上直方图的高度代表x轴上该点或者区域有多少数据点。在上图中小窗口定义为petal_length。\n直方图的高度越高，即在给定的区域内密度越大，则找到的种类和花瓣的长度值之间的对应越多。因此上图也称为概率密度图，通过对直方图进行平滑处理（KDE）制成的图像曲线为PDF，即概率密度函数曲线。\n结论：\n\n如果 petal_length ≤ 2，种类为 Setosa；\n如果 petal_length ＞ 2，并且 petal_length ≤ 4.7，种类为 Versicolor；\n如果 petal_length ≥ 4.7，种类为 Virginica；\n另一个结论是，通过 petal_length 单变量的分析，对于区分不同的鸢尾花种类很有帮助，仅仅使用这一个特征，可以构建一个使用if-else条件判定的简单模型。\n\n\n\n\n\n\n\n\n\n\n在区分Versicolor的时候，使用了4.7作为分界点，而不是5的原因是， petal_length ≤ 4.7条件下，分类结果更多的可能性是Versicolor，而不是Virginica，这也和数据可视化的结果更为接近。\n当然，也可以使用petal_width、sepal_length、sepal_width进行单变量的分析，但是最终的结果可能并没有使用petal_length的结果好。\nPDF的局限性在于，无法查看其直观的图标或者统计性数据。例如，无法根据petal_length单变量分析，看到petal_length ＜ 5的情况下，属于Versicolor类型数据的百分比等。\n鉴于此，还需要使用CDF（累积分布函数）。\nCDF（累积分布函数）累积分布函数计算给定x值的累积概率。可以使用CDF来确定从总体中抽取的随机观察值小于或者等于某个值的可能性。\nCDF的优势在于可以通过可视化的方式查看，例如查看Setosa类型的鸢尾花，petal_length 小于1.6的百分比。PDF和直方图无法提供相同的确切的百分比，PDF只是分布图。\n# Need for Cumulative Distribution Function (CDF)\n# We can visually see what percentage of setosa flowers have a\n# petal_length of less than 1.6\n\n# Plot CDF petal_length\niris_setosa &#x3D; iris.loc[iris[&#39;species&#39;] &#x3D;&#x3D; &#39;setosa&#39;]\niris_virginica &#x3D; iris.loc[iris[&#39;species&#39;] &#x3D;&#x3D; &#39;virginica&#39;]\niris_versicolor &#x3D; iris.loc[iris[&#39;species&#39;] &#x3D;&#x3D; &#39;versicolor&#39;]\n\ncounts, bin_edges &#x3D; np.histogram(iris_setosa[&#39;petal_length&#39;], bins&#x3D;10, density&#x3D;True)\n\npdf &#x3D; counts&#x2F;(sum(counts))\nprint(pdf)\nprint(bin_edges)\n\n# compute CDF\ncdf &#x3D; np.cumsum(pdf)\nplt.plot(bin_edges[1:], pdf, label&#x3D;&#39;PDF&#39;)\nplt.plot(bin_edges[1:], cdf, label&#x3D;&#39;CDF&#39;)\n\nplt.legend()\nplt.show()\n\n[0.02 0.02 0.04 0.14 0.24 0.28 0.14 0.08 0.   0.04]\n[1.   1.09 1.18 1.27 1.36 1.45 1.54 1.63 1.72 1.81 1.9 ]\n\n\n示例代码中构建了三个数据框对应三种不同的鸢尾花种类。图中x轴代表petal_length，y轴则是对应的累积分布概率。\ncumsum()函数是NumPy类库中通过PDF计算CDF的方法。\n\n假设petal_length的值我们关心的是1.6。对于1.6，数据中有接近82%的Setosa类型鸢尾花，petal_length ≤ 1.6。即意味着在总共50朵Setosa鸢尾花中，有41朵的petal_length ≤ 1.6；\n根据CDF也可以得到所有Setosa鸢尾花的petal_length ≤ 1.9。\n\n一张图中查看三种类型鸢尾花的单变量CDF# Plots of CDF of petal_length for various types of flowers.\n\n# Misclassification error if you use petal_length only.\n\n# setosa\ncounts, bin_edges &#x3D; np.histogram(iris_setosa[&#39;petal_length&#39;], bins&#x3D;10, density&#x3D;True)\npdf &#x3D; counts&#x2F;(sum(counts))\nprint(&#39;setosa_pdf:&#39;, pdf)\nprint(&#39;setosa_bin_edges:&#39;,bin_edges)\ncdf &#x3D; np.cumsum(pdf)\nplt.plot(bin_edges[1:], pdf, label&#x3D;&#39;setosa_pdf&#39;)\nplt.plot(bin_edges[1:], cdf, label&#x3D;&#39;setosa_cdf&#39;)\n\n# virginica\ncounts, bin_edges &#x3D; np.histogram(iris_virginica[&#39;petal_length&#39;], bins&#x3D;10, density&#x3D;True)\npdf &#x3D; counts&#x2F;(sum(counts))\nprint(&#39;virginica_pdf:&#39;,pdf)\nprint(&#39;virginica_bin_edges:&#39;,bin_edges)\ncdf &#x3D; np.cumsum(pdf)\nplt.plot(bin_edges[1:], pdf, label&#x3D;&#39;virginica_pdf&#39;)\nplt.plot(bin_edges[1:], cdf, label&#x3D;&#39;virginica_cdf&#39;)\n\n# versicolor\ncounts, bin_edges &#x3D; np.histogram(iris_versicolor[&#39;petal_length&#39;], bins&#x3D;10, density&#x3D;True)\npdf &#x3D; counts&#x2F;(sum(counts))\nprint(&#39;versicolor_pdf:&#39;,pdf)\nprint(&#39;versicolor_bin_edges:&#39;,bin_edges)\ncdf &#x3D; np.cumsum(pdf)\nplt.plot(bin_edges[1:], pdf, label&#x3D;&#39;versicolor_pdf&#39;)\nplt.plot(bin_edges[1:], cdf, label&#x3D;&#39;versicolor_cdf&#39;)\n\nplt.legend()\nplt.show()\n\nsetosa_pdf: [0.02 0.02 0.04 0.14 0.24 0.28 0.14 0.08 0.   0.04]\nsetosa_bin_edges: [1.   1.09 1.18 1.27 1.36 1.45 1.54 1.63 1.72 1.81 1.9 ]\nvirginica_pdf: [0.02 0.1  0.24 0.08 0.18 0.16 0.1  0.04 0.02 0.06]\nvirginica_bin_edges: [4.5  4.74 4.98 5.22 5.46 5.7  5.94 6.18 6.42 6.66 6.9 ]\nversicolor_pdf: [0.02 0.04 0.06 0.04 0.16 0.14 0.12 0.2  0.14 0.08]\nversicolor_bin_edges: [3.   3.21 3.42 3.63 3.84 4.05 4.26 4.47 4.68 4.89 5.1 ]\n\n\n通过可视化，可以得到如下的结论：\n\n如果 petal_length ≤ 2，则鸢尾花的类型为Setosa，并且正确率接近于100%；\n如果 petal_length ＞ 2并且 petal_length ≤ 5：\n鸢尾花种类为Virginica。 此结论的正确性可能只有10%，因为在petal_length = 5情况下，CDF的值为10，同理，再次区间判定结果有90%的错误可能；\n鸢尾花种类为Versicolor。 此结论的正确率为95%，因为在petal_length = 5时，Virginica的CDF值为95。\n\n\n当 petal_length位于5到7之间，并且如果在此处将一个鸢尾花的种类定为Virginica，则正确预测该种类的可能性为90%，10%的可能性为Versicolor。\n\n箱须图（Box-and-Whisker Plots）箱形图（或箱须图）以有助于变量之间比较的方式显示定量数据的分布 Box显示数据集的四分位数，而Whisker显示其余分布。\n箱须图是显示数据分布的一种标准化方法，该方法基于以下五个数据的摘要绘制：\n\n最小值\n最大值\n中位数\n第一个四分位数\n第三个四分位数\n\n在一个简单的箱形图中，中心矩形跨越第一个四分位数到第三个四分位数（四分位数间距或IQR）。\nBox Plot\n# Box-plot with whiskers: another method of visualizing the 1-D scatter plot more untuitivey.\n\n# NOTE: In the plot below, a technique call inter-quartile range is used in plotting the whiskers.\n# Whiskers in the plot below donot correposnd to the min and max values.\n\n# Box-plot can be visualized as a PDF on the side-ways.\n\nsns.boxplot(x&#x3D;&#39;species&#39;, y&#x3D;&#39;petal_length&#39;, data&#x3D;iris)\nplt.show()\n\n\n\nWhisker Plot\n# A violin Plot combines the benefits of the previous two plots and simplifies them\n\n# Denser regions of the data are fatter, and sparser ones thinner in a violin plot\n\nsns.violinplot(x&#x3D;&#39;species&#39;, y&#x3D;&#39;petal_length&#39;, data&#x3D;iris, size&#x3D;8)\nplt.show()\n\n\n\n仓促的结语在本文中，粗略的对数据科学问题的前期工作—探索性数据分析，进行了简单的介绍，从中可以了解到如何进行数据的EDA，并从EDA中了解到数据的深层特性，对后续的特征抽取和建模具有非常大的意义。\n\n\n\n\n\n\n\n\n\n在文中，部分内容并没有深入进行介绍，与其说本文是介绍EDA，倒不如是针对EDA阶段如何一步一步的深入到数据内部的简单了解，希望对您有帮助。\n","slug":"2019-11-04-simple-eda","date":"2023-05-13T11:29:06.791Z","categories_index":"数据科学","tags_index":"数据科学 Python"},{"id":"2c512333e4536b8feed1c221955d12fa","title":"如何成为更好的iOS开发工程师之S.O.L.I.D原则","content":"在互联网时代，S.O.L.I.D原则可谓影响力久远，在计算机程序设计语言以及各个平台特性中都有S.O.L.I.D的身影，S.O.L.I.D原则也指导着软件工程的设计与编码工程。iOS平台的软件开发亦是软件开发领域的一支，S.O.L.I.D原则也同样对iOS软件开发有效，并且做称为一个更好的iOS软件开发人员，对S.O.L.I.D原则或许要理解更加深刻，并付诸实践。\nS.O.L.I.D原则本质上是五个面向对象编程（OOP）的指导性原则。当在进行类或者模块的设计和编码时，遵循S.O.L.I.D原则可以让软件更加的健壮和稳定。\n\nSingle Responsibility Principle（单一职责原则，SRP）\nOpen&#x2F;closed Principle（开放封闭原则，OCP）\nLiskov Substitution Principle（里氏替换原则，LSP）\nInterface Segregation Principle（接口隔离原则，ISP）\nDependency Inversion Principle（依赖倒置原则，DIP）\n\n单一职责原则（SRP）单一职责原则（SRP）指的是一个类或者模块有且只有一个职责。一个类就像一个容器，它能添加任意数量的属性、方法等。但是，如果视图让一个类实现太多功能，很快这个类就开始变得臃肿笨重。任意小的一个改动都可能导致这个类发生变化，重复的全量测试等等。但是如果遵循SRP，类将保持简洁且灵活的状态，每个类将只负责单一的一个问题、任务或者关注点，这样的方式对于开发测试来说，代价最小。SRP的核心就是把整个问题拆分成小模块，并且每个小模块都将通过一个单独的类进行实现、负责。\n通常在开发阶段，因为SRP原则的简单，我们很容易违背SRP原则。最大的现象是小功能或者小特性。那些小特性往往让开发慢慢陷入困境，特别是在团队作战中，你为一个类添加了一个小特性，另一个人添加了另一个小特性，慢慢的该类的功能开始变得繁多，而到最后，如何使用该类以及优化和重构该类成了最大的纠结。\n相对来说，iOS开发人员可能是最容易违背SRP原则的，因为iOS体系的特殊性，UIViewController是我们无法避开的。\n简单点说，UIViewController是将屏幕上的各个视图组合在一起，例如表格视图、图片视图等等，另外UIViewController还承担着UIViewController之间的导航作用，有时，还可能承担网络请求等等。不完全统计UIViewController共有12中职责，这可能是严重违背SRP原则的一个iOS组件，因此在进行iOS软件开发的时候，人们都称App中的UIViewControllers为Massive View Controller，即大规模视图控制器。\n这也是为什么几乎每个iOS开发者都不愿意随意的改变ViewController的地方，由于其承担的责任较多、小特性很多，一个不完整或者考虑不周全的改动，可能导致应用程序无法正常运行或者运行不符合预期等。\n如何应对呢？首先，坚决不为了单一的快而在原有的类上添加小功能、小特性，转而思考模块、组件或者API的方式。在开发过程中，需要我们摆脱掉修修补补的思想或者黑客的思维，为了软件的生命完整性和可扩展性，考虑类库形式的解决方案等。构建尽量小的类，只完成一个任务或者只解决一个问题。如果面对的问题是个相对大的问题，试着分解问题成多个小问题，然后为每个小问题编写对应的解决方案类，最终构建一个类来组装各个小类，解决大的问题。\n重新审视项目中的ViewController，如果该类过于沉重，试着分解该类中不同功能，让ViewController变的轻量。一个很好的例子是iOS SDK提供的UITableView的组装方式，使用delegate和dataSource分离动作和数据源，让TableView的实现条理分明，简洁快速。使用Data Source的方式组织数据，是任何类都可以施行的方式，不仅仅只针对ViewController。\n开放封闭原则（OCP）开放封闭原则（OCP）指出，一个类应该对扩展开放，对修改关闭。这意味一旦你创建了一个类并且应用程序的其他部分开始使用它，你不应该修改它。为什么呢？因为如果你改变它，很可能你的改变会引发系统的崩溃。如果你需要一些额外功能，你应该扩展这个类而不是修改它。使用这种方式，现有系统不会看到任何新变化的影响。同时，你只需要测试新创建的类。\n假设我们有一个获取用户数据的类UserFetcher，在该类中有一个方法fetchUsers，如下：\nclass UserFetcher &#123;\n    func fetchUsers(onComplete: @escaping ([User]) -&gt; Void) &#123;\n        let session &#x3D; URLSession.shared\n        let url &#x3D; URL(string: &quot;&quot;)!\n        session.dataTask(with: url) &#123; (data, _, error) in\n            guard let data &#x3D; data else &#123;\n                print(error!)\n                onComplete([])\n                return\n            &#125;\n            \n            let decoder &#x3D; JSONDecoder()\n            let decoded &#x3D; try? decoder.decode([User].self, from: data)\n            onComplete(decoded ?? [])\n        &#125;\n    &#125;\n&#125;\n\n该方法乍一看很好的实现了从网络加载数据，进行解析并返回解析后的数据。但是，假设有另一个任务需要从网络加载Article的数据，如果依照上述写法，需要重新构建一个类，用来加载Article数据，看似无误，但是问题在于，加载User的方法和加载Article的方法99%都是相同的，如果要如此重复的写下去，那么代码量将翻倍重复。另一个严重的问题在于，如果加载协议发生了改变，每一个加载数据的类都需要修改，很有可能演变成异常灾难。那么比较好的写法是什么呢？\nclass Fetcher&lt;T: Decodable&gt; &#123;\n    func fetch(onComplete: @escaping ([T]) -&gt; Void) &#123;\n        let session &#x3D; URLSession.shared\n        let url &#x3D; URL(string: &quot;&quot;)!\n        session.dataTask(with: url) &#123; (data, _, error) in\n            guard let data &#x3D; data else &#123;\n                print(error!)\n                onComplete([])\n                return\n            &#125;\n            \n            let decoder &#x3D; JSONDecoder()\n            let decoded &#x3D; try? decoder.decode([T].self, from: data)\n            onComplete(decoded ?? [])\n        &#125;\n    &#125;\n&#125;\n\n针对数据加载类进行了重构，定义了一个支持任何Decodable协议的类Fetcher，也就是定义了一个支持泛型的类，改造后的类能够支持所有相同的返回值的数据接在与解析等。例如：\ntypealias UserFetcher &#x3D; Fetcher&lt;User&gt;\ntypealias ArticleFetcher &#x3D; Fetcher&lt;Article&gt;\n\n开放封闭原则（OCP）的良好遵循，能够很好的拯救开发人员的时间，也能够让整个项目快速演进。上述例子可能不足以完整的说明开放封闭原则的重要性，但是在不断地思考和实践的过程中，还是建议有意的将开放封闭原则带入到软件开发的过程中，会有意想不到的好效果。\n里氏替换原则（LSP）里氏替换原则（LSP）指的是，派生的子类应该是可替换基类的，也就是说任何基类出现的地方，子类一定可以出现。值得注意的是，当你通过继承实现多态行为时，如果派生类没有遵循LSP，可能会使系统出现异常。所有要谨慎使用继承，只有确定是is-a关系时才使用继承。另外，LSP表示任何与类一起使用的方法函数也应该与这些类的任何子类一起使用，如果重写方法，该方法的使用者应该看不到基类对应的方法与子类所重写的方法之间的区别。\n例如上述例子中，ArticleFetcher是从网络加载数据，进行解析和返回结果的，但是某个时刻，Article数据可能并不需要从网络进行加载，而是从本地文件系统进行加载，此时良好的解决方案就是重写fetch方法，例如：\nclass FileFetcher&lt;T: Decodable&gt;: Fetcher&lt;T&gt; &#123;\n    override func fetch(onComplete: @escaping ([T]) -&gt; Void) &#123;\n        let json &#x3D; try? String(contentsOfFile: &quot;article.json&quot;)\n        guard let data &#x3D; json?.data(using: .utf8) else &#123;\n            return\n        &#125;\n        \n        let decoder &#x3D; JSONDecoder()\n        let decoded &#x3D; try? decoder.decode([T].self, from: data)\n        onComplete(decoded ?? [])\n    &#125;\n&#125;\n\n快速的方法重写后，好像都对，但是这里犯了一个严重的错误。基类的工作方式是，如果发生了错误，会返回一个空的数组，完成程序处理，然而重写后的方法如果发生了错误，则什么都不发生。这样对于使用该方法的UI界面则不会更新，也不会有提示等。\n&#x2F;&#x2F; 方式1\nlet fetcher &#x3D; FileFetcher&lt;Article&gt;()\nfetcher.fetch &#123; articles in\n    self.articles &#x3D; articles\n    self.tableView.reloadData()\n&#125;\n&#x2F;&#x2F; 方式2\nif fetcher is FileFetcher &#123;\n    tableView.reloadData()\n&#125;\n\n其实这两种方式都是不对或不严谨的。无论是上述哪一种方式，最终的目的都是不改变基类的基础上，让子类完整的实现和基类相同的行为，达到目标一致的结果。方式1看似没有问题，但是子类的行为在实现的时候忽略了发生错误时的程序行为，方式2 可以算作是一种偷懒的方式，虽然fetcher对象的确是FileFetcher，但是这样的方式完全丢弃了构建子类的目的，也失去了子类化的意义，就像使用代理回调和Block回调一样。\n接口隔离原则（ISP）接口隔离原则（ISP）表明类不应该被迫依赖他们不使用的方法，也就是说一个接口应该拥有尽可能少的行为，接口的实现应该精简且功能单一。假设上述关于Article的数据获取之后，在列表中展示后，我们还需要获取用户点击列表项之后，展示详情。作为一个面向协议的程序员，这里可以使用协议的方式解决该问题。\nprotocol ArticleFetcher &#123;\n    func getArticles(onComplete: ([Article]) -&gt; Void)\n    func getArticle(id: String, _: ([Article]) -&gt; Void)\n&#125;\n\n此时构建一个获取详情的类，并实现ArticleFetcher协议。虽然这样可以解决上述问题，但是带来的问题是，在列表页，并不需要getArticle，在详情页不需要getArticles。上述协议方法的定义方式，提供了不需要的方法，直接增加了混乱和噪声，这也违背了单一职责原则（SRP）中讨论的所有问题。\n为了解决此问题，可以分解上述协议为两个，提供职责单一，不耦合的协议定义方式，例如：\nprotocol ArticlesFetcher &#123;\n    func getArticles(onComplete: ([Article]) -&gt; Void)\n&#125;\n\nprotocol ArticlesFetcher &#123;\n    func getArticle(id: String, _: ([Article]) -&gt; Void)\n&#125;\n\n分开定义后，之前的实现并不需要再次修改，同一个类可以同时实现这两个协议。在列表控制器里，使用ArticlesFetcher的实例，而不会造成额外的混乱，这样，不仅可以在获取详情的勒种添加功能，还不会为类的用户带来使用麻烦。\n这也是为什么在Swift语言中会有Decodable、Encodable、Codable这样的协议。但是这样的设计可能并不符合所有人的设计，也不是每个人都需要的功能。但是良好的设计，符合SRP的设计对软件的稳定性、健壮性更有利。\n依赖倒置原则（DIP）依赖倒置原则（DIP）表明高层模块不应该依赖底层模块，相反，他们应该依赖抽象类或接口。在模块设计中，不应该在高层模块中使用具体的底层模块。因为这样的话，高层模块将变得紧耦合底层模块。如果改变了底层模块，那么高层模块也会被修改。根据DIP原则，高层模块应该依赖抽象类或者接口，底层模块也是如此。通过面向接口（抽象类）编程，紧耦合被消除。\n那么什么是高层模块，什么是低层模块呢？通常情况下，我们会在一个类（高层模块）的内部实例化它依赖的对象（低层模块），这样势必造成两者的紧耦合，任何依赖对象的改变都将引起类的改变。\n依赖倒置原则表明高层模块、低层模块都依赖于抽象。如果我们将上述定义的协议称为Fetchable协议，那么在视图控制器中使用的应该是Fetchable协议，而不是Fetcher类。\n原因则是减少耦合。当一个类严重依赖另一个类的实现时，会发生强耦合，可能会调用很多方法，对类的内部工作做了假设，或者使用了将其绑定到特定类的变量名等。\n强耦合带来的直接后果是，代码库的优化和重构难上加难。例如你正在使用CoreDataService协议进行数据库的使用，但事后由于业务的发展等原因，你需要改用RealmService，此时最好的情况便是视图控制器没有强依赖CoreDataService。\n解决此问题的最佳实践是，使用同样的基协议，例如DatabaseService，再构建不同的数据库工具类，以实现该协议。\nprotocol DatabaseService &#123;\n    func getUsers() -&gt; [User]\n&#125;\n\nclass CoreDataService: DatabaseService &#123;\n    &#x2F;&#x2F; ...\n&#125;\n\n\nlet databaseService: DatabaseService &#x3D; CoreDataService()\n\n在视图控制器中使用协议实例，是因为协议比类要少。一个类会有一些特定的名称和特定的方法。另外，协议是抽象的。多个类可以实现同一个协议，使其成为减少耦合的理想选择。\n如果要切换到RealmService，需要做的就是创建一个符合相同协议的类，因为并没有依赖任何特定的实现，所有不需要在试图控制器中修改代码，节省大量时间。\n在软件开发的过程中，最好是对代码的组织进行提前思考，将低耦合，高内聚在每一次实现中有所体现，最终软件的稳定性和健壮性会为你带来良好的效果。\n总结 以上便是S.O.L.I.D原则，我们完整从回归了五个重要的软件开发中的最佳实践，但是要说明的是，这些原则虽然非常有用，但是它们不是规则，它们是帮助你提高开发效率、增强软件稳定性、健壮性的工具。S.O.L.I.D原则的创造者罗伯特·C·马丁（Robert C. Martin）指出：“他们的陈述是’每天要吃一个苹果，才能远离医生’。”因此，请记住它们，但要妥协。\n Happy coding!\n","slug":"2019-11-06-solid-principles-for-becoming-a-better-ios-developer","date":"2023-05-13T11:29:06.791Z","categories_index":"技术人生","tags_index":"开发知识 技术人生"},{"id":"9bf30773ec01d0aa2cdc72baf1be3d0d","title":"Swift语言中的轻量级API设计","content":"Swift语言自诞生以来，总是或多或少受到人们的非议，新生的编程语言难免有些不够尽善尽美，但是哪种编程语言是尽善尽美的呢？OC语言算得上是一种古老的面向对象语言了，发展至今，其版本仍处于2.0，但是Apple为了让其看起来强大一点，增加了很多特性，例如Block、instancetype等等，但是其核心的语法变化并不大。\n截止目前，Swift的版本已经迭代到5.*，整个ABI也已经稳定，每一次迭代更新，总是会带来一些漂亮的设计模式实践，例如在如何设计API方面，给开发者带来了舒适而强大的枚举、扩展和协议等，不仅让开发者对于函数的定义有了更清晰的认识，而且对于构建API而言，第一印象往往是轻量的，同时，仍会根据需要逐步显现出更多的功能，以及底层的复杂性。\n在本篇文章里，将尝试创建一些轻量级的API，以及如何使用API组合的力量使得功能或者系统更加强大等。\n功能和易用性之间的较量通常，当我们设计API时，会在数据结构和函数功能的相互交互上，寻找一个相对平衡的方式，最终构建出在功能上满足需求，数据结构尽量简单的API。但是，让API过于简单，可能它们又不够灵活，无法使功能有不断发展的潜力，然而，太过复杂的设计又难免导致开发工作复杂而无章法，容易造成开发者挫败，逻辑混乱而且API也难以使用，最终可能会导致延期甚至失败。\n例如，一款应用程序的主要功能是对用户选择的图像应用不同的滤镜效果。每一种滤镜的核心其实都是一组图像变换的组合，不同的变换组合形成不同的滤镜效果。假设使用ImageFilter 结构体作为图像滤镜的定义，如下：\nstruct ImageFilter &#123;\n    var name: String\n    var icon: Icon\n    var transforms: [ImageTransform]\n&#125;\n\nImageTransform是图像变换的统一入口，因为可能会由多种不同的变换，因此可以将其定义为一个protocol，然后由实现单独变换操作的各种变换类型所遵循：\nprotocol ImageTransform &#123;\n    func apply(to image: Image) throws -&gt; Image\n&#125;\n\nstruct PortraitImageTransform: ImageTransform &#123;\n    var zoomMultiplier: Double\n    \n    func apply(to image: Image) throws -&gt; Image &#123;\n        ...\n    &#125;\n&#125;\n\nstruct GrayScaleImageTransform: ImageTransform &#123;\n    var brightnessLevel: BrightnessLevel\n    \n    func apply(to image: Image) throws -&gt; Image &#123;\n        ...\n    &#125;\n&#125;\n\n上述设计方式的优势在于，由于每种转换都是按照自己的类型实现的，因此在使用时可以自由地让每种变换类型定义自己所需的属性和参数。例如GrayScaleImageTransform 接受 BrightnessLevel参数，以将图像转换为灰度图像。\n然后，可以根据需要组合任意数量的图像变换类型，以形成不同类型的滤镜效果。例如，通过一系列的转换使得图像具有某种“戏剧性”外观的滤镜：\nlet dramaticFilter &#x3D; ImageFilter(\n    name: &quot;Dramatic&quot;, icon: .drama, transforms: [\n        PortraitImageTransform(zoomMultiplier: 2.1),\n        ContrastBoostImageTransform(),\n        GrayScaleImageTransform(brightnessLevel: .dark)\n    ]\n)\n\nSo far so Good.  但是回头重新审视上述API的实现，可以肯定的说，上述实现仅仅是为了功能的实现，在API的易用性方面并没有优势，那么该如何进行优化，来保证功能的同时，提高API的灵活性和易用性呢？在上述实现中，每个图像的变换都是作为单独的类型实现的，因此没有一个可以对所有变换类型一目了然的地方，使用者难以清楚该代码库都包含哪些图像变换的类型。\n为了解决外部使用者无法得知软件库所支持的变换类型，假设使用枚举的方式代替上述方式，来观察哪种方式更能够体现API的简洁明了以及使用上的清晰易用？\nenum ImageTransform &#123;\n    case protrait(_ zoomMultiplier: Double)\n    case grayScale(_ brightnessLevel: BrightnessLevel)\n    case contrastBoost\n&#125;\n\n使用枚举的好处既能够提高代码的整洁程度和可读性，也使得API更加的灵活易用，因为在枚举的使用上，开发者可以直接使用点语法构造任意数量的转换，如下：\nlet dramaticFilter &#x3D; ImageFilter(\n    name: &quot;Dramatic&quot;,\n    icon: .drama,\n    transforms: [\n        .protrait(2.1),\n        .contrastBoost,\n        .grayScale(.dark)\n    ]\n)\n\n截止目前，枚举都是很漂亮的一个工具，在很多情况下Swift的枚举类型都能够提供良好的解决方式，但是枚举也有其明显的弊端。\n就上述例子来说，由于每个转换都需要执行截然不同的图像操作，因此在这种情况下使用枚举将迫使我们编写一个庞大的switch语句来处理这些操作中的每一项, 这可能会造成代码的冗长繁琐等。\n枚举虽轻，结构体更优幸运的事，针对上述问题，我们还有第三种选择 — 一种目前算是两全其美的方案。相较于协议或者枚举，结构体是一个既能够定义操作类型，还能够封装给定各种操作的闭包的数据结构。例如：\nstruct ImageTransform &#123;\n    let closure: (Image) throws -&gt; Image\n\n    func apply(to image: Image) throws -&gt; Image &#123;\n        try closure(image)\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\napply(to:) 方法在这里并不应该被外部调用，这里写出来是为了代码的美观性以及代码的向前兼容。在实际项目开发中，这里可以使用宏定义区分。\n完成上述操作后，我们现在可以使用静态工厂方法和属性来创建我们的转换 — 每个转换仍可以单独定义并具有自己的一组参数：\nextension ImageTransform &#123;\n    static var contrastBoost: Self &#123;\n        ImageTransform &#123; image in\n            &#x2F;&#x2F; ...\n        &#125;\n    &#125;\n    \n    static func portrait(_ multiplier: Double) -&gt; Self &#123;\n        ImageTransform &#123; image in\n            &#x2F;&#x2F; ...\n        &#125;\n    &#125;\n    \n    static func grayScale(_ brightness: BrightnessLevel) -&gt; Self &#123;\n        ImageTransform &#123; image in\n            &#x2F;&#x2F; ...\n        &#125;\n    &#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\n\n在 Swift 5.1 中，可以将Self用作静态工厂方法的返回类型。\n上面方法的优点在于，我们回到了将ImageTransform定义为协议时所具有的灵活性和功能性，同时仍保持了与定义为枚举时的调用方式 — 点语法一致，保证了易用性。\nlet dramaticFilter &#x3D; ImageFilter(\n    name: &quot;Dramatic&quot;,\n    icon: .drama,\n    transforms: [\n        .portrait(2.1),\n        .contrastBoost,\n        .grayScale(.dark)\n    ]\n)\n\n点语法本身与枚举无关，但是其可以与任何静态API一起使用，这点对于开发者而言非常友好。使用点语法可以将上述的几个滤镜的创建和建模构造成静态属性，使得我们能够进一步的封装特性等。例如：\nextension ImageFilter &#123;\n    static var dramatic: Self &#123;\n        ImageFilter(\n            name:&quot;Dramatic&quot;,\n            icon: .drama,\n            transforms: [\n                .portrait(2.1),\n                .contrastBoost,\n                .grayScale(.dark)\n            ]\n        )\n    &#125;\n&#125;\n\n通过上述改造，一系列复杂的任务 — 包括图像滤镜和图像转换 – 封装到一个API中，在使用上，可以像传值给函数一样轻松。\nlet filtered &#x3D; image.withFilter(.dramatic)\n\n上述一系列的改造可以成为为类型构造语法糖。不仅改善了API读取的方式，还改善了API的组织方式，由于所有的转换和滤镜现在只需要进行传单一的值即可，因此在可扩展性方面来说，能够组织多种方式，不仅使得API轻巧灵活，对于使用者来说也简洁明了。\n可变参数与API设计接下来我们一起看看Swift语言的另一个特性 — 可变参数，以及可变参数如何影响API设计中的代码构建的。\n假设正在开发一个使用基于形状的绘图来创建其用户界面的应用程序，并且我们已经使用了与上述类似的基于结构的方法来对每种形状进行建模，并最终将结果绘制到了DrawingContext中：\nstruct Shape &#123;\n    var drawing: (inout DrawingContext) -&gt; Void\n&#125;\n\n\n\n\n\n\n\n\n\n\n上面使用inout关键字来启用值类型（DrawingContext）的传递。\n类似我们在上面例子中使用静态工厂方法轻松创建ImageTransform一样，在这里也能够将每个形状的绘图代码封装在一个完全独立的方法中，如下所示：\nextension Shape &#123;\n    func square(at point: Point, sideLength: Double) -&gt; Self &#123;\n        Shape &#123; context in\n            let origin &#x3D; point.movedBy(\n                x: -sideLength &#x2F; 2,\n                y: -sideLength &#x2F; 2\n            )\n\n            context.move(to: origin)\n            context.drawLine(to: origin.movedBy(x: sideLength))\n            context.drawLine(to: origin.movedBy(x: sideLength, y: sideLength))\n            context.drawLine(to: origin.movedBy(y: sideLength))\n            context.drawLine(to: origin)\n        &#125;\n    &#125;\n&#125;\n\n由于将每个形状简单地建模为一个属性值，因此绘制它们的数组变得非常容易-我们要做的就是创建一个DrawingContext实例，然后将其传递到每个形状的闭包中以构建最终图像：\nfunc draw(_ shapes: [Shape]) -&gt; Image &#123;\n    var context &#x3D; DrawingContext()\n    \n    shapes.forEach &#123; shape in\n        context.move(to: .zero)\n        shape.drawing(&amp;context)\n    &#125;\n    \n    return context.makeImage()\n&#125;\n\n调用上面的函数看起来也很优雅，因为我们再次可以使用点语法来大大减少执行工作所需的语法量：\nlet image &#x3D; draw([\n    .circle(at: point, radius: 10),\n    .square(at: point, sideLength: 5)\n])\n\n但是，让我们看看是否可以使用可变参数来使事情更进一步。虽然不是Swift独有的功能，但结合Swift真正灵活的参数命名功能后，使用可变参数可以产生一些非常有趣的结果。\n当参数被标记为可变参数时（通过在其类型中添加...后缀），我们基本上可以将任意数量的值传递给该参数 — 编译器会自动为我们将这些值组织到一个数组中，例如这个：\nfunc draw(_ shapes: Shape...) -&gt; Image &#123;\n    ...\n    &#x2F;&#x2F; Within our function, &#39;shapes&#39; is still an array:\n    shapes.forEach &#123; ... &#125;\n&#125;\n\n完成上述更改后，我们现在可以从对draw函数的调用中删除所有数组文字，而使它们看起来像这样：\nlet image &#x3D; draw(.circle(at: point, radius: 10),\n                 .square(at: point, sideLength: 5))\n\n这看起来似乎不是很大的变化，但是尤其是在设计旨在用于创建更多更高级别值（例如我们的draw函数）的更低级别的API时，使用可变参数可以使这类API感觉更轻巧和方便。\n但是，使用可变参数的一个缺点是，预先计算的值数组不能再作为单个参数传递。值得庆幸的是，在这种情况下，可以通过创建一个特殊的组形状（就像draw函数本身一样），在一组基础形状上进行迭代并绘制它们来轻松解决：\nextension Shape &#123;\n    static func group(_ shapes: [Shape]) -&gt; Self &#123;\n        Shape &#123; context in\n            shapes.forEach &#123; shape in\n                context.move(to: .zero)\n                shape.drawing(&amp;context)\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n完成上述操作后，我们现在可以再次轻松地将一组预先计算的Shape值传递给我们的draw函数，如下所示：\nlet shapes: [Shape] &#x3D; loadShapes()\nlet image &#x3D; draw(.group(shapes))\n\n不过，真正酷的是，上述组API不仅使我们能够构造形状数组，而且还使我们能够更轻松地将多个形状组合到更高级的组件中。例如，这是我们如何使用一组组合形状来表示整个图形（例如徽标）的方法：\nextension Shape &#123;\n    static func logo(withSize size: Size) -&gt; Self &#123;\n        .group([\n            .rectangle(at: size.centerPoint, size: size),\n            .text(&quot;The Drawing Company&quot;, fittingInto: size),\n            ...\n        ])\n    &#125;\n&#125;\n\n由于上述徽标与其他徽标一样都是Shape，因此只需调用一次draw方法就可以轻松绘制它，并使用与之前相同的优雅点语法：\nlet logo &#x3D; draw(.logo(withSize: size))\n\n有趣的是，尽管我们最初的目标可能是使我们的API更轻量级，但这样做也使它的可组合性和灵活性也得到了提高。\n总结我们向“ API设计者的工具箱”添加的工具越多，我们越有可能能够设计出在功能，灵活性和易用性之间达到适当平衡的API。 使API尽可能轻巧可能不是我们的最终目标，但是通过尽可能减少API的数量，我们也经常发现如何使它们变得更强大-通过使我们创建类型的方式更灵活，以及使他们组成。所有这些都可以帮助我们在简单性与功能之间实现完美的平衡。\n\n\n\n\n\n\n\n\n\n原文： Lightweight API design in Swift链接：https://www.swiftbysundell.com/articles/lightweight-api-design-in-swift\n","slug":"2019-11-28-lightweight-api-design-in-swift","date":"2023-05-13T11:29:06.791Z","categories_index":"开发知识","tags_index":"开发知识 iOS"},{"id":"e90242255f8181a299a4107cc70159e8","title":"\\#1\\ 为什么要学习数据结构与算法","content":"随机网络上有大量的程序员应该学习数据结构和算法的文章。还记得实在大学时代的时候，系统的学习过数据结构、算法相关的课程，而后几乎没有系统学习过了。工作后从一开始的各种业务逻辑的开发，慢慢深入了解到系统底层，了解了代码的执行效率以及对硬件设备资源的消耗基本上都是由数据结构和算法决定的，才开始慢慢关心起来良好的数据结构设计和良好的算法设计，才能够在数据量越来越多的时候，所设计的软件才能良好地执行等。\n那么对于程序员来说，到底为什么要学习数据结构和算法呢？首先要了解的是什么是数据结构？\n什么是数据结构？具体的定义这里摘录了维基百科的定义，具体如下：\n\n\n\n\n\n\n\n\n\n在计算机科学中，数据结构（英语：data structure）是计算机中存储、组织数据的方式。\n数据结构意味着接口或封装：一个数据结构可被视为两个函数之间的接口，或者是由数据类型联合组成的存储内容的访问方法封装。\n大多数数据结构都由数列、记录、可辨识联合、引用等基本类型构成。举例而言，可为空的引用（nullable reference）是引用与可辨识联合的结合体，而最简单的链式结构链表则是由记录与可空引用构成。\n数据结构可透过编程语言所提供的数据类型、引用及其他操作加以实现。一个设计良好的数据结构，应该在尽可能使用较少的时间与空间资源的前提下，支持各种程序运行。\n不同种类的数据结构适合不同种类的应用，部分数据结构甚至是为了解决特定问题而设计出来的。例如B树即为加快树状结构访问速度而设计的数据结构，常被应用在数据库和文件系统上。\n正确的数据结构选择可以提高算法的效率（请参考算法效率）。在计算机程序设计的过程中，选择适当的数据结构是一项重要工作。许多大型系统的编写经验显示，程序设计的困难程度与最终成果的质量与表现，取决于是否选择了最适合的数据结构。\n系统架构的关键因素是数据结构而非算法的见解，导致了多种形式化的设计方法与编程语言的出现。绝大多数的语言都带有某种程度上的模块化思想，透过将数据结构的具体实现封装隐藏于用户界面之后的方法，来让不同的应用程序能够安全地重用这些数据结构。C++、Java、Python等面向对象的编程语言可使用类 (计算机科学)来达到这个目的。\n摘录自维基百科: 数据结构\n\n\n\n其中有一段个人觉得很有启发，“不同种类的数据结构适合不同种类的应用，部分数据结构甚至是为了解决特定问题而设计出来的。” 个人理解是数据结构不仅仅百年不变的，不同的问题在不同的条件下，可能需要不同的数据结构设计，对于软件开发者而言，数据结构思维要时刻记载心间，根据特定的问题、所处的环境，选择或者设计那种平衡了性能和效率的数据结构。\n什么是算法？同样摘录自维基百科，具体如下：\n\n\n\n\n\n\n\n\n\n算法（algorithm），在数学（算学）和计算机科学之中，为任何一系列良定义的具体计算步骤，常用于计算、数据处理和自动推理。作为一个有效方法，算法被用于计算函数，它包含了一系列定义清晰的指令，并可于有限的时间及空间内清楚的表述出来。\n算法中的指令描述的是一个计算，当其运行时能从一个初始状态和初始输入（可能为空）开始，经过一系列有限而清晰定义的状态最终产生输出并停止于一个终态。一个状态到另一个状态的转移不一定是确定的。包括随机化算法在内的一些算法，都包含了一些随机输入。\n摘录自维基百科: 算法\n简言之，就是算法是具体的计算步骤，算法的输入和输出都需要有效。在不同的问题上，所采用的算法也不尽相同，可以说算法也是针对特定的问题和特定的环境下，进行优化设计的一种计算步骤。\n由算法衍生出来一系列和算法相关的内容，例如设计模式、时间复杂度、空间复杂度等，为算法的设计和实现提供理论支撑，衡量算法的性能和效率等。具体在后续的内容中将会深入学习。\n为什么要学习数据结构和算法计算数据结构和算法都是为了特定的问题在特定的环境下，设计软件开发的系统结构、代码实现方式等，那么程序员就应该熟谙其中的知识点，掌握基本的数据结构设计和算法设计，以最优化的思维编写程序代码，完成对特定功能的最优化实现，保证软件的高质量完成和执行。具体程序员为什么要学习数据结构和算法，大概有如下三点理由：\n1. 面试毫不客气地讲，良好的数据结构和算法知识储备，是程序员或者软件开发工程师找工作的敲门砖。在工程师面试的中，几乎都会涉及到算法和数据结构的测试，具有扎实的数据结构和算法基础，越来越成为面试中是否可以继续的红线。\n2. 工作在工作中面临巨大的数据量时，良好数据结构的设计，能够应对更加从容；使用正确地算法能够让软件的性能和效率更好。移动端应用程序将会更灵活并且耗电量低。服务端应用程序将会在少量的能耗下处理多并发请求等。\n3. 自我提升技术的革新是日新月异的，作为技术从业者，我们可能要不断地进行学习，以了解技术的发展，并应对业务的发展。例如在Swift语言中，Swift标准库有一个通用的集合类型的系列，他们不需要定义所有特定的情况，通用类型即可。在不断学习之后，你才能了解到语言本身所涵盖的特性等，为了更加高效和完善的软件提供知识支援等。\n总结或许每个人的学习方式和目的不尽相同，但是上述三个理由，总有一个给与你学习的充分理由的，不论是为了即将到来的面试、还是正在进行中的工作任务，抑或为了不让自己的技术落伍等，作为程序员来说，都应该重视数据结构和算法，夯实自己的基础知识，并在其上映射到你所擅长或者感兴趣的编程语言上，了解语言的特性并编写设计出良好的数据结构和算法，为自己的下一次远程储备粮草！\n","slug":"2019-12-01-Data-Structures-&-Algorithms-in-Swift-01","date":"2023-05-13T11:29:06.791Z","categories_index":"Data Structures & Algorithms in Swift","tags_index":"Swift中的数据结构与算法"},{"id":"c0089ea14d61cc249075e2e9c2241913","title":"\\#2\\ 认识 Array & Dictionary","content":"在 Swift Standard Library 中包含了Swift语言的核心组件。在标准库框架中你可以发现很多可用于应用程序开发的同居和类型，在开始设计自己的数据结构前，了解Swift语言本身的语言特性是设计良好数据结构和算法设计的基础。\n在此篇内容中，着重了解 Swift Standard Library 中的两大数据结构：Array &amp; Dictionary。\nArrayArray 是一个通用型的容器组件，用于存储元素的有序集合，在Swift语言中被大量使用。Swift Standard Library中的 Array 可以使用任意的数据类型创建数组。例如使用文字创建数据时，文字使用用逗号分隔，方括号括起来，如下：\nvar people &#x3D; [&quot;Brian&quot;, &quot;Stanley&quot;, &quot;Ringo&quot;]\n\n在Swift中，Array的定义是通过协议定义的，不同的协议层给Array提供了不同的能力。例如，数组是一个**序列(Sequence)，至少可以遍历它一次。它也是一个集合(Collection)，又可以被多次遍历，而且不具有破坏性，并且可以使用下标运算符访问它。数组也是一个随机访问集合(RandomAccessCollection)**，它保证了效率。\n上文提到，Swift中的Array是一个通用型的数据结构，意味着你可以在数据中使用任何数据类型。事实上，在Swift标准库中有大量的通用型代码。\n对于任何数据结构，都会有一些显著性的特征值的关注，对于Array来说，首先需要关注的是 — 顺序。\n顺序（Order）Array中的元素（Element）具有显性的顺序，例如上述people数组，”Brian” 会出现在 “Stanley” 的前面。\n数据中的所有元素都有一个明确的基于0开始的整数类型下标。例如上述例子中，数组中包含了三个元素，每一个下标将对应唯一的一个元素，可以通过下标的方式获取具体的某个元素。例如：\npeople[0] &#x2F;&#x2F; &quot;Brian&quot;\npeople[1] &#x2F;&#x2F; &quot;Stanley&quot;\npeople[2] &#x2F;&#x2F; &quot;Ringo&quot;\n\n数据中的元素顺序是显著性的，该顺序也是数组的数据结构所定义的，但是需要注意的是并不是所有的集合类型都有显著性的顺序。例如Dictionary，并没有显著性的顺序，仅有有一个弱化的顺序的概念。\n随机访问权限（Random-access）随机访问权限是数组的数据结构所定义的特性，表示在数组可以在恒定的时间内完成数据元素的检索。例如在上述数组中，”Brian”元素的获取总是在恒定的时间内。同样地，并不是所有的集合类型都是如此，例如链表、树并没有随机访问权限，元素的获取也不会有恒定的时间。\n数组的性能随机访问权限的另一个影响是数组操作的性能。对于一个开发者而言，对于数组的各种操作，了解其在数据量持续增大的情况下性能的变更，是影响程序是否高效的关键因素之一。而对于数组而言，影响其性能的因素主要有两个：\n插入位置（Insertion location）在Swift中，数组的插入操作大多数高效的规则是进行数据元素的追加，也就是在现有数据上使用追加的方式，在数据末尾添加新的元素：\npeople.append(&quot;Charles&quot;)\nprint(people)  &#x2F;&#x2F; [&quot;Brian&quot;, &quot;Stanley&quot;, &quot;Ringo&quot;, &quot;Charles&quot;]\n\n上述示例中使用append方法，在数组的末尾位置插入了新的元素”Charles”，这个操作的耗时是恒定的，也意味着不论原数组中的元素有多少，在该数组的末尾插入新的元素并不会带来额外的时间消耗。但是如果在原数组的除了末尾位置之外的其他既定位置插入元素，例如在数组的中间位置插入新的元素，会带来更多的时间消耗。\n举个例子，人们正在按秩序排队进行结账，此时来了一个新的顾客，在不妨碍其他任何人的情况下，新顾客应该直接在队伍的尾部加入队伍，也不会引起其他人的反感等，而如果该新顾客非要走到队伍中间位置插队，那么该位置后面的每一个人都需要向后挪动，这样至少给原有队伍中一半的人带来的愤怒。\n有一条经验是，如果在开发工作中，你需要在原有的集合类型数据结构中，频繁的在集合的头部或者非末尾位置进行元素的插入，那你可能需要重新设计你的数据结构了。\n数组容量（Capacity）影响数组性能的另一个因素便是数组的容量，这里所说的容量是数组的预制容量。Swift中的数组是根据数组中的元素总量来进行内存空间的预开辟的。如果数组的容量已经达到了预设定的最大值，那么数组必须重构自己来为新的元素增加空间。这一步操作是底层帮你完成的，系统会拷贝所有原有的元素并在内存中新建一个更大容量的数组，这将带来性能和时间的消耗，因为数组中的每一个元素都需要被访问到并进行拷贝。\n也就意味着，数组的插入操作，除了在数组的末尾进行追加式插入新元素外，其他的插入操作都会使得数组进行 n（数组大小） 步才能完整操作。\nDictionaryDictionary 是另一种集合类型的数据结构，存储key-value对数据。例如：\nvar scores: [String: Int] &#x3D; [&quot;Eric&quot;: 9, &quot;Mark&quot;: 12, &quot;Wayne&quot;: 1]\n\n在字典中没有任何既定的顺序，也不能通过索引插入。在Swift中，字典的必备条件是key值必须是Hashable的。幸运的是，在最近几个版本的Swift中，几乎所有的标准类型都遵循Hashable协议，开发者不用自己去实现Hashable了。\n在字典中插入新的数据，一般情况下，通过如下的句法进行：\nscores[&quot;Andrew&quot;] &#x3D; 0\n\n这样底层实现会创建一个新的key-value对，并添加到字典中：\n[&quot;Eric&quot;: 9, &quot;Andrew&quot;: 0, &quot;Mark&quot;: 12, &quot;Wayne&quot;: 1]\n\n可以看到字典是无序的集合类型。对于同一个字典，新数据的插入，会访问到字典中的每一个键值对，其消耗的时间是相同的，直到集合被改变。对于字典而言，并不需要关心数据插入和获取的时间消耗问题，每次操作都是字典中数据量的总访问时间。但是相对于数组来说，字典的数据获取会更高效。\n关键点总结\n每一种数据结构都有其优点和缺点，了解数据结构的优缺点，能够为高效的软件性能提供帮助；\n数组是有序的集合。数组的插入操作会影响数组的操作耗时，末尾追加除外。如果在软件开发中，需要在数组的非末尾位置频繁的进行插入，可能需要重新设计数据结构，例如链表等；\n字典是无序的集合。字典为了快速插入和搜索而牺牲了保持元素顺序的能力。\n\n","slug":"2019-12-01-Data-Structures-&-Algorithms-in-Swift-02","date":"2023-05-13T11:29:06.791Z","categories_index":"Data Structures & Algorithms in Swift","tags_index":"Swift中的数据结构与算法"},{"id":"9f08952be24e03501c17b0dc2ee6bf37","title":"2022-07-17  重构那些事","content":"WHAT：什么是重构？\n\n\n\n\n\n\n\n\nMartin Fowler：重构是一种对软件内部结构的改善，目的是在不改变软件的可见行为的情况下，使其更易理解，修改成本更低。\n\n大型重构\n对象：对系统、模块、代码结构、类与类之间的关系等的重构\n方法：有分层垂直拆分、模块化水平拆分、解耦、抽象UI组件、抽象业务组件、抽象区块\n方法论：编程范式、设计原则、设计模式\n影响：代码改动多，影响面广，难度较大，耗时较长，引入BUG风险高\n\n\n小型重构\n对象：对类、函数、变量等代码级别的重构\n方法：规范命名(见名知意)、规范注释、函数拆分、提取重复代码、eslint等\n方法论：统一代码风格、制定规范、语义化编程、eslint\n影响：影响面小，难度小，次数频繁，引入BUG风险低\n\n\n\nWHY：为什么要重构？\n软件最初设计的时候没有考虑到全部的功能和细节\n软件需求变更和持续迭代导致原先的设计已不适用\n消除破窗效应，当代码里面有了坏味道而不及时改善，容易破罐子破摔加速恶化\n\nHOW：如何重构代码？\n灵活运用编程范式思想\n面向对象\n面向过程\n函数式编程\n\n\n以设计原则为核心\nSOLID\nKISS\nDRY\nYAGNI\nLOD\nCRP\n\n\n以eslint为基础手段\nairbnb\nstandard\nrecommanded\nprettier\n自定义\n\n\n以渐进式持续重构代码为方法论\n优点：持续集成、进度可控、过程可逆、不影响正常业务开发进度\n按金字塔原则对项目代码进行拆分\n业务模块水平拆分\n代码分层垂直拆分\n\n\n评估出每一个重构单元的耗时\n合理评估工作量\n权衡重构的性价比\n增加重构的可控性\n\n\n正在做或规划中的业务单元顺手完成重构，其他部分安排空闲时间依次重构\n注意\n从0-&gt;1一次性完成重构的理想场景只存在于理想中。如果真实存在，只能说明项目过小或者已经趋于稳定迭代很少，这种情况要考虑是否真的有重构的必要！！！\n不要有了锤子(重构方法论)，就满世界去找钉子\n重构不是软件开发的必要流程，而是现有代码的组织缺陷或不合理的补救方式。\n养成好的代码风格和code review的习惯避免代码的坏味道才是根本\n\n\n\nWHEN：什么时候重构？\n不要等到积重难返有了瓶颈之后再进行重构，大规模高层次的重构耗时耗力难度剧大\n应该建立起渐进式持续重构的意识，发现当前业务代码写的有问题就应该及时进行小规模的重构，而不是欠一屁股技术债\n\nBUG：重构会不会引入新的BUG？会，所以怎么办呢？\n\n通过完整的单元测试保证重构前后的外部可见性一致\n有条件的话找专业的测试进行端到端测试和灰度测试\n\nRISK：重构上线带来BUG的风险怎么解决？如果不通知业务方直接将重构的代码上线，一旦出现问题，你肯定全责并且重构没有功劳也没有苦劳了\n\n有条件的话找专业的测试进行端到端测试和灰度测试\n必须通知业务方并说服业务方同意，让业务方做好准备上线后检查一下。如果真的引入了bug也不太会追责，因为在预期内并且我们的目标也是为了项目的长远发展呀\n\nFEASIBILITY：如何让业务方意识到现阶段重构是必要的并同意？\n让业务方、产品、测试看到开发中的痛点和技术上的瓶颈\n让所有人意识到缝缝补补破窗效应导致问题加剧，已经积重难返了\n强调重构带来的技术收益和业务收益\n提供切实可行并可控的重构计划方案\n\nPERFORMANCE：重构价值不被认可怎么办？\n明明是你代码写的烂才导致的重构，浪费时间，还有脸要绩效？想屁吃呢\n承认自己会写bug，表明没有不写bug的程序员（勇于担当并弱化责任，表明owner身份和地盘）\n指出导致重构的其他原因：需求频繁变更，紧急需求倒排工时，没有将业务长期规划方向信息同步给开发，多人协作团队没有统一风格，团队没有code review，没有eslint规范等等（表明主要责任不在我，但是我意识到了问题并主动解决了）\n强调重构带来的优点：BUG数量减少，维护成本下降，BUG排查变快，开发速度增高等（业务价值才是绩效的根本）\n\n\n\n","slug":"2022-07-17-log","date":"2022-07-17T20:30:38.000Z","categories_index":"Logs","tags_index":"","author_index":"Yak-0xff"},{"id":"e0ae854e6f0229d985990b4529079d67","title":"2022-07-04  关于死锁的简单记录","content":"\n死锁 指的是在多线程环境中，两个以上的线程在执行过程中，因争夺资源而造成一种相互等待的现象，如果无外力作用下，它们都将无法推进下去。\n\n举个简单例子：\n如下图所示，线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。\n\n\n死锁的条件：\n\n互斥条件：线程对资源的访问是排他性的，如果一个线程占用了某个资源，那么其他线程等待，直到锁被释放。\n\n不可剥夺条件：线程在已经获得资源的情况下，未使用完之前，不能被其他线程剥夺，只能在使用完之后自己释放。\n\n**保持和请求条件： **线程T1至少已经保持了一个资源R1的占用，同时又提出对另一个资源R2的请求，但是R2 又被其他线程T2占用，所以线程T1必须等待，但又对自己保持对R1 不释放，而T2又必须要得到R1的资源才能继续执行。\n\n环路等待条件：在死锁发生时，必然存在一个“线程-资源环形链”，即：{p0,p1,p2,…pn},进程p0（或线程）等待p1占用的资源，p1等待p2占用的资源，pn等待p0占用的资源。\n\n避免线程死锁：\n\n\n避免死锁的方案可以从造成死锁的四个条件入手，破坏导致死锁必要条件中的任意一个就可以预防死锁：\n\n破坏互斥条件：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的(临界资源需要互斥访问)。\n破坏请求与保持条件：不再分批申请资源，一次性申请所有的资源。\n破坏不剥夺条件：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。\n破坏循环等待条件：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。对于前面的例子如果线程1，线程2都是先申请资源1，再申请资源2就不会导致死锁了。\n\n死锁的例子：\nNSObject *resource1 &#x3D; [NSObject new];\nNSObject *resource2 &#x3D; [NSObject new];\n\ndispatch_queue_t queue1 &#x3D; dispatch_queue_create(&quot;thread1&quot;, DISPATCH_QUEUE_CONCURRENT);\ndispatch_queue_t queue2 &#x3D; dispatch_queue_create(&quot;thread2&quot;, DISPATCH_QUEUE_CONCURRENT);\n\ndispatch_async(queue1, ^&#123;\n    @synchronized (resource1) &#123;\n        IDLLogInfo(@&quot;queue1获取到资源1&quot;);\n        sleep(10);\n        IDLLogInfo(@&quot;queue1尝试获取资源2&quot;);\n        @synchronized (resource2) &#123;\n             IDLLogInfo(@&quot;queue1获取到资源2&quot;);\n         &#125;\n    &#125;\n&#125;);\n    \ndispatch_async(queue2, ^&#123;\n  @synchronized (resource2) &#123;\n      IDLLogInfo(@&quot;queue2获取到资源2&quot;);\n      sleep(20);\n       IDLLogInfo(@&quot;queue2尝试获取资源1&quot;);\n       @synchronized (resource1) &#123;\n            IDLLogInfo(@&quot;queue2获取到资源1&quot;);\n       &#125;\n   &#125;\n&#125;);\n\n","slug":"2022-07-04-log","date":"2022-07-04T14:21:38.000Z","categories_index":"Logs","tags_index":"","author_index":"Yak-0xff"},{"id":"151a15539ff01fdc8f45662f9abcfbf2","title":"2022-04-30","content":"\n4月份最后一天了，下定决定要重启这个小博客网站了。来来回回很多次无暇顾及，也可能是自己太懒了吧，总之，庆祝重启了。👏\n五一放假之前，想法很多，但是真正放假后，却觉得还是不要到处跑动了，世事难料，人生无常，此时利用闲暇时间做点一直没有时间去做的事情，也不乏是个美好的假期。\n","slug":"2022-04-30-log-md","date":"2022-04-30T20:55:38.000Z","categories_index":"Logs","tags_index":"","author_index":"Yak-0xff"}]